<!doctype html><html lang=zh><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Spark Basic - 香取海</title>
<meta property="og:title" content="Spark Basic - 香取海"><meta name=twitter:card content="summary"><meta property="description" content="大数据计算和普通的程序并无本质区别：数据输入=&amp;gt;计算=&amp;gt;输出和结果的持久化。这里的挑战在于计算的效率和容错性。由于数据输入巨大，计算的效率是基本的要求。为了在通用硬件上高效完成大量计算，唯一的途径就是将计算任务拆分分布式计算。这就引出了新的问题：分布式计算资源的管理（Mesos,YARN）,分布式计算失败后的恢复（容错性）（Spark RDD）,以及分布式的数据输入和保存（ &amp;hellip;"><meta property="og:description" content="大数据计算和普通的程序并无本质区别：数据输入=&amp;gt;计算=&amp;gt;输出和结果的持久化。这里的挑战在于计算的效率和容错性。由于数据输入巨大，计算的效率是基本的要求。为了在通用硬件上高效完成大量计算，唯一的途径就是将计算任务拆分分布式计算。这就引出了新的问题：分布式计算资源的管理（Mesos,YARN）,分布式计算失败后的恢复（容错性）（Spark RDD）,以及分布式的数据输入和保存（ &amp;hellip;"><meta name=twitter:image content="https://jsd.cdn.zzko.cn/gh/zhimoe/zhimoe.pic@main/pic/File-ingestion-into-a-multinode-cluster.78cwj4jjnjg0.webp"><link rel=stylesheet href=../../css/style.css><link rel=stylesheet href=../../css/fonts.css><link rel=stylesheet href=../../css/custom.css><link rel=icon type=image/png href=../../img/logo.png><link rel=apple-touch-icon href=../../img/logo.png><link rel=apple-touch-icon-precomposed href=../../img/logo.png></head><body class="single post"><div class=crop-h></div><div class=crop-v></div><div class=crop-c></div><nav class="nav-top small"><div class=logo><a href=../../>香取海</a></div><div class=menu><span class=active><a href=../../post/>博客</a></span>
<span><a href=../../categories/%E7%BC%96%E7%A8%8B/>编程</a></span>
<span><a href=../../categories/%E7%BF%BB%E8%AF%91/>翻译</a></span>
<span><a href=../../categories/%E9%9A%8F%E6%83%B3/>随想</a></span>
<span><a href=../../search/>搜索</a></span></div></nav><div class=article-meta><h1 class=title>Spark Basic</h1><h3 class=meta-line><span><span class=date>2018-03-31</span>
</span><span class=term><a href=../../categories/%E7%BC%96%E7%A8%8B/ class=term-cat>编程</a>
<a href=../../tags/code/ class=term-tag>#code </a><a href=../../tags/spark/ class=term-tag>#spark</a></span></h3></div><div class=main><nav id=TableOfContents><ul><li><a href=#引言>引言</a></li><li><a href=#hdfs>HDFS</a></li><li><a href=#yarn>YARN</a></li><li><a href=#spark-基本概念>Spark 基本概念</a></li><li><a href=#rdd>RDD</a></li><li><a href=#sparkstreaming>SparkStreaming</a></li><li><a href=#sparkstreamingkafka>SparkStreaming+Kafka</a></li><li><a href=#常见错误>常见错误</a><ul><li><a href=#数据库-mysql-redis-连接的可序列化问题>数据库 (mysql redis) 连接的可序列化问题</a></li></ul></li><li><a href=#最佳实践>最佳实践</a></li></ul></nav><h2 id=引言>引言</h2><p>大数据计算和普通的程序并无本质区别：数据输入=>计算=>输出和结果的持久化。这里的挑战在于计算的效率和容错性。由于数据输入巨大，计算的效率是基本的要求。为了在通用硬件上高效完成大量计算，唯一的途径就是将计算任务拆分分布式计算。这就引出了新的问题：分布式计算资源的管理（Mesos,YARN）,分布式计算失败后的恢复（容错性）（Spark RDD）,以及分布式的数据输入和保存（分布式文件 HDFS）.hadoop 生态圈就是为了解决几个问题设计的 (YARN,MapR,HDFS).只不过在计算这一环节 Spark 做的更加高效取代了 MapR.所以先看下 hadoop 的核心两个组件。</p><h2 id=hdfs>HDFS</h2><ul><li>HDFS 是 hadoop 的虚拟分布式文件系统。满足大数据问题下要求的：可扩展的，容错的，硬件通用的和高并发的特性.HDFS 最重要的特性是不可变性&ndash;数据提交到 HDFS 后即不可更新了，也就是所谓的 WORM(write once read many).</li><li>文件在 HDFS 中是以 block 构成，默认一个 block 是 128M.block 是是分布式的，即如果集群中如果有多于 1 个节点，那么有文件可能会被分布在多个节点上.block 是被复制的，这主要是两个目的：1.容错，2.增加数据局部性的概率，有利于访问.block 复制在数据节点接收（ingest：消化）block 时同时发生。如图所示：</li></ul><p><img src=https://jsd.cdn.zzko.cn/gh/zhimoe/zhimoe.pic@main/pic/File-ingestion-into-a-multinode-cluster.78cwj4jjnjg0.webp alt="File ingestion into a multi-node cluster"></p><ul><li>NameNode：不知道怎么翻译，NameNode 主要负责管理 HDFS 的元数据，包括 directory，文件对象和相关属性（e.g. ACL),元数据是常驻内存中的，硬盘上也有备份以及日志保证持久性和崩溃后的一致性（和数据库相似）.还包括 block 的位置信息&ndash;block 之间的关系。注意，数据（文件）并不经过 NameNode，否则很容易成为性能瓶颈，数据是直接到达 DataNode，并上报给 NameNode 管理。</li><li>数据节点（DataNode）负责：block 复制；管理本节点的存储；向 NameNode 上报 block 信息。注意，数据节点不会意识到 HDFS 的目录（directory）和文件（Files）的概念，这些信息是 NameNode 管理保存的，客户端只会和 NameNode 交道。</li><li>hdfs 客户端分为：fs shell;hdfs java api;rest proxy 接口（HttpFS 等）.</li><li>常见命令：</li></ul><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#177500># 上传一个文件 -f表示覆盖</span>
</span></span><span style=display:flex><span>hadoop fs -put -f jour.txt /user/dahu/jour/
</span></span><span style=display:flex><span><span style=color:#177500># 下载</span>
</span></span><span style=display:flex><span>hadoop fs -get /user/dahu/jour/jour.txt
</span></span><span style=display:flex><span><span style=color:#177500># ls</span>
</span></span><span style=display:flex><span>hadoop fs -ls /user/dahu/
</span></span><span style=display:flex><span><span style=color:#177500># 删除 -r表示递归,删除目录</span>
</span></span><span style=display:flex><span>hadoop fs -rm /user/dahu/jour/jour.txt
</span></span><span style=display:flex><span>hadoop fs -rm -r /user/dahu/jour
</span></span></code></pre></div><h2 id=yarn>YARN</h2><ul><li>YARN:Yet Another Resource Negotiator 是 hadoop 的资源管理器.YARN 有个守护进程&ndash;ResourceManager，负责全局的资源管理和任务调度，把整个集群当作计算资源池，只关注分配，不管应用，且不负责容错.YARN 将 application（或者叫 job）分发给各个 NodeManager,NodeManager 是实际的 worker 或者 worker 的代理.ResourceManager 主要有两个组件：Scheduler 和 ApplicationsManager. 下图是 YARN 的结构示意图：</li></ul><p><img src=https://jsd.cdn.zzko.cn/gh/zhimoe/zhimoe.pic@main/pic/yarn_architecture.3l75sdsbjm00.gif alt=yarn_architecture></p><ul><li><p>上图中 ResourceManager 负责管理和分配全局的计算资源。而 NodeManager 看着更复杂一些：1.用户提交一个 app 给 RM（ResourceManager）；2.RM 在资源充足的 NodeManager 上启动一个 ApplicationMaster（也就是这个 app 对应的第一个 container）.3.ApplicationMaster 负责在所有 NodeManagers 中协调创建几个 task container，也包括 ApplicationMaster 自己所在的 NodeManager（上图中紫色 2 个和红色的 4 个分别表示 2 个 app 的 task container 和 ApplicationMaster）.4. NodeManager 向各个 ApplicationMaster 汇报 task container 的进展和状态.5. ApplicationMaster 向 RM 汇报应用的进展和状态.6.RM 向用户返回 app 的进度，状态，结果。用户一般可通过 Web UI 查看这些。</p></li><li><p>上面的示意图是 YARN 的核心概念，Spark 程序的运行结构示意图和上面的示意图相同。每个组件都可以近似一样的理解，例如，上面的 Client 在 Spark 中叫 Driver 程序;ResourceManager 在 Spark 中叫 Cluster Manager（为了理解方便，认为一样即可，Spark 的 ClusterManager 目前主要有 YARN,Mesos 和 Spark 自带的三种）；NodeManager 就是 Spark 中的 Worker Node.</p></li></ul><h2 id=spark-基本概念>Spark 基本概念</h2><ul><li>上图中的 client 程序在 Spark 中即 Driver 程序.Driver 就是我们编写 Spark 程序 app 的主要部分，包括<code>SparkContext</code>的创建和关闭以及计算任务（Task）的计划（Planning，包括数据数据，转换，输出，持久化等).<code>SparkContext</code>负责和 Cluster Manager 通信，进行资源申请，任务的分配和监控。一般认为<code>SparkContext</code>代表 Driver.</li><li>ClusterManager：就是上面说的三种-Standalone,YARN,Mesos.</li><li>WorkerNode: 集群中运行 app 代码的节点，也就是上图中 YARN 的 NodeManager 节点。一个节点运行一个/多个 executor.</li><li>Executor：app 运行在 worker 节点的一个进程，进程负责执行 task 的 planning.Spark On YARN 中这个进程叫 CoarseGrainedExecutorBackend.每个进程能并行执行的 task 数量取决于分配给它的 CPU 个数了。下图是一个 Spark 程序集群概览图，和上图很相似。</li></ul><p><img src=https://jsd.cdn.zzko.cn/gh/zhimoe/zhimoe.pic@main/pic/cluster-overview.67t13s367a40.webp alt=cluster-overview></p><ul><li>仔细对比上面两个示意图，在 YARN 的结构示意图中，ResourceManager 为程序在某个 NodeManager 上创建的第一个 container 叫 ApplicationMaster,ApplicationMaster 负责只是其他的 task container.在 Spark On YARN 有两种运行模式：client 和 cluster 模式。在 cluster 模式下，用户编写的 driver 程序运行在 YARN 的 ApplicationMaster 的内部。<br>*RDD:Spark 的核心数据结构。后面详细介绍，可以简单的理解为一个 Spark 程序所有需要处理的数据在 Spark 中被抽象成一个 RDD，数据需要被拆分分发到各个 worker 去计算，所以 RDD 有一个分区（Partation）概念。一般我们的数据是放在分布式文件系统上的 (e.g. HDFS),可以简单理解为一个 RDD 包含一或多个 Partation，每个 Partation 对应的就是 HDFS 的一个 block.当然，Partation 不是和 HDFS 的 block 绑定的，你也可以手动的对数据进行分区，即使他们只是待处理的一个本地文件或者一个小数组。一个 Partation 包含一到多个 Record,Record 可以理解为文本中的一行，excel 的一条记录或者是 kafka 的一条消息。</li><li>Task：RDD 的一个 Patation 对应一个 Task,Task 是单个分区上最小的处理单元。</li></ul><h2 id=rdd>RDD</h2><p>pass</p><h2 id=sparkstreaming>SparkStreaming</h2><p>pass</p><h2 id=sparkstreamingkafka>SparkStreaming+Kafka</h2><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#a90d91>import</span> <span style=color:#000>org.apache.kafka.clients.consumer.ConsumerRecord</span>
</span></span><span style=display:flex><span><span style=color:#a90d91>import</span> <span style=color:#000>org.apache.kafka.common.serialization.StringDeserializer</span>
</span></span><span style=display:flex><span><span style=color:#a90d91>import</span> <span style=color:#000>org.apache.spark.streaming.kafka010._</span>
</span></span><span style=display:flex><span><span style=color:#a90d91>import</span> <span style=color:#000>org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent</span>
</span></span><span style=display:flex><span><span style=color:#a90d91>import</span> <span style=color:#000>org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a90d91>val</span> <span style=color:#000>kafkaParams</span> <span style=color:#a90d91>=</span> <span style=color:#3f6e75>Map</span><span style=color:#000>[</span><span style=color:#a90d91>String</span>, <span style=color:#a90d91>Object</span><span style=color:#000>](</span>
</span></span><span style=display:flex><span>  <span style=color:#c41a16>&#34;bootstrap.servers&#34;</span> <span style=color:#000>-&gt;</span> <span style=color:#c41a16>&#34;localhost:9092,anotherhost:9092&#34;</span><span style=color:#000>,</span>
</span></span><span style=display:flex><span>  <span style=color:#c41a16>&#34;key.deserializer&#34;</span> <span style=color:#000>-&gt;</span> <span style=color:#000>classOf</span><span style=color:#000>[</span><span style=color:#a90d91>StringDeserializer</span><span style=color:#000>],</span>
</span></span><span style=display:flex><span>  <span style=color:#c41a16>&#34;value.deserializer&#34;</span> <span style=color:#000>-&gt;</span> <span style=color:#000>classOf</span><span style=color:#000>[</span><span style=color:#a90d91>StringDeserializer</span><span style=color:#000>],</span>
</span></span><span style=display:flex><span>  <span style=color:#c41a16>&#34;group.id&#34;</span> <span style=color:#000>-&gt;</span> <span style=color:#c41a16>&#34;use_a_separate_group_id_for_each_stream&#34;</span><span style=color:#000>,</span>
</span></span><span style=display:flex><span>  <span style=color:#c41a16>&#34;auto.offset.reset&#34;</span> <span style=color:#000>-&gt;</span> <span style=color:#c41a16>&#34;latest&#34;</span><span style=color:#000>,</span>
</span></span><span style=display:flex><span>  <span style=color:#c41a16>&#34;enable.auto.commit&#34;</span> <span style=color:#000>-&gt;</span> <span style=color:#000>(</span><span style=color:#a90d91>false</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>java.lang.Boolean</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a90d91>val</span> <span style=color:#000>topics</span> <span style=color:#a90d91>=</span> <span style=color:#3f6e75>Array</span><span style=color:#000>(</span><span style=color:#c41a16>&#34;topicA&#34;</span><span style=color:#000>,</span> <span style=color:#c41a16>&#34;topicB&#34;</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span><span style=color:#a90d91>val</span> <span style=color:#000>stream</span> <span style=color:#a90d91>=</span> <span style=color:#3f6e75>KafkaUtils</span><span style=color:#000>.</span><span style=color:#000>createDirectStream</span><span style=color:#000>[</span><span style=color:#a90d91>String</span>, <span style=color:#a90d91>String</span><span style=color:#000>](</span>
</span></span><span style=display:flex><span>  <span style=color:#000>streamingContext</span><span style=color:#000>,</span>
</span></span><span style=display:flex><span>  <span style=color:#3f6e75>PreferConsistent</span><span style=color:#000>,</span>
</span></span><span style=display:flex><span>  <span style=color:#3f6e75>Subscribe</span><span style=color:#000>[</span><span style=color:#a90d91>String</span>, <span style=color:#a90d91>String</span><span style=color:#000>](</span><span style=color:#000>topics</span><span style=color:#000>,</span> <span style=color:#000>kafkaParams</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000>stream</span><span style=color:#000>.</span><span style=color:#000>map</span><span style=color:#000>(</span><span style=color:#000>record</span> <span style=color:#a90d91>=&gt;</span> <span style=color:#000>(</span><span style=color:#000>record</span><span style=color:#000>.</span><span style=color:#000>key</span><span style=color:#000>,</span> <span style=color:#000>record</span><span style=color:#000>.</span><span style=color:#000>value</span><span style=color:#000>))</span>
</span></span></code></pre></div><p>DStream 的 elements:record is ConsumerRecord&lt;K,V>: A key/value pair to be received from Kafka. This consists of a topic name and a partition number, from which the record is being received and an offset that points to the record in a Kafka partition.包含 key(),offset(),partation() 方法等。</p><ul><li>当一个 StreamingContext 中有多个 input stream 时，记得保证给程序分配了足够的资源（特别是 core 的数量，必须大于输入源的数量）.</li><li>本地执行程序时，不要使用“local”or“local[1]”as the master URL,streaming 程序至少需要两个 thread，一个接受数据，一个处理数据。直接使用 local[n],n>输入源个数。</li><li>DStream 和 RDD 一样支持各种 trans 和 action</li><li>DStream is batches of RDDs.</li></ul><h2 id=常见错误>常见错误</h2><h3 id=数据库-mysql-redis-连接的可序列化问题>数据库 (mysql redis) 连接的可序列化问题</h3><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#000>dstream</span><span style=color:#000>.</span><span style=color:#000>foreachRDD</span> <span style=color:#000>{</span> <span style=color:#000>rdd</span> <span style=color:#a90d91>=&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#a90d91>val</span> <span style=color:#000>connection</span> <span style=color:#a90d91>=</span> <span style=color:#000>createNewConnection</span><span style=color:#000>()</span>  <span style=color:#177500>// executed at the driver
</span></span></span><span style=display:flex><span><span style=color:#177500></span>  <span style=color:#000>rdd</span><span style=color:#000>.</span><span style=color:#000>foreach</span> <span style=color:#000>{</span> <span style=color:#000>record</span> <span style=color:#a90d91>=&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#000>connection</span><span style=color:#000>.</span><span style=color:#000>send</span><span style=color:#000>(</span><span style=color:#000>record</span><span style=color:#000>)</span> <span style=color:#177500>// executed at the worker
</span></span></span><span style=display:flex><span><span style=color:#177500></span>  <span style=color:#000>}</span>
</span></span><span style=display:flex><span><span style=color:#000>}</span>
</span></span><span style=display:flex><span><span style=color:#177500>// 上面的写法会导致 connection 不可序列化的错误：Task not serializable
</span></span></span><span style=display:flex><span><span style=color:#177500>// RDD 的函数 (map,foreach) 会被序列化发送到 worker 节点执行，但是 connection 是和 tcp 连接，和机器绑定的，无法序列化
</span></span></span><span style=display:flex><span><span style=color:#177500></span>
</span></span><span style=display:flex><span><span style=color:#000>dstream</span><span style=color:#000>.</span><span style=color:#000>foreachRDD</span> <span style=color:#000>{</span> <span style=color:#000>rdd</span> <span style=color:#a90d91>=&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#000>rdd</span><span style=color:#000>.</span><span style=color:#000>foreach</span> <span style=color:#000>{</span> <span style=color:#000>record</span> <span style=color:#a90d91>=&gt;</span>  <span style=color:#177500>// on worker node
</span></span></span><span style=display:flex><span><span style=color:#177500></span>    <span style=color:#a90d91>val</span> <span style=color:#000>connection</span> <span style=color:#a90d91>=</span> <span style=color:#000>createNewConnection</span><span style=color:#000>()</span> <span style=color:#177500>// 给每个 record 处理时新建一个连接，会导致严重的数据库连接性能问题
</span></span></span><span style=display:flex><span><span style=color:#177500></span>    <span style=color:#000>connection</span><span style=color:#000>.</span><span style=color:#000>send</span><span style=color:#000>(</span><span style=color:#000>record</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>    <span style=color:#000>connection</span><span style=color:#000>.</span><span style=color:#000>close</span><span style=color:#000>()</span>
</span></span><span style=display:flex><span>  <span style=color:#000>}</span>
</span></span><span style=display:flex><span><span style=color:#000>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#177500>// 更好的方式是给每个 partation 新建一个连接
</span></span></span><span style=display:flex><span><span style=color:#177500></span><span style=color:#000>dstream</span><span style=color:#000>.</span><span style=color:#000>foreachRDD</span> <span style=color:#000>{</span> <span style=color:#000>rdd</span> <span style=color:#a90d91>=&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#000>rdd</span><span style=color:#000>.</span><span style=color:#000>foreachPartition</span> <span style=color:#000>{</span> <span style=color:#000>partitionOfRecords</span> <span style=color:#a90d91>=&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#a90d91>val</span> <span style=color:#000>connection</span> <span style=color:#a90d91>=</span> <span style=color:#000>createNewConnection</span><span style=color:#000>()</span> 
</span></span><span style=display:flex><span>    <span style=color:#000>partitionOfRecords</span><span style=color:#000>.</span><span style=color:#000>foreach</span><span style=color:#000>(</span><span style=color:#000>record</span> <span style=color:#a90d91>=&gt;</span> <span style=color:#000>connection</span><span style=color:#000>.</span><span style=color:#000>send</span><span style=color:#000>(</span><span style=color:#000>record</span><span style=color:#000>))</span>
</span></span><span style=display:flex><span>    <span style=color:#000>connection</span><span style=color:#000>.</span><span style=color:#000>close</span><span style=color:#000>()</span>
</span></span><span style=display:flex><span>  <span style=color:#000>}</span>
</span></span><span style=display:flex><span><span style=color:#000>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#177500>// 最好的方法是维护一个静态线程池：
</span></span></span><span style=display:flex><span><span style=color:#177500></span><span style=color:#000>[</span><span style=color:#a90d91>ConnectionPool</span><span style=color:#000>](</span><span style=color:#000>https</span><span style=color:#a90d91>:</span><span style=color:#177500>//github.com/RedisLabs/spark-redis/blob/master/src/main/scala/com/redislabs/provider/redis/ConnectionPool.scala)
</span></span></span><span style=display:flex><span><span style=color:#177500>// then use in partition
</span></span></span><span style=display:flex><span><span style=color:#177500></span><span style=color:#000>dstream</span><span style=color:#000>.</span><span style=color:#000>foreachRDD</span> <span style=color:#000>{</span> <span style=color:#000>rdd</span> <span style=color:#a90d91>=&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#000>rdd</span><span style=color:#000>.</span><span style=color:#000>foreachPartition</span> <span style=color:#000>{</span> <span style=color:#000>partitionOfRecords</span> <span style=color:#a90d91>=&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#177500>// ConnectionPool is a static, lazily initialized pool of connections
</span></span></span><span style=display:flex><span><span style=color:#177500></span>    <span style=color:#a90d91>val</span> <span style=color:#000>connection</span> <span style=color:#a90d91>=</span> <span style=color:#3f6e75>ConnectionPool</span><span style=color:#000>.</span><span style=color:#000>getConnection</span><span style=color:#000>()</span>
</span></span><span style=display:flex><span>    <span style=color:#000>partitionOfRecords</span><span style=color:#000>.</span><span style=color:#000>foreach</span><span style=color:#000>(</span><span style=color:#000>record</span> <span style=color:#a90d91>=&gt;</span> <span style=color:#000>connection</span><span style=color:#000>.</span><span style=color:#000>send</span><span style=color:#000>(</span><span style=color:#000>record</span><span style=color:#000>))</span>
</span></span><span style=display:flex><span>    <span style=color:#3f6e75>ConnectionPool</span><span style=color:#000>.</span><span style=color:#000>returnConnection</span><span style=color:#000>(</span><span style=color:#000>connection</span><span style=color:#000>)</span>  <span style=color:#177500>// return to the pool for future reuse
</span></span></span><span style=display:flex><span><span style=color:#177500></span>  <span style=color:#000>}</span>
</span></span><span style=display:flex><span><span style=color:#000>}</span>
</span></span><span style=display:flex><span><span style=color:#177500>// Note that the connections in the pool should be lazily created on demand and timed out if not used for a while. 
</span></span></span><span style=display:flex><span><span style=color:#177500>// This achieves the most efficient sending of data to external systems.
</span></span></span><span style=display:flex><span><span style=color:#177500></span>
</span></span><span style=display:flex><span><span style=color:#177500>// 示例
</span></span></span><span style=display:flex><span><span style=color:#177500></span><span style=color:#a90d91>case</span> <span style=color:#a90d91>class</span> <span style=color:#3f6e75>RedisCluster</span><span style=color:#000>(</span><span style=color:#000>clusterHosts</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>String</span><span style=color:#000>,</span> <span style=color:#000>password</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>String</span><span style=color:#000>)</span> <span style=color:#a90d91>extends</span> <span style=color:#3f6e75>Serializable</span> <span style=color:#000>{</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#a90d91>def</span> <span style=color:#a90d91>this</span><span style=color:#000>(</span><span style=color:#000>conf</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>SparkConf</span><span style=color:#000>)</span> <span style=color:#000>{</span>
</span></span><span style=display:flex><span>    <span style=color:#a90d91>this</span><span style=color:#000>(</span>
</span></span><span style=display:flex><span>      <span style=color:#000>conf</span><span style=color:#000>.</span><span style=color:#000>get</span><span style=color:#000>(</span><span style=color:#c41a16>&#34;spark.redis.host&#34;</span><span style=color:#000>,</span> <span style=color:#3f6e75>Protocol</span><span style=color:#000>.</span><span style=color:#3f6e75>DEFAULT_HOST</span><span style=color:#000>),</span>
</span></span><span style=display:flex><span>      <span style=color:#000>conf</span><span style=color:#000>.</span><span style=color:#000>get</span><span style=color:#000>(</span><span style=color:#c41a16>&#34;spark.redis.auth&#34;</span><span style=color:#000>,</span> <span style=color:#a90d91>null</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>    <span style=color:#000>)</span>
</span></span><span style=display:flex><span>  <span style=color:#000>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#177500>/**
</span></span></span><span style=display:flex><span><span style=color:#177500>   *
</span></span></span><span style=display:flex><span><span style=color:#177500>   * @return use for JedisCluster or JedisPool
</span></span></span><span style=display:flex><span><span style=color:#177500>   */</span>
</span></span><span style=display:flex><span>  <span style=color:#a90d91>def</span> <span style=color:#000>toSet</span><span style=color:#000>()</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>java.util.Set</span><span style=color:#000>[</span><span style=color:#a90d91>HostAndPort</span><span style=color:#000>]</span> <span style=color:#a90d91>=</span> <span style=color:#000>{</span>
</span></span><span style=display:flex><span>    <span style=color:#a90d91>val</span> <span style=color:#000>nodes</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>mutable.Set</span><span style=color:#000>[</span><span style=color:#a90d91>HostAndPort</span><span style=color:#000>]</span> <span style=color:#a90d91>=</span> <span style=color:#000>mutable</span><span style=color:#000>.</span><span style=color:#3f6e75>Set</span><span style=color:#000>()</span>
</span></span><span style=display:flex><span>    <span style=color:#a90d91>for</span> <span style=color:#000>(</span><span style=color:#000>host_port</span> <span style=color:#a90d91>&lt;-</span> <span style=color:#000>clusterHosts</span><span style=color:#000>.</span><span style=color:#000>split</span><span style=color:#000>(</span><span style=color:#c41a16>&#34;,&#34;</span><span style=color:#000>))</span> <span style=color:#000>{</span>
</span></span><span style=display:flex><span>      <span style=color:#a90d91>val</span> <span style=color:#000>hp</span> <span style=color:#a90d91>=</span> <span style=color:#000>host_port</span>
</span></span><span style=display:flex><span>      <span style=color:#000>print</span><span style=color:#000>(</span><span style=color:#000>hp</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>      <span style=color:#000>nodes</span> <span style=color:#000>+=</span> <span style=color:#3f6e75>HostAndPort</span><span style=color:#000>.</span><span style=color:#000>from</span><span style=color:#000>(</span><span style=color:#000>host_port</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>    <span style=color:#000>}</span>
</span></span><span style=display:flex><span>    <span style=color:#000>nodes</span><span style=color:#000>.</span><span style=color:#000>asJava</span>
</span></span><span style=display:flex><span>  <span style=color:#000>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a90d91>object</span> <span style=color:#3f6e75>RedisClusterUtils</span> <span style=color:#a90d91>extends</span> <span style=color:#3f6e75>Serializable</span> <span style=color:#000>{</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#000>@transient</span> <span style=color:#a90d91>private</span> <span style=color:#a90d91>lazy</span> <span style=color:#a90d91>val</span> <span style=color:#000>pools</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>ConcurrentHashMap</span><span style=color:#000>[</span><span style=color:#a90d91>RedisCluster</span>, <span style=color:#a90d91>JedisCluster</span><span style=color:#000>]</span> <span style=color:#a90d91>=</span>
</span></span><span style=display:flex><span>    <span style=color:#a90d91>new</span> <span style=color:#3f6e75>ConcurrentHashMap</span><span style=color:#000>[</span><span style=color:#a90d91>RedisCluster</span>, <span style=color:#a90d91>JedisCluster</span><span style=color:#000>]()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#177500>/**
</span></span></span><span style=display:flex><span><span style=color:#177500>   * 获取一个 JedisCluster
</span></span></span><span style=display:flex><span><span style=color:#177500>   * @param rc
</span></span></span><span style=display:flex><span><span style=color:#177500>   * @return
</span></span></span><span style=display:flex><span><span style=color:#177500>   */</span>
</span></span><span style=display:flex><span>  <span style=color:#a90d91>def</span> <span style=color:#000>connect</span><span style=color:#000>(</span><span style=color:#000>rc</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>RedisCluster</span><span style=color:#000>)</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>JedisCluster</span> <span style=color:#000>=</span> <span style=color:#000>{</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#000>pools</span><span style=color:#000>.</span><span style=color:#000>getOrElseUpdate</span><span style=color:#000>(</span><span style=color:#000>rc</span><span style=color:#000>,</span> <span style=color:#000>{</span>
</span></span><span style=display:flex><span>      <span style=color:#a90d91>val</span> <span style=color:#000>poolConfig</span> <span style=color:#a90d91>=</span> <span style=color:#a90d91>new</span> <span style=color:#3f6e75>JedisPoolConfig</span><span style=color:#000>();</span>
</span></span><span style=display:flex><span>      <span style=color:#000>poolConfig</span><span style=color:#000>.</span><span style=color:#000>setMaxTotal</span><span style=color:#000>(</span><span style=color:#1c01ce>250</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>      <span style=color:#000>poolConfig</span><span style=color:#000>.</span><span style=color:#000>setMaxIdle</span><span style=color:#000>(</span><span style=color:#1c01ce>32</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>      <span style=color:#000>poolConfig</span><span style=color:#000>.</span><span style=color:#000>setTestOnBorrow</span><span style=color:#000>(</span><span style=color:#a90d91>false</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>      <span style=color:#000>poolConfig</span><span style=color:#000>.</span><span style=color:#000>setTestOnReturn</span><span style=color:#000>(</span><span style=color:#a90d91>false</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>      <span style=color:#000>poolConfig</span><span style=color:#000>.</span><span style=color:#000>setTestWhileIdle</span><span style=color:#000>(</span><span style=color:#a90d91>false</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>      <span style=color:#000>poolConfig</span><span style=color:#000>.</span><span style=color:#000>setNumTestsPerEvictionRun</span><span style=color:#000>(-</span><span style=color:#1c01ce>1</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#a90d91>val</span> <span style=color:#000>jedisCluster</span> <span style=color:#a90d91>=</span> <span style=color:#a90d91>new</span> <span style=color:#3f6e75>JedisCluster</span><span style=color:#000>(</span><span style=color:#000>rc</span><span style=color:#000>.</span><span style=color:#000>toSet</span><span style=color:#000>(),</span>
</span></span><span style=display:flex><span>        <span style=color:#1c01ce>3000</span><span style=color:#000>,</span>
</span></span><span style=display:flex><span>        <span style=color:#1c01ce>3000</span><span style=color:#000>,</span>
</span></span><span style=display:flex><span>        <span style=color:#1c01ce>5</span><span style=color:#000>,</span>
</span></span><span style=display:flex><span>        <span style=color:#000>rc</span><span style=color:#000>.</span><span style=color:#000>password</span><span style=color:#000>,</span>
</span></span><span style=display:flex><span>        <span style=color:#000>poolConfig</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#000>jedisCluster</span>
</span></span><span style=display:flex><span>    <span style=color:#000>})</span>
</span></span><span style=display:flex><span>  <span style=color:#000>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#177500>/**
</span></span></span><span style=display:flex><span><span style=color:#177500>   * 查询币种对应汇率
</span></span></span><span style=display:flex><span><span style=color:#177500>   * @param jedisCluster 目标 redis
</span></span></span><span style=display:flex><span><span style=color:#177500>   * @param ccyCd 币种代码
</span></span></span><span style=display:flex><span><span style=color:#177500>   * @return 折美元汇率
</span></span></span><span style=display:flex><span><span style=color:#177500>   */</span>
</span></span><span style=display:flex><span>  <span style=color:#a90d91>def</span> <span style=color:#000>getCcyRatio</span><span style=color:#000>(</span><span style=color:#000>jedisCluster</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>JedisCluster</span><span style=color:#000>,</span> <span style=color:#000>ccyCd</span><span style=color:#a90d91>:</span><span style=color:#a90d91>String</span><span style=color:#000>)</span><span style=color:#a90d91>:</span> <span style=color:#a90d91>Double</span> <span style=color:#000>={</span>
</span></span><span style=display:flex><span>    <span style=color:#a90d91>val</span> <span style=color:#000>res</span> <span style=color:#a90d91>=</span> <span style=color:#000>jedisCluster</span><span style=color:#000>.</span><span style=color:#000>get</span><span style=color:#000>(</span><span style=color:#c41a16>&#34;CCY:&#34;</span><span style=color:#000>+</span><span style=color:#000>ccyCd</span><span style=color:#000>)</span>
</span></span><span style=display:flex><span>    <span style=color:#000>res</span><span style=color:#000>.</span><span style=color:#000>split</span><span style=color:#000>(</span><span style=color:#c41a16>&#34;:&#34;</span><span style=color:#000>)(</span><span style=color:#1c01ce>2</span><span style=color:#000>).</span><span style=color:#000>toDouble</span>
</span></span><span style=display:flex><span>  <span style=color:#000>}</span>
</span></span><span style=display:flex><span><span style=color:#000>}</span>
</span></span></code></pre></div><p>参考<br><a href=https://spark.apache.org/docs/latest/streaming-programming-guide.html#design-patterns-for-using-foreachrdd>Design Patterns for using foreachRDD</a><br><a href=https://stackoverflow.com/questions/28006517/redis-on-sparktask-not-serializable>Redis on Spark:Task not serializable</a><br><a href=https://stackoverflow.com/questions/55190315/how-to-create-connections-to-a-datasource-in-spark-streaming-for-lookups>How to create connection(s) to a Datasource in Spark Streaming for Lookups</a></p><ul><li>DStream 的 RDD 分区数是由 topic 分区数相同的。</li></ul><h2 id=最佳实践>最佳实践</h2><nav class="post-nav fullwidth"><span>&larr; <a href=../../post/java-concurrency-4-threadpool-hierachy/>Java 并发 4-线程池与执行器</a></span>
<span class=post-nav-next><a href=../../post/java-how-test-void-method-with-parameter/>java 单元测试如何 Mock 有参数的 void 方法</a> &rarr;</span></nav></div><footer class=small><script src=//cdn.jsdelivr.net/npm/@xiee/utils/js/fix-toc.min.js defer></script><script src=//cdn.jsdelivr.net/npm/@xiee/utils/js/center-img.min.js defer></script><script src=//cdn.jsdelivr.net/npm/@xiee/utils/js/alt-title.min.js defer></script><link rel=stylesheet href=//cdn.jsdelivr.net/gh/rstudio/markdown/inst/resources/prism-xcode.css><script src=//cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js defer></script><script src=//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js defer></script><script src=//cdn.jsdelivr.net/npm/@xiee/utils/js/copy-button.min.js defer></script><link rel=stylesheet href=//cdn.jsdelivr.net/npm/@xiee/utils/css/copy-button.min.css><script src=//cdn.jsdelivr.net/npm/@xiee/utils/js/key-buttons.min.js defer></script><link rel=stylesheet href=//cdn.jsdelivr.net/npm/@xiee/utils/css/key-buttons.min.css><script src=//cdn.jsdelivr.net/npm/@xiee/utils/js/heading-anchor.min.js defer></script><script src=//cdn.jsdelivr.net/npm/@xiee/utils/js/external-link.min.js defer></script><script src=//cdn.jsdelivr.net/npm/@xiee/utils/js/fullwidth.min.js defer></script><hr><p class=nav-bottom><span><a href=https://zhi.moe>xdh</a> © 2024</span>
<span class=menu-bottom><a href=../../categories/>分类</a> <a href=../../tags/>标签</a>
<a href=../../post/index.xml type=application/rss+xml title="RSS feed">订阅</a>
<a href=#>回到顶部</a></span></p></footer></body></html>