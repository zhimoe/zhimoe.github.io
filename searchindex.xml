<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>在macOS通过SSH访问Windows的WSL2 Ubuntu</title><url>https://zhimoe.github.io/post/access-into-wsl2-ubuntu-from-macos/</url><categories><category>编程</category></categories><tags><tag>ssh</tag><tag>mac</tag><tag>wsl</tag></tags><content type="html"> 配置Windows和WSL2, 使得能通过其他电脑远程SSH到WSL2 Ubuntu.
背景 之前的电脑配置是LinuxMint台式机 + M1 macbook笔记本. 使用Linux主要原因是命令行和Docker. 最近由于二十大, 工作VPN在macOS不让用, 只能将台式机安装上Win10, 发现docker在WSL2运行非常丝滑, 这样正好可以当作macbook的Docker服务器. 切换到Windows还有一个原因就是, Linux的桌面真的不行, 最近三年各种版本的桌面使用一圈, Budgie,Gnome,Cinnamon,Xfce这些桌面总是偶尔界面失去响应,KDE用的不多, 卡顿没遇到但是启动总是慢半秒. Win10除了没有Bash/Zsh, 中文字体垃圾点, 其他的都完胜Linux.
下面的教程主要参考:Configuring SSH access into WSL 1 and WSL 2
1 Win10 安装 WSL2 Ubuntu 注意, 是安装WSL2. 方法参考这个enable-virtual-machine-feature:
以管理员身份打开 PowerShell（“开始”菜单 >“PowerShell” >单击右键 >“以管理员身份运行”）, 然后输入以下命令:
dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart; 安装 &ldquo;适用于 x64 计算机的 WSL2 Linux 内核更新包&rdquo;; 将WSL设置默认version 2, in PowerShell: wsl --set-default-version 2; 安装Ubuntu, in PowerShell: wsl --install -d Ubuntu-22.04; 更多参考 .
2 配置SSH server（在Ubuntu执行） 进入Ubuntu
#修改软件源 sudo sed -i "s@http://.*archive.ubuntu.com@https://mirrors.tuna.tsinghua.edu.cn@g" /etc/apt/sources.list sudo sed -i "s@http://.*security.ubuntu.com@https://mirrors.tuna.tsinghua.edu.cn@g" /etc/apt/sources.list sudo apt update &amp;&amp; sudo apt upgrade -y 安装配置ssh服务
sudo apt install openssh-server sudo vim /etc/ssh/sshd_config # 修改下面几个配置 # Port 2222 # AddressFamily any # ListenAddress 0.0.0.0 # PasswordAuthentication yes # 如果启动遇到这个错误, 请执行下面命令: sshd: no hostkeys available -- exiting sudo ssh-keygen -A # 启动ssh服务 sudo /usr/sbin/service ssh start 3 Win10防火墙设置 打开控制面板\系统和安全\Windows Defender 防火墙.
最左边有高级设置 右键点击入站规则 新建入站规则 点击端口,特定端口设置2222 然后命名之后一路下一步就行 或者通过shell设置,以管理员身份打开 PowerShell:
New-NetFirewallRule -Name sshd -DisplayName 'sshd for WSL' -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 2222 4 本地验证SSH访问Ubuntu 打开Windows Terminal, 尝试ssh访问Ubuntu
ssh -p 2222 wsluser@localhost 如果连接上说明ssh配置已经完成.
5 Ubuntu ssh服务开机自动启动 WSL2 Ubuntu 的ssh服务不是跟着Win10开机自动启动的. 在Win10的%USERPROFILE%目录下面新建文件sshd.bat
rem sshd.bat @echo off setlocal C:\Windows\System32\bash.exe -c "sudo /usr/sbin/service ssh start" rem C:\Windows\System32\wsl.exe -e "sudo /usr/sbin/service ssh start" endlocal 注意上面 bash.exe -c 和 wsl.exe -e 两个功能是一样的. bash后面不维护了, wsl是官方推荐命令, 但是bash有输出.
接下来把上面的脚本配置成开机自动执行:
按下Win键, 搜索“任务计划程序”, 右边点击“创建任务”, 常规:设置任务名字“Start WSL SSH”, 勾选上“使用最高权限运行”（这是给后面网卡映射命令的权限） 触发器: 新建, 选择“启动时” 操作: 选择上面的sshd.bat脚本文件. 保存, 重启电脑, 打开Terminal, 重新试试ssh -p 2222 wsluser@localhost
5 网卡映射 到目前为止, 在Win10本地已经可以在开机后直接通过SSH访问Ubuntu了, 但是你如果在局域网内的其他电脑访问, 还是连不上的. 这是因为WSL2是个虚拟机.
WSL 2 is a well-hidden virtual machine, but it is still a virtual machine—and the consequences of this design are leaky. The network interface we see within WSL is a virtual interface that does not match the physical interface that Windows manages. Windows does a good job at hiding this fact when operating directly on the local machine (e.g. you can SSH into WSL from localhost and it will work), but attempts to reach WSL from a separate machine will fail.
设置开机自动执行网卡映射命令, 将上面的sshd.bat文件改成如下:
rem sshd.bat @echo off setlocal C:\Windows\System32\bash.exe -c "sudo /usr/sbin/service ssh start" rem C:\Windows\System32\wsl.exe -e "sudo /usr/sbin/service ssh start" C:\Windows\System32\netsh.exe interface portproxy delete v4tov4 listenport=2222 listenaddress=0.0.0.0 protocol=tcp for /f %%i in ('wsl hostname -I') do set IP=%%i C:\Windows\System32\netsh.exe interface portproxy add v4tov4 listenport=2222 listenaddress=0.0.0.0 connectport=2222 connectaddress=%IP% endlocal 保存后启动, 在macbook试试, 成功.</content></entry><entry><title>云原生Java开发框架Quarkus学习笔记</title><url>https://zhimoe.github.io/post/quarkus-notes/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>quarkus</tag></tags><content type="html"> 什么是 MicroProfile MicroProfile是一个微服务的平台定义, 目标是针对微服务架构优化企业Java开发. 由于JavaEE的标准更新越来越慢, 跟不上Web技术与K8S的发展, 于是一组供应商（包括Tomitribe）决定创建MicroProfile, 这是一个优化的微服务架构平台, 在2016年加入Eclipse基金会.
MicroProfile是一组规范, 包含如OpenTracing 、OpenAPI 、RestClient、Config、 FaultTolerance、 CDI等一组标准.当前最新标准是5.0. 各大Java厂商有很多实现, 最有名的就是红帽的Quarkus, 其他实现有Open Liberty和Payara Enterprise.
注意SpringBoot不是MicroProfile规范实现, Boot是独立于MicroProfile和JavaEE规范的, 但是功能上大同小异, Quarkus也提供了Spring注解的支持.
Quarkus Quarkus是一个MicroProfile规范的实现, 专门为云时代打造.有：启动时间短, 内存占用小, 支持native编译（部署在GraalVM), 支持K8S特性(不仅是部署, 还包括自动生成K8S资源文件等)优势. 本质上是精选了一些优质组件, 通过扩展(extensions)模式提供快速业务开发的能力.
创建项目 Quarkus提供了强大Cli、Maven插件、Gradle插件支持. 以下主要使用maven.
mvn io.quarkus.platform:quarkus-maven-plugin:2.10.2.Final:create \ -DprojectGroupId=moe.zhi \ -DprojectArtifactId=quarkus-demo \ -Dextensions="resteasy-reactive-jackson" cd quarkus-demo 打开IDE,可以看到自动包含pom.xml和Dockerfile(分为不同目标部署环境, 每个文件提供了详细使用说明).项目直接运行就是一个hello world api服务. 如果需要增加一个扩展, 通过maven add-extension插件的extensions参数添加, 插件自动会修改pom.xml文件, 添加对应的maven lib.
# add Caffeine cache support mvn quarkus:add-extension -Dextensions="cache" quarkus 目前已经有上百个extension, 可以通过mvn quarkus:list-extensions查看所有.也可以在quarkus doc查看.
注解 Quarkus的注解符合Java CDI规范. DI部分的注解基本可以和Spring的做一一对上.
//Spring -> CDI/MicroProfile @Autowired -> @Inject @Qualifier -> @Named @Value -> @ConfigProperty(ConfigMap用于分组配置key的公共前缀,ConfigProperties已经废弃) @Component -> @Singleton @Configuration -> @ApplicationScoped @Bean -> @Produces 配置 和Spring类似, Quarkus使用一个application.properties文件配置属性.
使用@ConfigProperty读取配置属性.如果属性是list, 使用逗号分隔.
配置文件中都是String和Int, MicroProfile Configuration自带了一系列的转换器：
boolean: true、1、YES、Y、ON为true, 其他为false Byte,Short,Integer,Long,Float,Double,Character,Class(Class.forName)自动转换 目标类型有 public static T of(String) 或者public static T valueOf(String) 方法 目标类型有 public static T parse(CharSequence) 方法 目标类型有 public constructor(String)构造函数 自定义转换器参考org.eclipse.microprofile.config.spi.Converter
配置属性的验证 需要quarkus-hibernate-validator扩展, 然后使用@Max、@Digits、@Email、@NotNull和@NotBlank等校验注解.
自定义校验器需要实现javax.validation.ConstraintValidator接口.
自定义配置源 参考org.eclipse.microprofile.config.spi.ConfigSource
获取环境变量 使用@Inject Config config的getPropertyNames()获得所有属性.
属性来源优先级 Profile Quarkus自带三个profile环境:dev, test, prod.
设置不同的profile属性使用%{profile}.config.key=value.例如
%dev.quarkus.http.port=8181 logging level Quarkus内部使用 JBoss Logging, 如果需要使用Slf4j,添加依赖:
&lt;dependency> &lt;groupId>org.jboss.slf4j&lt;/groupId> &lt;artifactId>slf4j-jboss-logmanager&lt;/artifactId> &lt;/dependency> quarkus.log.level=DEBUG quarkus.log.file.enable=true # 调整package下面的log level, 注意双引号 quarkus.log.category."io.undertow.request.security".level=TRACE 支持集中管理日志, 参考logging-json扩展.
quarkus生命周期事件 注入io.quarkus.runtime.StartupEvent和io.quarkus.runtime.ShutdownEvent事件即可响应.
@ApplicationScoped @Slf4j public class AppEventListener { void onStart(@Observes StartupEvent event) { log.info("#### app started..."); } void onShutdown(@Observes ShutdownEvent event) { log.info("### app shutdown..."); } } 拦截器 首先通过@javax.interceptor.InterceptorBinding创建一个拦截器注解.
@Inherited @InterceptorBinding @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD, ElementType.TYPE}) public @interface Logit { } 然后通过@javax.init.AroundInvoke和@javax.init.AroundConstruct两个具有相应拦截绑定功能的拦截器.
@Logit @Interceptor public class LogitInterceptor { @AroundInvoke public Object invoke(InvocationContext ctx) throws Exception { System.out.println("#### interceptor" + ctx.getMethod().getName()); return ctx.proceed(); } } Restful服务 Quarkus实现了JAX-RS规范, 支持@GET,@POST, @PUT等http动词注解.默认设置下, quarkus使用RESTEasy和Vertx框架, 而不是Servlet规范.如果需要使用Servlet, 则增加quarkus-undertow扩展, 这是JBOSS（wildfly)的Servlet服务器的引擎.
通过@Path注解匹配URI.
通过@Context UriInfo uriInfo获取url内容.
通过@QueryParam("p")参数注解获取QueryString中的参数.
其他参数：表单参数 (@FormParam)、矩阵参数(@MatrixParam)或cookie值 (@CookieParam).
此外, 使用@Context注解, 你还可以注入其他与 JAX-RS相关的元素, 如javax.ws.rs.core.SecurityContext、
javax.ws.rs.sse.SseEventSink或javax.ws.rs.sse.Sse.
json-p(processing)和json-b(binding)是JavaEE规范.如果API需要返回json,需要增加quarkus-testeasy-jsonb扩展.
如果data model的字段与json字段不同名, 需要使用javax.json.bind.annotation.JsonbProperty注解绑定.
class Stu { @Jsonbproperty("first-name") String firstNm; } 如果使用jackson, 则需要quarkus-resteasy-jackon扩展, 使用com.fasterxml.jackson.databind.ObjectMapper做json转换.
Rest客户端 使用rest客户端调用外部服务接口, 需要增加"rest-client"和"resteasy-jsonb"扩展.
private Client rest=ClientBuilder.newClient(); public String getTime(){ Response resp=rest.target("http://worldclockapi.com") .path("/api/json/{timezone}/now") .resolveTemplate("timezone","GMT") .request(MediaType.APPLICATION_JSON) .get(Response.class); return resp.readEntity(String.class); } 持久化 Agroal是Quarkus中首选的数据源和连接池实现,与安全、事务管 理和健康指标进行了集成. 虽然它是一个扩展程序,但如果你正在使 用Hibernate ORM或Panache,Agroal扩展会被顺带加载进来. 之后你 还需要一个数据库驱动扩展,目前,H2、PostgreSQL、MariaDB、 MySQL、Microsoft SQL Server和Derby都有支持的扩展,可以通过 Maven add-extension添加正确的数据库驱动扩展
如果你想要使用响应式编程, 也可以使用Vert.x reactive drivers.
# 配置多个数据源的话在 quarkus.datasource后面跟着一个自定义的ds name即可.例如 # configure your datasource quarkus.datasource.url = jdbc:postgresql://localhost:5432/library-database quarkus.datasource.driver = org.postgresql.Driver quarkus.datasource.username = melvil quarkus.datasource.password = dewey # 配置第二个数据源 指定ds name 为 orders quarkus.datasource.orders.url = jdbc:postgresql://localhost:5432/library-database quarkus.datasource.orders.driver = org.postgresql.Driver quarkus.datasource.orders.username = melvil quarkus.datasource.orders.password = dewey 非默认数据源需要使用@DataSource(&ldquo;ds name&rdquo;)指定:
import javax.inject.Inject; @Inject DataSource("orders") AgroalDatasource ordersDs; 容错 需要添加quarkus-smallrye-fault-tolerance扩展.
回退与重试：@org.eclipse.microprofile.faulttolerance.Retry, @org.eclipse.microprofile.faulttolerance.Fallback. Fallback的handler需要实现org.eclipse.micropro file.faulttolerance.FallbackHandler接口
超时： @org.eclipse.microprofile.faultttoler ance.Timeout.
过载保护(并发请求个数)： @org.eclipse.microprofile.faultttolerance.Bulkhead.
压测 >siege -r 1 -c 4 -v http:localhost:8080/hello/bulkhead
断路器： @CircuitBreaker
@CircuitBreaker(requestVolumeThreshold = 4, // &lt;1> 滚动窗口 failureRatio = 0.75, // &lt;2>断路阈值 delay = 2000) // &lt;3> 重新打开时长ms 如果使用@Fallback, 且CircuitBreakerOpenException被抛出, 回 退逻辑将被执行. 如果使用@Retry, 每次重试都由断路器处理, 并记录成功或失 败. 如果使用@Bulkhead, 则在试图进入bulkhead之前检查断路器. 可观察 health health： 添加了quarkus-smallrye-health自动注册 q/health/live和q/health/ready两个探针 自定义：实现一个 org.eclipse.microprofile.health.HealthCheck接口, 并加上@org.eclipse.microprofile.health.Liveness
或@org.eclipse.microprofile.health.Readiness注解 指标 添加quarkus-smallrye-metrics扩展, 自动暴露q/metrics端点. 自定义指标： @Counted @Gauge @Metered @Timed OpenTelemetry Quarkus Opentelemetry configuration
Reactive编程 Quarkus支持两种响应式编程方式：
Reactive Programming with Mutiny Coroutines with Kotlin Quarkus支持混合命令式与响应式编程, 所以不需要刻意将所有代码改造成响应式就可以享受到高性能.更多见：
unification-of-imperative-and-reactive
class loading in quarkus production模式和native image模式下, quarkus的类加载器都是 system ClassLoader(native模式不支持多ClassLoaders)
所有quarkus app都是通过QuarkusBootstrap class创建.这个类解析app所有的相关依赖(编译或运行时的依赖),最终得到一个CuratedApplication class, 这个类包含这个app所有的类加载信息.
CuratedApplication 可以用于创建一个AugmentAction 实例, 这个实例用于创建app并启动/重启.
在dev模式下, quarkus通过classloader支持热加载, 在prod模式下, 只有 system ClassLoader.
除了热加载, 在dev模式下, 提供了q/dev DEV UI,支持配置应用, 查看缓存, 查看类信息, 查看/执行定时任务, 查看健康状态, 执行数据脚本迁移等等.</content></entry><entry><title>Git 的detatched Head模式和解决问题方法</title><url>https://zhimoe.github.io/post/git-detatched-head/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>git</tag></tags><content type="html"> 有时候commit完代码后git push会遇到下面的错误
To push the history leading to the current (detached HEAD) 错误提示说当前HEAD没有指向任何分支，但是你记得明明有指向一个分支的
复现问题 1、假设你当前在master分支，且有两次提交
Prj on  master ❯ git log --oneline --graph --decorate * 314c9df (HEAD -> master) 2nd commit * ae15845 initial commit 2、切回到ec6a47e这次提交
Prj on  master ❯ git checkout ae15845 Note: switching to 'ae15845'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -c with the switch command. Example: git switch -c &lt;new-branch-name> Or undo this operation with: git switch - Turn off this advice by setting config variable advice.detachedHead to false HEAD is now at ae15845 initial commit git直接会提示你当前HEAD已经detached。这是因为当HEAD离开当前分支（master）的末端commit时，Git会默认你想要离开当前分支，但是Git不会自动创建一个新分支（因为没有提供分支名称）。
所以HEAD变成没有指向任何分支的窘境，即使你再次回到刚才那个分支的末端commit，还是处于detached状态。
3、切回master分支的末端commit并提交新内容
Prj (ae15845) # 注意 zsh配置这里展示的是当前HEAD，下面也给了提示 ❯ git checkout 314c9df Previous HEAD position was ae15845 initial commit HEAD is now at 314c9df 2nd commit # 提交点新东西 Prj (314c9df) ❯ echo "3nd file " > 3.txt Prj (314c9df) [?] ❯ git add . &amp;&amp; git commit -m "3nd commit" [detached HEAD 09fb4a5] 3nd commit 1 file changed, 1 insertion(+) create mode 100644 3.txt Prj (09fb4a5) ❯ git log --oneline --graph --decorate * 09fb4a5 (HEAD) 3nd commit * 314c9df (master) 2nd commit * ae15845 initial commit 可以看到此时HEAD和master分支还是分离的。
真实场景复现 上面复现的方式很刻意，毕竟极少情况你会checkout一个具体的commit而不手动创建一个分支。日常工作中最可能遇到这个detached HEAD的场景是你使用Git submodule的时候。
敢说每个新手在使用submodule都会碰到detached HEAD问题。
原因是你的submodule没有记录正确的分支，即你在使用git submodule add时没有指定-b &lt;branch>参数。
git submodule add -b main https://github.com/zhimoe/hugo-theme-next.git themes/next 或者直接在项目根目录下的.gitmodules文件中加上一行
branch = main # or branch = master 解决方法 1、预防的方法就是没有commit的时候及时切回一个具体分支git checkout master
2.1、 如果已经提交了的话，给当前游离的commit创建一个分支，切换到该分支
Prj (09fb4a5) ❯ git branch oops 09fb4a5 Prj (09fb4a5) ❯ git log --oneline --graph --decorate * 09fb4a5 (HEAD, oops) 3nd commit * 314c9df (master) 2nd commit * ae15845 initial commit Prj (09fb4a5) ❯ git checkout oops Switched to branch 'oops' 2.2、 接着使用rebase将oops分支接在master分支的末尾commit之后
Prj on  oops ❯ git rebase master Current branch oops is up to date. Prj on  oops ❯ git log --oneline --graph --decorate * 09fb4a5 (HEAD -> oops) 3nd commit * 314c9df (master) 2nd commit * ae15845 initial commit Prj on  oops ❯ git checkout master &amp;&amp; git merge oops Switched to branch 'master' Updating 314c9df..09fb4a5 Fast-forward 3.txt | 1 + 1 file changed, 1 insertion(+) create mode 100644 3.txt Prj on  master ❯ git log --oneline --graph --decorate * 09fb4a5 (HEAD -> master, oops) 3nd commit * 314c9df 2nd commit * ae15845 initial commit 最后删除oops分支：git branch -d oops.
参考一个完美的GitFlow模型</content></entry><entry><title>Scala3 缩进语法总结表</title><url>https://zhimoe.github.io/post/scala3-indent-syntax/</url><categories><category>编程</category></categories><tags><tag>scala3</tag><tag>cheatsheet</tag></tags><content type="html"> Scala 3 在语法上面新增了一种Python的缩进格式,两种格式都可以使用. 但是目前部分情况还是需要使用括号.
个人对新语法是支持的. 缩进可以极大地提供代码的可读性和整洁, 最大的体会就是SparkStreaming的rdd处理代码,新手容易写出十几个}括号嵌套代码.
当然缺点是缩进不利于代码复制和格式化.
下面是书本上关于Scala3的语法对比. 注意,两个语法格式都是支持的. for和if去掉小括号真的是太棒了.</content></entry><entry><title>使用speed-measure-webpack-plugin和Happypack优化webpack打包速度</title><url>https://zhimoe.github.io/post/speed-up-angular-build-use-happypack/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>JS</tag><tag>webpack</tag></tags><content type="html"> 问题 一个ionic app本地编译需要8分钟,提交到流水线编译耗时需要近40分钟,从日志看到webpack打包步骤耗时最严重.
排查与解决 初步判断是流水线使用的容器CPU性能较弱或者存储mount性能导致的.找流水线同事支持配置了一个纯内存编译流水线,发现还是很慢. 接下来使用webpack的插件speed-measure-webpack-plugin监控性能.
在webpack.config.js配置：
// webpack.config.js // npm i --save-dev speed-measure-webpack-plugin const SpeedMeasurePlugin = require("speed-measure-webpack-plugin"); const smp = new SpeedMeasurePlugin(); // ...the webpack configuration const prodConfig = {/*...*/} module.exports = { prod: smp.wrap(prodConfig) }; 得到下图左侧的结果,可以看到主要耗时都在angular的PurifyPlugin上.搜索了一番后找到HappPack这个多核执行的插件.
配置happypack,由于主要耗时都在const PurifyPlugin = require('@angular-devkit/build-optimizer').PurifyPlugin;插件上,这里只需要针对这一个插件配置happypack即可.
// webpack.config.js // const HappyPack = require('happypack'); const os = require('os');//获取cpu core数量 //loaders配置 { test: /\.ts$/, use: [ { loader: 'happypack/loader?id=ts', // 在所有loader之前加上happypack/loader,id是plugins中定义的 }, { loader: process.env.IONIC_CACHE_LOADER }, { loader: '@angular-devkit/build-optimizer/webpack-loader', options: { sourceMap: true } }, { loader: process.env.IONIC_WEBPACK_LOADER } ] } // 在plugins中配置happypack插件 plugins: [ ionicWebpackFactory.getIonicEnvironmentPlugin(), ionicWebpackFactory.getCommonChunksPlugin(), new ModuleConcatPlugin(), new PurifyPlugin(), new HappyPack({ id: 'js', threads: os.cpus().length, loaders: ['@angular-devkit/build-optimizer/webpack-loader'] }), new HappyPack({ id: 'ts', // 在loader中使用 threads: os.cpus().length, // 开启操作系统cpu的最大核心数 loaders: ['@angular-devkit/build-optimizer/webpack-loader'] }) ] 再次本地执行,性能提升巨大.在流水线上测试,两次build都在15分钟左右.</content></entry><entry><title>在githook中调用nodejs脚本</title><url>https://zhimoe.github.io/post/nodejs-as-githook/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>nodejs</tag></tags><content type="html"> 如何在git hook中调用nodejs脚本.主要踩坑在于不知道如何在bash中获取node脚本返回值,搜了好大一圈.
背景 微服务模式开发中,每个小组维护自己的应用,通过一个nginx入口反向代理所有的子应用,向用户开放一个站点.nginx应用中需要维护各个子应用的代理,即ng.conf中的location.
此外,一个应用需要配置DEV,ST,UAT,PRD四个环境的location.目前的做法是www/ngconf/目录下面分为dev、st、uat、prd四个文件夹,在文件夹内部每个小组各自维护一个conf文件.
每增加一个应用,需要在四个文件夹中自己小组的配置文件添加配置.随着应用越来越多,以及人员流动,会发生不同文件配置相同的location entry.
例如A应用上线一个功能需要依赖B应用,但是新人不知道B已经配置过了,所以又重复添加了一个,导致启动报错.
需求 入口应用是一个nodejs应用,自然选择了js脚本检查conf文件location path配置是否重复.
实现 在git hook目录下,新增一个pre-commit文件,添加内容：
#!/usr/bin/sh # 检查项目中同一个目录下面的nginx conf 所有location是否重复 if [ -e ./ngconf_check.js ]; then node ngconf_check.js if [[ $? != 0 ]]; then echo >&amp;2 fix duplicate location entry in nginx conf exit 1 fi fi # 如果项目有自定义pre-commit,执行 if [ -e ./.git/hooks/pre-commit ]; then ./.git/hooks/pre-commit "$@" fi exit 0 要点： bash中$?表示获取上命令的返回值.这里获得的是js脚本的process.exit(code)返回的code. 默认返回是0.
ngconf_check.js：
// 检查ng conf是否有重复的location entry const fs = require('fs'); const path = require('path'); const ConfEnvDirs = new Set(); ConfEnvDirs.add('dev'); ConfEnvDirs.add('st'); ConfEnvDirs.add('uat'); ConfEnvDirs.add('prd'); const NgconfPath = 'www/ngconf'; let result = 'pass'; countLocationInDir(NgconfPath); if(result !== 'pass'){ process.exit(1);//向bash返回1 } /** * * @param rootPath */ function countLocationInDir(rootPath) { if (!fs.existsSync(rootPath)) return; let dirs = fs.readdirSync(rootPath); dirs.forEach(dir => { let envDir = path.join(rootPath, dir); //只处理四个环境目录下的conf文件,每个目录用一个map记录 const LocationEntryMap = new Map();//location entry -> file,line if (!(fs.statSync(envDir).isDirectory() &amp;&amp; ConfEnvDirs.has(dir))) { return; } let confFiles = fs.readdirSync(envDir); confFiles.forEach(filename => { let fullPath = path.join(envDir, filename); if (fs.lstatSync(fullPath).isFile() &amp;&amp; /[\w\W.].conf$/.test(filename)) { countLocationsInFile(fullPath, LocationEntryMap); } }); }); } /** * * @param confFile * @param countMap */ function countLocationsInFile(confFile, countMap) { let lines = fs.readFileSync(confFile, "utf-8") .split("\n") .filter(Boolean); lines.forEach((line, lineNumber) => { if (line.trim().startsWith("location")) { const arr = line.trim().split(' '); const locationEntry = arr[1]; const entryInfo = `${confFile}, at line:${lineNumber}`; if (countMap.has(locationEntry)) { console.log(`ERROR: duplicate location entry: ${locationEntry}`); console.log(`location 1:${countMap.get(locationEntry)}`); console.log(`location 2:${entryInfo}`); //修改result变量 result='error'; } else { countMap.set(locationEntry, entryInfo); } } }); }</content></entry><entry><title>Typescript Comprehensive Cheatsheet</title><url>https://zhimoe.github.io/post/ts-comprehensive-notes/</url><categories><category>编程</category></categories><tags><tag>typescript</tag></tags><content type="html"> 一份详尽的ts语法笔记. 这周在看组里前端同事的代码,感觉完全还是在写JS,以我有限的JS/TS知识,也知道可以写得更加规范一点.但是一上手开始改,还真是手生.
又重新过了一遍文档,做了一点笔记.
install # Install npm install typescript # Run npx tsc # Run with a specific config npx tsc --project configs/my_tsconfig.json # Triple slash directives # Reference built-in types /// &lt;reference lib="es2016.array.include" /> # Reference other types /// &lt;reference path="../my_types" /> /// &lt;reference types="jquery" /> # AMD /// &lt;amd-module name="Name" /> /// &lt;amd-dependency path="app/foo" name="foo" /> # Compiler comments # Don’t check this file // @ts-nocheck # Check this file (JS) // @ts-check # Ignore the next line // @ts-ignore # Expect an error on the next line // @ts-expect-error # ignore ts type error tsc --noEmitOnError hello.ts # tsconfig.json "strict": true "noImplicitAny" "strictNullChecks" ts syntax cheatsheet //-------------------------------- Basic type any // untyped, use as js, disables all further type checking unknown // The unknown type represents any value. This is similar to the any type, but is safer because it’s not legal to do anything with an unknown value: void // void is not the same as undefined. // a contextual function type with a void return type (type vf = () => void), when implemented, can return any other value, but it will be ignored. null // prefer use undefined undefined // check optional param? if undefined before use it never // unreachable see: https://www.typescriptlang.org/docs/handbook/2/narrowing.html#exhaustiveness-checking object // object is not Object. Always use object! object also diff from {} // In compile time {} doesn't have Object's members and Object has more strict behavior boolean number string // The type names String , Number , and Boolean (starting with capital letters) are legal, but refer to // some special built-in types that will very rarely appear in your code. Always use string , number , or // boolean for types. bigint //ES2020 // Creating a bigint via the BigInt function const oneHundred: bigint = BigInt(100); // Creating a BigInt via the literal syntax const anotherHundred: bigint = 100n; string[] // or Array&lt;string> // ReadonlyArray // error: new ReadonlyArray("red", "green", "blue"); // use: const roArray: ReadonlyArray&lt;string> = ["red", "green", "blue"]; // Just as TypeScript provides a shorthand syntax for Array&lt;Type> with Type[], // it also provides a shorthand syntax for ReadonlyArray&lt;Type> with readonly Type[] let x: readonly string[] = []; let y: string[] = []; [string, number] // tuple string | null | undefined // union type // use isArray function narrowing the array type function welcomePeople(x: string[] | string) { if (Array.isArray(x)) { console.log("Hello, " + x.join(" and ")); } else { console.log("Welcome lone traveler " + x); } } // use in operator narrowing method structual type // instanceof narrowing type direction= 'left' | 'right'; // Literal types type roll= 1 | 2 | 3 | 4 | 5 | 6; // ?? (nullish coalescing) function getValue(val?: number): number | 'nil' { // Will only return 'nil' if `val` is null or undefined return val ?? 'nil'; } // ?. (optional chaining) function countCaps(value?: string) { // The `value` expression be undefined if `value` is null or // undefined, or if the `match` call doesn't find anything. return value?.match(/[A-Z]/g)?.length ?? 0; } // ! (null assertion) skip the null/undefined check let value: string | undefined; // ... Code that we're sure will initialize `value` ... // Assert that `value` is defined console.log(`value is ${value!.length} characters long`); // &amp;&amp;= assign a value only if current value is truthy let a; let b = 1; a &amp;&amp;= 'default'; // a is still undefined b &amp;&amp;= 5; // b is now 5 // ||= assign a value only if current value is falsy let a; let b = 1; a ||= 'default'; // a is 'default' now b ||= 5; // b is still 1 // ??= assign a value only if current value is null or undefined let a; let b = 0; a ??= 'default'; // a is now 'default' b ??= 5; // b is still 0 // Object { requiredStringVal: string; optionalNum?: number; readonly readOnlyBool: bool; } // Index signature: object with arbitrary string properties (like a hashmap or dictionary) { [key: string]: Type; } { [key: number]: Type; } { [key: symbol]: Type; } { [key: `data-${string}`]: Type; } // Array of functions that return strings (() => string)[] // or { (): string; }[] // or Array&lt;() => string> // Basic tuples let myTuple: [ string, number, boolean? ]; myTuple = [ 'test', 42 ]; // Variadic tuples type Numbers = [number, number]; type Strings = [string, string]; type NumbersAndStrings = [...Numbers, ...Strings]; // [number, number, string, string] type NumberAndRest = [number, ...string[]]; // [number, varying number of string] type RestAndBoolean = [...any[], boolean]; // [varying number of any, boolean] // Named tuples type Vector2D = [x: number, y: number]; function createVector2d(...args: Vector2D) {} // function createVector2d(x: number, y: number): void // !!!cation, you can not use v2d.x the name is just for hint, not for compiler // Interface interface Child extends Parent, SomeClass { property: Type; optionalProp?: Type; optionalMethod?(arg1: Type): ReturnType; } // Class class Child extends Parent implements Child, OtherChild { property: Type; defaultProperty = 'default value'; private _privateProperty: Type; private readonly _privateReadonlyProperty: Type; static staticProperty: Type; static { try { Child.staticProperty = calcStaticProp(); } catch { Child.staticProperty = defaultValue; } } constructor(arg1: Type) { super(arg1); } private _privateMethod(): Type {} methodProperty: (arg1: Type) => ReturnType; overloadedMethod(arg1: Type): ReturnType; overloadedMethod(arg1: OtherType): ReturnType; overloadedMethod(arg1: CommonT): CommonReturnT {} static staticMethod(): ReturnType {} subclassedMethod(arg1: Type): ReturnType { super.subclassedMethod(arg1); } } //-------------------------------- Function // Function type (arg1: Type, argN: Type) => Type; // or { (arg1: Type, argN: Type): Type; } // Function type with optional param (arg1: Type, optional?: Type) => ReturnType // Function type with rest param (arg1: Type, ...allOtherArgs: Type[]) => ReturnType // Function type with static property { (): Type; staticProp: Type; } // Default argument function fn(arg1 = 'default'): ReturnType {} // Arrow function (arg1: Type): ReturnType => { ...; return value; } // or (arg1: Type): ReturnType => value; // this typing function fn(this: Foo, arg1: string) {} // Overloads function conv(a: string): number; function conv(a: number): string; function conv(a: string | number): string | number { ... } // Call Signatures type DescribableFunction = { description: string; (someArg: number): boolean; }; function doSomething(fn: DescribableFunction) { console.log(fn.description + " returned " + fn(6)); } // Construct Signatures type SomeConstructor = { new (s: string): SomeObject; }; function fn(ctor: SomeConstructor) { return new ctor("hello"); } // Generic Functions function firstElement&lt;Type>(arr: Type[]): Type | undefined { return arr[0]; } // Constraints function longest&lt;Type extends { length: number }>(a: Type, b: Type) { if (a.length >= b.length) { return a; } else { return b; } } // longerArray is of type 'number[]' const longerArray = longest([1, 2], [1, 2, 3]); // longerString is of type 'alice' | 'bob' const longerString = longest("alice", "bob"); // Error! Numbers don't have a 'length' property const notOK = longest(10, 100); // Working with Constrained Values // 期望返回Type,而不是具有{ length: number }约束的类型.即期望子类,返回了父类,会导致属性变少 function minimumLength&lt;Type extends { length: number }>( obj: Type, minimum: number ): Type { if (obj.length >= minimum) { return obj; } else { return { length: minimum }; // Type '{ length: number; }' is not assignable to type 'Type'. // '{ length: number; }' is assignable to the constraint of type 'Type', but 'Type' could be instantiated with a different subtype of constraint '{ length: number; }' } } // Rule: If a type parameter only appears in one location, strongly reconsider if you actually need it // Rule: Always use as few type parameters as possible // Rule: When possible, use the type parameter itself rather than constraining it // 函数重载 function makeDate(timestamp: number): Date; function makeDate(m: number, d: number, y: number): Date; // 上面两个为函数重载签名 function makeDate(mOrTimestamp: number, d?: number, y?: number): Date { if (d !== undefined &amp;&amp; y !== undefined) { return new Date(y, mOrTimestamp, d); } else { return new Date(mOrTimestamp); } } const d1 = makeDate(12345678); const d2 = makeDate(5, 5, 5); const d3 = makeDate(1, 3); // Always prefer parameters with union types instead of overloads when possible //-------------------------------- Enum // Unlike most TypeScript features, this is not a type-level addition to JavaScript but something added to the language and runtime. // Because of this, it’s a feature which you should know exists, but maybe hold off on using unless you are sure enum Color {Red, Green, Blue = 4} // default get Red=0, all of the following members are auto-incremented Green=1, except you give. let c: Color = Color.Green // enum有两种, value是number（默认）或string的. // !!!numeric enums members also get a reverse mapping from enum values to enum names, for example: // !!! careful with numeric enum iteration enum LogLevel { ERROR, WARN, INFO } for (let element in LogLevel) { // 先遍历index,再遍历value console.log(element +" - "+ LogLevel[element]);// output // [LOG]: "0 - ERROR" // [LOG]: "1 - WARN" // [LOG]: "2 - INFO" // [LOG]: "ERROR - 0" // [LOG]: "WARN - 1" // [LOG]: "INFO - 2" } // string value enum没有上面这个问题. // 在编译内部, ts编译得到一个name->value value->name的双向map enum Enum { VAL, } // tsc output "use strict"; var Enum; (function (Enum) { Enum[Enum["VAL"] = 0] = "VAL"; })(Enum || (Enum = {})); // for in是ES5标准,遍历key. in会遍历原型链prototype上面的属性.非底层代码,禁止使用for..in. // for of是ES6标准,遍历value. // 语法上enum允许 string value 和 numeric value并存,但是代码业务含义 enum BooleanLikeHeterogeneousEnum { No = 0, Yes = "YES", } // Try to use ts.forEach, ts.map, and ts.filter instead of loops when it is not strongly inconvenient. //-------------------------------- Type alias type Name = string; type Direction = 'left' | 'right'; type ElementCreator = (type: string) => Element; type Point = { x: number, y: number }; type Point3D = Point &amp; { z: number }; type PointProp = keyof Point; // 'x' | 'y' const point: Point = { x: 1, y: 2 }; type PtValProp = keyof typeof point; // 'x' | 'y' // Extending a type via intersections type Animal = { name: string } type Bear = Animal &amp; { honey: boolean } // type alias , interface 区别 //-------------------------------- Generics // Function using type parameters &lt;T>(items: T[], callback: (item: T) => T): T[] // Interface with multiple types interface Pair&lt;T1, T2> { first: T1; second: T2; } // Constrained type parameter &lt;T extends ConstrainedType>(): T // Default type parameter &lt;T = DefaultType>(): T // Constrained and default type parameter &lt;T extends ConstrainedType = DefaultType>(): T // Generic tuples type Arr = readonly any[]; function concat&lt;U extends Arr, V extends Arr>(a: U, b: V): [...U, ...V] { return [...a, ...b] } const strictResult = concat([1, 2] as const, ['3', '4'] as const); const relaxedResult = concat([1, 2], ['3', '4']); // strictResult is of type [1, 2, '3', '4'] // relaxedResult is of type (string | number)[] //-------------------------------- Index, mapped, and conditional types // Index type query (keyof) type Point = { x: number, y: number }; let pointProp: keyof Point = 'x'; function getProp&lt;T, K extends keyof T>( val: T, propName: K ): T[K] { ... } // Mapped types // see more: https://www.typescriptlang.org/docs/handbook/utility-types.html type Stringify&lt;T> = { [P in keyof T]: string; } type Partial&lt;T> = { [P in keyof T]?: T[P]; } // Conditional types type Swapper = &lt;T extends number | string> (value: T) => T extends number ? string : number; // is equivalent to (value: number) => string // if T is number, or (value: string) => number // if T is string // Conditional mapped types interface Person { firstName: string; lastName: string; age: number; } type StringProps&lt;T> = { [K in keyof T]: T[K] extends string ? K : never; }; type PersonStrings = StringProps&lt;Person>; // PersonStrings is "firstName" | "lastName" // Utility types // Partial Partial&lt;{ x: number; y: number; z: number; }> // is equivalent to { x?: number; y?: number; z?: number; } // Readonly Readonly&lt;{ x: number; y: number; z: number; }> // is equivalent to { readonly x: number; readonly y: number; readonly z: number; } //-------------------------------- Pick Pick&lt;{ x: number; y: number; z: number; }, 'x' | 'y'> // is equivalent to { x: number; y: number; } // Record, 和 index signature区别是 后者key限制在 string number symbol Record&lt;'x' | 'y' | 'z', number> // is equivalent to { x: number; y: number; z: number; } // Exclude type Excluded = Exclude&lt;string | number, string>; // is equivalent to number // Extract type Extracted = Extract&lt;string | number, string>; // is equivalent to string // NonNullable type NonNull = NonNullable&lt;string | number | void>; // is equivalent to string | number // ReturnType type ReturnValue = ReturnType&lt;() => string>; // is equivalent to string // InstanceType class Renderer() {} type Instance = InstanceType&lt;typeof Renderer>; // is equivalent to Renderer // Type guards // Type predicates function isThing(val: unknown): val is Thing { // return true if val is a Thing } if (isThing(value)) { // value is of type Thing } //-------------------------------- typeof // "string" // "number" // "bigint" // "boolean" // "symbol" // "undefined" // "object" // "function" declare value: string | number | boolean; const isBoolean = typeof value === "boolean"; if (typeof value === "number") { // value is of type Number } else if (isBoolean) { // value is of type Boolean } else { // value is a string } // False // 0 // NaN // "" (the empty string) // 0n (the bigint version of zero) // null // undefined // instanceof declare value: Date | Error | MyClass; const isMyClass = value instanceof MyClass; if (value instanceof Date) { // value is a Date } else if (isMyClass) { // value is an instance of MyClass } else { // value is an Error } // in 属性和方法 interface Dog { woof(): void; } interface Cat { meow(): void; } function speak(pet: Dog | Cat) { if ('woof' in pet) { pet.woof() } else { pet.meow() } } //-------------------------------- Assertions // Type let val = someValue as string; // or let val = &lt;string>someValue; Const (immutable value) let point = { x: 20, y: 30 } as const; // or let point = &lt;const>{ x: 20, y: 30 }; function handle(url:string,method: "GET"|"POST"){ console.log("handle") } const req = { url: "https://example.com", method: "GET" }; handle(req.url, req.method as "GET"); // remove as "GET", throw: Argument of type 'string' is not assignable to parameter of type '"GET" | "POST"'.(2345) // or const req = { url: "https://example.com", method: "GET" as "GET" }; // or convert to type literals const req = { url: "https://example.com", method: "GET" } as const; //-------------------------------- Indexed Access Types type Person = { age: number; name: string; alive: boolean }; type Age = Person["age"]; // number type I1 = Person["age" | "name"]; // type I1 = string | number type I2 = Person[keyof Person]; // type I2 = string | number | boolean type AliveOrName = "alive" | "name"; type I3 = Person[AliveOrName]; // type I3 = string | boolean //-------------------------------- Ambient declarations // Global declare const $: JQueryStatic; // Module declare module "foo" { export class Bar { ... } } // Wildcard module declare module "text!*" { const value: string; export default value; }</content></entry><entry><title>开源与心理健康[翻译]</title><url>https://zhimoe.github.io/post/open-source-mental-health/</url><categories><category>翻译</category></categories><tags><tag>开源</tag><tag>心理健康</tag></tags><content type="html"> 我一位亲爱的朋友,也是高产的Redox OS贡献者jD91mZM2在2021年3月去世了,年仅18岁.他参与了2018、2019和2020年的Redox OS夏季代码活动.他在开发Redox OS的各个方面都做出了贡献,从内核,到relibc,到移植程序.他的工作详细介绍可以在Redox OS新闻中署名为jD91mZM2的帖子看到.
这个帖子可能是黑暗的、深沉的、沉重的、原始的、未经编辑的.如果你和我们中的许多人一样有自己的问题,请随时与我联系：https://twitter.com/jeremy_soller.在这种情况下,我不建议阅读这篇文章的其他内容.我的结论是,开源要成为可持续发展,还有大量的工作要做,而其中很大一部分是对社区及其成员的健康的关怀.
反思 昨天,另一个贡献者给我发了消息,说jD91mZM2已经长时间离线,而且也没有回复邮件.我通过我所掌握的信息进行了联系,但无济于事.我把他的真实姓名告诉了另一位贡献者,后者找到了他的讣告.我们验证了他的名字、地点和出生日期是否相符.虽然没有列出死因,但我相信我们找到的证据表明他是在精神疾病发作后自杀.
在得知这一切后,我感到很震惊.这样一个多产的贡献者,不仅对Redox,而且对许多项目都有贡献,怎么会觉得死亡比生命更重要？这是一个能力无穷的人,而且直到最近,他似乎还能很好地把握自己的生活.但我活得越久,就越意识到这可能是一个极大的幻觉,事情会迅速恶化.
我最后一次与jD91mZM2交流是在二月,在他去世前一个月.这次交流纯粹是技术性的,关于Redox内核的arch64端口.我不禁想到,这也许是他决定选择死亡的一个因素.
在开源工作中,我们经常强调好代码的重要性.毕竟,每个开源项目的交付物,都是源代码,对吧？ 但我们常常忘记,好的代码是由优秀的人编写的,而留住这些人并让他们保持快乐,应该是任何项目维护者的首要考虑.
心理健康问题的发作有很多方面.一方面,精神疾病通常有遗传因素.另一方面,这些遗传的前兆通常需要慢性和急性的环境触发因素.这些慢性诱因可以是长期的不良家庭或工作环境,并导致精神疾病本身的表现.急性诱因可能是,例如,与某人发生争执,导致精神疾病发作.这些发作可能严重到足以克服生存的极端本能,导致自杀.
在这种情况下,自杀并不是一种软弱的表现.事实上,它是一种极端信念和力量的展示.即使在精神疾病的背景下,大脑的某些部分通常不受影响.这些部分在进化过程中非常原始,我们几乎没有意识到对它们的控制.企图自杀需要克服有意识的求生欲望.要成功,就是要克服极端的潜意识欲望.这意味着,对于自杀,往往是最聪明、最有能力的人才能够做到.
这种对有能力的人的反选择是一种可怕的流行病.人类总体上迫切需要人为地解决长期存在的问题.以气候变化为例.在每年80万自杀的人中,平均来说也许比我们其他人更有能力,如果有几个人在开发核聚变发电方面起到了作用,那会怎么样？
然而,我们作为一个社会已经采取了这样的立场：这些事件是一种不可阻挡的力量.导致自杀的因素是内部的,而不是外部的.原则上,我拒绝相信这一点.对于每一个问题,我们都必须寻找原因并加以缓解,即使最后不可能做到.
因此,我不得不审视自己的行为,看看有什么可以做得不同.看看我是否可以挽救一个人的生命,以及看看我在未来可以挽救哪些生命.
开源与心理健康 开源的某些方面似乎吸引了最奇怪的人类,包括我自己.这群人坚持所有的东西都是可检查的,这也许是由强迫症行为所驱动的.而那些容易出现这种行为的人,往往会从其他疾病中继承下来.多动症、自闭症、双相情感障碍、抑郁症和其他疾病在开放源码贡献者中非常普遍.
因此,开源社区中也明显缺乏软技能.这显然有分裂社区和将开源本身与 &ldquo;正常 &ldquo;世界隔离的效果.对我们来说,幸运的是,开放源代码最终成为一个有利可图的行业.这种资本的注入导致了开源领域人才的显著多样化.
然而,这也是有代价的.那些不符合开源项目新的商业利益的人往往被抛在一边.由于与原始维护者的分歧导致项目本身出现难以克服的变化,项目被进一步划分为分叉上的分叉.我自己也参与了所有这些方面的工作.
在大多数情况下,都缺乏对人类成本的调查.调查开源贡献者中众多的心理健康事件,并试图找出一些共同的因素.有时这些事件会导致新的项目,有时会导致贡献者精疲力尽,然后离开开放源码,有时会导致自杀.
我们必须认识到我们在创造导致精神疾病的慢性压力以及导致危险发作的急性压力方面的作用.
我自己的旅程 我对精神疾病没有免疫力.我经常收到这样的信息：&ldquo;你似乎把你的事情都控制住了,你是怎么做到的？&rdquo; 残酷的事实是,我怀疑我们中是否有人真的做到了.而我们对 &ldquo;控制 &ldquo;的定义可能是非常不同的.拥有成功的项目并不等同于拥有普遍的幸福.
我不得不承认,我现在比以前幸福多了.因此,也许与一般人相比,我确实有事情在控制之中.我的生活一直是治疗师、精神病医生、药物和隔离的奥德赛.它本来很容易像其他人一样结束.我很幸运地找到了我的慢性压力源,并尽职尽责地消除它们.
我的大学一年&ndash;与jD91mZM2决定结束自己生命的时间差不&ndash;特别艰难.我的体重增加了近50磅.我和另外三个室友住在一起,其中两个也早逝了.我交替使用多动症药物、抗抑郁药,甚至吸烟&ndash;以寻找能 &ldquo;修复 &ldquo;我的方法.在整个过程中,我一直在编程,为此常常忽略了我的学校工作.
在上大学之前,我曾在卓尔医疗公司担任实习生,编写除颤器软件.我在这项工作中拥有两项专利.老实说,在对计算机的理解上,我比别人高出一截.我也对自己说实话,在对人的理解方面,我比别人差了一大截,包括我自己.
在那段时间里,我与研发部的副总裁建立了关系,他成了我事实上的老板.大一快结束时,他联系我,问我是否想继续工作.我答应了.
大二的时候,我的情况非常不同.我把大部分时间花在写软件上,并且赚了不少钱.我对学校没有兴趣.我有几门课不及格,但高分通过了许多高水平的CS课程.我很快就从大学退学,全职从事软件工程.
这对我的心理健康产生了巨大的积极影响.我降了体重.与我大学的其他校友保持联系,并最终通过他们认识了我的妻子.我们一起买了一套房子.我开始了Redox操作系统.我的妻子和我结婚了.我开始在System76工作.我的妻子和我有一个漂亮的女儿.从大二开始,我从来没有想过自己的心理健康问题,也不需要去治疗或用药.我所有的压力都消失了.
一个人的心理健康成功并不总是能复刻成其他人的成功.在这一历程中,我创造和破坏了（通过忽视）数百种关系.我不得不承认,虽然我很快乐,但我有一种倾向,会在别人身上造成相当大的反差.我保留了给我带来快乐的关系,而忽略了那些需要努力的关系.而在某些时候,也许我忘记了与jD91mZM2保持联系,确保他找到与我一样的幸福.
一个解决方案？ 没有解决方案,每个案例都是不同的.但我觉得有必要检查一下这些年来我失去的许多人,我希望你也这样做.我们仍然处于了解人类思想的黑暗时代,我们越是互相检查,我们就会做得越好.我知道我本可以有所作为,如果我多做一点的话.也许不是为了jD91mZM2,而是为了有同样感觉的人.我不会再以他们所写的代码来评价贡献者.代码不会自己写,而写代码的人甚至比 &ldquo;开源 &ldquo;本身更需要维护.
原文-Open Source and Mental Health</content></entry><entry><title>买房装修总结</title><url>https://zhimoe.github.io/post/hangzhou-house-tip/</url><categories><category>生活</category></categories><tags><tag>买房</tag></tags><content type="html"> 简单记录一下自己买房和装修的一点经验.
买房 自己买房比较离奇,杭州开始实行摇号的半年后,端午节在老家刷微信,看到有个红盘有6000多人报名,感觉买房都要开始碰运气了想到了车牌的悲剧,于是返杭后下车就去那个楼盘看了一下,小区旁边在修地铁,看了几眼沙盘,第二天就借钱登记摇号了,没想到第一次就中了.现在回想起就做梦一样.网上关于如何买房的经验特别多,例如杭州房产知识扫盲,上海买房等等. 这些我都没用上. 这里说说自己的一些经验和踩坑.
户型方正通透干湿分离这些网上都会说.提醒的是认真看沙盘旁边每栋楼的说明挂幅. 挂幅下面会有小字,说明每栋楼的一些坑,例如一些设备平台在哪栋楼（噪音）,楼的腰线在几楼（腰线只是为了楼外观好看,但是非常影响该层的采光）,选的时候要避开那些楼层. 如果选择低层的话,或者你的号码靠后只能买低层,看下光照时间测评,同一栋楼的不同单元的光照时间都会有所不同的,特别是一些凹凸造型的楼面.我自己的房子就是客厅采光不好,卧室很好.优先应该考虑客厅采光好的户型. 买房的时候如果预算足够,一定买边套,因为中间套的小户型客厅采光和隔音（楼上楼下电梯过道的走路说话声都会从厨房或者厕所窗户闯进来,非常清晰）,厕所隐私性等都有很大问题.这点是我最后悔的,当时没经验以为自己贷款额度有限,首付也基本是借的,压力很大,满脑子就是要总价低的. 其实隔壁夹边套（两栋楼连在一起的边套,南北通透但是没有侧面窗）才多10平,总价多25万而已,客厅采光,私密性都好很多.主要还是太仓促了. 当然边套很多是90方以上的,除了总价,契税和卖出时各种费用会高不少,自己量力而行,如果边套/夹边套是89方的,不要犹豫,总价多个二三十万的换来的是完全不一样的体验. 如果小区靠近地铁或者交通比较便利, 投资客又比较多,建议开盘不要买车位, 交房后会有投资客或者开发商打折卖车位. 装修 因为限价,杭州的新房精装修等于毛坯,我这个交付的时候没有空调,灯还是白炽灯.
第一次买房务必请一个验房师,术业有专攻,千万不要网上看了点收房验房攻略就自信满满自己去收房,等到装修一半又发现一堆问题. 装修顺序很重要,优先考虑打孔,很多业主都是装修尾声去买空调,安装时发现需要重新打孔,墙布已经贴好了,弄破很心疼.还有业主给阳台贴了瓷砖（交付是乳胶漆）,买了带新风的客厅空调管道太大需要重新打孔,不小心打破水管,需要重新敲掉2块瓷砖.非常费事. 拿到水电图,如果没有,打孔和物业(或者房修)说一声,让他们告诉哪里打孔,这样打破水管让他们修. 网上买家电不一定比实体店便宜,我在国美买了美的colmo的空调,比淘宝最便宜的还便宜三千. 如果不懂设计,千万不要乱选墙的颜色,自己当时晚上在灯光下面选了一个灰蓝墙布做主色, 结果施工当天发现在日光下是水蓝,只能施工当天临时加钱换颜色,还耽误了进度. 墙布样品因为面积小,颜色和实际上墙效果相差甚远,日光和灯光下也不一样. 而且,墙面的颜色对于后期买家具,沙发和窗帘的影响非常大. 没有十足把握的直接选白色或者极浅灰. 采光特别好的才建议选浅灰, 因为上墙后灰色会变重！ 优先考虑乳胶漆,自己选了硅藻泥质感的墙布,确实质感很好,也好看.但是感觉容易积灰,虽然防水,但是布面不平凹处根本擦不掉. 而且油漆的优势还可以单面墙修复. 现在都是智能家具,门锁冰箱空调都有app,手机遥控聊胜于无,所以家里宽带可以提前开通. 如果是自己布置家具, 建议不要着急安装防倒装置,等家具全部摆放完适应几天再决定,极大可能会调整家具位置. 2021.11.11 蒸汽拖把毫无用处,蒸汽是向上的,地板很难加热. 买一个好点的拖把,带水桶的那种可以方便洗抹布和挤干的. 买东西要有预算,买colmo和墙布都是严重超预算的.卖家很心机地介绍贵的,一上手质感确实不一样.预算就是这么超的. 买一些米箱,保鲜盒,置物架.厨房是最难收拾的,第一步尽量保证不要把超市的东西连着塑料袋放进冰箱/柜子.只有这样后续才能不乱. 提前规划一个工具间,目前家里有戴森,拖把,扫把畚斗,就已经乱放了,戴森没地方挂着充电每次扣电池充电.还有螺丝刀,锤子,扳手等到处乱扔.</content></entry><entry><title>Tour of Rusts Standard Library Traits[翻译]</title><url>https://zhimoe.github.io/post/tour-of-rusts-standard-library-traits/</url><categories><category>翻译</category></categories><tags><tag>code</tag><tag>rust</tag></tags><content type="html"> 关于rust trait非常好的介绍,比rust book详细,系统.
Tour of Rust&rsquo;s Standard Library Traits Table of Contents
Intro Trait Basics Trait Items Self Functions Methods Associated Types Generic Parameters Generic Types vs Associated Types Scope Derive Macros Default Impls Generic Blanket Impls Subtraits &amp; Supertraits Trait Objects Marker Traits Auto Traits Unsafe Traits Auto Traits Send &amp; Sync Sized General Traits Default Clone Copy Any Formatting Traits Display &amp; ToString Debug Operator Traits Comparison Traits PartialEq &amp; Eq Hash PartialOrd &amp; Ord Arithmetic Traits Add &amp; AddAssign Closure Traits FnOnce, FnMut, &amp; Fn Other Traits Deref &amp; DerefMut Index &amp; IndexMut Drop Conversion Traits From &amp; Into Error Handling Error Conversion Traits Continued TryFrom &amp; TryInto FromStr AsRef &amp; AsMut Borrow &amp; BorrowMut ToOwned Iteration Traits Iterator IntoIterator FromIterator I/O Traits Read &amp; Write Conclusion Discuss Notifications Further Reading Intro Have you ever wondered what&rsquo;s the difference between:
Deref&lt;Target = T>, AsRef&lt;T>, and Borrow&lt;T>? Clone, Copy, and ToOwned? From&lt;T> and Into&lt;T>? TryFrom&lt;&amp;str> and FromStr? FnOnce, FnMut, Fn, and fn? Or ever asked yourself the questions:
&ldquo;When do I use associated types vs generic types in my trait?&rdquo; &ldquo;What are generic blanket impls?&rdquo; &ldquo;How do subtraits and supertraits work?&rdquo; &ldquo;Why does this trait not have any methods?&rdquo; Well then this is the article for you! It answers all of the above questions and much much more. Together we&rsquo;ll do a quick flyby tour of all of the most popular and commonly used traits from the Rust standard library!
You can read this article in order section by section or jump around to whichever traits interest you the most because each trait section begins with a list of links to Prerequisite sections that you should read to have adequate context to understand the current section&rsquo;s explanations.
Trait Basics We&rsquo;ll cover just enough of the basics so that the rest of the article can be streamlined without having to repeat the same explanations of the same concepts over and over as they reappear in different traits.
Trait Items Trait items are any items that are part of a trait declaration.
Self Self always refers to the implementing type.
trait Trait { // always returns i32 fn returns_num() -> i32; // returns implementing type fn returns_self() -> Self; } struct SomeType; struct OtherType; impl Trait for SomeType { fn returns_num() -> i32 { 5 } // Self == SomeType fn returns_self() -> Self { SomeType } } impl Trait for OtherType { fn returns_num() -> i32 { 6 } // Self == OtherType fn returns_self() -> Self { OtherType } } Functions A trait function is any function whose first parameter does not use the self keyword.
trait Default { // function fn default() -> Self; } Trait functions can be called namespaced by the trait or implementing type:
fn main() { let zero: i32 = Default::default(); let zero = i32::default(); } Methods A trait method is any function whose first parameter uses the self keyword and is of type Self, &amp;Self, &amp;mut Self. The former types can also be wrapped with a Box, Rc, Arc, or Pin.
trait Trait { // methods fn takes_self(self); fn takes_immut_self(&amp;self); fn takes_mut_self(&amp;mut self); // above methods desugared fn takes_self(self: Self); fn takes_immut_self(self: &amp;Self); fn takes_mut_self(self: &amp;mut Self); } // example from standard library trait ToString { fn to_string(&amp;self) -> String; } Methods can be called using the dot operator on the implementing type:
fn main() { let five = 5.to_string(); } However, similarly to functions, they can also be called namespaced by the trait or implementing type:
fn main() { let five = ToString::to_string(&amp;5); let five = i32::to_string(&amp;5); } Associated Types A trait can have associated types. This is useful when we need to use some type other than Self within function signatures but would still like the type to be chosen by the implementer rather than being hardcoded in the trait declaration:
trait Trait { type AssociatedType; fn func(arg: Self::AssociatedType); } struct SomeType; struct OtherType; // any type implementing Trait can // choose the type of AssociatedType impl Trait for SomeType { type AssociatedType = i8; // chooses i8 fn func(arg: Self::AssociatedType) {} } impl Trait for OtherType { type AssociatedType = u8; // chooses u8 fn func(arg: Self::AssociatedType) {} } fn main() { SomeType::func(-1_i8); // can only call func with i8 on SomeType OtherType::func(1_u8); // can only call func with u8 on OtherType } Generic Parameters &ldquo;Generic parameters&rdquo; broadly refers to generic type parameters, generic lifetime parameters, and generic const parameters. Since all of those are a mouthful to say people commonly abbreviate them to &ldquo;generic types&rdquo;, &ldquo;lifetimes&rdquo;, and &ldquo;generic consts&rdquo;. Since generic consts are not used in any of the standard library traits we&rsquo;ll be covering they&rsquo;re outside the scope of this article.
We can generalize a trait declaration using parameters:
// trait declaration generalized with lifetime &amp; type parameters trait Trait&lt;'a, T> { // signature uses generic type fn func1(arg: T); // signature uses lifetime fn func2(arg: &amp;'a i32); // signature uses generic type &amp; lifetime fn func3(arg: &amp;'a T); } struct SomeType; impl&lt;'a> Trait&lt;'a, i8> for SomeType { fn func1(arg: i8) {} fn func2(arg: &amp;'a i32) {} fn func3(arg: &amp;'a i8) {} } impl&lt;'b> Trait&lt;'b, u8> for SomeType { fn func1(arg: u8) {} fn func2(arg: &amp;'b i32) {} fn func3(arg: &amp;'b u8) {} } It&rsquo;s possible to provide default values for generic types. The most commonly used default value is Self but any type works:
// make T = Self by default trait Trait&lt;T = Self> { fn func(t: T) {} } // any type can be used as the default trait Trait2&lt;T = i32> { fn func2(t: T) {} } struct SomeType; // omitting the generic type will // cause the impl to use the default // value, which is Self here impl Trait for SomeType { fn func(t: SomeType) {} } // default value here is i32 impl Trait2 for SomeType { fn func2(t: i32) {} } // the default is overridable as we'd expect impl Trait&lt;String> for SomeType { fn func(t: String) {} } // overridable here too impl Trait2&lt;String> for SomeType { fn func2(t: String) {} } Aside from parameterizing the trait it&rsquo;s also possible to parameterize individual functions and methods:
trait Trait { fn func&lt;'a, T>(t: &amp;'a T); } Generic Types vs Associated Types Both generic types and associated types defer the decision to the implementer on which concrete types should be used in the trait&rsquo;s functions and methods, so this section seeks to explain when to use one over the other.
The general rule-of-thumb is:
Use associated types when there should only be a single impl of the trait per type. Use generic types when there can be many possible impls of the trait per type. Let&rsquo;s say we want to define a trait called Add which allows us to add values together. Here&rsquo;s an initial design and impl that only uses associated types:
trait Add { type Rhs; type Output; fn add(self, rhs: Self::Rhs) -> Self::Output; } struct Point { x: i32, y: i32, } impl Add for Point { type Rhs = Point; type Output = Point; fn add(self, rhs: Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } fn main() { let p1 = Point { x: 1, y: 1 }; let p2 = Point { x: 2, y: 2 }; let p3 = p1.add(p2); assert_eq!(p3.x, 3); assert_eq!(p3.y, 3); } Let&rsquo;s say we wanted to add the ability to add i32s to Points where the i32 would be added to both the x and y members:
trait Add { type Rhs; type Output; fn add(self, rhs: Self::Rhs) -> Self::Output; } struct Point { x: i32, y: i32, } impl Add for Point { type Rhs = Point; type Output = Point; fn add(self, rhs: Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } impl Add for Point { // ❌ type Rhs = i32; type Output = Point; fn add(self, rhs: i32) -> Point { Point { x: self.x + rhs, y: self.y + rhs, } } } fn main() { let p1 = Point { x: 1, y: 1 }; let p2 = Point { x: 2, y: 2 }; let p3 = p1.add(p2); assert_eq!(p3.x, 3); assert_eq!(p3.y, 3); let p1 = Point { x: 1, y: 1 }; let int2 = 2; let p3 = p1.add(int2); // ❌ assert_eq!(p3.x, 3); assert_eq!(p3.y, 3); } Throws:
error[E0119]: conflicting implementations of trait `Add` for type `Point`: --> src/main.rs:23:1 | 12 | impl Add for Point { | ------------------ first implementation here ... 23 | impl Add for Point { | ^^^^^^^^^^^^^^^^^^ conflicting implementation for `Point` Since the Add trait is not parameterized by any generic types we can only impl it once per type, which means we can only pick the types for both Rhs and Output once! To allow adding both Pointss and i32s to Point we have to refactor Rhs from an associated type to a generic type, which would allow us to impl the trait multiple times for Point with different type arguments for Rhs:
trait Add&lt;Rhs> { type Output; fn add(self, rhs: Rhs) -> Self::Output; } struct Point { x: i32, y: i32, } impl Add&lt;Point> for Point { type Output = Self; fn add(self, rhs: Point) -> Self::Output { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } impl Add&lt;i32> for Point { // ✅ type Output = Self; fn add(self, rhs: i32) -> Self::Output { Point { x: self.x + rhs, y: self.y + rhs, } } } fn main() { let p1 = Point { x: 1, y: 1 }; let p2 = Point { x: 2, y: 2 }; let p3 = p1.add(p2); assert_eq!(p3.x, 3); assert_eq!(p3.y, 3); let p1 = Point { x: 1, y: 1 }; let int2 = 2; let p3 = p1.add(int2); // ✅ assert_eq!(p3.x, 3); assert_eq!(p3.y, 3); } Let&rsquo;s say we add a new type called Line which contains two Points, and now there are contexts within our program where adding two Points should produce a Line instead of a Point. This is not possible given the current design of the Add trait where Output is an associated type but we can satisfy these new requirements by refactoring Output from an associated type into a generic type:
trait Add&lt;Rhs, Output> { fn add(self, rhs: Rhs) -> Output; } struct Point { x: i32, y: i32, } impl Add&lt;Point, Point> for Point { fn add(self, rhs: Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } impl Add&lt;i32, Point> for Point { fn add(self, rhs: i32) -> Point { Point { x: self.x + rhs, y: self.y + rhs, } } } struct Line { start: Point, end: Point, } impl Add&lt;Point, Line> for Point { // ✅ fn add(self, rhs: Point) -> Line { Line { start: self, end: rhs, } } } fn main() { let p1 = Point { x: 1, y: 1 }; let p2 = Point { x: 2, y: 2 }; let p3: Point = p1.add(p2); assert!(p3.x == 3 &amp;&amp; p3.y == 3); let p1 = Point { x: 1, y: 1 }; let int2 = 2; let p3 = p1.add(int2); assert!(p3.x == 3 &amp;&amp; p3.y == 3); let p1 = Point { x: 1, y: 1 }; let p2 = Point { x: 2, y: 2 }; let l: Line = p1.add(p2); // ✅ assert!(l.start.x == 1 &amp;&amp; l.start.y == 1 &amp;&amp; l.end.x == 2 &amp;&amp; l.end.y == 2) } So which Add trait above is the best? It really depends on the requirements of your program! They&rsquo;re all good in the right situations.
Scope Trait items cannot be used unless the trait is in scope. Most Rustaceans learn this the hard way the first time they try to write a program that does anything with I/O because the Read and Write traits are not in the standard library prelude:
use std::fs::File; use std::io; fn main() -> Result&lt;(), io::Error> { let mut file = File::open("Cargo.toml")?; let mut buffer = String::new(); file.read_to_string(&amp;mut buffer)?; // ❌ read_to_string not found in File Ok(()) } read_to_string(buf: &amp;mut String) is declared by the std::io::Read trait and implemented by the std::fs::File struct but in order to call it std::io::Read must be in scope:
use std::fs::File; use std::io; use std::io::Read; // ✅ fn main() -> Result&lt;(), io::Error> { let mut file = File::open("Cargo.toml")?; let mut buffer = String::new(); file.read_to_string(&amp;mut buffer)?; // ✅ Ok(()) } The standard library prelude is a module in the standard library, i.e. std::prelude::v1, that gets auto imported at the top of every other module, i.e. use std::prelude::v1::*. Thus the following traits are always in scope and we never have to explicitly import them ourselves because they&rsquo;re part of the prelude:
AsMut AsRef Clone Copy Default Drop Eq Fn FnMut FnOnce From Into ToOwned IntoIterator Iterator PartialEq PartialOrd Send Sized Sync ToString Ord Derive Macros The standard library exports a handful of derive macros which we can use to quickly and conveniently impl a trait on a type if all of its members also impl the trait. The derive macros are named after the traits they impl:
Clone Copy Debug Default Eq Hash Ord PartialEq PartialOrd Example usage:
// macro derives Copy &amp; Clone impl for SomeType #[derive(Copy, Clone)] struct SomeType; Note: derive macros are just procedural macros and can do anything, there&rsquo;s no hard rule that they must impl a trait or that they can only work if all the members of the type impl a trait, these are just the conventions followed by the derive macros in the standard library.
Default Impls Traits can provide default impls for their functions and methods.
trait Trait { fn method(&amp;self) { println!("default impl"); } } struct SomeType; struct OtherType; // use default impl for Trait::method impl Trait for SomeType {} impl Trait for OtherType { // use our own impl for Trait::method fn method(&amp;self) { println!("OtherType impl"); } } fn main() { SomeType.method(); // prints "default impl" OtherType.method(); // prints "OtherType impl" } This is especially handy if some of the trait methods can be implemented solely using other trait methods.
trait Greet { fn greet(&amp;self, name: &amp;str) -> String; fn greet_loudly(&amp;self, name: &amp;str) -> String { self.greet(name) + "!" } } struct Hello; struct Hola; impl Greet for Hello { fn greet(&amp;self, name: &amp;str) -> String { format!("Hello {}", name) } // use default impl for greet_loudly } impl Greet for Hola { fn greet(&amp;self, name: &amp;str) -> String { format!("Hola {}", name) } // override default impl fn greet_loudly(&amp;self, name: &amp;str) -> String { let mut greeting = self.greet(name); greeting.insert_str(0, "¡"); greeting + "!" } } fn main() { println!("{}", Hello.greet("John")); // prints "Hello John" println!("{}", Hello.greet_loudly("John")); // prints "Hello John!" println!("{}", Hola.greet("John")); // prints "Hola John" println!("{}", Hola.greet_loudly("John")); // prints "¡Hola John!" } Many traits in the standard library provide default impls for many of their methods.
Generic Blanket Impls A generic blanket impl is an impl on a generic type instead of a concrete type. To explain why and how we&rsquo;d use one let&rsquo;s start by writing an is_even method for number types:
trait Even { fn is_even(self) -> bool; } impl Even for i8 { fn is_even(self) -> bool { self % 2_i8 == 0_i8 } } impl Even for u8 { fn is_even(self) -> bool { self % 2_u8 == 0_u8 } } impl Even for i16 { fn is_even(self) -> bool { self % 2_i16 == 0_i16 } } // etc #[test] // ✅ fn test_is_even() { assert!(2_i8.is_even()); assert!(4_u8.is_even()); assert!(6_i16.is_even()); // etc } Obviously, this is very verbose. Also, all of our impls are almost identical. Furthermore, in the unlikely but still possible event that Rust decides to add more number types in the future we have to remember to come back to this code and update it with the new number types. We can solve all these problems using a generic blanket impl:
use std::fmt::Debug; use std::convert::TryInto; use std::ops::Rem; trait Even { fn is_even(self) -> bool; } // generic blanket impl impl&lt;T> Even for T where T: Rem&lt;Output = T> + PartialEq&lt;T> + Sized, u8: TryInto&lt;T>, &lt;u8 as TryInto&lt;T>>::Error: Debug, { fn is_even(self) -> bool { // these unwraps will never panic self % 2.try_into().unwrap() == 0.try_into().unwrap() } } #[test] // ✅ fn test_is_even() { assert!(2_i8.is_even()); assert!(4_u8.is_even()); assert!(6_i16.is_even()); // etc } Unlike default impls, which provide an impl, generic blanket impls provide the impl, so they are not overridable.
use std::fmt::Debug; use std::convert::TryInto; use std::ops::Rem; trait Even { fn is_even(self) -> bool; } impl&lt;T> Even for T where T: Rem&lt;Output = T> + PartialEq&lt;T> + Sized, u8: TryInto&lt;T>, &lt;u8 as TryInto&lt;T>>::Error: Debug, { fn is_even(self) -> bool { self % 2.try_into().unwrap() == 0.try_into().unwrap() } } impl Even for u8 { // ❌ fn is_even(self) -> bool { self % 2_u8 == 0_u8 } } Throws:
error[E0119]: conflicting implementations of trait `Even` for type `u8`: --> src/lib.rs:22:1 | 10 | / impl&lt;T> Even for T 11 | | where 12 | | T: Rem&lt;Output = T> + PartialEq&lt;T> + Sized, 13 | | u8: TryInto&lt;T>, ... | 19 | | } 20 | | } | |_- first implementation here 21 | 22 | impl Even for u8 { | ^^^^^^^^^^^^^^^^ conflicting implementation for `u8` These impls overlap, hence they conflict, hence Rust rejects the code to ensure trait coherence. Trait coherence is the property that there exists at most one impl of a trait for any given type. The rules Rust uses to enforce trait coherence, the implications of those rules, and workarounds for the implications are outside the scope of this article.
Subtraits &amp; Supertraits The &ldquo;sub&rdquo; in &ldquo;subtrait&rdquo; refers to subset and the &ldquo;super&rdquo; in &ldquo;supertrait&rdquo; refers to superset. If we have this trait declaration:
trait Subtrait: Supertrait {} All of the types which impl Subtrait are a subset of all the types which impl Supertrait, or to put it in opposite but equivalent terms: all the types which impl Supertrait are a superset of all the types which impl Subtrait.
Also, the above is just syntax sugar for:
trait Subtrait where Self: Supertrait {} It&rsquo;s a subtle yet important distinction to understand that the bound is on Self, i.e. the type impling Subtrait, and not on Subtrait itself. The latter would not make any sense, since trait bounds can only be applied to concrete types which can impl traits. Traits cannot impl other traits:
trait Supertrait { fn method(&amp;self) { println!("in supertrait"); } } trait Subtrait: Supertrait { // this looks like it might impl or // override Supertrait::method but it // does not fn method(&amp;self) { println!("in subtrait") } } struct SomeType; // adds Supertrait::method to SomeType impl Supertrait for SomeType {} // adds Subtrait::method to SomeType impl Subtrait for SomeType {} // both methods exist on SomeType simultaneously // neither overriding or shadowing the other fn main() { SomeType.method(); // ❌ ambiguous method call // must disambiguate using fully-qualified syntax &lt;SomeType as Supertrait>::method(&amp;st); // ✅ prints "in supertrait" &lt;SomeType as Subtrait>::method(&amp;st); // ✅ prints "in subtrait" } Furthermore, there are no rules for how a type must impl both a subtrait and a supertrait. It can use the methods from either in the impl of the other.
trait Supertrait { fn super_method(&amp;mut self); } trait Subtrait: Supertrait { fn sub_method(&amp;mut self); } struct CallSuperFromSub; impl Supertrait for CallSuperFromSub { fn super_method(&amp;mut self) { println!("in super"); } } impl Subtrait for CallSuperFromSub { fn sub_method(&amp;mut self) { println!("in sub"); self.super_method(); } } struct CallSubFromSuper; impl Supertrait for CallSubFromSuper { fn super_method(&amp;mut self) { println!("in super"); self.sub_method(); } } impl Subtrait for CallSubFromSuper { fn sub_method(&amp;mut self) { println!("in sub"); } } struct CallEachOther(bool); impl Supertrait for CallEachOther { fn super_method(&amp;mut self) { println!("in super"); if self.0 { self.0 = false; self.sub_method(); } } } impl Subtrait for CallEachOther { fn sub_method(&amp;mut self) { println!("in sub"); if self.0 { self.0 = false; self.super_method(); } } } fn main() { CallSuperFromSub.super_method(); // prints "in super" CallSuperFromSub.sub_method(); // prints "in sub", "in super" CallSubFromSuper.super_method(); // prints "in super", "in sub" CallSubFromSuper.sub_method(); // prints "in sub" CallEachOther(true).super_method(); // prints "in super", "in sub" CallEachOther(true).sub_method(); // prints "in sub", "in super" } Hopefully the examples above show that the relationship between subtraits and supertraits can be complex. Before introducing a mental model that neatly encapsulates all of that complexity let&rsquo;s quickly review and establish the mental model we use for understanding trait bounds on generic types:
fn function&lt;T: Clone>(t: T) { // impl } Without knowing anything about the impl of this function we could reasonably guess that t.clone() gets called at some point because when a generic type is bounded by a trait that strongly implies it has a dependency on the trait. The mental model for understanding the relationship between generic types and their trait bounds is a simple and intuitive one: generic types depend on their trait bounds.
Now let&rsquo;s look the trait declaration for Copy:
trait Copy: Clone {} The syntax above looks very similar to the syntax for applying a trait bound on a generic type and yet Copy doesn&rsquo;t depend on Clone at all. The mental model we developed earlier doesn&rsquo;t help us here. In my opinion, the most simple and elegant mental model for understanding the relationship between subtraits and supertraits is: subtraits refine their supertraits.
&ldquo;Refinement&rdquo; is intentionally kept somewhat vague because it can mean different things in different contexts:
a subtrait might make its supertrait&rsquo;s methods&rsquo; impls more specialized, faster, use less memory, e.g. Copy: Clone a subtrait might make additional guarantees about the supertrait&rsquo;s methods&rsquo; impls, e.g. Eq: PartialEq, Ord: PartialOrd, ExactSizeIterator: Iterator a subtrait might make the supertrait&rsquo;s methods more flexible or easier to call, e.g. FnMut: FnOnce, Fn: FnMut a subtrait might extend a supertrait and add new methods, e.g. DoubleEndedIterator: Iterator, ExactSizeIterator: Iterator Trait Objects Generics give us compile-time polymorphism where trait objects give us run-time polymorphism. We can use trait objects to allow functions to dynamically return different types at run-time:
fn example(condition: bool, vec: Vec&lt;i32>) -> Box&lt;dyn Iterator&lt;Item = i32>> { let iter = vec.into_iter(); if condition { // Has type: // Box&lt;Map&lt;IntoIter&lt;i32>, Fn(i32) -> i32>> // But is cast to: // Box&lt;dyn Iterator&lt;Item = i32>> Box::new(iter.map(|n| n * 2)) } else { // Has type: // Box&lt;Filter&lt;IntoIter&lt;i32>, Fn(&amp;i32) -> bool>> // But is cast to: // Box&lt;dyn Iterator&lt;Item = i32>> Box::new(iter.filter(|&amp;n| n >= 2)) } } Trait objects also allow us to store heterogeneous types in collections:
use std::f64::consts::PI; struct Circle { radius: f64, } struct Square { side: f64 } trait Shape { fn area(&amp;self) -> f64; } impl Shape for Circle { fn area(&amp;self) -> f64 { PI * self.radius * self.radius } } impl Shape for Square { fn area(&amp;self) -> f64 { self.side * self.side } } fn get_total_area(shapes: Vec&lt;Box&lt;dyn Shape>>) -> f64 { shapes.into_iter().map(|s| s.area()).sum() } fn example() { let shapes: Vec&lt;Box&lt;dyn Shape>> = vec![ Box::new(Circle { radius: 1.0 }), // Box&lt;Circle> cast to Box&lt;dyn Shape> Box::new(Square { side: 1.0 }), // Box&lt;Square> cast to Box&lt;dyn Shape> ]; assert_eq!(PI + 1.0, get_total_area(shapes)); // ✅ } Trait objects are unsized so they must always be behind a pointer. We can tell the difference between a concrete type and a trait object at the type level based on the presence of the dyn keyword within the type:
struct Struct; trait Trait {} // regular struct &amp;Struct Box&lt;Struct> Rc&lt;Struct> Arc&lt;Struct> // trait objects &amp;dyn Trait Box&lt;dyn Trait> Rc&lt;dyn Trait> Arc&lt;dyn Trait> Not all traits can be converted into trait objects. A trait is object-safe if it meets these requirements:
trait doesn&rsquo;t require Self: Sized all of the trait&rsquo;s methods are object-safe A trait method is object-safe if it meets these requirements:
method requires Self: Sized or method only uses a Self type in receiver position Understanding why the requirements are what they are is not relevant to the rest of this article, but if you&rsquo;re still curious it&rsquo;s covered in Sizedness in Rust.
Marker Traits Marker traits are traits that have no trait items. Their job is to &ldquo;mark&rdquo; the implementing type as having some property which is otherwise not possible to represent using the type system.
// Impling PartialEq for a type promises // that equality for the type has these properties: // - symmetry: a == b implies b == a, and // - transitivity: a == b &amp;&amp; b == c implies a == c // But DOES NOT promise this property: // - reflexivity: a == a trait PartialEq { fn eq(&amp;self, other: &amp;Self) -> bool; } // Eq has no trait items! The eq method is already // declared by PartialEq, but "impling" Eq // for a type promises this additional equality property: // - reflexivity: a == a trait Eq: PartialEq {} // f64 impls PartialEq but not Eq because NaN != NaN // i32 impls PartialEq &amp; Eq because there's no NaNs :) Auto Traits Auto traits are traits that get automatically implemented for a type if all of its members also impl the trait. What &ldquo;members&rdquo; means depends on the type, for example: fields of a struct, variants of an enum, elements of an array, items of a tuple, and so on.
All auto traits are marker traits but not all marker traits are auto traits. Auto traits must be marker traits so the compiler can provide an automatic default impl for them, which would not be possible if they had any trait items.
Examples of auto traits:
// implemented for types which are safe to send between threads unsafe auto trait Send {} // implemented for types whose references are safe to send between threads unsafe auto trait Sync {} Unsafe Traits Traits can be marked unsafe to indicate that impling the trait might require unsafe code. Both Send and Sync are marked unsafe because if they aren&rsquo;t automatically implemented for a type that means it must contains some non-Send or non-Sync member and we have to take extra care as the implementers to make sure there are no data races if we want to manually mark the type as Send and Sync.
// SomeType is not Send or Sync struct SomeType { not_send_or_sync: *const (), } // but if we're confident that our impl doesn't have any data // races we can explicitly mark it as Send and Sync using unsafe unsafe impl Send for SomeType {} unsafe impl Sync for SomeType {} Auto Traits Send &amp; Sync Prerequisites
Marker Traits Auto Traits Unsafe Traits unsafe auto trait Send {} unsafe auto trait Sync {} If a type is Send that means it&rsquo;s safe to send between threads. If a type is Sync that means it&rsquo;s safe to share references of it between threads. In more precise terms some type T is Sync if and only if &amp;T is Send.
Almost all types are Send and Sync. The only notable Send exception is Rc and the only notable Sync exceptions are Rc, Cell, RefCell. If we need a Send version of Rc we can use Arc. If we need a Sync version of Cell or RefCell we can Mutex or RwLock. Although if we&rsquo;re using the Mutex or RwLock to just wrap a primitive type it&rsquo;s often better to use the atomic primitive types provided by the standard library such as AtomicBool, AtomicI32, AtomicUsize, and so on.
That almost all types are Sync might be a surprise to some people, but yup, it&rsquo;s true even for types without any internal synchronization. This is possible thanks to Rust&rsquo;s strict borrowing rules.
We can pass many immutable references to the same data to many threads and we&rsquo;re guaranteed there are no data races because as long as any immutable references exist Rust statically guarantees the underlying data cannot be mutated:
use crossbeam::thread; fn main() { let mut greeting = String::from("Hello"); let greeting_ref = &amp;greeting; thread::scope(|scoped_thread| { // spawn 3 threads for n in 1..=3 { // greeting_ref copied into every thread scoped_thread.spawn(move |_| { println!("{} {}", greeting_ref, n); // prints "Hello {n}" }); } // line below could cause UB or data races but compiler rejects it greeting += " world"; // ❌ cannot mutate greeting while immutable refs exist }); // can mutate greeting after every thread has joined greeting += " world"; // ✅ println!("{}", greeting); // prints "Hello world" } Likewise we can pass a single mutable reference to some data to a single thread and we&rsquo;re guaranteed there will be no data races because Rust statically guarantees aliased mutable references cannot exist and the underlying data cannot be mutated through anything other than the single existing mutable reference:
use crossbeam::thread; fn main() { let mut greeting = String::from("Hello"); let greeting_ref = &amp;mut greeting; thread::scope(|scoped_thread| { // greeting_ref moved into thread scoped_thread.spawn(move |_| { *greeting_ref += " world"; println!("{}", greeting_ref); // prints "Hello world" }); // line below could cause UB or data races but compiler rejects it greeting += "!!!"; // ❌ cannot mutate greeting while mutable refs exist }); // can mutate greeting after the thread has joined greeting += "!!!"; // ✅ println!("{}", greeting); // prints "Hello world!!!" } This is why most types are Sync without requiring any explicit synchronization. In the event we need to simultaneously mutate some data T across multiple threads the compiler won&rsquo;t let us until we wrap the data in a Arc&lt;Mutex&lt;T>> or Arc&lt;RwLock&lt;T>> so the compiler enforces that explicit synchronization is used when it&rsquo;s needed.
Sized Prerequisites
Marker Traits Auto Traits If a type is Sized that means its size in bytes is known at compile-time and it&rsquo;s possible to put instances of the type on the stack.
Sizedness of types and its implications is a subtle yet huge topic that affects a lot of different aspects of the language. It&rsquo;s so important that I wrote an entire article on it called Sizedness in Rust which I highly recommend reading for anyone who would like to understand sizedness in-depth. I&rsquo;ll summarize a few key things which are relevant to this article.
All generic types get an implicit Sized bound. fn func&lt;T>(t: &amp;T) {} // example above desugared fn func&lt;T: Sized>(t: &amp;T) {} Since there&rsquo;s an implicit Sized bound on all generic types, if we want to opt-out of this implicit bound we need to use the special &ldquo;relaxed bound&rdquo; syntax ?Sized which currently only exists for the Sized trait: // now T can be unsized fn func&lt;T: ?Sized>(t: &amp;T) {} There&rsquo;s an implicit ?Sized bound on all traits. trait Trait {} // example above desugared trait Trait: ?Sized {} This is so that trait objects can impl the trait. Again, all of the nitty gritty details are in Sizedness in Rust.
General traits Default Prerequisites
Self Functions Derive Macros trait Default { fn default() -> Self; } It&rsquo;s possible to construct default values of Default types.
struct Color { r: u8, g: u8, b: u8, } impl Default for Color { // default color is black fn default() -> Self { Color { r: 0, g: 0, b: 0, } } } This is useful for quick prototyping but also in any instance where we just need an instance of a type and aren&rsquo;t picky about what it is:
fn main() { // just give me some color! let color = Color::default(); } This is also an option we may want to explicitly expose to the users of our functions:
struct Canvas; enum Shape { Circle, Rectangle, } impl Canvas { // let user optionally pass a color fn paint(&amp;mut self, shape: Shape, color: Option&lt;Color>) { // if no color is passed use the default color let color = color.unwrap_or_default(); // etc } } Default is also useful in generic contexts where we need to construct generic types:
fn guarantee_length&lt;T: Default>(mut vec: Vec&lt;T>, min_len: usize) -> Vec&lt;T> { for _ in 0..min_len.saturating_sub(vec.len()) { vec.push(T::default()); } vec } Another way we can take advantage of Default types is for partial initialization of structs using Rust&rsquo;s struct update syntax. We may have a new constructor for Color which takes every member as an argument:
impl Color { fn new(r: u8, g: u8, b: u8) -> Self { Color { r, g, b, } } } However we can also have convenience constructors that only accept a particular struct member each and fall back to the default values for the other struct members:
impl Color { fn red(r: u8) -> Self { Color { r, ..Color::default() } } fn green(g: u8) -> Self { Color { g, ..Color::default() } } fn blue(b: u8) -> Self { Color { b, ..Color::default() } } } There&rsquo;s also a Default derive macro for so we can write Color like this:
// default color is still black // because u8::default() == 0 #[derive(Default)] struct Color { r: u8, g: u8, b: u8 } Clone Prerequisites
Self Methods Default Impls Derive Macros trait Clone { fn clone(&amp;self) -> Self; // provided default impls fn clone_from(&amp;mut self, source: &amp;Self); } We can convert immutable references of Clone types into owned values, i.e. &amp;T -> T. Clone makes no promises about the efficiency of this conversion so it can be slow and expensive. To quickly impl Clone on a type we can use the derive macro:
#[derive(Clone)] struct SomeType { cloneable_member1: CloneableType1, cloneable_member2: CloneableType2, // etc } // macro generates impl below impl Clone for SomeType { fn clone(&amp;self) -> Self { SomeType { cloneable_member1: self.cloneable_member1.clone(), cloneable_member2: self.cloneable_member2.clone(), // etc } } } Clone can also be useful in constructing instances of a type within a generic context. Here&rsquo;s an example from the previous section except using Clone instead of Default:
fn guarantee_length&lt;T: Clone>(mut vec: Vec&lt;T>, min_len: usize, fill_with: &amp;T) -> Vec&lt;T> { for _ in 0..min_len.saturating_sub(vec.len()) { vec.push(fill_with.clone()); } vec } People also commonly use cloning as an escape hatch to avoid dealing with the borrow checker. Managing structs with references can be challenging, but we can turn the references into owned values by cloning them.
// oof, we gotta worry about lifetimes 😟 struct SomeStruct&lt;'a> { data: &amp;'a Vec&lt;u8>, } // now we're on easy street 😎 struct SomeStruct { data: Vec&lt;u8>, } If we&rsquo;re working on a program where performance is not the utmost concern then we don&rsquo;t need to sweat cloning data. Rust is a low-level language that exposes a lot of low-level details so it&rsquo;s easy to get caught up in premature optimizations instead of actually solving the problem at hand. For many programs the best order of priorities is usually to build for correctness first, elegance second, and performance third, and only focus on performance after the program has been profiled and the performance bottlenecks have been identified. This is good general advice to follow, and if it doesn&rsquo;t apply to your particular program then you would know.
Copy Prerequisites
Marker Traits Subtraits &amp; Supertraits Derive Macros trait Copy: Clone {} We copy Copy types, e.g. T -> T. Copy promises the copy operation will be a simple bitwise copy so it will be very fast and efficient. We cannot impl Copy ourselves, only the compiler can provide an impl, but we can tell it to do so by using the Copy derive macro, together with the Clone derive macro since Copy is a subtrait of Clone:
#[derive(Copy, Clone)] struct SomeType; Copy refines Clone. A clone may be slow and expensive but a copy is guaranteed to be fast and cheap, so a copy is just a fast clone. If a type impls Copy that makes the Clone impl trivial:
// this is what the derive macro generates impl&lt;T: Copy> Clone for T { // the clone method becomes just a copy fn clone(&amp;self) -> Self { *self } } Impling Copy for a type changes its behavior when it gets moved. By default all types have move semantics but once a type impls Copy it gets copy semantics. To explain the difference between the two let&rsquo;s examine these simple scenarios:
// a "move", src: !Copy let dest = src; // a "copy", src: Copy let dest = src; In both cases, dest = src performs a simple bitwise copy of src&rsquo;s contents and moves the result into dest, the only difference is that in the case of &ldquo;a move&rdquo; the borrow checker invalidates the src variable and makes sure it&rsquo;s not used anywhere else later and in the case of &ldquo;a copy&rdquo; src remains valid and usable.
In a nutshell: Copies are moves. Moves are copies. The only difference is how they&rsquo;re treated by the borrow checker.
For a more concrete example of a move, imagine src was a Vec&lt;i32> and its contents looked something like this:
{ data: *mut [i32], length: usize, capacity: usize } When we write dest = src we end up with:
src = { data: *mut [i32], length: usize, capacity: usize } dest = { data: *mut [i32], length: usize, capacity: usize } At this point both src and dest have aliased mutable references to the same data, which is a big no-no, so the borrow checker invalidates the src variable so it can&rsquo;t be used again without throwing a compile error.
For a more concrete example of a copy, imagine src was an Option&lt;i32> and its contents looked something like this:
{ is_valid: bool, data: i32 } Now when we write dest = src we end up with:
src = { is_valid: bool, data: i32 } dest = { is_valid: bool, data: i32 } These are both usable simultaneously! Hence Option&lt;i32> is Copy.
Although Copy could be an auto trait the Rust language designers decided it&rsquo;s simpler and safer for types to explicitly opt into copy semantics rather than silently inheriting copy semantics whenever the type is eligible, as the latter can cause surprising confusing behavior which often leads to bugs.
Any Prerequisites
Self Generic Blanket Impls Subtraits &amp; Supertraits Trait Objects trait Any: 'static { fn type_id(&amp;self) -> TypeId; } Rust&rsquo;s style of polymorphism is parametric, but if we&rsquo;re looking to use a more ad-hoc style of polymorphism similar to dynamically-typed languages then we can emulate that using the Any trait. We don&rsquo;t have to manually impl this trait for our types because that&rsquo;s already covered by this generic blanket impl:
impl&lt;T: 'static + ?Sized> Any for T { fn type_id(&amp;self) -> TypeId { TypeId::of::&lt;T>() } } The way we get a T out of a dyn Any is by using the downcast_ref::&lt;T>() and downcast_mut::&lt;T>() methods:
use std::any::Any; #[derive(Default)] struct Point { x: i32, y: i32, } impl Point { fn inc(&amp;mut self) { self.x += 1; self.y += 1; } } fn map_any(mut any: Box&lt;dyn Any>) -> Box&lt;dyn Any> { if let Some(num) = any.downcast_mut::&lt;i32>() { *num += 1; } else if let Some(string) = any.downcast_mut::&lt;String>() { *string += "!"; } else if let Some(point) = any.downcast_mut::&lt;Point>() { point.inc(); } any } fn main() { let mut vec: Vec&lt;Box&lt;dyn Any>> = vec![ Box::new(0), Box::new(String::from("a")), Box::new(Point::default()), ]; // vec = [0, "a", Point { x: 0, y: 0 }] vec = vec.into_iter().map(map_any).collect(); // vec = [1, "a!", Point { x: 1, y: 1 }] } This trait rarely needs to be used because on top of parametric polymorphism being superior to ad-hoc polymorphism in most scenarios the latter can also be emulated using enums which are more type-safe and require less indirection. For example, we could have written the above example like this:
#[derive(Default)] struct Point { x: i32, y: i32, } impl Point { fn inc(&amp;mut self) { self.x += 1; self.y += 1; } } enum Stuff { Integer(i32), String(String), Point(Point), } fn map_stuff(mut stuff: Stuff) -> Stuff { match &amp;mut stuff { Stuff::Integer(num) => *num += 1, Stuff::String(string) => *string += "!", Stuff::Point(point) => point.inc(), } stuff } fn main() { let mut vec = vec![ Stuff::Integer(0), Stuff::String(String::from("a")), Stuff::Point(Point::default()), ]; // vec = [0, "a", Point { x: 0, y: 0 }] vec = vec.into_iter().map(map_stuff).collect(); // vec = [1, "a!", Point { x: 1, y: 1 }] } Despite Any rarely being needed it can still be convenient to use sometimes, as we&rsquo;ll later see in the Error Handling section.
Formatting Traits We can serialize types into strings using the formatting macros in std::fmt, the most well-known of the bunch being println!. We can pass formatting parameters to the {} placeholders used within format strs which are then used to select which trait impl to use to serialize the placeholder&rsquo;s argument.
Trait Placeholder Description Display {} display representation Debug {:?} debug representation Octal {:o} octal representation LowerHex {:x} lowercase hex representation UpperHex {:X} uppercase hex representation Pointer {:p} memory address Binary {:b} binary representation LowerExp {:e} lowercase exponential representation UpperExp {:E} uppercase exponential representation Display &amp; ToString Prerequisites
Self Methods Generic Blanket Impls trait Display { fn fmt(&amp;self, f: &amp;mut Formatter&lt;'_>) -> Result; } Display types can be serialized into Strings which are friendly to the end users of the program. Example impl for Point:
use std::fmt; #[derive(Default)] struct Point { x: i32, y: i32, } impl fmt::Display for Point { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { write!(f, "({}, {})", self.x, self.y) } } fn main() { println!("origin: {}", Point::default()); // prints "origin: (0, 0)" // get Point's Display representation as a String let stringified_point = format!("{}", Point::default()); assert_eq!("(0, 0)", stringified_point); // ✅ } Aside from using the format! macro to get a type&rsquo;s display representation as a String we can use the ToString trait:
trait ToString { fn to_string(&amp;self) -> String; } There&rsquo;s no need for us to impl this ourselves. In fact we can&rsquo;t, because of this generic blanket impl that automatically impls ToString for any type which impls Display:
impl&lt;T: Display + ?Sized> ToString for T; Using ToString with Point:
#[test] // ✅ fn display_point() { let origin = Point::default(); assert_eq!(format!("{}", origin), "(0, 0)"); } #[test] // ✅ fn point_to_string() { let origin = Point::default(); assert_eq!(origin.to_string(), "(0, 0)"); } #[test] // ✅ fn display_equals_to_string() { let origin = Point::default(); assert_eq!(format!("{}", origin), origin.to_string()); } Debug Prerequisites
Self Methods Derive Macros Display &amp; ToString trait Debug { fn fmt(&amp;self, f: &amp;mut Formatter&lt;'_>) -> Result; } Debug has an identical signature to Display. The only difference is that the Debug impl is called when we use the {:?} formatting specifier. Debug can be derived:
use std::fmt; #[derive(Debug)] struct Point { x: i32, y: i32, } // derive macro generates impl below impl fmt::Debug for Point { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { f.debug_struct("Point") .field("x", &amp;self.x) .field("y", &amp;self.y) .finish() } } Impling Debug for a type also allows it to be used within the dbg! macro which is superior to println! for quick and dirty print logging. Some of its advantages:
dbg! prints to stderr instead of stdout so the debug logs are easy to separate from the actual stdout output of our program. dbg! prints the expression passed to it as well as the value the expression evaluated to. dbg! takes ownership of its arguments and returns them so you can use it within expressions: fn some_condition() -> bool { true } // no logging fn example() { if some_condition() { // some code } } // println! logging fn example_println() { // 🤦 let result = some_condition(); println!("{}", result); // just prints "true" if result { // some code } } // dbg! logging fn example_dbg() { // 😍 if dbg!(some_condition()) { // prints "[src/main.rs:22] some_condition() = true" // some code } } The only downside is that dbg! isn&rsquo;t automatically stripped in release builds so we have to manually remove it from our code if we don&rsquo;t want to ship it in the final executable.
Operator Traits All operators in Rust are associated with traits. If we&rsquo;d like to impl operators for our types we have to impl the associated traits.
Trait(s) Category Operator(s) Description Eq, PartialEq comparison == equality Ord, PartialOrd comparison &lt;, >, &lt;=, >= comparison Add arithmetic + addition AddAssign arithmetic += addition assignment BitAnd arithmetic &amp; bitwise AND BitAndAssign arithmetic &amp;= bitwise assignment BitXor arithmetic ^ bitwise XOR BitXorAssign arithmetic ^= bitwise XOR assignment Div arithmetic / division DivAssign arithmetic /= division assignment Mul arithmetic * multiplication MulAssign arithmetic *= multiplication assignment Neg arithmetic - unary negation Not arithmetic ! unary logical negation Rem arithmetic % remainder RemAssign arithmetic %= remainder assignment Shl arithmetic &lt;&lt; left shift ShlAssign arithmetic &lt;&lt;= left shift assignment Shr arithmetic >> right shift ShrAssign arithmetic >>= right shift assignment Sub arithmetic - subtraction SubAssign arithmetic -= subtraction assignment Fn closure (...args) immutable closure invocation FnMut closure (...args) mutable closure invocation FnOnce closure (...args) one-time closure invocation Deref other * immutable dereference DerefMut other * mutable derenence Drop other - type destructor Index other [] immutable index IndexMut other [] mutable index RangeBounds other .. range Comparison Traits Trait(s) Category Operator(s) Description Eq, PartialEq comparison == equality Ord, PartialOrd comparison &lt;, >, &lt;=, >= comparison PartialEq &amp; Eq Prerequisites
Self Methods Generic Parameters Default Impls Generic Blanket Impls Marker Traits Subtraits &amp; Supertraits Sized trait PartialEq&lt;Rhs = Self> where Rhs: ?Sized, { fn eq(&amp;self, other: &amp;Rhs) -> bool; // provided default impls fn ne(&amp;self, other: &amp;Rhs) -> bool; } PartialEq&lt;Rhs> types can be checked for equality to Rhs types using the == operator.
All PartialEq&lt;Rhs> impls must ensure that equality is symmetric and transitive. That means for all a, b, and c:
a == b implies b == a (symmetry) a == b &amp;&amp; b == c implies a == c (transitivity) By default Rhs = Self because we almost always want to compare instances of a type to each other, and not to instances of different types. This also automatically guarantees our impl is symmetric and transitive.
struct Point { x: i32, y: i32 } // Rhs == Self == Point impl PartialEq for Point { // impl automatically symmetric &amp; transitive fn eq(&amp;self, other: &amp;Point) -> bool { self.x == other.x &amp;&amp; self.y == other.y } } If all the members of a type impl PartialEq then it can be derived:
#[derive(PartialEq)] struct Point { x: i32, y: i32 } #[derive(PartialEq)] enum Suit { Spade, Heart, Club, Diamond, } Once we impl PartialEq for our type we also get equality comparisons between references of our type for free thanks to these generic blanket impls:
// this impl only gives us: Point == Point #[derive(PartialEq)] struct Point { x: i32, y: i32 } // all of the generic blanket impls below // are provided by the standard library // this impl gives us: &amp;Point == &amp;Point impl&lt;A, B> PartialEq&lt;&amp;'_ B> for &amp;'_ A where A: PartialEq&lt;B> + ?Sized, B: ?Sized; // this impl gives us: &amp;mut Point == &amp;Point impl&lt;A, B> PartialEq&lt;&amp;'_ B> for &amp;'_ mut A where A: PartialEq&lt;B> + ?Sized, B: ?Sized; // this impl gives us: &amp;Point == &amp;mut Point impl&lt;A, B> PartialEq&lt;&amp;'_ mut B> for &amp;'_ A where A: PartialEq&lt;B> + ?Sized, B: ?Sized; // this impl gives us: &amp;mut Point == &amp;mut Point impl&lt;A, B> PartialEq&lt;&amp;'_ mut B> for &amp;'_ mut A where A: PartialEq&lt;B> + ?Sized, B: ?Sized; Since this trait is generic we can define equality between different types. The standard library leverages this to allow checking equality between the many string-like types such as String, &amp;str, PathBuf, &amp;Path, OsString, &amp;OsStr, and so on.
Generally, we should only impl equality between different types if they contain the same kind of data and the only difference between the types is how they represent the data or how they allow interacting with the data.
Here&rsquo;s a cute but bad example of how someone might be tempted to impl PartialEq to check equality between different types that don&rsquo;t meet the above criteria:
#[derive(PartialEq)] enum Suit { Spade, Club, Heart, Diamond, } #[derive(PartialEq)] enum Rank { Ace, Two, Three, Four, Five, Six, Seven, Eight, Nine, Ten, Jack, Queen, King, } #[derive(PartialEq)] struct Card { suit: Suit, rank: Rank, } // check equality of Card's suit impl PartialEq&lt;Suit> for Card { fn eq(&amp;self, other: &amp;Suit) -> bool { self.suit == *other } } // check equality of Card's rank impl PartialEq&lt;Rank> for Card { fn eq(&amp;self, other: &amp;Rank) -> bool { self.rank == *other } } fn main() { let AceOfSpades = Card { suit: Suit::Spade, rank: Rank::Ace, }; assert!(AceOfSpades == Suit::Spade); // ✅ assert!(AceOfSpades == Rank::Ace); // ✅ } It works and kinda makes sense. A card which is an Ace of Spades is both an Ace and a Spade, and if we&rsquo;re writing a library to handle playing cards it&rsquo;s reasonable that we&rsquo;d want to make it easy and convenient to individually check the suit and rank of a card. However, something&rsquo;s missing: symmetry! We can Card == Suit and Card == Rank but we cannot Suit == Card or Rank == Card so let&rsquo;s fix that:
// check equality of Card's suit impl PartialEq&lt;Suit> for Card { fn eq(&amp;self, other: &amp;Suit) -> bool { self.suit == *other } } // added for symmetry impl PartialEq&lt;Card> for Suit { fn eq(&amp;self, other: &amp;Card) -> bool { *self == other.suit } } // check equality of Card's rank impl PartialEq&lt;Rank> for Card { fn eq(&amp;self, other: &amp;Rank) -> bool { self.rank == *other } } // added for symmetry impl PartialEq&lt;Card> for Rank { fn eq(&amp;self, other: &amp;Card) -> bool { *self == other.rank } } We have symmetry! Great. Adding symmetry just broke transitivity! Oops. This is now possible:
fn main() { // Ace of Spades let a = Card { suit: Suit::Spade, rank: Rank::Ace, }; let b = Suit::Spade; // King of Spades let c = Card { suit: Suit::Spade, rank: Rank::King, }; assert!(a == b &amp;&amp; b == c); // ✅ assert!(a == c); // ❌ } A good example of impling PartialEq to check equality between different types would be a program that works with distances and uses different types to represent different units of measurement.
#[derive(PartialEq)] struct Foot(u32); #[derive(PartialEq)] struct Yard(u32); #[derive(PartialEq)] struct Mile(u32); impl PartialEq&lt;Mile> for Foot { fn eq(&amp;self, other: &amp;Mile) -> bool { self.0 == other.0 * 5280 } } impl PartialEq&lt;Foot> for Mile { fn eq(&amp;self, other: &amp;Foot) -> bool { self.0 * 5280 == other.0 } } impl PartialEq&lt;Mile> for Yard { fn eq(&amp;self, other: &amp;Mile) -> bool { self.0 == other.0 * 1760 } } impl PartialEq&lt;Yard> for Mile { fn eq(&amp;self, other: &amp;Yard) -> bool { self.0 * 1760 == other.0 } } impl PartialEq&lt;Foot> for Yard { fn eq(&amp;self, other: &amp;Foot) -> bool { self.0 * 3 == other.0 } } impl PartialEq&lt;Yard> for Foot { fn eq(&amp;self, other: &amp;Yard) -> bool { self.0 == other.0 * 3 } } fn main() { let a = Foot(5280); let b = Yard(1760); let c = Mile(1); // symmetry assert!(a == b &amp;&amp; b == a); // ✅ assert!(b == c &amp;&amp; c == b); // ✅ assert!(a == c &amp;&amp; c == a); // ✅ // transitivity assert!(a == b &amp;&amp; b == c &amp;&amp; a == c); // ✅ assert!(c == b &amp;&amp; b == a &amp;&amp; c == a); // ✅ } Eq is a marker trait and a subtrait of PartialEq&lt;Self>.
trait Eq: PartialEq&lt;Self> {} If we impl Eq for a type, on top of the symmetry &amp; transitivity properties required by PartialEq, we&rsquo;re also guaranteeing reflexivity, i.e. a == a for all a. In this sense Eq refines PartialEq because it represents a stricter version of equality. If all members of a type impl Eq then the Eq impl can be derived for the type.
Floats are PartialEq but not Eq because NaN != NaN. Almost all other PartialEq types are trivially Eq, unless of course if they contain floats.
Once a type impls PartialEq and Debug we can use it in the assert_eq! macro. We can also compare collections of PartialEq types.
#[derive(PartialEq, Debug)] struct Point { x: i32, y: i32, } fn example_assert(p1: Point, p2: Point) { assert_eq!(p1, p2); } fn example_compare_collections&lt;T: PartialEq>(vec1: Vec&lt;T>, vec2: Vec&lt;T>) { // if T: PartialEq this now works! if vec1 == vec2 { // some code } else { // other code } } Hash Prerequisites
Self Methods Generic Parameters Default Impls Derive Macros PartialEq &amp; Eq trait Hash { fn hash&lt;H: Hasher>(&amp;self, state: &amp;mut H); // provided default impls fn hash_slice&lt;H: Hasher>(data: &amp;[Self], state: &amp;mut H); } This trait is not associated with any operator, but the best time to talk about it is right after PartialEq &amp; Eq so here it is. Hash types can be hashed using a Hasher.
use std:#️⃣:Hasher; use std:#️⃣:Hash; struct Point { x: i32, y: i32, } impl Hash for Point { fn hash&lt;H: Hasher>(&amp;self, hasher: &amp;mut H) { hasher.write_i32(self.x); hasher.write_i32(self.y); } } There&rsquo;s a derive macro which generates the same impl as above:
#[derive(Hash)] struct Point { x: i32, y: i32, } If a type impls both Hash and Eq those impls must agree with each other such that for all a and b if a == b then a.hash() == b.hash(). So we should always use the derive macro to impl both or manually impl both, but not mix the two, otherwise we risk breaking the above invariant.
The main benefit of impling Eq and Hash for a type is that it allows us to store that type as keys in HashMaps and HashSets.
use std::collections::HashSet; // now our type can be stored // in HashSets and HashMaps! #[derive(PartialEq, Eq, Hash)] struct Point { x: i32, y: i32, } fn example_hashset() { let mut points = HashSet::new(); points.insert(Point { x: 0, y: 0 }); // ✅ } PartialOrd &amp; Ord Prerequisites
Self Methods Generic Parameters Default Impls Subtraits &amp; Supertraits Derive Macros Sized PartialEq &amp; Eq enum Ordering { Less, Equal, Greater, } trait PartialOrd&lt;Rhs = Self>: PartialEq&lt;Rhs> where Rhs: ?Sized, { fn partial_cmp(&amp;self, other: &amp;Rhs) -> Option&lt;Ordering>; // provided default impls fn lt(&amp;self, other: &amp;Rhs) -> bool; fn le(&amp;self, other: &amp;Rhs) -> bool; fn gt(&amp;self, other: &amp;Rhs) -> bool; fn ge(&amp;self, other: &amp;Rhs) -> bool; } PartialOrd&lt;Rhs> types can be compared to Rhs types using the &lt;, &lt;=, >, and >= operators.
All PartialOrd impls must ensure that comparisons are asymmetric and transitive. That means for all a, b, and c:
a &lt; b implies !(a > b) (asymmetry) a &lt; b &amp;&amp; b &lt; c implies a &lt; c (transitivity) PartialOrd is a subtrait of PartialEq and their impls must always agree with each other.
fn must_always_agree&lt;T: PartialOrd + PartialEq>(t1: T, t2: T) { assert_eq!(t1.partial_cmp(&amp;t2) == Some(Ordering::Equal), t1 == t2); } PartialOrd refines PartialEq in the sense that when comparing PartialEq types we can check if they are equal or not equal, but when comparing PartialOrd types we can check if they are equal or not equal, and if they are not equal we can check if they are unequal because the first item is less than or greater than the second item.
By default Rhs = Self because we almost always want to compare instances of a type to each other, and not to instances of different types. This also automatically guarantees our impl is symmetric and transitive.
use std::cmp::Ordering; #[derive(PartialEq, PartialOrd)] struct Point { x: i32, y: i32 } // Rhs == Self == Point impl PartialOrd for Point { // impl automatically symmetric &amp; transitive fn partial_cmp(&amp;self, other: &amp;Point) -> Option&lt;Ordering> { Some(match self.x.cmp(&amp;other.x) { Ordering::Equal => self.y.cmp(&amp;other.y), ordering => ordering, }) } } If all the members of a type impl PartialOrd then it can be derived:
#[derive(PartialEq, PartialOrd)] struct Point { x: i32, y: i32, } #[derive(PartialEq, PartialOrd)] enum Stoplight { Red, Yellow, Green, } The PartialOrd derive macro orders types based on the lexicographical order of their members:
// generates PartialOrd impl which orders // Points based on x member first and // y member second because that's the order // they appear in the source code #[derive(PartialOrd, PartialEq)] struct Point { x: i32, y: i32, } // generates DIFFERENT PartialOrd impl // which orders Points based on y member // first and x member second #[derive(PartialOrd, PartialEq)] struct Point { y: i32, x: i32, } Ord is a subtrait of Eq and PartialOrd&lt;Self>:
trait Ord: Eq + PartialOrd&lt;Self> { fn cmp(&amp;self, other: &amp;Self) -> Ordering; // provided default impls fn max(self, other: Self) -> Self; fn min(self, other: Self) -> Self; fn clamp(self, min: Self, max: Self) -> Self; } If we impl Ord for a type, on top of the asymmetry &amp; transitivity properties required by PartialOrd, we&rsquo;re also guaranteeing that the asymmetry is total, i.e. exactly one of a &lt; b, a == b or a > b is true for any given a and b. In this sense Ord refines Eq and PartialOrd because it represents a stricter version of comparisons. If a type impls Ord we can use that impl to trivially impl PartialOrd, PartialEq, and Eq:
use std::cmp::Ordering; // of course we can use the derive macros here #[derive(Ord, PartialOrd, Eq, PartialEq)] struct Point { x: i32, y: i32, } // note: as with PartialOrd, the Ord derive macro // orders a type based on the lexicographical order // of its members // but here's the impls if we wrote them out by hand impl Ord for Point { fn cmp(&amp;self, other: &amp;Self) -> Ordering { match self.x.cmp(&amp;self.y) { Ordering::Equal => self.y.cmp(&amp;self.y), ordering => ordering, } } } impl PartialOrd for Point { fn partial_cmp(&amp;self, other: &amp;Self) -> Option&lt;Ordering> { Some(self.cmp(other)) } } impl PartialEq for Point { fn eq(&amp;self, other: &amp;Self) -> bool { self.cmp(other) == Ordering::Equal } } impl Eq for Point {} Floats impl PartialOrd but not Ord because both NaN &lt; 0 == false and NaN >= 0 == false are simultaneously true. Almost all other PartialOrd types are trivially Ord, unless of course if they contain floats.
Once a type impls Ord we can store it in BTreeMaps and BTreeSets as well as easily sort it using the sort() method on slices and any types which deref to slices such as arrays, Vecs, and VecDeques.
use std::collections::BTreeSet; // now our type can be stored // in BTreeSets and BTreeMaps! #[derive(Ord, PartialOrd, PartialEq, Eq)] struct Point { x: i32, y: i32, } fn example_btreeset() { let mut points = BTreeSet::new(); points.insert(Point { x: 0, y: 0 }); // ✅ } // we can also .sort() Ord types in collections! fn example_sort&lt;T: Ord>(mut sortable: Vec&lt;T>) -> Vec&lt;T> { sortable.sort(); sortable } Arithmetic Traits Trait(s) Category Operator(s) Description Add arithmetic + addition AddAssign arithmetic += addition assignment BitAnd arithmetic &amp; bitwise AND BitAndAssign arithmetic &amp;= bitwise assignment BitXor arithmetic ^ bitwise XOR BitXorAssign arithmetic ^= bitwise XOR assignment Div arithmetic / division DivAssign arithmetic /= division assignment Mul arithmetic * multiplication MulAssign arithmetic *= multiplication assignment Neg arithmetic - unary negation Not arithmetic ! unary logical negation Rem arithmetic % remainder RemAssign arithmetic %= remainder assignment Shl arithmetic &lt;&lt; left shift ShlAssign arithmetic &lt;&lt;= left shift assignment Shr arithmetic >> right shift ShrAssign arithmetic >>= right shift assignment Sub arithmetic - subtraction SubAssign arithmetic -= subtraction assignment Going over all of these would be very redundant. Most of these only apply to number types anyway. We&rsquo;ll only go over Add and AddAssign since the + operator is commonly overloaded to do other stuff like adding items to collections or concatenating things together, that way we cover the most interesting ground and don&rsquo;t repeat ourselves.
Add &amp; AddAssign Prerequisites
Self Methods Associated Types Generic Parameters Generic Types vs Associated Types Derive Macros trait Add&lt;Rhs = Self> { type Output; fn add(self, rhs: Rhs) -> Self::Output; } Add&lt;Rhs, Output = T> types can be added to Rhs types and will produce T as output.
Example Add&lt;Point, Output = Point> impl for Point:
#[derive(Clone, Copy)] struct Point { x: i32, y: i32, } impl Add for Point { type Output = Point; fn add(self, rhs: Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } fn main() { let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let p3 = p1 + p2; assert_eq!(p3.x, p1.x + p2.x); // ✅ assert_eq!(p3.y, p1.y + p2.y); // ✅ } But what if we only had references to Points? Can we still add them then? Let&rsquo;s try:
fn main() { let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let p3 = &amp;p1 + &amp;p2; // ❌ } Unfortunately not. The compiler throws:
error[E0369]: cannot add `&amp;Point` to `&amp;Point` --> src/main.rs:50:25 | 50 | let p3: Point = &amp;p1 + &amp;p2; | --- ^ --- &amp;Point | | | &amp;Point | = note: an implementation of `std::ops::Add` might be missing for `&amp;Point` Within Rust&rsquo;s type system, for some type T, the types T, &amp;T, and &amp;mut T are all treated as unique distinct types which means we have to provide trait impls for each of them separately. Let&rsquo;s define an Add impl for &amp;Point:
impl Add for &amp;Point { type Output = Point; fn add(self, rhs: &amp;Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } fn main() { let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let p3 = &amp;p1 + &amp;p2; // ✅ assert_eq!(p3.x, p1.x + p2.x); // ✅ assert_eq!(p3.y, p1.y + p2.y); // ✅ } However, something still doesn&rsquo;t feel quite right. We have two separate impls of Add for Point and &amp;Point and they happen to do the same thing currently but there&rsquo;s no guarantee that they will in the future! For example, let&rsquo;s say we decide that when we add two Points together we want to create a Line containing those two Points instead of creating a new Point, we&rsquo;d update our Add impl like this:
use std::ops::Add; #[derive(Copy, Clone)] struct Point { x: i32, y: i32, } #[derive(Copy, Clone)] struct Line { start: Point, end: Point, } // we updated this impl impl Add for Point { type Output = Line; fn add(self, rhs: Point) -> Line { Line { start: self, end: rhs, } } } // but forgot to update this impl, uh oh! impl Add for &amp;Point { type Output = Point; fn add(self, rhs: &amp;Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } fn main() { let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let line: Line = p1 + p2; // ✅ let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let line: Line = &amp;p1 + &amp;p2; // ❌ expected Line, found Point } Our current impl of Add for &amp;Point creates an unnecessary maintenance burden, we want the impl to match Point&rsquo;s impl without having to manually update it every time we change Point&rsquo;s impl. We&rsquo;d like to keep our code as DRY (Don&rsquo;t Repeat Yourself) as possible. Luckily this is achievable:
// updated, DRY impl impl Add for &amp;Point { type Output = &lt;Point as Add>::Output; fn add(self, rhs: &amp;Point) -> Self::Output { Point::add(*self, *rhs) } } fn main() { let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let line: Line = p1 + p2; // ✅ let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let line: Line = &amp;p1 + &amp;p2; // ✅ } AddAssign&lt;Rhs> types allow us to add + assign Rhs types to them. The trait declaration:
trait AddAssign&lt;Rhs = Self> { fn add_assign(&amp;mut self, rhs: Rhs); } Example impls for Point and &amp;Point:
use std::ops::AddAssign; #[derive(Copy, Clone)] struct Point { x: i32, y: i32 } impl AddAssign for Point { fn add_assign(&amp;mut self, rhs: Point) { self.x += rhs.x; self.y += rhs.y; } } impl AddAssign&lt;&amp;Point> for Point { fn add_assign(&amp;mut self, rhs: &amp;Point) { Point::add_assign(self, *rhs); } } fn main() { let mut p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; p1 += &amp;p2; p1 += p2; assert!(p1.x == 7 &amp;&amp; p1.y == 10); } Closure Traits Trait(s) Category Operator(s) Description Fn closure (...args) immutable closure invocation FnMut closure (...args) mutable closure invocation FnOnce closure (...args) one-time closure invocation FnOnce, FnMut, &amp; Fn Prerequisites
Self Methods Associated Types Generic Parameters Generic Types vs Associated Types Subtraits &amp; Supertraits trait FnOnce&lt;Args> { type Output; fn call_once(self, args: Args) -> Self::Output; } trait FnMut&lt;Args>: FnOnce&lt;Args> { fn call_mut(&amp;mut self, args: Args) -> Self::Output; } trait Fn&lt;Args>: FnMut&lt;Args> { fn call(&amp;self, args: Args) -> Self::Output; } Although these traits exist it&rsquo;s not possible to impl them for our own types in stable Rust. The only types we can create which impl these traits are closures. Depending on what the closure captures from its environment determines whether it impls FnOnce, FnMut, or Fn.
An FnOnce closure can only be called once because it consumes some value as part of its execution:
fn main() { let range = 0..10; let get_range_count = || range.count(); assert_eq!(get_range_count(), 10); // ✅ get_range_count(); // ❌ } The .count() method on iterators consumes the iterator so it can only be called once. Hence our closure can only be called once. Which is why when we try to call it a second time we get this error:
error[E0382]: use of moved value: `get_range_count` --> src/main.rs:5:5 | 4 | assert_eq!(get_range_count(), 10); | ----------------- `get_range_count` moved due to this call 5 | get_range_count(); | ^^^^^^^^^^^^^^^ value used here after move | note: closure cannot be invoked more than once because it moves the variable `range` out of its environment --> src/main.rs:3:30 | 3 | let get_range_count = || range.count(); | ^^^^^ note: this value implements `FnOnce`, which causes it to be moved when called --> src/main.rs:4:16 | 4 | assert_eq!(get_range_count(), 10); | ^^^^^^^^^^^^^^^ An FnMut closure can be called multiple times and can also mutate variables it has captured from its environment. We might say FnMut closures perform side-effects or are stateful. Here&rsquo;s an example of a closure that filters out all non-ascending values from an iterator by keeping track of the smallest value it has seen so far:
fn main() { let nums = vec![0, 4, 2, 8, 10, 7, 15, 18, 13]; let mut min = i32::MIN; let ascending = nums.into_iter().filter(|&amp;n| { if n &lt;= min { false } else { min = n; true } }).collect::&lt;Vec&lt;_>>(); assert_eq!(vec![0, 4, 8, 10, 15, 18], ascending); // ✅ } FnMut refines FnOnce in the sense that FnOnce requires taking ownership of its arguments and can only be called once, but FnMut requires only taking mutable references and can be called multiple times. FnMut can be used anywhere FnOnce can be used.
An Fn closure can be called multiple times and does not mutate any variables it has captured from its environment. We might say Fn closures have no side-effects or are stateless. Here&rsquo;s an example closure that filters out all values less than some stack variable it captures from its environment from an iterator:
fn main() { let nums = vec![0, 4, 2, 8, 10, 7, 15, 18, 13]; let min = 9; let greater_than_9 = nums.into_iter().filter(|&amp;n| n > min).collect::&lt;Vec&lt;_>>(); assert_eq!(vec![10, 15, 18, 13], greater_than_9); // ✅ } Fn refines FnMut in the sense that FnMut requires mutable references and can be called multiple times, but Fn only requires immutable references and can be called multiple times. Fn can be used anywhere FnMut can be used, which includes anywhere FnOnce can be used.
If a closure doesn&rsquo;t capture anything from its environment it&rsquo;s technically not a closure, but just an anonymously declared inline function, and can be casted to, used, and passed around as a regular function pointer, i.e. fn. Function pointers can be used anywhere Fn can be used, which includes anwhere FnMut and FnOnce can be used.
fn add_one(x: i32) -> i32 { x + 1 } fn main() { let mut fn_ptr: fn(i32) -> i32 = add_one; assert_eq!(fn_ptr(1), 2); // ✅ // capture-less closure cast to fn pointer fn_ptr = |x| x + 1; // same as add_one assert_eq!(fn_ptr(1), 2); // ✅ } Example of passing a regular function pointer in place of a closure:
fn main() { let nums = vec![-1, 1, -2, 2, -3, 3]; let absolutes: Vec&lt;i32> = nums.into_iter().map(i32::abs).collect(); assert_eq!(vec![1, 1, 2, 2, 3, 3], absolutes); // ✅ } Other Traits Trait(s) Category Operator(s) Description Deref other * immutable dereference DerefMut other * mutable derenence Drop other - type destructor Index other [] immutable index IndexMut other [] mutable index RangeBounds other .. range Deref &amp; DerefMut Prerequisites
Self Methods Associated Types Subtraits &amp; Supertraits Sized trait Deref { type Target: ?Sized; fn deref(&amp;self) -> &amp;Self::Target; } trait DerefMut: Deref { fn deref_mut(&amp;mut self) -> &amp;mut Self::Target; } Deref&lt;Target = T> types can dereferenced to T types using the dereference operator *. This has obvious use-cases for smart pointer types like Box and Rc. However, we rarely see the dereference operator explicitly used in Rust code, and that&rsquo;s because of a Rust feature called deref coercion.
Rust automatically dereferences types when they&rsquo;re being passed as function arguments, returned from a function, or used as part of a method call. This is the reason why we can pass &amp;String and &amp;Vec&lt;T> to functions expecting &amp;str and &amp;[T] because String impls Deref&lt;Target = str> and Vec&lt;T> impls Deref&lt;Target = [T]>.
Deref and DerefMut should only be implemented for smart pointer types. The most common way people attempt to misuse and abuse these traits is to try to shoehorn some kind of OOP-style data inheritance into Rust. This does not work. Rust is not OOP. Let&rsquo;s examine a few different situations where, how, and why it does not work. Let&rsquo;s start with this example:
use std::ops::Deref; struct Human { health_points: u32, } enum Weapon { Spear, Axe, Sword, } // a Soldier is just a Human with a Weapon struct Soldier { human: Human, weapon: Weapon, } impl Deref for Soldier { type Target = Human; fn deref(&amp;self) -> &amp;Human { &amp;self.human } } enum Mount { Horse, Donkey, Cow, } // a Knight is just a Soldier with a Mount struct Knight { soldier: Soldier, mount: Mount, } impl Deref for Knight { type Target = Soldier; fn deref(&amp;self) -> &amp;Soldier { &amp;self.soldier } } enum Spell { MagicMissile, FireBolt, ThornWhip, } // a Mage is just a Human who can cast Spells struct Mage { human: Human, spells: Vec&lt;Spell>, } impl Deref for Mage { type Target = Human; fn deref(&amp;self) -> &amp;Human { &amp;self.human } } enum Staff { Wooden, Metallic, Plastic, } // a Wizard is just a Mage with a Staff struct Wizard { mage: Mage, staff: Staff, } impl Deref for Wizard { type Target = Mage; fn deref(&amp;self) -> &amp;Mage { &amp;self.mage } } fn borrows_human(human: &amp;Human) {} fn borrows_soldier(soldier: &amp;Soldier) {} fn borrows_knight(knight: &amp;Knight) {} fn borrows_mage(mage: &amp;Mage) {} fn borrows_wizard(wizard: &amp;Wizard) {} fn example(human: Human, soldier: Soldier, knight: Knight, mage: Mage, wizard: Wizard) { // all types can be used as Humans borrows_human(&amp;human); borrows_human(&amp;soldier); borrows_human(&amp;knight); borrows_human(&amp;mage); borrows_human(&amp;wizard); // Knights can be used as Soldiers borrows_soldier(&amp;soldier); borrows_soldier(&amp;knight); // Wizards can be used as Mages borrows_mage(&amp;mage); borrows_mage(&amp;wizard); // Knights &amp; Wizards passed as themselves borrows_knight(&amp;knight); borrows_wizard(&amp;wizard); } So at first glance the above looks pretty good! However it quickly breaks down to scrutiny. First of all, deref coercion only works on references, so it doesn&rsquo;t work when we actually want to pass ownership:
fn takes_human(human: Human) {} fn example(human: Human, soldier: Soldier, knight: Knight, mage: Mage, wizard: Wizard) { // all types CANNOT be used as Humans takes_human(human); takes_human(soldier); // ❌ takes_human(knight); // ❌ takes_human(mage); // ❌ takes_human(wizard); // ❌ } Furthermore, deref coercion doesn&rsquo;t work in generic contexts. Let&rsquo;s say we impl some trait only on humans:
trait Rest { fn rest(&amp;self); } impl Rest for Human { fn rest(&amp;self) {} } fn take_rest&lt;T: Rest>(rester: &amp;T) { rester.rest() } fn example(human: Human, soldier: Soldier, knight: Knight, mage: Mage, wizard: Wizard) { // all types CANNOT be used as Rest types, only Human take_rest(&amp;human); take_rest(&amp;soldier); // ❌ take_rest(&amp;knight); // ❌ take_rest(&amp;mage); // ❌ take_rest(&amp;wizard); // ❌ } Also, although deref coercion works in a lot of places it doesn&rsquo;t work everywhere. It doesn&rsquo;t work on operands, even though operators are just syntax sugar for method calls. Let&rsquo;s say, to be cute, we wanted Mages to learn Spells using the += operator:
impl DerefMut for Wizard { fn deref_mut(&amp;mut self) -> &amp;mut Mage { &amp;mut self.mage } } impl AddAssign&lt;Spell> for Mage { fn add_assign(&amp;mut self, spell: Spell) { self.spells.push(spell); } } fn example(mut mage: Mage, mut wizard: Wizard, spell: Spell) { mage += spell; wizard += spell; // ❌ wizard not coerced to mage here wizard.add_assign(spell); // oof, we have to call it like this 🤦 } In languages with OOP-style data inheritance the value of self within a method is always equal to the type which called the method but in the case of Rust the value of self is always equal to the type which implemented the method:
struct Human { profession: &amp;'static str, health_points: u32, } impl Human { // self will always be a Human here, even if we call it on a Soldier fn state_profession(&amp;self) { println!("I'm a {}!", self.profession); } } struct Soldier { profession: &amp;'static str, human: Human, weapon: Weapon, } fn example(soldier: &amp;Soldier) { assert_eq!("servant", soldier.human.profession); assert_eq!("spearman", soldier.profession); soldier.human.state_profession(); // prints "I'm a servant!" soldier.state_profession(); // still prints "I'm a servant!" 🤦 } The above gotcha is especially damning when impling Deref or DerefMut on a newtype. Let&rsquo;s say we want to create a SortedVec type which is just a Vec but it&rsquo;s always in sorted order. Here&rsquo;s how we might do that:
struct SortedVec&lt;T: Ord>(Vec&lt;T>); impl&lt;T: Ord> SortedVec&lt;T> { fn new(mut vec: Vec&lt;T>) -> Self { vec.sort(); SortedVec(vec) } fn push(&amp;mut self, t: T) { self.0.push(t); self.0.sort(); } } Obviously we cannot impl DerefMut&lt;Target = Vec&lt;T>> here or anyone using SortedVec would be able to trivially break the sorted order. However, impling Deref&lt;Target = Vec&lt;T>> surely must be safe, right? Try to spot the bug in the program below:
use std::ops::Deref; struct SortedVec&lt;T: Ord>(Vec&lt;T>); impl&lt;T: Ord> SortedVec&lt;T> { fn new(mut vec: Vec&lt;T>) -> Self { vec.sort(); SortedVec(vec) } fn push(&amp;mut self, t: T) { self.0.push(t); self.0.sort(); } } impl&lt;T: Ord> Deref for SortedVec&lt;T> { type Target = Vec&lt;T>; fn deref(&amp;self) -> &amp;Vec&lt;T> { &amp;self.0 } } fn main() { let sorted = SortedVec::new(vec![2, 8, 6, 3]); sorted.push(1); let sortedClone = sorted.clone(); sortedClone.push(4); } We never implemented Clone for SortedVec so when we call the .clone() method the compiler is using deref coercion to resolve that method call on Vec and so it returns a Vec and not a SortedVec!
fn main() { let sorted: SortedVec&lt;i32> = SortedVec::new(vec![2, 8, 6, 3]); sorted.push(1); // still sorted // calling clone on SortedVec actually returns a Vec 🤦 let sortedClone: Vec&lt;i32> = sorted.clone(); sortedClone.push(4); // sortedClone no longer sorted 💀 } Anyway, none of the above limitations, constraints, or gotchas are faults of Rust because Rust was never designed to be an OO language or to support any OOP patterns in the first place.
The main takeaway from this section is do not try to be cute or clever with Deref and DerefMut impls. They&rsquo;re really only appropriate for smart pointer types, which can only be implemented within the standard library for now as smart pointer types currently require unstable features and compiler magic to work. If we want functionality and behavior similar to Deref and DerefMut then what we&rsquo;re actually probably looking for is AsRef and AsMut which we&rsquo;ll get to later.
Index &amp; IndexMut Prerequisites
Self Methods Associated Types Generic Parameters Generic Types vs Associated Types Subtraits &amp; Supertraits Sized trait Index&lt;Idx: ?Sized> { type Output: ?Sized; fn index(&amp;self, index: Idx) -> &amp;Self::Output; } trait IndexMut&lt;Idx>: Index&lt;Idx> where Idx: ?Sized { fn index_mut(&amp;mut self, index: Idx) -> &amp;mut Self::Output; } We can index [] into Index&lt;T, Output = U> types with T values and the index operation will return &amp;U values. For syntax sugar, the compiler auto inserts a deref operator * in front of any value returned from an index operation:
fn main() { // Vec&lt;i32> impls Index&lt;usize, Output = i32> so // indexing Vec&lt;i32> should produce &amp;i32s and yet... let vec = vec![1, 2, 3, 4, 5]; let num_ref: &amp;i32 = vec[0]; // ❌ expected &amp;i32 found i32 // above line actually desugars to let num_ref: &amp;i32 = *vec[0]; // ❌ expected &amp;i32 found i32 // both of these alternatives work let num: i32 = vec[0]; // ✅ let num_ref = &amp;vec[0]; // ✅ } It&rsquo;s kinda confusing at first, because it seems like the Index trait does not follow its own method signature, but really it&rsquo;s just questionable syntax sugar.
Since Idx is a generic type the Index trait can be implemented many times for a given type, and in the case of Vec&lt;T> not only can we index into it using usize but we can also index into its using Range&lt;usize>s to get slices.
fn main() { let vec = vec![1, 2, 3, 4, 5]; assert_eq!(&amp;vec[..], &amp;[1, 2, 3, 4, 5]); // ✅ assert_eq!(&amp;vec[1..], &amp;[2, 3, 4, 5]); // ✅ assert_eq!(&amp;vec[..4], &amp;[1, 2, 3, 4]); // ✅ assert_eq!(&amp;vec[1..4], &amp;[2, 3, 4]); // ✅ } To show off how we might impl Index ourselves here&rsquo;s a fun example which shows how we can use a newtype and the Index trait to impl wrapping indexes and negative indexes on a Vec:
use std::ops::Index; struct WrappingIndex&lt;T>(Vec&lt;T>); impl&lt;T> Index&lt;usize> for WrappingIndex&lt;T> { type Output = T; fn index(&amp;self, index: usize) -> &amp;T { &amp;self.0[index % self.0.len()] } } impl&lt;T> Index&lt;i128> for WrappingIndex&lt;T> { type Output = T; fn index(&amp;self, index: i128) -> &amp;T { let self_len = self.0.len() as i128; let idx = (((index % self_len) + self_len) % self_len) as usize; &amp;self.0[idx] } } #[test] // ✅ fn indexes() { let wrapping_vec = WrappingIndex(vec![1, 2, 3]); assert_eq!(1, wrapping_vec[0_usize]); assert_eq!(2, wrapping_vec[1_usize]); assert_eq!(3, wrapping_vec[2_usize]); } #[test] // ✅ fn wrapping_indexes() { let wrapping_vec = WrappingIndex(vec![1, 2, 3]); assert_eq!(1, wrapping_vec[3_usize]); assert_eq!(2, wrapping_vec[4_usize]); assert_eq!(3, wrapping_vec[5_usize]); } #[test] // ✅ fn neg_indexes() { let wrapping_vec = WrappingIndex(vec![1, 2, 3]); assert_eq!(1, wrapping_vec[-3_i128]); assert_eq!(2, wrapping_vec[-2_i128]); assert_eq!(3, wrapping_vec[-1_i128]); } #[test] // ✅ fn wrapping_neg_indexes() { let wrapping_vec = WrappingIndex(vec![1, 2, 3]); assert_eq!(1, wrapping_vec[-6_i128]); assert_eq!(2, wrapping_vec[-5_i128]); assert_eq!(3, wrapping_vec[-4_i128]); } There&rsquo;s no requirement that the Idx type has to be a number type or a Range, it could be an enum! Here&rsquo;s an example using basketball positions to index into a basketball team to retrieve players on the team:
use std::ops::Index; enum BasketballPosition { PointGuard, ShootingGuard, Center, PowerForward, SmallForward, } struct BasketballPlayer { name: &amp;'static str, position: BasketballPosition, } struct BasketballTeam { point_guard: BasketballPlayer, shooting_guard: BasketballPlayer, center: BasketballPlayer, power_forward: BasketballPlayer, small_forward: BasketballPlayer, } impl Index&lt;BasketballPosition> for BasketballTeam { type Output = BasketballPlayer; fn index(&amp;self, position: BasketballPosition) -> &amp;BasketballPlayer { match position { BasketballPosition::PointGuard => &amp;self.point_guard, BasketballPosition::ShootingGuard => &amp;self.shooting_guard, BasketballPosition::Center => &amp;self.center, BasketballPosition::PowerForward => &amp;self.power_forward, BasketballPosition::SmallForward => &amp;self.small_forward, } } } Drop Prerequisites
Self Methods trait Drop { fn drop(&amp;mut self); } If a type impls Drop then drop will be called on the type when it goes out of scope but before it&rsquo;s destroyed. We will rarely need to impl this for our types but a good example of where it&rsquo;s useful is if a type holds on to some external resources which needs to be cleaned up when the type is destroyed.
There&rsquo;s a BufWriter type in the standard library that allows us to buffer writes to Write types. However, what if the BufWriter gets destroyed before the content in its buffer has been flushed to the underlying Write type? Thankfully that&rsquo;s not possible! The BufWriter impls the Drop trait so that flush is always called on it whenever it goes out of scope!
impl&lt;W: Write> Drop for BufWriter&lt;W> { fn drop(&amp;mut self) { self.flush_buf(); } } Also, Mutexs in Rust don&rsquo;t have unlock() methods because they don&rsquo;t need them! Calling lock() on a Mutex returns a MutexGuard which automatically unlocks the Mutex when it goes out of scope thanks to its Drop impl:
impl&lt;T: ?Sized> Drop for MutexGuard&lt;'_, T> { fn drop(&amp;mut self) { unsafe { self.lock.inner.raw_unlock(); } } } In general, if you&rsquo;re impling an abstraction over some resource that needs to be cleaned up after use then that&rsquo;s a great reason to make use of the Drop trait.
Conversion Traits From &amp; Into Prerequisites
Self Functions Methods Generic Parameters Generic Blanket Impls trait From&lt;T> { fn from(T) -> Self; } From&lt;T> types allow us to convert T into Self.
trait Into&lt;T> { fn into(self) -> T; } Into&lt;T> types allow us to convert Self into T.
These traits are two different sides of the same coin. We can only impl From&lt;T> for our types because the Into&lt;T> impl is automatically provided by this generic blanket impl:
impl&lt;T, U> Into&lt;U> for T where U: From&lt;T>, { fn into(self) -> U { U::from(self) } } The reason both traits exist is because it allows us to write trait bounds on generic types slightly differently:
fn function&lt;T>(t: T) where // these bounds are equivalent T: From&lt;i32>, i32: Into&lt;T> { // these examples are equivalent let example: T = T::from(0); let example: T = 0.into(); } There are no hard rules about when to use one or the other, so go with whatever makes the most sense for each situation. Now let&rsquo;s look at some example impls on Point:
struct Point { x: i32, y: i32, } impl From&lt;(i32, i32)> for Point { fn from((x, y): (i32, i32)) -> Self { Point { x, y } } } impl From&lt;[i32; 2]> for Point { fn from([x, y]: [i32; 2]) -> Self { Point { x, y } } } fn example() { // using From let origin = Point::from((0, 0)); let origin = Point::from([0, 0]); // using Into let origin: Point = (0, 0).into(); let origin: Point = [0, 0].into(); } The impl is not symmetric, so if we&rsquo;d like to convert Points into tuples and arrays we have to explicitly add those as well:
struct Point { x: i32, y: i32, } impl From&lt;(i32, i32)> for Point { fn from((x, y): (i32, i32)) -> Self { Point { x, y } } } impl From&lt;Point> for (i32, i32) { fn from(Point { x, y }: Point) -> Self { (x, y) } } impl From&lt;[i32; 2]> for Point { fn from([x, y]: [i32; 2]) -> Self { Point { x, y } } } impl From&lt;Point> for [i32; 2] { fn from(Point { x, y }: Point) -> Self { [x, y] } } fn example() { // from (i32, i32) into Point let point = Point::from((0, 0)); let point: Point = (0, 0).into(); // from Point into (i32, i32) let tuple = &lt;(i32, i32)>::from(point); let tuple: (i32, i32) = point.into(); // from [i32; 2] into Point let point = Point::from([0, 0]); let point: Point = [0, 0].into(); // from Point into [i32; 2] let array = &lt;[i32; 2]>::from(point); let array: [i32; 2] = point.into(); } A popular use of From&lt;T> is to trim down boilerplate code. Let&rsquo;s say we add a Triangle type to our program which contains three Points, here&rsquo;s some of the many ways we can construct it:
struct Point { x: i32, y: i32, } impl Point { fn new(x: i32, y: i32) -> Point { Point { x, y } } } impl From&lt;(i32, i32)> for Point { fn from((x, y): (i32, i32)) -> Point { Point { x, y } } } struct Triangle { p1: Point, p2: Point, p3: Point, } impl Triangle { fn new(p1: Point, p2: Point, p3: Point) -> Triangle { Triangle { p1, p2, p3 } } } impl&lt;P> From&lt;[P; 3]> for Triangle where P: Into&lt;Point> { fn from([p1, p2, p3]: [P; 3]) -> Triangle { Triangle { p1: p1.into(), p2: p2.into(), p3: p3.into(), } } } fn example() { // manual construction let triangle = Triangle { p1: Point { x: 0, y: 0, }, p2: Point { x: 1, y: 1, }, p3: Point { x: 2, y: 2, }, }; // using Point::new let triangle = Triangle { p1: Point::new(0, 0), p2: Point::new(1, 1), p3: Point::new(2, 2), }; // using From&lt;(i32, i32)> for Point let triangle = Triangle { p1: (0, 0).into(), p2: (1, 1).into(), p3: (2, 2).into(), }; // using Triangle::new + From&lt;(i32, i32)> for Point let triangle = Triangle::new( (0, 0).into(), (1, 1).into(), (2, 2).into(), ); // using From&lt;[Into&lt;Point>; 3]> for Triangle let triangle: Triangle = [ (0, 0), (1, 1), (2, 2), ].into(); } There are no rules for when, how, or why we should impl From&lt;T> for our types so it&rsquo;s up to us to use our best judgement for every situation.
One popular use of Into&lt;T> is to make functions which need owned values generic over whether they take owned or borrowed values:
struct Person { name: String, } impl Person { // accepts: // - String fn new1(name: String) -> Person { Person { name } } // accepts: // - String // - &amp;String // - &amp;str // - Box&lt;str> // - Cow&lt;'_, str> // - char // since all of the above types can be converted into String fn new2&lt;N: Into&lt;String>>(name: N) -> Person { Person { name: name.into() } } } Error Handling The best time to talk about error handling and the Error trait is after going over Display, Debug, Any, and From but before getting to TryFrom hence why the Error Handling section awkwardly bisects the Conversion Traits section.
Error Prerequisites
Self Methods Default Impls Generic Blanket Impls Subtraits &amp; Supertraits Trait Objects Display &amp; ToString Debug Any From &amp; Into trait Error: Debug + Display { // provided default impls fn source(&amp;self) -> Option&lt;&amp;(dyn Error + 'static)>; fn backtrace(&amp;self) -> Option&lt;&amp;Backtrace>; fn description(&amp;self) -> &amp;str; fn cause(&amp;self) -> Option&lt;&amp;dyn Error>; } In Rust errors are returned, not thrown. Let&rsquo;s look at some examples.
Since dividing integer types by zero panics if we wanted to make our program safer and more explicit we could impl a safe_div function which returns a Result instead like this:
use std::fmt; use std::error; #[derive(Debug, PartialEq)] struct DivByZero; impl fmt::Display for DivByZero { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { write!(f, "division by zero error") } } impl error::Error for DivByZero {} fn safe_div(numerator: i32, denominator: i32) -> Result&lt;i32, DivByZero> { if denominator == 0 { return Err(DivByZero); } Ok(numerator / denominator) } #[test] // ✅ fn test_safe_div() { assert_eq!(safe_div(8, 2), Ok(4)); assert_eq!(safe_div(5, 0), Err(DivByZero)); } Since errors are returned and not thrown they must be explicitly handled, and if the current function cannot handle an error it should propagate it up to the caller. The most idiomatic way to propagate errors is to use the ? operator, which is just syntax sugar for the now deprecated try! macro which simply does this:
macro_rules! try { ($expr:expr) => { match $expr { // if Ok just unwrap the value Ok(val) => val, // if Err map the err value using From and return Err(err) => { return Err(From::from(err)); } } }; } If we wanted to write a function which reads a file into a String we could write it like this, propagating the io::Errors using ? everywhere they can appear:
use std::io::Read; use std::path::Path; use std::io; use std::fs::File; fn read_file_to_string(path: &amp;Path) -> Result&lt;String, io::Error> { let mut file = File::open(path)?; // ⬆️ io::Error let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; // ⬆️ io::Error Ok(contents) } But let&rsquo;s say the file we&rsquo;re reading is actually a list of numbers and we want to sum them together, we&rsquo;d update our function like this:
use std::io::Read; use std::path::Path; use std::io; use std::fs::File; fn sum_file(path: &amp;Path) -> Result&lt;i32, /* What to put here? */> { let mut file = File::open(path)?; // ⬆️ io::Error let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; // ⬆️ io::Error let mut sum = 0; for line in contents.lines() { sum += line.parse::&lt;i32>()?; // ⬆️ ParseIntError } Ok(sum) } But what&rsquo;s the error type of our Result now? It can return either an io::Error or a ParseIntError. We&rsquo;re going to look at three approaches for solving this problem, starting with the most quick &amp; dirty way and finishing with the most robust way.
The first approach is recognizing that all types which impl Error also impl Display so we can map all the errors to Strings and use String as our error type:
use std::fs::File; use std::io; use std::io::Read; use std::path::Path; fn sum_file(path: &amp;Path) -> Result&lt;i32, String> { let mut file = File::open(path) .map_err(|e| e.to_string())?; // ⬆️ io::Error -> String let mut contents = String::new(); file.read_to_string(&amp;mut contents) .map_err(|e| e.to_string())?; // ⬆️ io::Error -> String let mut sum = 0; for line in contents.lines() { sum += line.parse::&lt;i32>() .map_err(|e| e.to_string())?; // ⬆️ ParseIntError -> String } Ok(sum) } The obvious downside of stringifying every error is that we throw away type information which makes it harder for the caller to handle the errors.
One nonobvious upside to the above approach is we can customize the strings to provide more context-specific information. For example, ParseIntError usually stringifies to "invalid digit found in string" which is very vague and doesn&rsquo;t mention what the invalid string is or what integer type it was trying to parse into. If we were debugging this problem that error message would almost be useless. However we can make it significantly better by providing all the context relevant information ourselves:
sum += line.parse::&lt;i32>() .map_err(|_| format!("failed to parse {} into i32", line))?; The second approach takes advantage of this generic blanket impl from the standard library:
impl&lt;E: error::Error> From&lt;E> for Box&lt;dyn error::Error>; Which means that any Error type can be implicitly converted into a Box&lt;dyn error::Error> by the ? operator, so we can set to error type to Box&lt;dyn error::Error> in the Result return type of any function which produces errors and the ? operator will do the rest of the work for us:
use std::fs::File; use std::io::Read; use std::path::Path; use std::error; fn sum_file(path: &amp;Path) -> Result&lt;i32, Box&lt;dyn error::Error>> { let mut file = File::open(path)?; // ⬆️ io::Error -> Box&lt;dyn error::Error> let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; // ⬆️ io::Error -> Box&lt;dyn error::Error> let mut sum = 0; for line in contents.lines() { sum += line.parse::&lt;i32>()?; // ⬆️ ParseIntError -> Box&lt;dyn error::Error> } Ok(sum) } While being more concise, this seems to suffer from the same downside of the previous approach by throwing away type information. This is mostly true, but if the caller is aware of the impl details of our function they can still handle the different errors types using the downcast_ref() method on error::Error which works the same as it does on dyn Any types:
fn handle_sum_file_errors(path: &amp;Path) { match sum_file(path) { Ok(sum) => println!("the sum is {}", sum), Err(err) => { if let Some(e) = err.downcast_ref::&lt;io::Error>() { // handle io::Error } else if let Some(e) = err.downcast_ref::&lt;ParseIntError>() { // handle ParseIntError } else { // we know sum_file can only return one of the // above errors so this branch is unreachable unreachable!(); } } } } The third approach, which is the most robust and type-safe way to aggregate these different errors would be to build our own custom error type using an enum:
use std::num::ParseIntError; use std::fs::File; use std::io; use std::io::Read; use std::path::Path; use std::error; use std::fmt; #[derive(Debug)] enum SumFileError { Io(io::Error), Parse(ParseIntError), } impl From&lt;io::Error> for SumFileError { fn from(err: io::Error) -> Self { SumFileError::Io(err) } } impl From&lt;ParseIntError> for SumFileError { fn from(err: ParseIntError) -> Self { SumFileError::Parse(err) } } impl fmt::Display for SumFileError { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { match self { SumFileError::Io(err) => write!(f, "sum file error: {}", err), SumFileError::Parse(err) => write!(f, "sum file error: {}", err), } } } impl error::Error for SumFileError { // the default impl for this method always returns None // but we can now override it to make it way more useful! fn source(&amp;self) -> Option&lt;&amp;(dyn error::Error + 'static)> { Some(match self { SumFileError::Io(err) => err, SumFileError::Parse(err) => err, }) } } fn sum_file(path: &amp;Path) -> Result&lt;i32, SumFileError> { let mut file = File::open(path)?; // ⬆️ io::Error -> SumFileError let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; // ⬆️ io::Error -> SumFileError let mut sum = 0; for line in contents.lines() { sum += line.parse::&lt;i32>()?; // ⬆️ ParseIntError -> SumFileError } Ok(sum) } fn handle_sum_file_errors(path: &amp;Path) { match sum_file(path) { Ok(sum) => println!("the sum is {}", sum), Err(SumFileError::Io(err)) => { // handle io::Error }, Err(SumFileError::Parse(err)) => { // handle ParseIntError }, } } Conversion Traits Continued TryFrom &amp; TryInto Prerequisites
Self Functions Methods Associated Types Generic Parameters Generic Types vs Associated Types Generic Blanket Impls From &amp; Into Error TryFrom and TryInto are the fallible versions of From and Into.
trait TryFrom&lt;T> { type Error; fn try_from(value: T) -> Result&lt;Self, Self::Error>; } trait TryInto&lt;T> { type Error; fn try_into(self) -> Result&lt;T, Self::Error>; } Similarly to Into we cannot impl TryInto because its impl is provided by this generic blanket impl:
impl&lt;T, U> TryInto&lt;U> for T where U: TryFrom&lt;T>, { type Error = U::Error; fn try_into(self) -> Result&lt;U, U::Error> { U::try_from(self) } } Let&rsquo;s say that in the context of our program it doesn&rsquo;t make sense for Points to have x and y values that are less than -1000 or greater than 1000. This is how we&rsquo;d rewrite our earlier From impls using TryFrom to signal to the users of our type that this conversion can now fail:
use std::convert::TryFrom; use std::error; use std::fmt; struct Point { x: i32, y: i32, } #[derive(Debug)] struct OutOfBounds; impl fmt::Display for OutOfBounds { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { write!(f, "out of bounds") } } impl error::Error for OutOfBounds {} // now fallible impl TryFrom&lt;(i32, i32)> for Point { type Error = OutOfBounds; fn try_from((x, y): (i32, i32)) -> Result&lt;Point, OutOfBounds> { if x.abs() > 1000 || y.abs() > 1000 { return Err(OutOfBounds); } Ok(Point { x, y }) } } // still infallible impl From&lt;Point> for (i32, i32) { fn from(Point { x, y }: Point) -> Self { (x, y) } } And here&rsquo;s the refactored TryFrom&lt;[TryInto&lt;Point>; 3]> impl for Triangle:
use std::convert::{TryFrom, TryInto}; use std::error; use std::fmt; struct Point { x: i32, y: i32, } #[derive(Debug)] struct OutOfBounds; impl fmt::Display for OutOfBounds { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { write!(f, "out of bounds") } } impl error::Error for OutOfBounds {} impl TryFrom&lt;(i32, i32)> for Point { type Error = OutOfBounds; fn try_from((x, y): (i32, i32)) -> Result&lt;Self, Self::Error> { if x.abs() > 1000 || y.abs() > 1000 { return Err(OutOfBounds); } Ok(Point { x, y }) } } struct Triangle { p1: Point, p2: Point, p3: Point, } impl&lt;P> TryFrom&lt;[P; 3]> for Triangle where P: TryInto&lt;Point>, { type Error = P::Error; fn try_from([p1, p2, p3]: [P; 3]) -> Result&lt;Self, Self::Error> { Ok(Triangle { p1: p1.try_into()?, p2: p2.try_into()?, p3: p3.try_into()?, }) } } fn example() -> Result&lt;Triangle, OutOfBounds> { let t: Triangle = [(0, 0), (1, 1), (2, 2)].try_into()?; Ok(t) } FromStr Prerequisites
Self Functions Associated Types Error TryFrom &amp; TryInto trait FromStr { type Err; fn from_str(s: &amp;str) -> Result&lt;Self, Self::Err>; } FromStr types allow performing a fallible conversion from &amp;str into Self. The idiomatic way to use FromStr is to call the .parse() method on &amp;strs:
use std::str::FromStr; fn example&lt;T: FromStr>(s: &amp;'static str) { // these are all equivalent let t: Result&lt;T, _> = FromStr::from_str(s); let t = T::from_str(s); let t: Result&lt;T, _> = s.parse(); let t = s.parse::&lt;T>(); // most idiomatic } Example impl for Point:
use std::error; use std::fmt; use std::iter::Enumerate; use std::num::ParseIntError; use std::str::{Chars, FromStr}; #[derive(Debug, Eq, PartialEq)] struct Point { x: i32, y: i32, } impl Point { fn new(x: i32, y: i32) -> Self { Point { x, y } } } #[derive(Debug, PartialEq)] struct ParsePointError; impl fmt::Display for ParsePointError { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { write!(f, "failed to parse point") } } impl From&lt;ParseIntError> for ParsePointError { fn from(_e: ParseIntError) -> Self { ParsePointError } } impl error::Error for ParsePointError {} impl FromStr for Point { type Err = ParsePointError; fn from_str(s: &amp;str) -> Result&lt;Self, Self::Err> { let is_num = |(_, c): &amp;(usize, char)| matches!(c, '0'..='9' | '-'); let isnt_num = |t: &amp;(_, _)| !is_num(t); let get_num = |char_idxs: &amp;mut Enumerate&lt;Chars&lt;'_>>| -> Result&lt;(usize, usize), ParsePointError> { let (start, _) = char_idxs .skip_while(isnt_num) .next() .ok_or(ParsePointError)?; let (end, _) = char_idxs .skip_while(is_num) .next() .ok_or(ParsePointError)?; Ok((start, end)) }; let mut char_idxs = s.chars().enumerate(); let (x_start, x_end) = get_num(&amp;mut char_idxs)?; let (y_start, y_end) = get_num(&amp;mut char_idxs)?; let x = s[x_start..x_end].parse::&lt;i32>()?; let y = s[y_start..y_end].parse::&lt;i32>()?; Ok(Point { x, y }) } } #[test] // ✅ fn pos_x_y() { let p = "(4, 5)".parse::&lt;Point>(); assert_eq!(p, Ok(Point::new(4, 5))); } #[test] // ✅ fn neg_x_y() { let p = "(-6, -2)".parse::&lt;Point>(); assert_eq!(p, Ok(Point::new(-6, -2))); } #[test] // ✅ fn not_a_point() { let p = "not a point".parse::&lt;Point>(); assert_eq!(p, Err(ParsePointError)); } FromStr has the same signature as TryFrom&lt;&amp;str>. It doesn&rsquo;t matter which one we impl for a type first as long as we forward the impl to the other one. Here&rsquo;s a TryFrom&lt;&amp;str> impl for Point assuming it already has a FromStr impl:
impl TryFrom&lt;&amp;str> for Point { type Error = &lt;Point as FromStr>::Err; fn try_from(s: &amp;str) -> Result&lt;Point, Self::Error> { &lt;Point as FromStr>::from_str(s) } } AsRef &amp; AsMut Prerequisites
Self Methods Sized Generic Parameters Sized Deref &amp; DerefMut trait AsRef&lt;T: ?Sized> { fn as_ref(&amp;self) -> &amp;T; } trait AsMut&lt;T: ?Sized> { fn as_mut(&amp;mut self) -> &amp;mut T; } AsRef is for cheap reference to reference conversions. However, one of the most common ways it&rsquo;s used is to make functions generic over whether they take ownership or not:
// accepts: // - &amp;str // - &amp;String fn takes_str(s: &amp;str) { // use &amp;str } // accepts: // - &amp;str // - &amp;String // - String fn takes_asref_str&lt;S: AsRef&lt;str>>(s: S) { let s: &amp;str = s.as_ref(); // use &amp;str } fn example(slice: &amp;str, borrow: &amp;String, owned: String) { takes_str(slice); takes_str(borrow); takes_str(owned); // ❌ takes_asref_str(slice); takes_asref_str(borrow); takes_asref_str(owned); // ✅ } The other most common use-case is returning a reference to inner private data wrapped by a type which protects some invariant. A good example from the standard library is String which is just a wrapper around Vec&lt;u8>:
struct String { vec: Vec&lt;u8>, } This inner Vec cannot be made public because if it was people could mutate any byte and break the String&rsquo;s valid UTF-8 encoding. However, it&rsquo;s safe to expose an immutable read-only reference to the inner byte array, hence this impl:
impl AsRef&lt;[u8]> for String; Generally, it often only makes sense to impl AsRef for a type if it wraps some other type to either provide additional functionality around the inner type or protect some invariant on the inner type.
Let&rsquo;s examine a example of bad AsRef impls:
struct User { name: String, age: u32, } impl AsRef&lt;String> for User { fn as_ref(&amp;self) -> &amp;String { &amp;self.name } } impl AsRef&lt;u32> for User { fn as_ref(&amp;self) -> &amp;u32 { &amp;self.age } } This works and kinda makes sense at first, but quickly falls apart if we add more members to User:
struct User { name: String, email: String, age: u32, height: u32, } impl AsRef&lt;String> for User { fn as_ref(&amp;self) -> &amp;String { // uh, do we return name or email here? } } impl AsRef&lt;u32> for User { fn as_ref(&amp;self) -> &amp;u32 { // uh, do we return age or height here? } } A User is composed of Strings and u32s but it&rsquo;s not really the same thing as a String or a u32. Even if we had much more specific types:
struct User { name: Name, email: Email, age: Age, height: Height, } It wouldn&rsquo;t make much sense to impl AsRef for any of those because AsRef is for cheap reference to reference conversions between semantically equivalent things, and Name, Email, Age, and Height by themselves are not the same thing as a User.
A good example where we would impl AsRef would be if we introduced a new type Moderator that just wrapped a User and added some moderation specific privileges:
struct User { name: String, age: u32, } // unfortunately the standard library cannot provide // a generic blanket impl to save us from this boilerplate impl AsRef&lt;User> for User { fn as_ref(&amp;self) -> &amp;User { self } } enum Privilege { BanUsers, EditPosts, DeletePosts, } // although Moderators have some special // privileges they are still regular Users // and should be able to do all the same stuff struct Moderator { user: User, privileges: Vec&lt;Privilege> } impl AsRef&lt;Moderator> for Moderator { fn as_ref(&amp;self) -> &amp;Moderator { self } } impl AsRef&lt;User> for Moderator { fn as_ref(&amp;self) -> &amp;User { &amp;self.user } } // this should be callable with Users // and Moderators (who are also Users) fn create_post&lt;U: AsRef&lt;User>>(u: U) { let user = u.as_ref(); // etc } fn example(user: User, moderator: Moderator) { create_post(&amp;user); create_post(&amp;moderator); // ✅ } This works because Moderators are just Users. Here&rsquo;s the example from the Deref section except using AsRef instead:
use std::convert::AsRef; struct Human { health_points: u32, } impl AsRef&lt;Human> for Human { fn as_ref(&amp;self) -> &amp;Human { self } } enum Weapon { Spear, Axe, Sword, } // a Soldier is just a Human with a Weapon struct Soldier { human: Human, weapon: Weapon, } impl AsRef&lt;Soldier> for Soldier { fn as_ref(&amp;self) -> &amp;Soldier { self } } impl AsRef&lt;Human> for Soldier { fn as_ref(&amp;self) -> &amp;Human { &amp;self.human } } enum Mount { Horse, Donkey, Cow, } // a Knight is just a Soldier with a Mount struct Knight { soldier: Soldier, mount: Mount, } impl AsRef&lt;Knight> for Knight { fn as_ref(&amp;self) -> &amp;Knight { self } } impl AsRef&lt;Soldier> for Knight { fn as_ref(&amp;self) -> &amp;Soldier { &amp;self.soldier } } impl AsRef&lt;Human> for Knight { fn as_ref(&amp;self) -> &amp;Human { &amp;self.soldier.human } } enum Spell { MagicMissile, FireBolt, ThornWhip, } // a Mage is just a Human who can cast Spells struct Mage { human: Human, spells: Vec&lt;Spell>, } impl AsRef&lt;Mage> for Mage { fn as_ref(&amp;self) -> &amp;Mage { self } } impl AsRef&lt;Human> for Mage { fn as_ref(&amp;self) -> &amp;Human { &amp;self.human } } enum Staff { Wooden, Metallic, Plastic, } // a Wizard is just a Mage with a Staff struct Wizard { mage: Mage, staff: Staff, } impl AsRef&lt;Wizard> for Wizard { fn as_ref(&amp;self) -> &amp;Wizard { self } } impl AsRef&lt;Mage> for Wizard { fn as_ref(&amp;self) -> &amp;Mage { &amp;self.mage } } impl AsRef&lt;Human> for Wizard { fn as_ref(&amp;self) -> &amp;Human { &amp;self.mage.human } } fn borrows_human&lt;H: AsRef&lt;Human>>(human: H) {} fn borrows_soldier&lt;S: AsRef&lt;Soldier>>(soldier: S) {} fn borrows_knight&lt;K: AsRef&lt;Knight>>(knight: K) {} fn borrows_mage&lt;M: AsRef&lt;Mage>>(mage: M) {} fn borrows_wizard&lt;W: AsRef&lt;Wizard>>(wizard: W) {} fn example(human: Human, soldier: Soldier, knight: Knight, mage: Mage, wizard: Wizard) { // all types can be used as Humans borrows_human(&amp;human); borrows_human(&amp;soldier); borrows_human(&amp;knight); borrows_human(&amp;mage); borrows_human(&amp;wizard); // Knights can be used as Soldiers borrows_soldier(&amp;soldier); borrows_soldier(&amp;knight); // Wizards can be used as Mages borrows_mage(&amp;mage); borrows_mage(&amp;wizard); // Knights &amp; Wizards passed as themselves borrows_knight(&amp;knight); borrows_wizard(&amp;wizard); } Deref didn&rsquo;t work in the prior version of the example above because deref coercion is an implicit conversion between types which leaves room for people to mistakenly formulate the wrong ideas and expectations for how it will behave. AsRef works above because it makes the conversion between types explicit and there&rsquo;s no room leftover to develop any wrong ideas or expectations.
Borrow &amp; BorrowMut Prerequisites
Self Methods Generic Parameters Subtraits &amp; Supertraits Sized AsRef &amp; AsMut PartialEq &amp; Eq Hash PartialOrd &amp; Ord trait Borrow&lt;Borrowed> where Borrowed: ?Sized, { fn borrow(&amp;self) -> &amp;Borrowed; } trait BorrowMut&lt;Borrowed>: Borrow&lt;Borrowed> where Borrowed: ?Sized, { fn borrow_mut(&amp;mut self) -> &amp;mut Borrowed; } These traits were invented to solve the very specific problem of looking up String keys in HashSets, HashMaps, BTreeSets, and BTreeMaps using &amp;str values.
We can view Borrow&lt;T> and BorrowMut&lt;T> as stricter versions of AsRef&lt;T> and AsMut&lt;T>, where the returned reference &amp;T has equivalent Eq, Hash, and Ord impls to Self. This is more easily explained with a commented example:
use std::borrow::Borrow; use std:#️⃣:Hasher; use std::collections::hash_map::DefaultHasher; use std:#️⃣:Hash; fn get_hash&lt;T: Hash>(t: T) -> u64 { let mut hasher = DefaultHasher::new(); t.hash(&amp;mut hasher); hasher.finish() } fn asref_example&lt;Owned, Ref>(owned1: Owned, owned2: Owned) where Owned: Eq + Ord + Hash + AsRef&lt;Ref>, Ref: Eq + Ord + Hash { let ref1: &amp;Ref = owned1.as_ref(); let ref2: &amp;Ref = owned2.as_ref(); // refs aren't required to be equal if owned types are equal assert_eq!(owned1 == owned2, ref1 == ref2); // ❌ let owned1_hash = get_hash(&amp;owned1); let owned2_hash = get_hash(&amp;owned2); let ref1_hash = get_hash(&amp;ref1); let ref2_hash = get_hash(&amp;ref2); // ref hashes aren't required to be equal if owned type hashes are equal assert_eq!(owned1_hash == owned2_hash, ref1_hash == ref2_hash); // ❌ // ref comparisons aren't required to match owned type comparisons assert_eq!(owned1.cmp(&amp;owned2), ref1.cmp(&amp;ref2)); // ❌ } fn borrow_example&lt;Owned, Borrowed>(owned1: Owned, owned2: Owned) where Owned: Eq + Ord + Hash + Borrow&lt;Borrowed>, Borrowed: Eq + Ord + Hash { let borrow1: &amp;Borrowed = owned1.borrow(); let borrow2: &amp;Borrowed = owned2.borrow(); // borrows are required to be equal if owned types are equal assert_eq!(owned1 == owned2, borrow1 == borrow2); // ✅ let owned1_hash = get_hash(&amp;owned1); let owned2_hash = get_hash(&amp;owned2); let borrow1_hash = get_hash(&amp;borrow1); let borrow2_hash = get_hash(&amp;borrow2); // borrow hashes are required to be equal if owned type hashes are equal assert_eq!(owned1_hash == owned2_hash, borrow1_hash == borrow2_hash); // ✅ // borrow comparisons are required to match owned type comparisons assert_eq!(owned1.cmp(&amp;owned2), borrow1.cmp(&amp;borrow2)); // ✅ } It&rsquo;s good to be aware of these traits and understand why they exist since it helps demystify some of the methods on HashSet, HashMap, BTreeSet, and BTreeMap but it&rsquo;s very rare that we would ever need to impl these traits for any of our types because it&rsquo;s very rare that we would ever need create a pair of types where one is the &ldquo;borrowed&rdquo; version of the other in the first place. If we have some T then &amp;T will get the job done 99.99% of the time, and T: Borrow&lt;T> is already implemented for all T because of a generic blanket impl, so we don&rsquo;t need to manually impl it and we don&rsquo;t need to create some U such that T: Borrow&lt;U>.
ToOwned Prerequisites
Self Methods Default Impls Clone Borrow &amp; BorrowMut trait ToOwned { type Owned: Borrow&lt;Self>; fn to_owned(&amp;self) -> Self::Owned; // provided default impls fn clone_into(&amp;self, target: &amp;mut Self::Owned); } ToOwned is a more generic version of Clone. Clone allows us to take a &amp;T and turn it into an T but ToOwned allows us to take a &amp;Borrowed and turn it into a Owned where Owned: Borrow&lt;Borrowed>.
In other words, we can&rsquo;t &ldquo;clone&rdquo; a &amp;str into a String, or a &amp;Path into a PathBuf, or an &amp;OsStr into an OsString, since the clone method signature doesn&rsquo;t support this kind of cross-type cloning, and that&rsquo;s what ToOwned was made for.
For similar reasons as Borrow and BorrowMut, it&rsquo;s good to be aware of this trait and understand why it exists but it&rsquo;s very rare we&rsquo;ll ever need to impl it for any of our types.
Iteration Traits Iterator Prerequisites
Self Methods Associated Types Default Impls trait Iterator { type Item; fn next(&amp;mut self) -> Option&lt;Self::Item>; // provided default impls fn size_hint(&amp;self) -> (usize, Option&lt;usize>); fn count(self) -> usize; fn last(self) -> Option&lt;Self::Item>; fn advance_by(&amp;mut self, n: usize) -> Result&lt;(), usize>; fn nth(&amp;mut self, n: usize) -> Option&lt;Self::Item>; fn step_by(self, step: usize) -> StepBy&lt;Self>; fn chain&lt;U>( self, other: U ) -> Chain&lt;Self, &lt;U as IntoIterator>::IntoIter> where U: IntoIterator&lt;Item = Self::Item>; fn zip&lt;U>(self, other: U) -> Zip&lt;Self, &lt;U as IntoIterator>::IntoIter> where U: IntoIterator; fn map&lt;B, F>(self, f: F) -> Map&lt;Self, F> where F: FnMut(Self::Item) -> B; fn for_each&lt;F>(self, f: F) where F: FnMut(Self::Item); fn filter&lt;P>(self, predicate: P) -> Filter&lt;Self, P> where P: FnMut(&amp;Self::Item) -> bool; fn filter_map&lt;B, F>(self, f: F) -> FilterMap&lt;Self, F> where F: FnMut(Self::Item) -> Option&lt;B>; fn enumerate(self) -> Enumerate&lt;Self>; fn peekable(self) -> Peekable&lt;Self>; fn skip_while&lt;P>(self, predicate: P) -> SkipWhile&lt;Self, P> where P: FnMut(&amp;Self::Item) -> bool; fn take_while&lt;P>(self, predicate: P) -> TakeWhile&lt;Self, P> where P: FnMut(&amp;Self::Item) -> bool; fn map_while&lt;B, P>(self, predicate: P) -> MapWhile&lt;Self, P> where P: FnMut(Self::Item) -> Option&lt;B>; fn skip(self, n: usize) -> Skip&lt;Self>; fn take(self, n: usize) -> Take&lt;Self>; fn scan&lt;St, B, F>(self, initial_state: St, f: F) -> Scan&lt;Self, St, F> where F: FnMut(&amp;mut St, Self::Item) -> Option&lt;B>; fn flat_map&lt;U, F>(self, f: F) -> FlatMap&lt;Self, U, F> where F: FnMut(Self::Item) -> U, U: IntoIterator; fn flatten(self) -> Flatten&lt;Self> where Self::Item: IntoIterator; fn fuse(self) -> Fuse&lt;Self>; fn inspect&lt;F>(self, f: F) -> Inspect&lt;Self, F> where F: FnMut(&amp;Self::Item); fn by_ref(&amp;mut self) -> &amp;mut Self; fn collect&lt;B>(self) -> B where B: FromIterator&lt;Self::Item>; fn partition&lt;B, F>(self, f: F) -> (B, B) where F: FnMut(&amp;Self::Item) -> bool, B: Default + Extend&lt;Self::Item>; fn partition_in_place&lt;'a, T, P>(self, predicate: P) -> usize where Self: DoubleEndedIterator&lt;Item = &amp;'a mut T>, T: 'a, P: FnMut(&amp;T) -> bool; fn is_partitioned&lt;P>(self, predicate: P) -> bool where P: FnMut(Self::Item) -> bool; fn try_fold&lt;B, F, R>(&amp;mut self, init: B, f: F) -> R where F: FnMut(B, Self::Item) -> R, R: Try&lt;Ok = B>; fn try_for_each&lt;F, R>(&amp;mut self, f: F) -> R where F: FnMut(Self::Item) -> R, R: Try&lt;Ok = ()>; fn fold&lt;B, F>(self, init: B, f: F) -> B where F: FnMut(B, Self::Item) -> B; fn fold_first&lt;F>(self, f: F) -> Option&lt;Self::Item> where F: FnMut(Self::Item, Self::Item) -> Self::Item; fn all&lt;F>(&amp;mut self, f: F) -> bool where F: FnMut(Self::Item) -> bool; fn any&lt;F>(&amp;mut self, f: F) -> bool where F: FnMut(Self::Item) -> bool; fn find&lt;P>(&amp;mut self, predicate: P) -> Option&lt;Self::Item> where P: FnMut(&amp;Self::Item) -> bool; fn find_map&lt;B, F>(&amp;mut self, f: F) -> Option&lt;B> where F: FnMut(Self::Item) -> Option&lt;B>; fn try_find&lt;F, R>( &amp;mut self, f: F ) -> Result&lt;Option&lt;Self::Item>, &lt;R as Try>::Error> where F: FnMut(&amp;Self::Item) -> R, R: Try&lt;Ok = bool>; fn position&lt;P>(&amp;mut self, predicate: P) -> Option&lt;usize> where P: FnMut(Self::Item) -> bool; fn rposition&lt;P>(&amp;mut self, predicate: P) -> Option&lt;usize> where Self: ExactSizeIterator + DoubleEndedIterator, P: FnMut(Self::Item) -> bool; fn max(self) -> Option&lt;Self::Item> where Self::Item: Ord; fn min(self) -> Option&lt;Self::Item> where Self::Item: Ord; fn max_by_key&lt;B, F>(self, f: F) -> Option&lt;Self::Item> where F: FnMut(&amp;Self::Item) -> B, B: Ord; fn max_by&lt;F>(self, compare: F) -> Option&lt;Self::Item> where F: FnMut(&amp;Self::Item, &amp;Self::Item) -> Ordering; fn min_by_key&lt;B, F>(self, f: F) -> Option&lt;Self::Item> where F: FnMut(&amp;Self::Item) -> B, B: Ord; fn min_by&lt;F>(self, compare: F) -> Option&lt;Self::Item> where F: FnMut(&amp;Self::Item, &amp;Self::Item) -> Ordering; fn rev(self) -> Rev&lt;Self> where Self: DoubleEndedIterator; fn unzip&lt;A, B, FromA, FromB>(self) -> (FromA, FromB) where Self: Iterator&lt;Item = (A, B)>, FromA: Default + Extend&lt;A>, FromB: Default + Extend&lt;B>; fn copied&lt;'a, T>(self) -> Copied&lt;Self> where Self: Iterator&lt;Item = &amp;'a T>, T: 'a + Copy; fn cloned&lt;'a, T>(self) -> Cloned&lt;Self> where Self: Iterator&lt;Item = &amp;'a T>, T: 'a + Clone; fn cycle(self) -> Cycle&lt;Self> where Self: Clone; fn sum&lt;S>(self) -> S where S: Sum&lt;Self::Item>; fn product&lt;P>(self) -> P where P: Product&lt;Self::Item>; fn cmp&lt;I>(self, other: I) -> Ordering where I: IntoIterator&lt;Item = Self::Item>, Self::Item: Ord; fn cmp_by&lt;I, F>(self, other: I, cmp: F) -> Ordering where F: FnMut(Self::Item, &lt;I as IntoIterator>::Item) -> Ordering, I: IntoIterator; fn partial_cmp&lt;I>(self, other: I) -> Option&lt;Ordering> where I: IntoIterator, Self::Item: PartialOrd&lt;&lt;I as IntoIterator>::Item>; fn partial_cmp_by&lt;I, F>( self, other: I, partial_cmp: F ) -> Option&lt;Ordering> where F: FnMut(Self::Item, &lt;I as IntoIterator>::Item) -> Option&lt;Ordering>, I: IntoIterator; fn eq&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialEq&lt;&lt;I as IntoIterator>::Item>; fn eq_by&lt;I, F>(self, other: I, eq: F) -> bool where F: FnMut(Self::Item, &lt;I as IntoIterator>::Item) -> bool, I: IntoIterator; fn ne&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialEq&lt;&lt;I as IntoIterator>::Item>; fn lt&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialOrd&lt;&lt;I as IntoIterator>::Item>; fn le&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialOrd&lt;&lt;I as IntoIterator>::Item>; fn gt&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialOrd&lt;&lt;I as IntoIterator>::Item>; fn ge&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialOrd&lt;&lt;I as IntoIterator>::Item>; fn is_sorted(self) -> bool where Self::Item: PartialOrd&lt;Self::Item>; fn is_sorted_by&lt;F>(self, compare: F) -> bool where F: FnMut(&amp;Self::Item, &amp;Self::Item) -> Option&lt;Ordering>; fn is_sorted_by_key&lt;F, K>(self, f: F) -> bool where F: FnMut(Self::Item) -> K, K: PartialOrd&lt;K>; } Iterator&lt;Item = T> types can be iterated and will produce T types. There&rsquo;s no IteratorMut trait. Each Iterator impl can specify whether it returns immutable references, mutable references, or owned values via the Item associated type.
Vec&lt;T> method Returns .iter() Iterator&lt;Item = &amp;T> .iter_mut() Iterator&lt;Item = &amp;mut T> .into_iter() Iterator&lt;Item = T> Something that is not immediately obvious to beginner Rustaceans but that intermediate Rustaceans take for granted is that most types are not their own iterators. If a type is iterable we almost always impl some custom iterator type which iterates over it rather than trying to make it iterate over itself:
struct MyType { items: Vec&lt;String> } impl MyType { fn iter(&amp;self) -> impl Iterator&lt;Item = &amp;String> { MyTypeIterator { index: 0, items: &amp;self.items } } } struct MyTypeIterator&lt;'a> { index: usize, items: &amp;'a Vec&lt;String> } impl&lt;'a> Iterator for MyTypeIterator&lt;'a> { type Item = &amp;'a String; fn next(&amp;mut self) -> Option&lt;Self::Item> { if self.index >= self.items.len() { None } else { let item = &amp;self.items[self.index]; self.index += 1; Some(item) } } } For the sake of teaching the above example shows how to impl an Iterator from scratch but the idiomatic solution in this situation would be to just defer to Vec&rsquo;s iter method:
struct MyType { items: Vec&lt;String> } impl MyType { fn iter(&amp;self) -> impl Iterator&lt;Item = &amp;String> { self.items.iter() } } Also this is a good generic blanket impl to be aware of:
impl&lt;I: Iterator + ?Sized> Iterator for &amp;mut I; It says that any mutable reference to an iterator is also an iterator. This is useful to know because it allows us to use iterator methods with self receivers as if they had &amp;mut self receivers.
As an example, imagine we have a function which processes an iterator of more than three items, but the first step of the function is to take out the first three items of the iterator and process them separately before iterating over the remaining items, here&rsquo;s how a beginner may attempt to write this function:
fn example&lt;I: Iterator&lt;Item = i32>>(mut iter: I) { let first3: Vec&lt;i32> = iter.take(3).collect(); for item in iter { // ❌ iter consumed in line above // process remaining items } } Well that&rsquo;s annoying. The take method has a self receiver so it seems like we cannot call it without consuming the whole iterator! Here&rsquo;s what a naive refactor of the above code might look like:
fn example&lt;I: Iterator&lt;Item = i32>>(mut iter: I) { let first3: Vec&lt;i32> = vec![ iter.next().unwrap(), iter.next().unwrap(), iter.next().unwrap(), ]; for item in iter { // ✅ // process remaining items } } Which is okay. However, the idiomatic refactor is actually:
fn example&lt;I: Iterator&lt;Item = i32>>(mut iter: I) { let first3: Vec&lt;i32> = iter.by_ref().take(3).collect(); for item in iter { // ✅ // process remaining items } } Not very easy to discover. But anyway, now we know.
Also, there are no rules or conventions on what can or cannot be an iterator. If the type impls Iterator then it&rsquo;s an iterator. Some creative examples from the standard library:
use std::sync::mpsc::channel; use std::thread; fn paths_can_be_iterated(path: &amp;Path) { for part in path { // iterate over parts of a path } } fn receivers_can_be_iterated() { let (send, recv) = channel(); thread::spawn(move || { send.send(1).unwrap(); send.send(2).unwrap(); send.send(3).unwrap(); }); for received in recv { // iterate over received values } } IntoIterator Prerequisites
Self Methods Associated Types Iterator trait IntoIterator where &lt;Self::IntoIter as Iterator>::Item == Self::Item, { type Item; type IntoIter: Iterator; fn into_iter(self) -> Self::IntoIter; } IntoIterator types can be converted into iterators, hence the name. The into_iter method is called on a type when it&rsquo;s used within a for-in loop:
// vec = Vec&lt;T> for v in vec {} // v = T // above line desugared for v in vec.into_iter() {} Not only does Vec impl IntoIterator but so does &amp;Vec and &amp;mut Vec if we&rsquo;d like to iterate over immutable or mutable references instead of owned values, respectively.
// vec = Vec&lt;T> for v in &amp;vec {} // v = &amp;T // above example desugared for v in (&amp;vec).into_iter() {} // vec = Vec&lt;T> for v in &amp;mut vec {} // v = &amp;mut T // above example desugared for v in (&amp;mut vec).into_iter() {} FromIterator Prerequisites
Self Functions Generic Parameters Iterator IntoIterator trait FromIterator&lt;A> { fn from_iter&lt;T>(iter: T) -> Self where T: IntoIterator&lt;Item = A>; } FromIterator types can be created from an iterator, hence the name. FromIterator is most commonly and idiomatically used by calling the collect method on Iterator:
fn collect&lt;B>(self) -> B where B: FromIterator&lt;Self::Item>; Example of collecting an Iterator&lt;Item = char> into a String:
fn filter_letters(string: &amp;str) -> String { string.chars().filter(|c| c.is_alphabetic()).collect() } All the collections in the standard library impl IntoIterator and FromIterator so that makes it easier to convert between them:
use std::collections::{BTreeSet, HashMap, HashSet, LinkedList}; // String -> HashSet&lt;char> fn unique_chars(string: &amp;str) -> HashSet&lt;char> { string.chars().collect() } // Vec&lt;T> -> BTreeSet&lt;T> fn ordered_unique_items&lt;T: Ord>(vec: Vec&lt;T>) -> BTreeSet&lt;T> { vec.into_iter().collect() } // HashMap&lt;K, V> -> LinkedList&lt;(K, V)> fn entry_list&lt;K, V>(map: HashMap&lt;K, V>) -> LinkedList&lt;(K, V)> { map.into_iter().collect() } // and countless more possible examples I/O Traits Read &amp; Write Prerequisites
Self Methods Scope Generic Blanket Impls trait Read { fn read(&amp;mut self, buf: &amp;mut [u8]) -> Result&lt;usize>; // provided default impls fn read_vectored(&amp;mut self, bufs: &amp;mut [IoSliceMut&lt;'_>]) -> Result&lt;usize>; fn is_read_vectored(&amp;self) -> bool; unsafe fn initializer(&amp;self) -> Initializer; fn read_to_end(&amp;mut self, buf: &amp;mut Vec&lt;u8>) -> Result&lt;usize>; fn read_to_string(&amp;mut self, buf: &amp;mut String) -> Result&lt;usize>; fn read_exact(&amp;mut self, buf: &amp;mut [u8]) -> Result&lt;()>; fn by_ref(&amp;mut self) -> &amp;mut Self where Self: Sized; fn bytes(self) -> Bytes&lt;Self> where Self: Sized; fn chain&lt;R: Read>(self, next: R) -> Chain&lt;Self, R> where Self: Sized; fn take(self, limit: u64) -> Take&lt;Self> where Self: Sized; } trait Write { fn write(&amp;mut self, buf: &amp;[u8]) -> Result&lt;usize>; fn flush(&amp;mut self) -> Result&lt;()>; // provided default impls fn write_vectored(&amp;mut self, bufs: &amp;[IoSlice&lt;'_>]) -> Result&lt;usize>; fn is_write_vectored(&amp;self) -> bool; fn write_all(&amp;mut self, buf: &amp;[u8]) -> Result&lt;()>; fn write_all_vectored(&amp;mut self, bufs: &amp;mut [IoSlice&lt;'_>]) -> Result&lt;()>; fn write_fmt(&amp;mut self, fmt: Arguments&lt;'_>) -> Result&lt;()>; fn by_ref(&amp;mut self) -> &amp;mut Self where Self: Sized; } Generic blanket impls worth knowing:
impl&lt;R: Read + ?Sized> Read for &amp;mut R; impl&lt;W: Write + ?Sized> Write for &amp;mut W; These say that any mutable reference to a Read type is also Read, and same with Write. This is useful to know because it allows us to use any method with a self receiver as if it had a &amp;mut self receiver. We already went over how to do this and why it&rsquo;s useful in the Iterator trait section so I&rsquo;m not going to repeat it again here.
I&rsquo;d like to point out that &amp;[u8] impls Read and that Vec&lt;u8> impls Write so we can easily unit test our file handling functions using Strings which are trivial to convert to &amp;[u8] and from Vec&lt;u8>:
use std::path::Path; use std::fs::File; use std::io::Read; use std::io::Write; use std::io; // function we want to test fn uppercase&lt;R: Read, W: Write>(mut read: R, mut write: W) -> Result&lt;(), io::Error> { let mut buffer = String::new(); read.read_to_string(&amp;mut buffer)?; let uppercase = buffer.to_uppercase(); write.write_all(uppercase.as_bytes())?; write.flush()?; Ok(()) } // in actual program we'd pass Files fn example(in_path: &amp;Path, out_path: &amp;Path) -> Result&lt;(), io::Error> { let in_file = File::open(in_path)?; let out_file = File::open(out_path)?; uppercase(in_file, out_file) } // however in unit tests we can use Strings! #[test] // ✅ fn example_test() { let in_file: String = "i am screaming".into(); let mut out_file: Vec&lt;u8> = Vec::new(); uppercase(in_file.as_bytes(), &amp;mut out_file).unwrap(); let out_result = String::from_utf8(out_file).unwrap(); assert_eq!(out_result, "I AM SCREAMING"); } Conclusion We learned a lot together! Too much in fact. This is us now:
Artist credit: The Jenkins Comic
Discuss Discuss this article on
Github learnrust subreddit official Rust users forum Twitter lobste.rs rust subreddit Notifications Get notified when the next blog post get published by
Following pretzelhammer on Twitter or Watching this repo&rsquo;s releases (click Watch -> click Custom -> select Releases -> click Apply) Further Reading Sizedness in Rust Common Rust Lifetime Misconceptions Learning Rust in 2020 Learn Assembly with Entirely Too Many Brainfuck Compilers source:Tour of Rust&rsquo;s Standard Library Traits</content></entry><entry><title>Py Tips for Impatient Dev</title><url>https://zhimoe.github.io/post/py-tips-for-impatient-dev/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> tricks python的dict中关于equal和hash计算方式会有意外的效果 ['no', 'yes'][True] # output? {True: 'yes', 1: 'no', 1.0: 'maybe'} # output? “布尔类型是整数类型的子类型,布尔值在几乎所有环境中的行为都类似于值 0 和 1,但在转换为字符串时,分别得到的是字符串 False 或 True.”
&ndash; The Standard Type Hierarchy
由于True,1, 1.0的__eq__和__hash__都一样,所以出现了神奇的结果.
(1) != (1,) 第一个是int,第二个是tuple 避免可变的默认参数, 例如: def fun(count=[]): count.append(2) #这里count两次调用如果都使用默认参数的话,则是同一个数组,非常危险! return count fun() #[2] fun() #[2,2] staticmethod classmethod staticmethod和classmethod都可以通过Cls.m()或instance.m()方式访问,都可以被继承,都可以访问全局变量.区别是
classmethod访问的class变量信息会自动在Derive子类中改变,而staticmethod因为缺少第一个cls参数,所以访问的全局变量始终是父类的变量.
staticmethod可以理解为Java的StringUtils类,只是和Cls放在一起方便代码阅读和组织.
classmethod则是可以通过cls参数访问到当前类信息的.
容器方法 合并字典： d1.update(d2) # 遍历d2,更新到d1 d = dict(**profile, **ext_info) #解构重新创建dict,右边的优先级高 d = dict(profile.items() | ext_info.items()) #同理 d = d1 | d2 # 新语法 {k: v for d in [profile, ext_info] for k, v in d.items()} # 推导式 py3.6开始 dict默认插入有序,无需使用OrderDict dict get and pop d.get(k,default) d.setdefault(k,default) d.pop(k) #删除不存在的键时,使用del d[k]有异常抛出,pop则不会 自定义dict 自定义自己的dict不能继承dict,而是collections.abc.MutableMapping, 因为自带的list和dict有一些特殊行为无法覆盖
sort dict by key: print(sorted(dic, key=dic.get)) #output: key in asc order
判断key是否存在: if k in d: 带索引遍历: for idx, item in enumerate(x): 浅复制 list(l)等方式构建的list dict set属于浅复制,如果容器的元素还是容器,那么元素属于引用.
深度复制需要使用copy module
import copy xs = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] zs = copy.deepcopy(xs) # 对象同样可以使用copy,还有__copy__等魔法方法可以探索 使用namedtuple可以让代码更容易阅读,当然现在可以是所有dataclass,特性更丰富 from collections import namedtuple class Car: """you do not modify the name and date attributes """ def __init__(self, name, date): self._name = name self._date = date # use namedtuple Car = namedtuple('Car', 'name date') # 注意,这里多个属性可以一次性传入,使用空格分割 # 然后你可以将Car作为data class使用 #还有一个type hint的版本 from typing import NamedTuple list的元素可以不同,更为紧凑的单一类型是array类型 Counter(string).most_common(3) deque from collections import deque names = deque(['raymond', 'rachel', 'matthew', 'roger', 'betty', 'melissa', 'judith', 'charlie']) names.popleft() names.appendleft('mark') 一些不常用的容器：CountedObject,ChainMap,MappingProxyType,frozenset,defaultdict 在遍历中修改list 使用for i in range(len(a))或者for i, v in enumerate(a)都是危险的.
# 方法1 将list拷贝一下,遍历新数组的过程中,修改原list: num_list = [1, 2, 3, 4, 5] print(num_list) for item in num_list[:]: # 这里list[:]是对原数组的拷贝,trick!!! if item == 2: num_list.remove(item) else: print(item) print(num_list) # 方法2 如果数组很大,那应该使用倒序遍历: for i in range(len(num_list)-1, -1, -1): if num_list[i] == 2: num_list.pop(i) else: print(num_list[i]) # 方法3 还是使用for推导式 [4 if x==3 else x for x in num_list] 打印容器可以使用pprint.pprint str和bytes py3.6开始,推荐使用f-string,不要使用 %s或者 "".format().如果接收用户输入,使用Template做安全校验 多行string my_very_big_string = ( "For a long time I used to go to bed early. Sometimes, " "when I had put out my candle, my eyes would close so quickly " "that I had not even time to say “I’m going to sleep.”" ) bytes 和bytesarray bytes是不可变的数组,每个元素必须在0～255之间.
bytearray是可变的,可以修改,增加,删除元素.
转换 bytes(ba)
小整数池是[-5,256], string也有 string intern 有时使用str.partition方法拆分str或者str.translate批量replace子串更方便 多行文本去除缩进可以使用 textwrap.deden("""\your text""") str重复n次print(s * n); 重要标准库 bisect二分法搜索 use pathlib over os.pathlib. 后者方法不全. os vs sys os module is for system, sys this module provides access to some variables used or maintained by
the interpreter and to functions that interact strongly with the interpreter.
迭代器 迭代器：__iter__ 和 __next__ 两个方法 可迭代对象：__iter__ 方法 如果希望可迭代对象可以重复使用,应该在 __iter__ 每次返回新的迭代器对象。 yield生成器也是迭代器。itertools简化循环,例如product pythonic的代码 使用for推导式,不要for..in遍历,也少用map,filter 多使用destructing,这点在Java/Go都不支持,可以在方法内部省很多代码 long_list = [x for x in range(100)] a, b, *c, d, e, f = long_list #e==98 f=99 使用if x is None,而不是 if x == None 异常处理 清楚except和assert场合,logging.error(&lsquo;xxxxxxx&rsquo;, exc_info=True).
自定义异常必须重写__init__() 和 str()
x if x &lt; 10 else y use reversed(lis) over lis[::-1] @property make a method to class&rsquo;s property. can not use () when access the method cuz it is prop. use assert protect your code. 不要使用assert检查数据, 断言可能被全局禁用,导致数据检查（或者更恐怖的权限检查）被跳过 @functools.wraps(func) __var 在class环境中会被改写 使用abc模块可以避免抽象类只有在未实现方法被调用时才抛出NotImplementedError 理解python的dunder方法,可以写出超级简洁的方法： import collections Card = collections.namedtuple('Card', ['rank', 'suit']) class FrenchDeck: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] deck = new FrenchDeck() from random import choice choice(deck) # Card(rank='3', suit='hearts') 上面的例子我们使用了__len__方法和__getitem__方法,好处就是你可以使用python的len(deck),deck[1]这种语法,也就是说FrenchDeck几乎就是一个容器类型,还可以使用for遍历.
更多查看&lt;fluent python 2nd>.
其他 使用help(),dir()获取信息 python中的每个函数都有__code__属性,包含字节码信息 使用dis模块的dis函数可以查看更容易阅读的汇编(dis == disassembler) sys.getsizeof(x)获取对象大小 ...和pass几乎等效的,这是一个ellipsis type的单例. 无限大 float(&lsquo;inf&rsquo;) float(&rsquo;-inf&rsquo;) dis查看字节码 ==会被__eq__方法改变,判断是否None时应该使用is判断id是否一致 python的try可以配合else：当没有任何异常或者try里面没有return break,才执行else部分。这个和finally有很重要的不同 with需要实现__enter__ __exit__两个方法 with语句可以同时打开多个文件,不要嵌套with,更多功能查看contextlib 不要手动做数据校验,使用pydantic 不要使用assert校验参数合法性,因为可以通过-O参数跳过 参考资料 Python 工匠系列
RealPython学习路径
一份非常详尽的Python小抄
Fluent Python 2nd</content></entry><entry><title>如何实现一个拼写检查器[翻译]</title><url>https://zhimoe.github.io/post/spell-correct/</url><categories><category>翻译</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> 谷歌AI负责人norvig在07年写的如何实现一个拼写纠正器的经典博文How to Write a Spelling Corrector.
上面的链接已经是16年更新过了,程序也更新到了python3.
中文版的翻译 如何实现一个拼写纠正器 还是基于07年版本的.
博文最有意思的地方是大牛记录了如何在飞机上面没有网络的条件下徒手写一个准确率超过70%的拼写纠正器.</content></entry><entry><title>Associated Type in Rust</title><url>https://zhimoe.github.io/post/type-in-rust/</url><categories><category>编程</category></categories><tags><tag>rust</tag></tags><content type="html"> Associated Type and generic diff in rust
type outside impl a type Foo = Bar outside is just type alias. most used in generic type.
like: type Thunk = Box&lt;dyn Fn() + Send + 'static>;
type inside impl type in an impl defines an associated type. associated type可以理解为一个类型占位符,在trait的方法声明中使用.
pub trait Iterator { type Item; // or type T: Display; fn next(&amp;mut self) -> Option&lt;Self::Item>; } 这里Iterator的Implementors将会指定Item的具体类型.例如：
impl Iterator for Counter { type Item = u32; fn next(&amp;mut self) -> Option&lt;Self::Item> { // --snip-- } } diff in associated type and generic 直接将上面的Iterator声明为如下泛型不是更简单么？
pub trait Iterator&lt;T> { fn next(&amp;mut self) -> Option&lt;T>; } // with generice, you can set default type: /// trait Iterator&lt;T = String> /// where T: Display, 主要的区别就是generic可是有任意多个实现,因为Iterator&lt;Foo>和Iterator&lt;Bar>是两个不同的类型.
而associated type只能有一个实现,因为Iterator只有一个类型,所以associated type可以用于限制类型.
when use The quick and dirty answer to when to use generics and when to use associated types is:
Use generics if it makes sense to have multiple implementations of a trait for a specific type (such as the From&lt;T> trait).
Otherwise, use associated types (like Iterator and Deref).
假设我们实现一个redis 客户端,那么比较适合使用associated types:
trait RedisCommand{ type Response; fn receive(&amp;self, message: String) -> Result&lt;Self::Response>; } impl RedisCommand for PingCommand { type Response = String fn receive(&amp;self, message: String) -> Result&lt;Self::Response>{ // -- snip -- } }</content></entry><entry><title>最佳编程字体</title><url>https://zhimoe.github.io/post/programmingfonts/</url><categories><category>项目</category></categories><tags><tag>font</tag><tag>aurulent</tag><tag>firacode</tag></tags><content type="html"> 个人对于编程字体有一点点洁癖.在尝试十几个字体后,终于使用FontForge和fontline.py动手修改制作自己的编程字体:Aurulent和 Fira Code
Aurulent 字体下载
小写字母来自Aurulent Sans Mono,其他基于Fira Code.Aurulent Sans Mono风格和SourceCodePro非常像,胖宽型,大开大合,简单却有具有设计.特别是字符g,a,p,y,s. 字母r的思路来自gintronic. 优点是在低分辨率屏,r的末尾不会被hint只剩下尖尖. 问号？也来自gintronic字体,非常漂亮. FiraCode Fira Code是全网最受欢迎的字体.但是这个r实在过于fancy,所以重新绘制了一个.只提供regular和bold两个字重.
其他字体 个人比较喜欢的字体有
SourceCodePro, 只是这个r在低分辨率下一塌糊涂, 结合office code pro做了一个更适合正文的SourceCodePro版本 Adobe LetterGothic： 这是一个经典的IBM打字机字体.这个字体经典在于字符r是我认为所有字体里面设计的最漂亮的. 在字体设计中,感觉r是最难设计的,像fira code这种r, 有点过于fanncy,很容易吸引你的目光; 像source code pro那种超级简洁, 在win下面渲染除非是高分屏,否则一塌糊涂.除了字符r, letter gothic作为1960时代打字机默认字体之一,在字符n,u的角上,都保留了非常漂亮而含蓄的细节,这一点,我非常吐槽jetbrains mono字体,居然把小写u的尾巴去掉,声称可以加快阅读, 或许能提速,但是丢了美感. LetterGothic具体的效果看我之前的推文Thread. TheSansMono: 经典等宽字体.你可以在很多书上面看到这个字体.斜体是所有字体最好看的,收费.作者也是windows经典的代码字体Consolas作者.</content></entry><entry><title>如何正确地系鞋带</title><url>https://zhimoe.github.io/post/how-to-tie-shoelace/</url><categories><category>生活</category></categories><tags><tag>鞋带</tag></tags><content type="html"> Ian安全结是登山系鞋带的首选,它越穿越紧,不会松开.解鞋带轻轻一拉即开. 而且对称美观,上手简单.值得每个人花十分钟学习.
本篇不仅给出Ian安全结示意图,还告诉大家如何让安全结和蝴蝶结水平对称,尽可能美观的秘诀.
以上是Ian结的步骤.下面是重点：
无论是蝴蝶结还是Ian安全结,如果你发现自己的鞋带系完是斜的而非水平,原因是第一个辅助结和第二个结上下关系反了. 即图1的那个结是辅助结,黄色在上,蓝色在下,那么第二个结必须和图2中一样,黄色在上,蓝色在下, 如果你在第二步黄蓝反了,最后成结就是斜的!!! 这是我毕生绝学了.
Ian安全结想要好看的诀窍在于,在快要拉紧绳结之前,先拉住鞋带两端松一下结,假装要扯开鞋带,这样安全结内部会变整齐,然后抓住8字环两端拉紧鞋带.注意,是快要拉紧之前扯松一下,扯的时候绳结应该已经有点摩擦了,太松了外扯整理不到结的内部,太紧了外扯结也不会改变形状了,就是拉紧之前反复整理一下,注意,如果这里你辅助结上下关系错了,最后很难整理出来满意的效果.最后的效果应该是最后一幅图的效果,而不是第一幅的图6那么丑的.
作者：zhimoe
链接：https://www.zhihu.com/question/19728687/answer/501699533</content></entry><entry><title>Java 8 Lambda笔记</title><url>https://zhimoe.github.io/post/java-lambda/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>java</tag><tag>lambda</tag></tags><content type="html"> 问题 Java是OOP语言,使用对象封装.由于函数不是一等公民,无法在方法中传递函数/方法. 在Java 8之前,使用匿名类表示行为：
// 监听器接口 public interface ActionListener { void actionPerformed(ActionEvent e); } // 使用匿名类传递一个行为 button.addActionListener(new ActionListener(){ public void actionPerformed(Event e){ System.out.println("button clicked"); } }); 上面的代码主要的问题在于addActionListener方法期望的是一个行为,为了描述这个行为（代码即数据的概念）,在Java中不得不传入一个对象. 除了代码冗余,还存在下面问题
业务逻辑淹没在匿名类语法中,就像Go语言的if err != nil一样 匿名类中的 this 和变量名容易使人产生误解 类型载入和实例创建语义不够灵活 无法捕获非 final 的局部变量 lambda表达式 为了解决上面的问题,Java8推出了lambda表达式——当接口只有一个抽象方法时,称为函数式接口（也叫单抽象方法类型,SAM类型）,可以使用lambda表达式表示这个接口的实现方法.
button.addActionListener(e -> System.out.println("button clicked")); 其中的e是actionPerformed(Event e)方法的参数,-> 后面的是方法体. 注意这里我们并没有提供e的类型,这是由类型推导技术实现的——javac根据addActionListener方法签名和actionPerformed方法签名推导出参数类型只能是Event.
不是所有情况都可以省略类型,但是请给IDE表现机会,只有在IDE提醒你有错误时再补充上类型信息.
下面都是合法的lambda表达式：
Runnable tsk = () -> println(""); Runnable tsk = name -> { println(name);} BinaryOperator&lt;Long> add = (Long x, Long y) -> x + y; BinaryOperator&lt;Long> add = (x, y) -> {return x + y;} //类型推断, return和{}是冗余的 // &lt;!-- 参数括号和大括号省略规则 --> // 1. 参数()：无参数使用(),1个参数可以省略括号,其他使用(). // 2. 函数体{}：单语句的可以省略{},多条语句必须有{} 在Java中,已经有大量的函数式接口：
java.lang.Runnable java.util.concurrent.Callable java.security.PrivilegedAction java.util.Comparator java.io.FileFilter java.beans.PropertyChangeListener this指向调用者,也即是button lambda的类型是根据上下文来决定的, 所以相同入参和返回值情况下,目标类型可能不同,在无法判断时,需要补充目标类型信息: Callable&lt;String> c = () -> "done"; PrivilegedAction&lt;String> a = () -> "done"; // error var add = (Long x, Long y) -> x + y; // 这里add会报错： // java: cannot infer type for local variable add // (lambda expression needs an explicit target-type) // 因为满足 (Long, Long) -> Long的函数式接口很多,编译器无法知道add目标类型应该是什么. 当涉及到泛型时,类型推导总是有点力不从心,需要添加必要的类型信息： 函数式接口与@FunctionalInterface 有了lambda和函数式接口,框架方法在形参类型上面可以更加泛化了.例如你希望你的框架方法支持一个T->R的操作,你可能会定义一个
@FunctionalInterface public interface Transfer&lt;T, R> { R apply(T t); } 这里T,R是泛型,这是一个非常泛化的函数式接口.所以Java8在util.function包中新增了43个函数式接口,目的就是方便框架开发者能够减少新建自己的FunctionalInterface.
基础的接口只有6个:
接口 函数签名 举例 UnaryOperator R apply(T t); String::toLocaerCase BinaryOperator R apply(T t, U u); BigInterger::add Predicate boolean test(T t); Collection::isEmpty Function R apply(T t); Arrays::asList Supplier T get(); Instant::now Consumer void accept(T t); System.out::println 上面的是基础接口,此外还有：
Consumer, Function, Predicate各自有一个2个入参的版本,共3个:BiConsumer,BiFunction,BiPredicate. 6个基础接口对应入参为基本类型int,long,double的接口,共18个:IntSupplier,LongFunction&hellip; 6个基础接口对应返回值为基本类型int,long,double的Function和BiFunction,共6个: ToIntBiFunction,ToIntFunction&hellip; int,long,double基本类型互转的Function共6个：DoubleToIntFunction,DoubleToLongFunction,IntToDoubleFunction,IntToLongFuncion,LongToDoubleFunction,LongToIntFunction. Consumer有同时接受一个Object和一个基本类型的版本,共3个: ObjDoubleConsumer{void accept(T t, int value);} 最后还有一个BooleanSupplier{boolean getAsBoolean();} 第一次见到BooleanSupplier可能完全不知道使用场景,毕竟有Supplier不就可以了么？
上面的基础接口虽然非常通用,但是如果有更好的接口名称时,应该使用更合适的那个.例如Comparator{int compare(T o1, T o2);}和ToIntBiFunction&lt;T, U> {int applyAsInt(T t, U u);}签名完全一致,但是还是在比较的时候使用Comparator.
在构建自己的函数式接口时,务必使用注解@FunctionalInterface标注你的接口,这样可以给IDE lint和使用者提供更加充分信息.
方法引用 如果lambda表达式的方法体过长,那么需要抽取方法,Java8提供了更近一步的语法——方法引用. 方法引用表示一个lambda表达式.只需要引用的方法签名和lambda目标类型的抽象方法签名一致即可.
方法引用一共有5种类型,其中,静态方法是最常用的类型.
方法引用类型 方法引用 对应lambda表达式 静态方法 Integer::parseInt str-> Integer.parseInt(str) 有限制(Bound receiver)实例引用 Instant.now()::isAfter Instant then = Instant.now(); then.isAfter(t) 无限制(Unbound receiver)实例引用 String::toLowerCase str -> str.toLowerCase 类构造器 TreeMap&lt;K,V>::new ()-> new TreeMap&lt;K,V>() 数组构造器 int[]::new len->new int[len] Bound receiver其实很好理解,方法的receiver(上面的then = Instant.now())是固定的. Unbound receiver的含义是方法的接收者(上面的str)是不确定的, 通过入参的形式传入. 而在方法引用的形式上面反而像静态方法引用(String::toLowerCase, toLowerCase不是静态方法,所以不是静态方法引用). 更粗暴的理解就是入参是方法的引用对象,所以方法引用对象取决于入参（不确定）. 数组构造器的比较难以理解,可以看成如下代码： IntFunction&lt;int[]> arrayMaker = int[]::new; int[] array = arrayMaker.apply(len) // 创建数组 int[len]</content></entry><entry><title>基于MDX的web词典</title><url>https://zhimoe.github.io/post/mdict-web/</url><categories><category>项目</category></categories><tags><tag>python</tag><tag>rust</tag></tags><content type="html"> Mdict项目是一个糅合了MDX词典、ES例句搜索和AI模型翻译的多源搜索功能Web词典.特别适合部署在内网中学习使用或者给孩子学习使用.
python版本增加了一个机器学习模型翻译.rust版本也有模型,但是还没来得及加.
mdict-py mdict-py源码
Mdict项目是一个糅合了MDX词典、ES例句搜索和AI模型翻译的多源搜索功能Web词典.特别适合部署在内网中学习使用或者给孩子学习使用.
特点：
自动识别中英文选择对应mdx词典,目前英文词典包含牛津8和朗文4,中文词典包含汉语词典3 英文尝试拼写纠错功能,动词时态纠错 如果配置了中文会尝试搜索朗文的例句,模糊搜索,对于有英语基础的同学很有用 如果配置了AI模型,会使用机器学习模型翻译,翻译结果比较粗糙,但是可以参考 mdict-rs mdict-rs源码
和python版本相比目前只有基本功能： mdx文件解析,查询.</content></entry><entry><title>Python 4道笔试题</title><url>https://zhimoe.github.io/post/python-interview-questions/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> 4道常见的python面试题和解答,以及一些python陷阱的链接.
问题 题目1 def change(v): v[1] = 4 return v a = [1, 2, 3] print(change(a)) print(a) 题目2 def append1(x=[]): x.append(1) return x def now(n=time.time()): time.sleep(1) return n print(append1(), append1()) #? print(now(), now()) #? 题目3 def arr_multi(): x = [[0] * 3] * 3 x[0][0] = 42 return x print(arr_multi()) 题目4 def fn_for(): f = [lambda x: x * i for i in range(3)] print(f[0](1), f[1](1), f[2](1)) print(fn_for()) 解答 [1, 4, 3] [1, 4, 3] # 就是简单的引用传递,但是很多人不自信,在选择题里面频频出错. # python中所有的都是对象, id(obj)会返回地址. # 但是如果新建对象是short string,int [-5,256],不可变的空集合(empty tuples) 等情况不会真的创建新对象. from copy import copy, deepcopy arr1 = [1,2,3,[4,5,6]] arr2 = copy(arr1) # shallow copy, new id, but elements in array is same id id(arr1[0]) == id(arr2[0]) #deepcopy arr3 = deepcopy(arr1) # elements id is new # 结果: [1, 1] [1, 1] 1590544209.9695618 1590544209.9695618 # 不少人认为是: [1] [1, 1].其实还是没有深入理解引用的原理, # 翻译一下就很好理解了: y = append1() # id(y) == id(x), y=[1] y = append1() # id(y) == id(x), y=[1,1] print(y,y) # 最好不要使用[]作为默认参数,使用下面的形式: def my_func(working_list=None): if working_list is None: working_list = [] working_list.append("a") print(working_list) # 或者 def fun(count=[]): count.append(2) #这里count两次调用如果都使用默认参数的话,则是同一个数组,非常危险! return count fun() #[2] fun() #[2,2] [[42, 0, 0], [42, 0, 0], [42, 0, 0]]
list 是mutable, []*3表示是引用复制三次. 赋值后为什么只改变列的值？ 4. ```text 2 2 2 None 本意其实是想得到一个函数列表[0x,1x,2*x],
但是 Python’s closures are late binding. This means that the values of variables used in closures are looked up at the time the inner function is called.
解决方案是偏函数partial
from functools import partial def fix_fn_for(): f = [partial(lambda y, x: y * x, x=i) for i in range(3)] print(f[0](1), f[1](1), f[2](1)) 或：
fl=[lambda x, i=i: x*i for i in range(3)] 常见python陷阱
The 10 Most Common Mistakes in Python
Some Common Gotchas in Python</content></entry><entry><title>Scala Python 文件读取跳过转义字符</title><url>https://zhimoe.github.io/post/scala-python-file-encoding-escape/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag><tag>python</tag></tags><content type="html"> 在文件读取的时候,会遇到非法转义字符,导致文件按行读取失败.此时可以通过忽略转义字符来解决.本文记录了scala和python的方法.
背景 有50G的服务器日志,拆分为几千个txt文件,编码是utf8,使用scala和python按行处理：
scala def main(args: Array[String]): Unit = { for (line &lt;- Source.fromFile("./txt1.log","UTF8").getLines()) { if (line.contains("ABC")) { //do something } } } python with open('./txt1.log','r',encoding='utf-8') as f: for line in f: pass #do something 但是文本中有一些行包含非法的转义字符,例如：
http://bbc.com/search.html \xa3\xa9 404 \r\n 李晓明 导致程序异常:
#scala java.nio.charset.MalformedInputException: Input length = 1 #python 'utf-8' codec can't decode byte 0xa3 in position 168: invalid start byte 方案 一般遇到这种非法转义字符,可以跳过这个错误,看成raw string来处理.
scala import java.nio.charset.CodingErrorAction import scala.io.{Codec, Source} implicit val codec = Codec("UTF-8") codec.onMalformedInput(CodingErrorAction.REPLACE) codec.onUnmappableCharacter(CodingErrorAction.REPLACE) // 注意,fromFile方法没有提供"UTF8"参数 def main(args: Array[String]): Unit = { for (line &lt;- Source.fromFile("./test.file").getLines()) { if (line.contains("ABC")) { //do something } } } python with open('./txt1.log','r',encoding='utf-8',errors='ignore') as f: for line in f: pass #do something 如果确认文本中没有中文的话,也可以使用下面的方式直接将其转义掉
with open('./txt1.log','r',encoding='unicode_escape') as f:</content></entry><entry><title>Matplotlib图例中文乱码解决方案</title><url>https://zhimoe.github.io/post/matplotlib-chinese-garbled-solution/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> 很久以前写的一个答案,四年来一直有人评论感谢,说只有我的方法是有效的.非常意外也很高兴. 也放到博客中里备份吧.
zhihu.com
# https://www.zhihu.com/question/25404709/answer/67672003 import matplotlib.font_manager as fm # 微软雅黑,如果需要宋体,可以用simsun.ttc myfont = fm.FontProperties(fname='C:/Windows/Fonts/msyh.ttc') # Linux字体在"/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc", # 需要先安装字体">sudo apt install fonts-noto-cjk -y" # MacOS中文字体文件在"/System/Library/Fonts/PingFang.ttc" # Win10,Linux已测试,MacOS未验证 import matplotlib.pyplot as plt plt.clf() # 清空画布 plt.plot([1, 2, 3], [4, 5, 6]) plt.xlabel("横轴",fontproperties=myfont) plt.ylabel("纵轴",fontproperties=myfont) plt.title("pythoner.com",fontproperties=myfont) plt.legend(['图例'],prop=myfont) plt.show()</content></entry><entry><title>Rust Ownerships Lifetimes教程</title><url>https://zhimoe.github.io/post/rust-ownership-lifetimes/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>rust</tag></tags><content type="html"> some notes on rust ownership,reference,string and &amp;str, and lifetimes
rust ownership //heap and stack: stack is store data that known,fixed size. //memory manager keeping track of what parts of code are using what data on the heap, //minimizing the amount of duplicate data on the heap, and cleaning up unused data on the heap //so you don’t run out of space are all problems that ownership addresses. //ownership rules: // Each value in Rust has a variable that’s called its owner. // There can only be one owner at a time. // When the owner goes out of scope, the value will be dropped. // stack only data(栈内数据) assignment will make a copy operation, since it is fixed size, the copy is fast // rust use h.clone() make a heap data deeply copy. // impl the Copy trait can make the original variable still usable after assignment. // Copy trait can not use with Drop trait, Drop可以理解为destructor,当数据超过自己的scope时, drop()方法被调用; fn copy() { let x = 5; let y = x; //copy the value(5) in the stack,since it is fixed-size, the copy operation is fast let s1 = String::from("hello"); //String 和 &amp;str区别见后文 let s2 = s1; //now s1 is invalid // println!("{}, world!", s1); //error, the "hello" ownership move to s2 let s3 = s2.clone(); //copy the heap value("hello"), String impl the Clone trait println!("{}, world!", s2); //s2 still usable } // passing function arguments or return value by function is same as // assigning a value to a variable, you need take care the ownership of heap value, fn ownership() { let x = 5; let x10 = plus10(x);//x still usable since the x is stack data println!("{}", x); println!("{}", x10); let s = String::from("hello"); takes_ownership(s); //s's value moves into the function and so is no longer valid here //println!(s) ;//error! } fn plus10(i: i32) -> i32 { // since the i is primitive in stack, so the function return a new value i + 10 } fn takes_ownership(some_string: String) { // some_string comes into scope println!("{}", some_string); } // Here, some_string goes out of scope and `drop()` is called. The backing memory is freed. 推荐阅读A closer look at Ownership in Rust
References and Borrowing: // since the ownership is too hard to track by coder's eye, rust introduce the ref and borrowing // a function that accept a ref will not takeover a value's ownership when the function is called // also will not drop the value's backend memory when function is return. // a variable can only have one mut ref or many immutable ref in a same scope; //dangling reference fn dangle() -> &amp;String { let s = String::from("dangle ref"); &amp;s //error }// the s is dropped, but the function try to return s reference ### String vs str vs &amp;String vs &amp;str //1. String is heap string buffer //2. &amp;String is a ref of String //3. str is unknown immutable sequence of utf8 bytes stored somewhere in memory. the memory may be: // 3a. in binary: a string literal "foo" is a &amp;'static str. The data is hardcoded into the executable and loaded into memory when the program runs. // 3b. in heap: String implement Deref&lt;Target=str>, and so inherit all of str's methods. // 3c. in stack: when use str::from_utf8(x).unwrap(); x is stack-value ref //> the &amp;str param can accept a &amp;String since the String implement Deref&lt;Target=str>. // 即接受&amp;str的地方都可以使用&amp;String //!!! since the str is unknown size, one can only use it by &amp;str, called slice. slice is a view of some data. fn str_demo() { let s = "hello str";//The type of s here is &amp;str: it’s a slice pointing to that specific point of the binary. // This is also why string literals are immutable; &amp;str is an immutable reference. let mut string = s.to_string(); //&amp;str to String string.push_str(" append"); println!("{}", string); } //a slice has static lifetime let s = "hello"; //means let s: &amp;’static str = "hello"; lifetimes are only about reference a ref must die before its referent
in rust:
A resource can only have one owner at a time. When it goes out of the scope, Rust removes it from the Memory.
When we want to reuse the same resource, we are referencing it/ borrowing its content.
When dealing with references, we have to specify lifetime annotations to provide instructions for the compiler to set
how long those referenced resources should be alive.
⭐ But because of lifetime annotations make the code more verbose, in order to make common patterns more ergonomic,
Rust allows lifetimes to be elided/omitted in fn definitions. In this case, the compiler assigns lifetime annotations
implicitly.
// No inputs, return a reference fn function1&lt;'a>() -> &amp;'a str {} // Single input fn function2&lt;'a>(x: &amp;'a str) {} // Single input and output, both have the same lifetime // The output should live at least as long as input exists fn function3&lt;'a>(x: &amp;'a str) -> &amp;'a str {} // no need the lifetime annotation,lifetime elision // Multiple inputs, only one input and the output share same lifetime // The output should live at least as long as y exists fn function4&lt;'a>(x: i32, y: &amp;'a str) -> &amp;'a str {} // Multiple inputs, both inputs and the output share same lifetime // The output should live at least as long as x and y exist fn function5&lt;'a>(x: &amp;'a str, y: &amp;'a str) -> &amp;'a str {} // Multiple inputs, inputs can have different lifetimes 🔎 // The output should live at least as long as x exists fn function6&lt;'a, 'b>(x: &amp;'a str, y: &amp;'b str) -> &amp;'a str {} lifetimes in struct/enum // Single element // Data of x should live at least as long as Struct exists struct Struct1&lt;'a> { x: &amp;'a str } // Multiple elements // Data of x and y should live at least as long as Struct exists struct Struct2&lt;'a> { x: &amp;'a str, y: &amp;'a str } // Variant with a single element // Data of the variant should live at least as long as Enum exists enum Enum&lt;'a> { Variant(&amp;'a Type) }</content></entry><entry><title>SpringBoot应用和Rust应用的Dockerfile最佳实践</title><url>https://zhimoe.github.io/post/dockerfile-best-practices/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>docker</tag><tag>spring</tag><tag>rust</tag></tags><content type="html"> 记录spring boot和rust项目的Dockerfile的最佳实践.
spring boot应用Dockerfile spring.io提供了一个boot应用的Dockerfile指导.
不过有个问题,这个Dockerfile使用的maven是项目源码里面copy过去的.在一般企业项目中这么做显然不规范,直接使用maven基础镜像更合理.
Dockerfile的最终版:
# syntax=docker/Dockerfile:experimental FROM maven:3-jdk-8-alpine as build WORKDIR /workspace/app COPY pom.xml . COPY src src RUN --mount=type=cache,target=/root/.m2 mvn package -DskipTests # app base image FROM openjdk:8-jdk-alpine VOLUME /tmp ARG BUILD=/workspace/app/target WORKDIR /app COPY --from=build ${BUILD}/*.jar . RUN jar -xf ./*.jar RUN rm ./*.jar ENTRYPOINT ["java","-cp","/app","org.springframework.boot.loader.JarLauncher"] 要点:
# syntax=docker/Dockerfile:experimental表示启用docker实验特性BuildKit的mount cache功能,这样可以利用maven lib的cache提高镜像构建速度. 可以搜索docker BuildKit了解.
如果没有这一行,那么下面的--mount=type=cache,target=/root/.m2就是非法的. 由于是实验特性,构建镜像的时候需要设置一个环境变量DOCKER_BUILDKIT=1才能运行: DOCKER_BUILDKIT=1 docker build -t zhimoe/boot-app . spring.io的教程里面使用的build镜像是openjdk:8-jdk-alpine,这个镜像是没有maven的,因为教程中的Dockerfile从源码复制了mvnw,.mvn/到镜像去.所以这里替换为maven:3-jdk-8-alpine 使用了docker的multi-stage build功能,openjdk:8-jdk-alpine由于没有maven,所以会比maven镜像少20M. spring.io的教程里面在ENTRYPOINT里面是直接设置main class启动应用的. 这种硬编码方式不通用也不利于维护(修改main class name后Dockerfile也要修改).只要将应用的jar包解压出来的org目录(即org.springframework.boot.loader.jar解压内容,不到1M)保留,即可通过org.springframework.boot.loader.JarLauncher启动应用. 注意java -cp /app中的classpath:/app 一定是绝对路径,否则java找不到main class,报错:Error: Could not find or load main class org.springframework.boot.loader.JarLauncher rust应用Dockerfile # pull the latest version of Rust FROM rust:latest AS builder # create a new empty shell project RUN USER=root cargo new --bin prj WORKDIR /prj # copy over your manifests COPY ./Cargo.lock ./Cargo.toml ./ # change the crate.io source COPY ./config $CARGO_HOME/ # this build step will cache your dependencies RUN cargo build --release RUN rm -r src/* # copy your source files to WORKDIR/src COPY ./src ./src COPY ./static ./static # build for release, note! the Cargo.toml package name in deps is _, not - RUN rm ./target/release/deps/rs_notes* RUN cargo build --release RUN mv ./target/release/rs-notes . ## 2 stage build # our final base FROM debian:stretch-slim AS app # for connecting to postgres and TLS hosts # RUN apt update -y &amp;&amp; apt install -y libpq-dev openssl libssl1.0-dev ca-certificates # copy the build artifact and static resources from the build stage COPY --from=builder /prj/rs-notes ./ COPY --from=builder /prj/static ./static # set the startup command to run your binary CMD ["./rs-notes"] 要点:
如果使用scratch或者alpine镜像,那么需要将编译目标设置为MUSL,网络上有教程,个人感觉不需要.rust应用使用debian-slim基本在60M左右,只有spring boot应用镜像的一半大小. 在国内由于网络问题,所以修改了cargo的crate.io mirror地址:COPY ./config $CARGO_HOME/. config内容如下: [source.crates-io] registry = "https://github.com/rust-lang/crates.io-index" replace-with = 'ustc' [source.ustc] registry = "git://mirrors.ustc.edu.cn/crates.io-index" build中使用了cargo缓存,即先将项目Cargo.toml和Cargo.lock复制到一个空项目中编译,然后再将源码复制进去编译. RUN rm ./target/release/deps/rs_notes*,注意这里的rs_notes是下划线.cargo中package name转换为crate name的默认规则.</content></entry><entry><title>Docker CMD ENTRYPOINT区别</title><url>https://zhimoe.github.io/post/docker-cmd-entrypoint-diff/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>docker</tag></tags><content type="html"> 记录docker中exec form和shell form的区别,CMD和ENTRYPOINT区别,以及最佳实践.
exec form VS shell form # exec form &lt;instruction> ["executable", "param1", "param2", ...] # shell form &lt;instruction> &lt;command> exec form 以JSON格式解析,所以命令参数必须使用""双引号包裹; exec form 不会invoke shell. 所以CMD [ "echo", "$HOME" ]中$HOME变量不会被替换; shell form实际是执行/bin/sh -c "&lt;command>"; 优先使用 exec form,因为在shell form中spawns your application in a new process and you won’t receive signals from Docker,在k8s中会遇到问题; 在shell form也可以使用exec &lt;cmd>形式; CMD VS ENTRYPOINT 直接翻译SO上面的回答,比较清楚
ENTRYPOINT是容器执行入口,CMD是参数设置.
Docker有默认的 ENTRYPOINT:/bin/sh -c,但是没有默认的CMD.但是一般镜像都会设置一个默认的CMD.(注意是docker的默认 ENTRYPOINT,和镜像的默认CMD,基础镜像一般不设置 ENTRYPOINT)
docker run -i -t ubuntu bash the ENTRYPOINT is the default /bin/sh -c, the image is ubuntu and the command is bash.
所以上面的命令实际上在启动容器中执行了/bin/sh -c bash. 不是所有场景都需要"/bin/sh"的,所以引入了 ENTRYPOINT and --entrypoint.
docker run -i -t ubuntu中 ubuntu(镜像名)后面跟的所有内容都作为参数传递给entrypoint. 这和使用CMD指令是完全一样的,也即是CMD指令可以在docker run中覆盖.
由于ubuntu镜像设置了默认CMD: CMD ["bash"],所以docker run -i -t ubuntu和docker run -i -t ubuntu bash是完全一样的效果.
所以到此,可以总结: ENTRYPOINT 是容器的执行入口,CMD是参数设置,不过参数也可以是bash中的可执行命令(例如,CMD ["echo","hello"],实际执行 /bin/sh -c "echo hello").
ENTRYPOINT和CMD的搭配可以实现将容器作为一个可执行文件启动,这个特性也是我们日常使用docker的主要目的.例如在Dockerfile中设置:
ENTRYPOINT ["/bin/cat"] 运行docker run cat-img /etc/passwd,/etc/passwd 是cmd, 实际执行的是/bin/cat /etc/passwd. 恭喜你,得到一个cat程序,假设你安装了一个linux系统,里面没有cat命令,cat-img镜像就可以实现你想要的功能.
再例如你有个redis镜像,与其运行 docker run redis-img redis -H srv-host -u toto get key,
不如设置ENTRYPOINT ["redis", "-H", "srv-host", "-u", "toto"] 然后运行docker run redis-img get key.
Dockerfile只有最后一个CMD会生效; 可以使用docker inspect &lt;img-id>查看默认的CMD参数; 取消默认ENTRYPOINT,可以在Dockerfile中设置: ENTRYPOINT []</content></entry><entry><title>scala uniform access principle</title><url>https://zhimoe.github.io/post/scala-uniform-access-principle/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> 虽然代码写的很水,但是我对各种编程语言一直比较感兴趣. 除了工作中使用的Java之外,自己也了解Python,Groovy,Scala,Kotlin,Clojure,Go,Rust.其中Python和Scala在工作中也偶尔使用. 了解不同的编程语言语法对于编程思维的影响还是蛮有意思的.
例如, 只会Java的开发者可能没有听过模式匹配(pattern match).在我学习了Scala之后,我对模式匹配的理解就是更强更优雅的switch+if. 而在我看过rust和elixir语言中关于模式匹配之后,我对模式匹配的理解就完全不一样了.
这些语言中,论说对编程思维改变最大的当属Clojure莫属. Lisp语言是一种非常优雅的语言. 这种优雅的最大特点就是Lisp(Clojure)从语法上面做到了代码即数据.即Clojure的代码形式和其数据结构list的形式是一样的(这也是lisp名字由来,LISt Processor).
这个特点的好处就是Clojure赋予了list这种数据结构强大的表达能力,可以在使用极其简练的语法在list数据结构实现复杂的逻辑.
&ldquo;It is better to have 100 functions operate on one data structure than 10 functions on 10 data structures.&rdquo; —Alan Perlis
尽可能的减少语法的规则,这种语法特点在Scala上面也有体现.
uniform access principle scala 中统一访问原则将class的方法和属性访问统一,都是通过obj.mbr访问.
这么做的好处是代码更加统一,而且重构更加方便.
A function that takes no parameters, which is defined without any empty parentheses.
Invocations of parameter less functions may not supply parentheses.
This supports the uniform access principle, which enables the def to be changed into a val without
requiring a change to client code.
class Person { private var privateName = "" def name = privateName def name_=(value: String) = privateName = value } val john = new Person john.name = "John Doe" println(john.name) 统一也体现在集合访问形式上,在Scala中,Map,List,Array的元素访问都是通过coll(ki)形式. ki表示key或者index.个人非常喜欢这种统一.</content></entry><entry><title>Highlights in Scala for Impatient 2nd</title><url>https://zhimoe.github.io/post/highlights-in-scala-for-impatient-2nd/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag><tag>scala-for-impatient</tag></tags><content type="html"> key points in scala-for-impatient 2nd book, best book for java developer to use scala in a rush.
scala-for-impatient章节摘要, 这本书对于Java开发者快速上手Scala帮助很大.
Functions • if expression has a value. • A block has a value — the value of its last expression. • The Scala for loop is like an “enhanced” Java for loop. • Semicolons are (mostly) optional. • The void type is Unit. • Avoid using `return` in a function. • Beware of missing = in a function definition. • Exceptions work just like in Java or C++, but you use a “pattern matching” syntax for catch. • Scala has no checked exceptions. Arrays • Use an Array if the length is fixed, and an ArrayBuffer if the length can vary. • Don’t use new when supplying initial values. • Use () to access elements. • Use for (elem &lt;- arr) to traverse the elements. • Use for (elem &lt;- arr if . . . ) . . . yield . . . to transform into a new array. • Scala and Java arrays are interoperable; with ArrayBuffer, use scala.collection.JavaConverters._ don't use scala.collection.JavaConversions. import scala.collection.mutable.ArrayBuffer val b = ArrayBuffer[Int]() // Or new ArrayBuffer[Int] // An empty array buffer, ready to hold integers b += 1 // ArrayBuffer(1) // Add an element at the end with += b += (1, 2, 3, 5) // ArrayBuffer(1, 1, 2, 3, 5) // Add multiple elements at the end by enclosing them in parentheses b ++= Array(8, 13, 21) // ArrayBuffer(1, 1, 2, 3, 5, 8, 13, 21) // You can append any collection with the ++= operator b.trimEnd(5) // ArrayBuffer(1, 1, 2) // Removes the last five elements b.insert(2, 6) // ArrayBuffer(1, 1, 6, 2) // Insert before index 2 // iterate array with index // use view or use index(it's faster) for (i&lt;-b.indices){val v = b(i)} Maps &amp; Tuples var scores = Map("Alice" -> 10, "Bob" -> 3, "Cindy" -> 8) val scores2 = Map(("Alice", 10), ("Bob", 3), ("Cindy", 8)) val bobsScore = scores("Bob") // Like scores.get("Bob") in Java val scores1 = scala.collection.mutable.Map("Alice" -> 10, "Bob" -> 3, "Cindy" -> 8) val scores3 = scala.collection.mutable.Map[String, Int]() scores1("Bob") = 10 val v = scores1("Bob") // NPE if key is not exists scores1.get("Bob") // None if key is not exists scores1.getOrElse("Bob",10)// 10 if key is not exists scores1 += ("Bob" -> 10, "Fred" -> 7) scores1 -= "Alice" // for immutable val newScores = scores + ("Bob" -> 10, "Fred" -> 7) // New map with update val scores4 = scores - "Alice" scores -= "Alice" for ((k, v) &lt;- scores){} for ((k, v) &lt;- scores) yield (v, k) // sorted map val sortedScores = scala.collection.mutable.SortedMap("Alice" -> 10,"Fred" -> 7, "Bob" -> 3, "Cindy" -> 8) // insert order val months = scala.collection.mutable.LinkedHashMap("January" -> 1,"February" -> 2, "March" -> 3, "April" -> 4, "May" -> 5) import scala.collection.JavaConverters._ // tuple val t = (1, 3.14, "Fred") val second = t._2 // Sets second to 3.14 val keys = Array() val values = Array() val kv = keys.zip(values).toMap() Object • Use objects for singletons and utility methods. • A class can have a companion object with the same name. • Objects can extend classes or traits. • The apply method of an object is usually used for constructing new instances of the companion class. • To avoid the main method, use an object that extends the App trait. • You can implement enumerations by extending the Enumeration object. Package The key points of this chapter are: • Packages nest just like inner classes. • Package paths are not absolute. • A chain x.y.z in a package clause leaves the intermediate packages x and x.y invisible. • Package statements without braces at the top of the file extend to the entire file. • A package object can hold functions and variables. • Import statements can import packages, classes, and objects. • Import statements can be anywhere. • Import statements can rename and hide members. • java.lang, scala, and Predef are always imported Inheritance • The `extends` and `final` keywords are as in Java. • You must use `override` when you override a method. • Only the primary constructor can call the primary superclass constructor. • You can `override` fields. Files • Source.fromFile(...).getLines.toArray yields all lines of a file. • Source.fromFile(...).mkString yields the file contents as a string. • To convert a string into a number, use the toInt or toDouble method. • Use the Java PrintWriter to write text files. • "regex".r is a Regex object. • Use """...""" if your regular expression contains backslashes or quotes. • If a regex pattern has groups, you can extract their contents using the syntax for (regex(var1, ...,varn) &lt;- string). Traits Key points of this chapter: • A class can implement any number of traits. • Traits can require implementing classes to have certain fields, methods, or superclasses. • Unlike Java interfaces, a Scala trait can provide implementations of methods and fields. • When you layer multiple traits, the order matters—the trait whose methods execute first goes to the back. Operators val a = 10 //a: Int = 10 -a // res0: Int = -10 //means the same as a.unary_-. a.unary_- //res1: Int = -10 High Order Functions Array(3.14, 1.42, 2.0).map{ (x: Double) => 3 * x } //== Array(3.14, 1.42, 2.0) map { (x: Double) => 3 * x } // diff method and function Collections The key points of this chapter are: • All collections extend the Iterable trait. • The three major categories of collections are sequences, sets, and maps. • Scala has mutable and immutable versions of most collections. • A Scala list is either empty, or it has a head and a tail which is again a list. • Sets are unordered collections. • Use a LinkedHashSet to retain the insertion order or a SortedSet to iterate in sorted order. • + adds an element to an unordered collection; +: and :+ prepend or append to a sequence; ++ concatenates two collections; - and -- remove elements. • The Iterable and Seq traits have dozens of useful methods for common operations. Check them out before writing tedious loops. • Mapping, folding, and zipping are useful techniques for applying a function or operation to the elements of a collection Iterable trait methods: head, last, headOption, lastOption tail, init length, isEmpty map(f), flatMap(f), foreach(f), transform(f), collect(pf) reduceLeft(op), reduceRight(op),foldLeft(init)(op), foldRight(init)(op) reduce(op), fold(init)(op),aggregate(init)(op, combineOp) sum, product, max, min count(pred), forall(pred), exists(pred) filter(pred), filterNot(pred), partition(pred) takeWhile(pred), dropWhile(pred), span(pred) take(n), drop(n), splitAt(n) takeRight(n), dropRight(n) slice(from, to), view(from, to) zip(coll2), zipAll(coll2, fill, fill2), zipWithIndex(cation! the 2nd value in tuple is index) grouped(n), sliding(n) groupBy(k) // mkString(before, between, after), addString(sb, before, between, after) toIterable, toSeq, toIndexedSeq, toArray, toBuffer, toList, toStream, toSet, toVector, toMap, to[C] Important Methods of the Seq Trait: contains(elem), containsSlice(seq), startsWith(seq), endsWith(seq) indexOf(elem), lastIndexOf(elem), indexOfSlice(seq), lastIndexOfSlice(seq), indexWhere(pred) prefixLength(pred), segmentLength(pred, n) padTo(n, fill) intersect(seq), diff(seq) reverse sorted, sortWith(less), sortBy(f) permutations, combinations(n) //The map and flatMap methods are important because they are used //for translating for expressions. For example, the expression: for (i &lt;- 1 to 10) yield i * i //is translated to (1 to 10).map(i => i * i) //and for (i &lt;- 1 to 10; j &lt;- 1 to i) yield i * j //becomes (1 to 10).flatMap(i => (1 to i).map(j => i * j)) val coll = List() coll.par.sum coll.par.count(_ % 2 == 0) for (i &lt;- (0 until 100000).par) print(s" $i") (for (i &lt;- (0 until 100000).par) yield i) == (0 until 100000) Pattern Matching The key points of this chapter are: • The match expression is a better switch, without fall-through. • If no pattern matches, a MatchError is thrown. Use the case _ pattern to avoid that. • A pattern can include an arbitrary condition, called a guard. • You can match on the type of an expression; prefer this over isInstanceOf/asInstanceOf. • You can match patterns of arrays, tuples, and case classes, and bind parts of the pattern to variables. • In a for expression, nonmatches are silently skipped. • A case class is a class for which the compiler automatically produces the methods that are needed for pattern matching. • The common superclass in a case class hierarchy should be sealed. • Use the Option type for values that may or may not be present—it is safer than using null. Annotations The key points of this chapter are: • You can annotate classes, methods, fields, local variables, parameters,expressions, type parameters, and types. • With expressions and types, the annotation follows the annotated item. • Annotations have the form @Annotation, @Annotation(value), or @Annotation(name1 =value1, ...). • @volatile, @transient, @strictfp, and @native generate the equivalent Java modifiers. • Use @throws to generate Java-compatible throws specifications. • The @tailrec annotation lets you verify that a recursive function uses tail call optimization. • The assert function takes advantage of the @elidable annotation. You can optionally remove assertions from your Scala programs. • Use the @deprecated annotation to mark deprecated features. Future The key points of this chapter are: • A block of code wrapped in a Future { ... } executes concurrently. • A future succeeds with a result or fails with an exception. • You can wait for a future to complete, but you don’t usually want to. • You can use callbacks to get notified when a future completes, but that gets tedious when chaining callbacks. • Use methods such as map/flatMap, or the equivalent for expressions, to compose futures. • A promise has a future whose value can be set (once), which gives added flexibility for implementing tasks that produce results. • Pick an execution context that is suitable for the concurrent workload of your computation. Implicits The key points of this chapter are: • Implicit conversions are used to convert between types. • You must import implicit conversions so that they are in scope. • An implicit parameter list requests objects of a given type. They can be obtained from implicit objects that are in scope, or from the companion object of the desired type. • If an implicit parameter is a single-argument function, it is also used as an implicit conversion. • A context bound of a type parameter requires the existence of an implicit object of the given type. • If it is possible to locate an implicit object, this can serve as evidence that a type conversion is valid. Type Class CanBuildFrom</content></entry><entry><title>Rust Packages Crates Mod Notes</title><url>https://zhimoe.github.io/post/rust-packages-crates-mod/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>rust</tag></tags><content type="html"> 初学rust对于项目的package和crate的关系,module和文件的关系有点理不清.做了一点笔记.
packages, crates and modules A Cargo.toml is a package. and must have a package name, like
[package] name = "actix-web" A package(project) contains one or more crates;
A package CAN contain as many binary crates as you’d like, but it must contain at least one crate (either library or binary);
use src/main.rs, will build to package-name binary, or use src/bin/b1.rs,src/bin/b2.rs, wil get 2 binaries: b1,b2.
A package must contain zero or one(0或者1个) library crates, and no more.
by convention, package-name is use - (dash,can be _), but lib_name must use _ (underscores, can not be -);
cargo will auto replace the - with _ in package-name to name the default library crate(lib.rs in src root). Also you can name it in [lib]:
[lib] name = "actix_web" path = "src/lib.rs" # also you can rename the binary: # it use [[]], array in toml [[bin]] name = "my-cool-binary" path = "src/my-cool-binary.rs" one package(project) can only have one library crate, when the lib continues to get bigger, you want to split up the lib into multiple packages.
cargo introduce you with workspace.
A workspace is a set of packages that share the same Cargo.lock and output directory.
here is the actix-web package Cargo.toml file:
[workspace] members = [ ".", "awc", "actix-http", "actix-cors", "actix-files", "actix-framed", "actix-session", "actix-identity", "actix-multipart", "actix-web-actors", "actix-web-codegen", "test-server", ] # awc,actix-http... all are packages that contains their own Cargo.toml and src/lib.rs; A crate is a compilation unit in Rust.
Whenever rustc some_file.rs is called, some_file.rs is treated as the crate file.
If some_file.rs has mod declarations in it, then the contents of the module files would be inserted
in places where mod declarations in the crate file are found, before running the compiler it.
In other words, modules do not get compiled individually, only crates get compiled.
mod mod_name {} defines a mod.
mod mod_name; cargo will look for mod_name.rs or mod_name/mod.rs and insert the content to current file.
by default the mod is private; but nested mod is allowed to use any code in super mod;
self and super is to ref the current mod and super mod;
fn main(){ // absolute path crate::music::popular::play(); // relative path music::popular::play(); } the Structs members is all private by default even struct name is pub;
the Enums members is all public by default if the name is pub;
use keyword the use keyword brings path(crate mod path) into scope;
//bring a module into scope with `use` and a relative path need start `self`: use self::music::popular; //!!!the self:: is no needed in rust 2018+ //use the absolute path use crate::music::popular; //make the path to public pub use crate::music::popular; //use use std::{cmp::Ordering,io}; use std::{self,Write}; split up mod into files the mod can be defined in mod_name.rs or mod_name/mod.rs. and nested mod can be in mod_name/nested_mod.rs. you can ref the nested_mod by use mod nested_mod; in mod_name.rs; summary 简单粗暴的理解,一个项目 == 一个package, 一个package可以包含多个crate.
crate是Cargo的编译单元,也是Cargo.toml中[dependencies]的依赖单元.
一个package只能包含一个lib crate(src/lib.rs),但是可以在src/main.rs或者src/bin/*.rs下面包含任意多个bin crate;
对于复杂项目,可以通过cargo的[workspace]管理多个crate,这样可以实现一个Cargo.toml管理/构建多个lib crate.
mod是rust中代码的组织最小单元. mod mod_name {} 是定义一个mod;mod mod_name; 表示将mod_name.rs或者mod_name/mod.rs中的内容插入到当前文件当前位置,并且插入内容被包含在mod mod_name中.
crate内部的mod引用使用self::开头,引用外部crate则使用crate::开头.</content></entry><entry><title>git 常用命令备忘录</title><url>https://zhimoe.github.io/post/git-useful-tips/</url><categories><category>编程</category></categories><tags><tag>git</tag><tag>code</tag></tags><content type="html"> 记录日常开发中偶尔会遇到的但是总是记不住的git命令.
以下技巧都来自于oh shit git 和 stackoverflow. 版权归作者所有.
delete all history commit and commit current content git checkout --orphan tmp_branch &amp;&amp; git add -A &amp;&amp; git commit -am "first commit" &amp;&amp; git branch -D master &amp;&amp; git branch -m master &amp;&amp; git push -f origin master store password in local git config credential.helper store git reflog git reflog # you will see a list of every thing you've # done in git, across all branches! # each one has an index HEAD@{index} # find the one before you broke everything git reset HEAD@{index} # magic time machine git commit &ndash;amend # make your change git add . # or add individual files git commit --amend --no-edit # now your last commit contains that change! # WARNING: never amend public(remote) commits!!! # I need to change the message on my last commit! git commit --amend # follow prompts to change the commit message undo a commit # Oh shit, I need to undo a commit from like 5 commits ago! # find the commit you need to undo git log # use the arrow keys to scroll up and down in history # once you've found your commit, save the hash git revert [saved hash] # git will create a new commit that undoes that commit # follow prompts to edit the commit message # or just save and commit undo a file&rsquo;s changes # find a hash for a commit before the file was changed git log # use the arrow keys to scroll up and down in history # once you've found your commit, save the hash git checkout [saved hash] -- path/to/file # the old version of the file will be in your index git commit -m "Wow, you don't have to copy-paste to undo" git stash # 如果临时想要将代码恢复到最近一次commit,帮助同事复现他的问题 # 使用git stash 暂存当前修改,这个不是stage,也不是commit git stash # 显示当前暂存历史 git stash list # 找回暂存 git stash apply # or spec which the stash git stash apply stash@{1} git rebase git pull request git cherry-pick commit change in submodule # submodule is a independent repo, # so you need commit/push change in submodule first and then # update(commit) the main project to refer a new submodule commit hash # step 1 cd path/to/submodule git add &lt;stuff> git commit -m "comment" git push # step 2 cd /main/project git add path/to/submodule git commit -m "updated my submodule" git push</content></entry><entry><title>DevOps能力成熟度模型</title><url>https://zhimoe.github.io/post/devops-maturity-model-checklist/</url><categories><category>编程</category></categories><tags><tag>devops</tag></tags><content type="html"> 之前听说过AWS的软件工程师是需要自己写需求说明书,前后端代码,测试和上线.还有instagram的工程师可以做到python的代码提交如果合并到主分支后可以在一个小时内自动部署到生产被用户使用到,感觉这个非常神奇.如果需要做到这个,对组织级与个人都有极高的devops能力成熟度要求.
上周代表CRM项目通过了信通院的DevOps三级认证.感觉提升的空间很大. 专门看了一下成熟度模型的标准.
核心要点是要有统一的管理系统,系统之间需要联动,
例如记录故事的系统,如何和你提交记录关联?
测试的缺陷问题如何和你的故事关联?
生产正在运行的代码,如何和代码库的某个基线对应上?
测试报告/需求说明书是否统一管理并和你的迭代有关联?
是否可以做到事故后定会之后回滚部署?
研发运营一体化（DevOps）能力成熟度模型 第1部分：总体架构</content></entry><entry><title>Scala Collection Tips</title><url>https://zhimoe.github.io/post/scala-collection-tips/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> scala collection 提供了一整套独立于Java的高性能集合,使用上非常灵活,所以需要清楚一些常用的方法:
reduce fold scan 集合的符号方法 数组,tuple 2.13的集合架构 reduce fold scan //reduce是一个二元函数,遍历整个集合 List(1, 3, 5).reduceLeft(_ + _) // == ((1+3)+5) //reduceRight start from end of the collection //also you can given initial argument List(1, 3, 5).foldLeft("")(_ + _) // == 135 //foldLeft 等价于 \: 操作符 (0 /: List(1, 3, 5)) (_ - _) //folding 常用于替代for-loop val wf1 = scala.collection.mutable.Map[Char, Int]() for (c &lt;- "Mississippi") wf1(c) = wf1.getOrElse(c, 0) + 1 // Now freq is Map('i' -> 4, 'M' -> 1, 's' -> 4, 'p' -> 2) //注意使用了不可变map val wf = (Map[Char, Int]() /: "Mississippi") { (m, c) => m + (c -> (m.getOrElse(c, 0) + 1)) } //scan 方法可以获得每一步中间结果集 (1 to 10).scanLeft(0)(_ + _) //Vector(0, 1, 3, 6, 10, 15, 21, 28, 36, 45, 55) 集合的符号方法 //+ 表示添加一个元素到无序集合 // :+ +:表示添加到有序集合的首/尾 //elem append or prepend to coll (Seq) coll :+ elem elem +: coll //add elem to set/map coll + elem coll + (e1,e2,...) coll ++ coll2 coll2 ++: coll // prepend to lst elem :: lst lst2 ::: lst // 等价list ++: list2 list ::: list2 // 含有=的表示修改,必须是mutable的集合 // TIP: As you can see, Scala provides many operators for adding and removing // elements. Here is a summary: // 1. Append (:+) or prepend (+:) to a sequence. // 2. Add (+) to an unordered collection. // 3. Remove with the - operator. // 4. Use ++ and -- for bulk add and remove. // 5. Mutations are += ++= -= --=. // 6. For lists, many Scala programmers prefer the :: and ::: operators. // 7. Stay away from ++: +=: ++=:. NOTE: For lists, you can use +: instead of :: for consistency, with one
exception: Pattern matching (case h::t) does not work with the +: operator.
其他 //数组的笔记 val ints = new Array[Int](30) // empty array val ints2 = Array[Int](1, 2, 3, 4) // array with init values val matrix4x9 = Array.ofDim[Double](4, 9) //update ints2(3) = 1000 // or ints2.update(3, 1000) //求和 val ints2Sum = ints2.sum val days = Array("Monday", "Tuesday", "Wednesday", "Thrusday", "Friday", "Saturday", "Sunday") //遍历 for (i &lt;- 0 until days.length) println(days(i)) for (day &lt;- days) println(day) days foreach println //遍历中使用index days.zipWithIndex.map { case (e, i) => (i, e) } //faster for (i &lt;- days.indices) yield (i, days(i)) //Possibly fastest Array.tabulate(days.length) { i => (i, days(i)) } //肯定最快 val b = new Array[(Int, String)](days.length) var i = 0 while (i &lt; days.length) { b(i) = (i, days(i)) i += 1 } //filter days.filter(day => day.length > 4) //map Array(1, 2, 3, 4, 5).map(x => x * x) //sort Array(3, 6, 2, 0, 8, 5).sortWith((e1, e2) => e1 &lt; e2) //小的在前 //reduce,下面的会提示使用sum, Array(1, 2, 3, 4, 5).reduce((e1, e2) => e1 + e2) //不定长数组 import scala.collection.mutable.ArrayBuffer val arr = ArrayBuffer[Int]() //tuple val oneAndTwo = (1, 2) val oneAndTwo1 = Tuple2(1, 2) //Pair is alias of Tuple2 val oneAndTwo2 = Pair(1, "two") val oneAndTwo3 = 1 -> 2 //访问元素下标是从1开始,这是因为tuple里面每个元素类型不一样,为了能够和list等区分开 //使用了类似Haskell/ML的习惯 val two = oneAndTwo._2 //option val emptyOpt: Option[Int] = None val fullOpt: Option[Int] = Some(42) emptyOpt match { case Some(value) => println(value) case None => println("Empty") } fullOpt.get //42 emptyOpt.isEmpty //true //either def divide(a: Double, b: Double): Either[String, Double] = { if (b == 0.0) Left("Division by zero") else Right(a / b) } divide(4, 0) def either(flag: Boolean): Either[String, List[Int]] = { if (flag) Right(List(1, 2, 3)) else Left("Wrong") } val content = either(true).right.map(_.filter(_ > 0)) //cast Seq(1).toArray Seq(1).toBuffer Seq(1).toList Seq((1, 2)).toMap Seq(1).toStream Seq(1).toString Seq(1).toVector Seq(1).toTraversable Seq(1).toIndexedSeq Seq(1).toIterable Set(1).toSeq Seq(1).toSet //zip, zipAll, zipWithIndex, unzip "abcde" zip 1.to(5) //zipAll:第二个参数是调用者元素缺失使用的默认值,第三个参数是第一个实参不够长的默认值 "abcde".zipAll(1.to(2), "caller", "arg") //尝试自己实现一个zipAll? // "abcde" zipWithIndex Seq((1, 2), (3, 4), (5, 6)) unzip // val s = Seq("a", "b") scala 2.13 collection 基本重写了.参考这两个文档:
collections migration 2.13
the architecture of scala 2.13’s collections</content></entry><entry><title>前端静态资源图片优化[翻译]</title><url>https://zhimoe.github.io/post/%E5%89%8D%E7%AB%AF%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E5%9B%BE%E7%89%87%E4%BC%98%E5%8C%96/</url><categories><category>翻译</category></categories><tags><tag>code</tag></tags><content type="html"> GTmetrix是一个前端页面测试的网站,可以发现你的站点哪些图片加载速度较慢,并针对性的优化.
source:How to Optimize Images: A Practical Guide</content></entry><entry><title>Spring FactoryBean and ContextAware</title><url>https://zhimoe.github.io/post/spring-factorybean-contextaware/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>spring</tag></tags><content type="html"> 理解Spring的FactoryBean 和 ContextAware接口.
FactoryBean 一句话就是FactoryBean用于返回其他对象实例的,而不是自身类型的实例.
public class Tool { private int id; // standard constructors, getters and setters } public class ToolFactory implements FactoryBean&lt;Tool> { private int factoryId; private int toolId; @Override public Tool getObject() throws Exception { return new Tool(toolId); } @Override public Class&lt;?> getObjectType() { return Tool.class; } @Override public boolean isSingleton() { return false; } // standard setters and getters } 注册Tool:
&lt;!-- factorybean-spring-ctx.xml --> &lt;beans> &lt;bean id="tool" class="com.baeldung.factorybean.ToolFactory"> &lt;property name="factoryId" value="9090"/> &lt;property name="toolId" value="1"/> &lt;/bean> &lt;/beans> 使用注解注册:
@Bean(name = "tool") ToolFactory toolFactory() { ToolFactory factory = new ToolFactory(); factory.setFactoryId(7070); factory.setToolId(2); return factory; } 使用Tool:
@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = { "classpath:factorybean-spring-ctx.xml" }) public class FactoryBeanXmlConfigTest { @Autowired private Tool tool; @Test public void testConstructWorkerByXml() { assertThat(tool.getId(), equalTo(1)); } } 访问ToolFactory,在bean id前面添加 &amp;:
@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = { "classpath:factorybean-spring-ctx.xml" }) public class FactoryBeanXmlConfigTest { @Resource(name = "&amp;tool") private ToolFactory toolFactory; @Test public void testConstructWorkerByXml() { assertThat(toolFactory.getFactoryId(), equalTo(9090)); } } 和BeanFactory的区别 除了FactoryBean,还有一个BeanFactory的接口及其实现.</content></entry><entry><title>通过例子学习Clojure</title><url>https://zhimoe.github.io/post/learn-clojure-by-example/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>clojure</tag></tags><content type="html"> 这份笔记试图打造最强的clojure小抄,keep refactoring it&hellip;
clojure 入门 (ns clj-notes.core (:gen-class)) ;:gen-class generate java class file ;Parameter is variable in the declaration of function. ;Argument is the actual value of this variable that gets passed to function. ; ;install leiningen: ;put lein.bat in your PATH ;open cmder,run: lein repl ;start repl,use exit,(exit),(quit) or ctrl+d to quit repl (println "hello clojure") ;Symbols are used to bind names to values ;' will prevent a form from being evaluated ;'() same as (quote ()) ;def global variable ;let local variable binding (def object "light") (println object) (let [x 10 y 20 z 30] (+ x y z)) ;=> 60 ;data collection ;seq is abstract for list vector array ;map (def dict {:k1 "v1" :k2 "v2"}) ;keyword as function (:k1 dict) ;return v1 ;map as function (dict :k1) ;return v1 (let [v (dict :k1)] (println v)) ;also you can use get on seq or map (get {:a 1 :b 2} :b) ;=> 2 ;clojure.core/seq is a function that produces a sequence over the given argument. ;Data types that clojure.core/seq can produce a sequence over are called seqable: ; ;Clojure collections ;Java maps ;All iterable types (types that implement java.util.Iterable) ;Java collections (java.util.Set, java.util.List, etc) ;Java arrays ;All types that implement java.lang.CharSequence interface, including Java strings ;All types that implement clojure.lang.Seqable interface ;nil ;function for seq or collection ;= ;count ;conj ;empty ;seq ;first ;rest ;next ;count ;counted? ;conj ;get ;assoc ;defn 定义函数 ;defn- 定义ns内私有函数 (defn f "the second line is doc-string" {:added "1.2" ;this is attr-map :static true} [param] (print "hello " param)) (meta (var f)) ;#' is the reader macro for var and works the exactly same (meta #'f) ;fn create a function (def f (fn [] (println "this is from fn function"))) ;#() is the shortcut for fn (def plus-one #(+ 1 %)) ;% will be replaced with arguments passed to the function ;%1 is for the first argument, %2 is for the second and so on (defn des [{k1 :k1}] ;get :k1 value from argument (map) and binding it to k1(parameter) (println "destructing in map" k1)) (des dict) ;destructing in map v1 ;key don't have to be keyword (defn currency-of [{currency "currency"}] currency) (defn currency-of [{currency 'currency}] currency) ;if want to destructing multi key,use :keys, in this case,parameter name(currency amount) ;must same as arguments's keys(:currency :amount),can not use string as key (defn currency-of [{:keys [currency amount]}] (* currency amount)) (currency-of {:currency "RMB" :amount 100000}) ;ok (currency-of {"currency" "RMB" "amount" 100000}) ;currency will be nil,you will need use :strs or syms (defn currency-strs [{:strs [currency amount]}] currency) (currency-strs {"currency" "RMB" "amount" 100000}) ;ok (defn currency-syms [{:syms [currency amount]}] currency) (currency-syms {'currency "CNY" 'amount 100000}) ;ok ;use :or to give a default value for parameter (defn currency-or [{:keys [currency amount] :or {currency "USD"}}] currency) (currency-or {:amount 100000}) ;=> "USD" ;use &amp; for Variadic Functions parameters (defn log [message &amp; args] (println "args: " args)) ;named params , achieved by Variadic Functions destructing (defn job-info [&amp; {:keys [name job income] :or {job "unemployed" income "$0.00"}}] (if name [name job income] (println "No name specified"))) ;cation! arguments to job-info is not a map (job-info :name "Robert" :job "Engineer") ;["Robert" "Engineer" "$0.00"] ;Without the use of a variadic argument list, ;you would have to call the function with a single map argument such as (job-info {:name "Robert" :job "Engineer"}) ;destructuring example ;https://gist.github.com/john2x/e1dca953548bfdfb9844 (def my-vec [1 2 3]) (let [[a b c d] my-vec] (println a b c d)) ;1 2 3 nil (let [[a b &amp; the-rest] my-vec] (println "a=" a "b=" b "the-rest=" the-rest)) ;a= 1 b= 2 the-rest= (3) (let [[:as all] my-vec] (println all)) ;[1 2 3] (let [[a :as all] my-vec] (println a all)) ;1 [1 2 3] (let [[a b &amp; the-rest :as all] my-vec] (println a b the-rest all)) ;1 2 (3) [1 2 3] ;note: &amp; the-rest convert vector to list, ;but :as preserves them (as a list, or as a vector) (def my-vec ["first" "second"]) (let [{a 0 b 1} my-vec] (println a b)) ;=> "first second" ;optional arguments to functions (defn foo [a b &amp; more-args] (println a b more-args)) (foo :a :b) ;; => :a :b nil (foo :a :b :x) ;; => :a :b (:x) (foo :a :b :x :y :z) ;; => :a :b (:x :y :z) ;map destructuring (def my-hashmap {:a "A" :b "B" :c "C" :d "D"}) (def my-nested-hashmap {:a "A" :b "B" :c "C" :d "D" :q {:x "X" :y "Y" :z "Z"}}) (let [{a :a d :d} my-hashmap] (println a d)) ;; => A D (let [{a :a, b :b, {x :x, y :y} :q} my-nested-hashmap] (println a b x y)) ;; => A B X Y (let [{a :a, b :b, not-found :not-found, :or {not-found ":)"}, :as all} my-hashmap] (println a b not-found all)) ;; => A B :) {:a A :b B :c C :d D} ;!!! There is no &amp; rest for maps. ;everything but false and nil evaluates to true in Clojure. ;:as bind entire map to param ;See https://github.com/ring-clojure/ring/wiki/File-Uploads for explanation (defn file-handler ;表示入参是一个map,里面有:params这个key,将:params ;[{{{tempfile :tempfile filename :filename} "file"} :params :as request}] [{{{tempfile :tempfile filename :filename} "file"} :params :as request}] (println request) (let [n (num-lines tempfile)] (response (str "File " filename " has " n " lines ")))) ;a simple example (defn first-first [[[i _] _]] i) (first-first [[1 2] [3 4]]) ;return 1 ;(defn name doc-string? attr-map? [params*] prepost-map? body) ;(defn name doc-string? attr-map? ([params*] prepost-map? body) + attr-map?) ;function can have params type hint (defn round "^double here is type hint" [^double d ^long precision] (let [factor (Math/pow 10 precision)] (/ (Math/floor (* d factor)) factor))) ;不定长参数 ;重载函数 (defn bar ([a b] (bar a b 100)) ([a b c] (* a b c))) (bar 5 6) (bar 5 6 3) (defn keyworded-map [&amp; {:keys [function sequence]}] (map function sequence)) (keyworded-map :sequence [1 2 3] :function #(+ % 2)) ;trampoline ;trampoline ;namespace ;create-ns create a namespace (create-ns 'zhi.moe.clj) ;in-ns move to a namespace ;require loads a namespace and ;refer refers the namespace. ;To do these at once, you can use use (require 'clojure.by.example) (clojure.by.example/favorite-language) (use 'clojure.by.example) ;you can rename namespace (require '[clojure.by.example :as temp-ns]) ;ns macro creates a new namespace and gives you an opportunity to load other namespaces at the creation time ;import java class (import java.util.Date) (println (str (new Date))) ;Wed Jul 24 22:55:24 CST 2019 ;boolean ;In Clojure, everything except false and nil are true. (if 1 (println "it is true") (println "will never print")) ;if (if true (println "executed when true") (println "executed when false")) ;use do to execute multi expressions (if true (do (println "one") (println "two"))) ;if-let: (defn positive-number [numbers] (if-let [pos-nums (not-empty (filter pos? numbers))] pos-nums "no positive numbers")) ;when when-let case cond condp ; (defn cond-test [n] (cond (= n 1) "n is 1" (and (> n 3) (&lt; n 10)) "n is over 3 and under 10" :else "n is other")) (cond-test 1000) ;string (let [first "Hirokuni" last "Kim"] (str "My name is " first " " last)) ;format (format "My name is %s %s" "Hirokuni" "Kim") ;power function (defn power [x n] (reduce * (repeat n x))) ;bigint,N is a literal for bigint (+ 9223372036854775807 10N) ;list conj nth count '(1 2 3) ;vector conj nth count .indexOf [1 2 3] (.indexOf [1 2 3] 4) (count [1 2]) ;set conj nth count disj sort contains? subset? superset? #{1 2 3} ;map assoc merge keys vals (let [os {:Apple "Mac" :Microsoft "Windows"}] (get os :Apple)) (assoc {:Apple "Mac" :Microsoft "Windows"} :Commodore "Amiga") ;Sequences are data types that abstract all more concrete data types with unified functions. ;These functions are called the Seq library in Clojure. ;seq first rest cons concat map reduce into ;To add an element to the head of sequence, use cons. (cons 4 [1 2 3]) (into [] `(1 2 3)) (reverse [1 2 3]) ;get a sequence of infinite integers with iterate. Be careful, ;though. Running this example will freeze your terminal since the evaluation of this expression never returns. (doc iterate) (doc range) (repeatedly 5 (fn [] (println "hi!"))) ;for each (doseq [animal ["cat" "dog" "horse"]] (println animal)) (take 5 (range 0 100)) (take-while neg? [-3 -2 -1 0 1 2 3]) ;drop will remove the first n elements (drop 5 (range 0 10)) (drop-while neg? [-3 -2 -1 0 1 2 3]) ;(0 1 2 3) (remove pos? [-1 -2 3 4]) ;(-1 -2) (filter pos? [-1 2 3]) (partition-by #(&lt; 3 %) [1 2 3 4 5 6]) (group-by #(&lt; 3 %) [1 2 3 4 5 6 1 2 3]) (println (take 5 (iterate inc 0))) ;for compression (for [x '(1 2 3)] (+ 10 x)) (doc for) ;双重for 循环 (for [x (range 10) y (range 20) :while (&lt; y x)] [x y]) ;&lt;==> {x | x >0} (for [x '(-1 1 2) :when (> x 0)] x) (for [x [0 1 2 3 4 5] :let [y (* x 3)] :when (even? y)] y) ;meta data for function parameters (defn round [^double d ^long precision] (let [factor (Math/pow 10 precision)] (/ (Math/floor (* d factor)) factor))) ;# is Dispatch character that tells the Clojure reader how to interpret the next character using a read table ;set #{1 2 3} ;discard {:a 1, #_#_:b 2, :c 3} ;regular expression (re-matches #"^test$" "test") ;anonymous function #(println %) ;var quote (read-string "#'foo") ;symbolic values (/ 1.0 0.0) ;##Inf ;tagged literals (type #inst "2014-05-19T19:12:37.925-00:00") ;java.util.Date ;meta (meta #'fn-name) ;reader conditionals #?(:clj (Clojure expression) :cljs (ClojureScript expression) :cljr (Clojure CLR expression) :default (fallthrough expression)) ;#?@ splicing reader conditional (defn build-list [] (list #?@(:clj [5 6 7 8] :cljs [1 2 3 4]))) ;return [5 6 7 8] when run on clojure ;#= allows the reader to evaluate an arbitrary form during read time (read-string "#=(+ 3 4)") ;7 ;Recursion ;simple recursion (defn fibo "this is recursion function" [n] (if (or (= n 0) (= n 1)) n (+ (fibo (- n 1)) (fibo (- n 2))))) ;do not do this!!! take a long time to finish (fibo 1000) ;use recur (defn fibo-recur [iteration] (let [fibo (fn [one two n] (if (= iteration n) one (recur two (+ one two) (inc n))))] ;recur re-binds it's arguments to new values and call the function with the new values ;fibo is an inner function (fibo 0N 1N 0))) (fibo-recur 1000) ;it is really fast ;notes ;with simple recursion, each recursive call creates a stack frame which is ;a data to store the information of the called function on memory. ;Doing deep recursion requires large memory for stack frames, but since it cannot, ;we get StackOverflowError ;尾递归 ;A function is tail recursive when the recursion is happening at the end of it's definition ;In other words, a tail recursive function must return itself as it's returned value. ;When you use recur, it makes sure you are doing tail recursion (doc loop) ;loop/recur is merely a friendly way to write recursion code. ;All imperative loops can be converted to recursions and all recursions can be converted to loops, ;so Clojure chose recursions. ;Although you can write code that looks like an imperative loop with loop/recur, ;Clojure is doing recursion under the hood. ; (defmacro unless [test then] "Evaluates then when test evaluates to be falsey" (list 'if (list 'not test) then)) (macroexpand '(unless false (println "hi"))) ;' quoting ;` syntax-quoting returns the fully qualified namespace. ;Using fully qualified namespace is very important in order to avoid name conflicts when defining macro. ;~ unquote `(+ ~(list 1 2 3)) ;(clojure.core/+ (1 2 3)) `(+ ~@(list 1 2 3)) ;(clojure.core/+ 1 2 3) ;The ~@ unquote splice works just like ~ unquote, ;except it expands a sequence and splice the contents of ;the sequence into the enclosing syntax-quoted data structure ;thread first macro (-> [] (conj 1) (conj 2) (conj 3)) ;[1 2 3] (first (.split (.replace (.toUpperCase "a b c d") "A" "X") " ")) ;"X" ;;Perhaps easier to read: ;-> 后面是初始参数,第2行开始每一行是一个函数调用, ;且上一行的返回值会作为这一行第一个参数(这就是thread first)的first含义 ;这里的thread是管道的意思,而不是并发编程的线程 ;如果省略(),那么野生符号(bare symbol)和keyword都会当作一个函数调用, ;例如,这里的.toUpperCase是bare symbol,等效于(.toUpperCase ,,,) ;clojure中 逗号等于空白符,所以上面用,,,表示将会插入的参数(即"a b c d") (-> "a b c d" .toUpperCase (.replace "A" "X") (.split " ") first) ;same as follow, ,,, is equals whitespace (-> "a b c d" (.toUpperCase,,,) (.replace "A" "X") (.split " ") first) ;suppose a function (defn calculate [] (reduce + (map #(* % %) (filter odd? (range 10))))) ;same as ;上一行的结果作为最后一个参数插入,这叫thread last (defn calculate* [] (->> (range 10) (filter odd?,,,) (map #(* % %),,,) (reduce +,,,))) ;如果想要指定每次插入的位置那么需要用 as-> ;v是每一行的返回值的名称,这样你可以在下一行任意参数位置指定 (as-> [:foo :bar] v (map name v) (first v) (.substring v 1)) ; ;destructing ({:keys [firstname lastname] :as person} {:firstname "John" :lastname "Smith"}) ;future and deref (let [future-val (future (inc 1))] (println (deref future-val))) ;deref == @ (let [future-val (future (inc 1))] (println @future-val)) (def my-future (future (Thread/sleep 5000))) (repeatedly 6 (fn [] (println (realized? my-future)) (Thread/sleep 1000))) (doc future) ;promise (def my-promise (promise)) ;you define a promise (def listen-and-callback (fn [] (println "Start listening...") (future (println "Callback fired: " @my-promise)))) (defn do-time-consuming-job [] (Thread/sleep 5000) (deliver my-promise "delivered value")) (listen-and-callback) (do-time-consuming-job) ;atom is like mutable var in other languages but atom is thread safe ;ref dosync ref-set alter (def my-ref (ref 0)) (dosync (alter my-ref (fn [current_ref] (inc current_ref)))) (print @my-ref) (def user (ref {})) (dosync (alter user merge {:name "Kim"}) (throw (Exception. "something wrong happens!")) (alter user merge {:age 32})) (def user-record (atom {})) (do (swap! user-record merge {:name "Kim"}) (throw (Exception. "something wrong happens!")) (swap! user-record merge {:age 32})) ;Java (new java.util.Date "2016/2/19") (java.util.Date.) (java.util.Date. "2016/2/19") (Math/pow 2 3) ;static method (def rnd (new java.util.Random)) (. rnd nextInt 10) (let [date1 (new java.util.Date) date2 (new java.util.Date)] (.equals date1 date2)) ;(.instanceMember instance args*) ;(.instanceMember Classname args*) ;(.-instanceField instance) ;(Classname/staticMethod args*) ;Classname/staticField ;;; (defn geohash [lat lng] (println "geohash:" lat lng) ;;this function take two separate values as params. ;;and it return a geohash for that position ) (let [{:strs [lat lng] :as coord} {"lat" 51.503331, "lng" -0.119500}] (println "calculating geohash for coordinates: " coord) (geohash lat lng)) ;assoc-in associate使加入</content></entry><entry><title>理解Elasticsearch Query DSL中的JSON结构</title><url>https://zhimoe.github.io/post/elasticsearch-query-dsl/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>elasticsearch</tag></tags><content type="html"> 理解ES搜索中JSON DSL有助于自己写JSON查询,特别是手写复杂嵌套json.
diffs in es 2.x and es 5.x query dsl aggr query diffs in es 2.x and es 5.x 没有string类型,改为text和keyword 2个类型了.text字段可以指定fields来不分词.如下： city字段被ingest为city和city.raw2个字段. { "mappings": { "_doc": { "properties": { "city": { "type": "text", "fields": { "raw": { "type": "keyword", "ignore_above": 256 } } } } } } } default double -> float geo_point //2.x "location": { "type": "geo_point", "lat_lon": true, "geohash": true, "geohash_prefix": true, "geohash_precision": "1m" } //5.x "location": { "type": "geo_point" } query dsl basic query 就像砌房子的砖头,基本查询就是ES查询的砖头.基本查询是组合查询(bool查询等)的单元.基本查询有：
//basic query element match, multi_match, common, geoshape, ids, match_all, query_string, simple_query_string, range, prefix, regexp, span_term, term, terms, wildcard 其中common, ids, prefix, span_term, term, terms, wildcard 是不分析(即不能用于text字段)搜索,match, multi_match, query_string, simple_query_string是全文检索,几乎可以确保可以返回结果.而prefix,regexp,wildcard是模式检索.这里分别给一些例子:
multi_match multi_match 查询为能在多个字段上反复执行相同查询提供了一种便捷方式
既然时多字段查询,则有3中场景:best_fields 、 most_fields 和 cross_fields （最佳字段、多数字段、跨字段）
{ "multi_match": { "query": "Quick brown fox", "type": "best_fields", //默认的,可不填 "fields": [ "title", "body" ], "tie_breaker": 0.3, "minimum_should_match": "30%" } } 等价于下面的形式:
{ "dis_max": { "queries": [ { "match": { "title": { "query": "Quick brown fox", "minimum_should_match": "30%" } } }, { "match": { "body": { "query": "Quick brown fox", "minimum_should_match": "30%" } } }, ], "tie_breaker": 0.3 } } 还可以使用通配符指定字段,以及给某些字段添加权重.
{ "multi_match": { "query": "Quick brown fox", "fields": [ "*_title", "chapter_title^2" ] } } query_string 和 simple_query_string 非常灵活的一个查询方式:
// GET index_name/_search { "query": { "query_string" : { "default_field" : "content", "query" : "(new york city) OR (big apple)" } } } 上面的query字段语法可以参考: query_string_syntax
simple_query_string不会抛出异常,直接忽略无效语句.
term terms // 不要用于text字段 // GET /_search { "query": { "term": { "user": { "value": "Kimchy", "boost": 1.0 } } } } //terms和term一样,不过可以指定多个值, "user" : ["kimchy", "elasticsearch"]// 返回user为kimchy或elasticsearch的文档 prefix // user字段(不分词字段)中以"ki"开头的文档 { "query": { "prefix" : { "user" : "ki" } } } 组合查询 bool, boosting, constant_score, dis_max, function_score, has_child, has_parent, indices, nested, span_first, span_multi,span_first, span_multi, span_near, span_not, span_or, span_term, top_children, filtered(废弃,使用bool包含一个must和一个filter替代) bool bool查询的外框架结构为：
{ "query": { "bool": { "must": [ {} ], "should": [ {} ], "must_not": [ {} ], "filter": [ {} ] } } } //some other parameter for bool: //boost,minimum_should_match,disable_coord</content></entry><entry><title>Useful Scala Code Snippets</title><url>https://zhimoe.github.io/post/useful-scala-code-snippets/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> merge two map and sum its values 多个map合并,key相同时则value相加
val map1 = Map(1 -> 1, 2 -> 2) val map2 = Map(1 -> 11, 3 -> 3) val map3 = Map(1 -> 111, 3 -> 3) val mapList = List(map1, map2, map3) val merged = mapList.reduce((m1, m2) => m1 ++ m2.map { case (k, v) => k -> (v + m1.getOrElse(k, 0)) } ) 文件读 // """"""可以避免\\符号 val file = """d:\data\file.txt""" for (line &lt;- Source.fromFile(file, encoding).getLines()) { print(line) } 文件写 //资源管理 def using[A &lt;: {def close() : Unit}, R](resource: A)(fun: A => R): R = { import scala.language.reflectiveCalls try { fun(resource) } finally { resource.close() } } using(new OutputStreamWriter(new FileOutputStream(outputFile), StandardCharsets.UTF_8)) { writer => writer.write(s"""${line}\n""") } 统计词频 val nanoUnit = 1000000 //分词并统计词频 def main(args: Array[String]): Unit = { val path = """D:\code\ideaProjects\scala-notes\data\src\out""" val files: List[File] = new File(path).listFiles.filter(_.isFile).toList val start = System.nanoTime() val wfList = ListBuffer[mutable.Map[String, Long]]() val futures = for (file &lt;- files) yield Future { countWrodsInFile(file, "UTF-8") } for (f &lt;- futures) { val words: mutable.Map[String, Long] = Await.result(f, Duration.Inf) wfList += words } //merge the word frequency map val finalWf = wfList.reduce((m1, m2) => m1 ++ m2.map { case (k, v) => k -> (v + m1.getOrElse(k, 0L)) } ) val end = System.nanoTime() println(s"container size=${finalWf.size}") // sort map val wordsFreq = finalWf.toList.sortWith(_._2 > _._2) write2file(wordsFreq, Paths.get(path, "final.txt").toFile) println(s"total used time = ${(end - start) / nanoUnit} ms") println(s"cups = ${Runtime.getRuntime.availableProcessors()}") } def countWrodsInFile(file: File, encoding: String): mutable.Map[String, Long] = { val wf = mutable.Map[String, Long]().withDefaultValue(0) for (line &lt;- Source.fromFile(file, encoding).getLines()) { val l = line.trim wf.update(l, wf(l) + 1) } println(s"${file.getName} has words:${wf.size}") wf } def write2file(wf: Seq[(String, Long)], out: File): Unit = { using(new OutputStreamWriter(new FileOutputStream(out), StandardCharsets.UTF_8)) { writer => for (it &lt;- wf) { writer.write(s"""${it._1} ${it._2}\n""") } } }</content></entry><entry><title>Scala Future</title><url>https://zhimoe.github.io/post/scala-future/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> some notes on scala future, includes:
future executor context await future result callback recover future import java.time._ import scala.concurrent._ import ExecutionContext.Implicits.global Future { Thread.sleep(10000) println(s"This is the future at ${LocalTime.now}") } println(s"This is the present at ${LocalTime.now}") executor context future need a new thread to execute it task. import ExecutionContext.Implicits.global is a implicit threadpool.
await for future result // for 10.seconds conversion import scala.concurrent.duration._ val f = Future { Thread.sleep(10000); 42 } val result = Await.result(f, Duration.Inf) // if f throw exception, it will rethrow to Await.result // use ready() solve this val f = Future { ... } Await.ready(f, 10.seconds) val Some(t) = f.value // The f.value method returns an Option[Try[T]], // which is None when the future is not completed // and Some(t) when it is is // t is Try type instance // A Try[T] instance is either a Success(v), where v is a value of type T or a Failure(ex) val t = Some(t).get t match { case Success(v) => println(s"The answer is $v") case Failure(ex) => println(ex.getMessage) } // or if (t.isSuccess) println(s"The answer is ${t.get}") callback val f = Future { Thread.sleep(10000) if (random() &lt; 0.5) throw new Exception 42 } f.onComplete { case Success(v) => println(s"The answer is $v") case Failure(ex) => println(ex.getMessage) } callback hell val future1 = Future { getData1() } val future2 = Future { getData2() } future1 onComplete { case Success(n1) => future2 onComplete { case Success(n2) => { val n = n1 + n2 println(s"Result: $n") } case Failure(ex) => ... } case Failure(ex) => ... } // improve val future1 = Future { getData1() } val combined = future1.map(n1 => n1 + getData2()) // val future1 = Future { getData1() } val future2 = Future { getData2() } val combined = future1.map(n1 => future2.map(n2 => n1 + n2)) // use for-yield for ( n1 &lt;- future1 n2 &lt;- future2 ) yield n1+n2</content></entry><entry><title>Spring Boot Notes</title><url>https://zhimoe.github.io/post/spring-boot-notes/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>spring</tag></tags><content type="html"> 一些容易忘记的spring boot知识要点.
注意,.yaml和.yml文件没任何区别.
配置 SpringBootApplication注解 @SpringBootApplication // &lt;=等价=> @Configuration @ComponentScan @EnableAutoConfiguration 自动配置 spring的自动配置依赖以下注解:
配置文件 任何时候硬编码的配置总是不好的,spring支持从很多环境中读取配置: 配置文件,yaml文件,环境变量,命令参数.
配置可以在@Value注解中使用,也可Environment访问,或者通过@ConfigurationProperties将配置属性绑定到特定的bean(例子).
spring boot的配置属性读取顺序为:
Devtools global settings properties on your home directory (~/.spring-boot-devtools.properties when devtools is active). @TestPropertySource annotations on your tests. @SpringBootTest#properties annotation attribute on your tests. Command line arguments. Properties from SPRING_APPLICATION_JSON (inline JSON embedded in an environment variable or system property) ServletConfig init parameters. ServletContext init parameters. JNDI attributes from java:comp/env. Java System properties (System.getProperties()). OS environment variables. A RandomValuePropertySource that only has properties in random.*. Profile-specific application properties outside of your packaged jar (application-{profile}.properties and YAML variants) Profile-specific application properties packaged inside your jar (application-{profile}.properties and YAML variants) Application properties outside of your packaged jar (application.properties and YAML variants). Application properties packaged inside your jar (application.properties and YAML variants). @PropertySource annotations on your @Configuration classes. Default properties (specified using SpringApplication.setDefaultProperties). 因为spring-boot主要使用的application.properties/yaml文件,所以后面主要关注这个文件.
此外,spring代码中使用了大约近千个(300多类)默认值,这些默认值都是可以覆盖的.只需你在你的propeties/yaml文件中用相同的key即可.
所有的参考值见: example application.properties
application.properties SpringApplication loads properties from application.properties files in the following locations and adds them to the Spring Environment:
A /config subdirectory of the current directory The current directory A classpath /config package The classpath root application.yml yaml是json的超集,相比properties文件,有着简洁灵活的优势 例如可以设置数组,设置group概念等.
yaml文件可以配置数组:
# 数组功能,等价 # my.servers[0]=dev.bar.com # my.servers[1]=foo.bar.com my: servers: - dev.bar.com - foo.bar.com #上面的配置可以通过注解绑定到以下bean中,非常强大. @ConfigurationProperties(prefix="my") public class Config { private List&lt;String> servers = new ArrayList&lt;String>(); } # 在一个yaml文件设置不同的profile配置,properties文件只能通过拆分文件`application-profiles.properties`实现. server: address: 192.168.1.100 --- spring: profiles: DEV server: address: 127.0.0.1 --- spring: profiles: PRD server: address: 192.168.1.120 yaml缺点: YAML files cannot be loaded by using the @PropertySource annotation. So, in the case that you need to load values that way, you need to use a properties file.
当然使用properties文件缺点也明显,不能分组(yaml的&mdash;功能);同时中文显示容易unicode码.
读取配置文件 除了application.properties文件,其他的配置属性文件需要我们自己加载读取.注意,下面的PropertySource无法加载yaml文件.
使用PropertySource cron=0/3 * * * * ? @Configuration @PropertySource("classpath:foo.properties") public class PropertiesWithJavaConfig { @Value(${cron}) private String cron; } //or @PropertySource({ "classpath:persistence-${envTarget:mysql}.properties" }) //multi files //java 8+ @PropertySource("classpath:foo.properties") @PropertySource("classpath:bar.properties") public class PropertiesWithJavaConfig { //... } //java 6+ @PropertySources({ @PropertySource("classpath:foo.properties"), @PropertySource("classpath:bar.properties") }) public class PropertiesWithJavaConfig { //... } //通过xml加载 //register file in xml &lt;context:property-placeholder location="classpath:foo.properties" /> //foo.properties in src/main/resources &lt;context:property-placeholder location="classpath:foo.properties, classpath:bar.properties"/> 如何加载自定义的yaml文件 上面提到spring会默认加载application.yml文件的配置.但是其他文件名的yml文件无法通过@PropertySource加载.可以有以下方法.
使用xml,然后在Java Config类加载xml. 个人不推荐使用xml文件,脱离spring boot的初衷了. 使用yml加载器: The YamlPropertiesFactoryBean will load YAML as Properties and the YamlMapFactoryBean will load YAML as a Map. 避免使用,尽量将你的所以配置放在application.yml里面,因为yml可以有分组功能. 将你文件命名为application-redis.yml,然后在application.yml使用spring.profiles.include: 'redis' 加载. 使用yaml文件的加载可以通过ConfigurationProperties绑定到配置bean中.还要添加2个注解注册到spring:
@Configuration @EnableConfigurationProperties @ConfigurationProperties public class YAMLConfig { private String name; private String environment; private List&lt;String> servers = new ArrayList&lt;>(); // standard getters and setters } spring: profiles: prod name: prod-YAML environment: production servers: - www.abc.com - www.xyz.com profiles 很多配置希望基于环境,spring boot支持application-profile.properties格式的配置,profile可以是DEV,ST,UAT,PRD,TEST等.
例如某个class希望只有在PRD环境才有:
@Profile("PRD") @Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter {} 然后在application.yml/properties设置profile:
spring: profiles: active: PRD properties文件设置profile application.properties文件只能使用application-DEV.properties,application-ST.properties设置profile.
yml文件设置profile application.yml既可以像properties文件使用application-DEV.yml来设置profile,也可以使用---分组.如下示例,logging.level=INFO在所有profile中生效,而在生产环境中增加日志文件设置,DEV环境则使用DEBUG级别日志.
# application.yml logging: level: root: INFO --- spring: profiles: DEV logging: level: root: DEBUG --- spring: profiles: PRD logging: path: /tmp/ file: BookWorm.log level: root: WARN 激活profiles 在application.yml/properties文件中激活某个profile:
spring: profiles: active: DEV 如果你设置了SPRING_PROFILES_ACTIVE环境变量,那么会覆盖上面的profile设置.当然你也可以使用自定义环境变量和默认值:
spring: profiles: active: ${ENV_TYP:PRD} # 读取ENV_TYP环境变量的值作为激活profile,如果没用这个环境变量,那么设置为PRD. 测试</content></entry><entry><title>Pattern Matching Anonymous Function</title><url>https://zhimoe.github.io/post/pattern-matching-anonymous-function/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> Scala中很多使用if的地方都可以用match case来替换.常见的就是下面的这种写法:
val res = msg match { case it if it.contains("H") => "Hello" case _ => "Other" } //更常见的用法是去匹配参数的模式: case class Player(name: String, score: Int) def message(player: Player) = player match { case Player(_, score) if score > 100000 => "Get a job, dude!" case Player(name, _) => "Hey, $name, nice to see you again!" } def printMessage(player: Player) = println(message(player)) 其实case还有一种在匿名函数中的用法,看如下的代码,在词频统计或者过滤中很常见:
val wordFrequencies = ("habitual", 6) :: ("and", 56) :: ("consuetudinary", 2) :: Nil def wordsWithoutOutliers(wordFrequencies: Seq[(String, Int)]): Seq[String] = wordFrequencies.filter(wf => wf._2 > 3 &amp;&amp; wf._2 &lt; 25).map(_._1) 上面的代码有比较大的问题是访问tuple元素的方式比较难看,Scala提供了一种pattern matching anonymous function解决这个问题:
def wordsWithoutOutliers(wordFrequencies: Seq[(String, Int)]): Seq[String] = wordFrequencies.filter { case (_, f) => f > 3 &amp;&amp; f &lt; 25 } map { case (w, _) => w } 注意到省略了最早版本的 wf =>,IDEA其实会提示你省略这个冗余部分.
另一个问题就是上面的操作中我们先过滤想要的序列,然后对序列进行了map映射操作.Scala 集合的 API 有一个叫做 collect 的方法,对于 Seq[A] ,它有如下方法签名：
def collect[B](pf: PartialFunction[A, B]): Seq[B] 这个方法将给定的_偏函数(partial function)_ 应用到序列的每一个元素上, 最后返回一个满足条件并处理后新的序列 ,这里偏函数做了 filter 和 map 要做的事情.
现在,我们来重构 wordsWithoutOutliers ,首先定义需要的偏函数：
val pf: PartialFunction[(String, Int), String] = { case (word, freq) if freq > 3 &amp;&amp; freq &lt; 25 => word } wordFrequencies.collect(pf) 我们为这个案例加入了 守卫语句,不在区间里的元素就没有定义.
以上来自Scala初学者指南
当然有中文版:Scala初学者指南-gitbook</content></entry><entry><title>Scala Type Class</title><url>https://zhimoe.github.io/post/scala-type-class/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> scala type class notes:
关于scala type class非常好的文章
核心知识点 //scala没有专门的type class语法,而是借助trait + implicit + context bound来实现的, //所以很多时候识别type class比较困难. //type class 由三部分构成 //1. type class: 即下面的Show,定义一个行为toHtml. //2. type class instances：希望实现toHtml方法的类型实例 //3. user interface: type class中伴生对象的同名方法或者隐式转换方法. // type class trait Show[A] { def toHtml(a: A): String } // 定义在伴生对象的好处就是implicit变量自动处于scope内 object Show { //利用伴生对象apply特点实现下面Show[A].toHtml调用方式,即隐藏implicit sh def apply[A](implicit sh: Show[A]): Show[A] = sh //如果没有apply,那么下面的toHtml需要一个隐式参数： //def toHtml[A](a: A)(implicit sh: Show[A]): String = sh.toHtml(a) //或者： //def toHtml[A: Show](a: A): String = implicitly[Show[A]].toHtml(a) //对外接口,提供toHtml("type")的调用形式 def toHtml[A: Show](a: A) = Show[A].toHtml(a) //对外接口,通过隐式转换提供10 toHtml的调用形式 implicit class ShowOps[A: Show](a: A) { // 惯例使用TypeCls+Ops def toHtml = Show[A].toHtml(a) } //为了避免运行开销,可以将Ops类定义为value class： // implicit class ShowOps[A](val a: A) extends AnyVal { // def toHtml(implicit sh: Show[A]) = sh.toHtml(a) // } //上面两个对外接口都利用了伴生对象的apply方法和context bound //type class instance int implicit val intCanShow: Show[Int] = int => s"&lt;int>$int&lt;/int>" //type class instance string implicit val stringCanShow: Show[String] = str => s"&lt;string>$str&lt;/string>" } //use type class import Show._ print(10 toHtml) print(toHtml("type")) 若使用import Show._ 导入全部内容,则用户无法自己实现一些 type class instance则会覆盖默认实例导致歧义.
可以将对外接口移动到单独的ops对象中：
trait Show[A] { def toHtml(a: A): String } object Show { def apply[A](implicit sh: Show[A]): Show[A] = sh object ops { def toHtml[A: Show](a: A) = Show[A].toHtml(a) implicit class ShowOps[A: Show](a: A) { // 惯例使用TypeCls+Ops def toHtml = Show[A].toHtml(a) } } implicit val intCanShow: Show[Int] = int => s"&lt;int>$int&lt;/int>" implicit val stringCanShow: Show[String] = str => s"&lt;string>$str&lt;/string>" } 使用：
import xxx.Show //如果需要实现自定义的type class instance则需要 import xxx.Show.ops._ 自定义 case class Person(name: String, age: Int) implicit val personOps: Show[Person] = p => s"&lt;person>name=${p.name},age=${p.age}&lt;/person>" print(Person("lee", 19) toHtml)//&lt;person>name=lee,age=19&lt;/person> Simulacrum Simulacrum通过宏为 type class 添加便捷语法,是否使用取决于个人判断.
若使用 Simulacrum,则可以一眼找出代码中所有的 type class,并且可省去很多样板代码.
另一方面,使用 @typeclass（Simulacrum 主要注解）则意味着需要依赖 macro paradise 编译器插件.
使用 Simulacrum 重写我们的 Show type class：
import simulacrum._ @typeclass trait Show[A] { def toHtml(a: A): String } 有了 Simulacrum,type class 定义变得非常简洁,我们在其伴生对象中添加 Show[String] 实例：
//Simulacrum 会为 Show 自动生成 ops 对象,与前面自定义的基本一致. object Show { implicit val stringShow: Show[String] = s ⇒ s"String: $s" }</content></entry><entry><title>Scala 学习笔记</title><url>https://zhimoe.github.io/post/scala-notes/</url><categories><category>编程</category></categories><tags><tag>code</tag></tags><content type="html"> some notes on scala, includes:
setup with maven import == and eq case class for&hellip;yield companion object and class method and function(def val) _ in scala => in scala () {} in scala implicit string setup with maven 目前用sbt的项目比较少,maven的更多. 而且sbt烧cpu. maven项目使用scala参考我的gist:scala_maven_pom.xml
学习scala可以使用scala插件的worksheet,这是一个基于脚本互动的REPL. 本文后面的代码全部在worksheet中测试.
import scala的import语句很灵活,可以在任何地方导入class内部外部,方法内部,代码块内部,这样做有一个好处,限制导入方法和对象的scope,防止污染变量.在后面学了implicit隐式转换后,就知道import scope有多重要了.
import scala.math._ // import everything in math package import java.util.{ ArrayList => _, _} //第一个下划线表示隐藏ArrayList,第二个表示通配符,导入所有 //默认,scala导入: java.lang._ scala._ scala.Predef._ //推荐看一下Predef的源代码包括： //Predef中定义的方法和属性 //常用方法和类 //打印方法 println等 //一些调试和错误方法 //一个特殊的方法表示方法未实现 def ??? : Nothing = throw new NotImplementedError //Predef还有大量的隐式转换和隐式参数 == and eq scala里面==等价于java的equals方法即内容比较,并且可以正确处理null(还记得java规范里面烦人的 "A".equals(m)规范么?). 而地址(引用)比较使用eq 方法,这个方法其实很少用到,应用代码一般无需比较2个变量的地址.
case class case class类似data class,即java的pojo bean,但是提供了更多的方法.
// 5个特性 // 1.添加companion object,apply方法,unapply方法 // 2.toString, hashCode and equals and copy methods case class Student(name: String, marks: Int) val s1 = Student("Rams", 550) val s2 = s1.copy() val s3 = s1.copy(marks = 590) s2 == s1 //true s3 == s1 //false // 3. 构造函数参数自动成为成员变量,即自动给构造参数添加val前缀 // 4. 可以用于模式匹配 // 5. 默认的,case class和case object是可序列化的(实现Serializable),也即是可以网络传输的 for&hellip;yield Scala’s “for comprehensions” are syntactic sugar for composition of multiple operations with foreach, map, flatMap, filter or withFilter
scala的for推导其实就是组合多个foreach, map, flatMap, filter or withFilter的语法糖.
以下代码结果r1,r2完全一致:
val c1 = List(1, 2, 3) val c2 = List("a", "b", "c") val c3 = List("!", "@", "#") val r1 = for (x &lt;- c1; y &lt;- c2; z &lt;- c3) yield { x + y + z } //&lt;==> val r2 = c1.flatMap(x => c2.flatMap(y => c3.map(z => { x + y + z }))) assert(r1 == r2)//true companion object Scala中,除了方法,一切都是对象！函数也是对象,根据参数的个数,函数的类型为FunctionN.N为函数参数个数.
伴生对象用于定义一些静态方法(工厂方法),其中apply和unapply方法常用. apply方法用于代替new的工厂方法.
同时,companion objects can access private fields and methods of their companion trait/class.
class Person(name: String, age: Int) { private var skill: String = "no skill" def introduce() = println(s"my name is $name, I am $age years old") } // companion object name should be identical to the class name. object Person { def apply(name: String, age: Int): Person = { new Person(name, age) } //apply method override def apply(name: String, age: Int, skill: String): Person = { val p = new Person(name, age) p.skill = skill p } } val dahu = Person("dahu", 30) dahu.introduce 伴生对象在模式匹配和抽取器的应用
//关于抽取器和unapply方法的进一步示例: trait User class FreeUser( val name: String, val score: Int, val upgradeProbability: Double) extends User class PremiumUser( val name: String, val score: Int) extends User object FreeUser { def unapply(user: FreeUser): Option[(String, Int, Double)] = Some((user.name, user.score, user.upgradeProbability)) } object PremiumUser { def unapply(user: PremiumUser): Option[(String, Int)] = Some((user.name, user.score)) } val freeUsr = new FreeUser("john", 70, 0.5) freeUsr match { case FreeUser(name, _, p) => if (p > 0.75) println(s"what can I do for you,$name") else println(s"hello,$name") case _ => println("who are you") } //bool抽取器 object premiumCandidate { def unapply(user: FreeUser): Boolean = user.upgradeProbability > 0.4 } // bool抽取器的用法 freeUsr match { case freeUser@premiumCandidate() => println(s"恭喜成为黄金会员候选人") case _ => println("欢迎回来") } //来源: [Scala初学者指南](http://danielwestheide.com/scala/neophytes.html) method and function(def val) 先看函数定义
A function can be invoked with a list of arguments to produce a result.
A function has a parameter list, a body, and a result type. Functions that are
members of a class, trait, or singleton object are called methods.
Functions defined inside other functions are called local functions. Functions
with the result type of Unit are called procedures. Anonymous functions in
source code are called function literals. At run time, function literals are
instantiated into objects called function values.
quote from：
Martin Odersky - Lex Spoon - Bill Venners
函数由一个参数列表,一个函数体,一个结果类型构成.函数如果作为class,trait或者object（注意,这里的object是scala特有的单例对象,不是Java中的instance）的成员,那么这个函数叫方法.函数和方法的区别就是函数时FunctionN的一个实例,编译后是一个单独的class文件,而方法是依附对象的,调用方法的格式是obj.method(param),而调用函数的格式本质是将调用函数对象的apply方法.
函数定义在别的函数内部叫局部函数.函数返回值是Unit称为过程（procedures）.
匿名函数是通过函数字面量（ ()=>{函数体} ）定义的函数.在运行时,函数字面量被实例化对象,叫函数值.
函数和方法的区别,大部分情况下不用在意区别：
函数是有类型的： (T1, &hellip;, Tn) => U,是trait FunctionN的一个实例对象,函数有一个apply方法,用来实际执行function的函数体.函数还有toString, andThen ,conpose等方法.
val fn: Int => String = i => i+"123" //声明一个函数 fn(3) //实际背后是fn.apply(3); scala中除了method,一切都是instance
method只能用def 声明,function可以是val和def声明
method可以有类型参数[] ,function不能有,函数在声明时就需要知道具体类型.
def fn(p: List[String]): Map[T] = {...} //is function def m[T](t: List[T]): Map[T] = {...} //is method,可以有泛型参数. 将method转换成function有两种方法： val f1 = m1 _ //下划线表示参数列表 eta-expansion val f2: (Int) => Int = m1 //m1 的入参和返回值要和f2的一样 //scala可以自动将method转换为function,如果一个方法需要一个函数作为参数, //那么可以直接将m1传递给他,不需要 下划线. //每一次将方法转换成function都是得到一个新的function object. //function既然是一个instance,那么编译成class文件会有一个class文件. _ in scala /** * class Reference[T] { * private var contents: T = _ * //使用类型默认值初始化变量,如果T是Int,则contents是0,T是boolean,则是false；Unit则是() * } * * * List(1, 2, 3) foreach (print _ ) //output 123,表示实参 * * //在匿名函数中作为参数占位符： * List(1, 2, 3) map ( _ + 2 ) * // _ + 2是一个匿名函数 * * //模式匹配中的最后一行作为通配符 * case _ => "this is match anything other than before cases " * * expr match { * * case List(1,_,_) => " a list with three element and the first element is 1" * case List(_*) => " a list with zero or more elements " * case Map[_,_] => " matches a map with any key type and any value type " * case _ => * } * * * //import中作为通配符和隐藏符 * import java.util.{ ArrayList => _, _} * //第一个下划线表示隐藏ArrayList,第二个表示通配符,导入所有 * * //将方法变为value * method _ // Eta expansion of method into method value * * //tuple 的访问 * tpl._2 //返回tpl第二个元素,注意,tuple是从1开始的 * * * //还有很多高级的概念,目前还不理解,so上给出的答案 * def f[M[_]] // Higher kinded type parameter * def f(m: M[_]) // Existential type * _ + _ // Anonymous function placeholder parameter * m _ // Eta expansion of method into method value * m(_) // Partial function application * _ => 5 // Discarded parameter * case _ => // Wild card pattern -- matches anything * val (a, _) = (1, 2) // same thing * for (_ &lt;- 1 to 10) // same thing * f(xs: _*) // Sequence xs is passed as multiple parameters to f(ys: T*) * case Seq(xs @ _*) // Identifier xs is bound to the whole matched sequence * var i: Int = _ // Initialization to the default value * def abc_&lt;>! // An underscore must separate alphanumerics from symbols on identifiers * t._2 */ => in scala 函数字面量分隔参数和函数体 在函数字面量中 =>分隔参数和函数体. 也可以表示一个函数类型.
(x: Int) => x * 2表示一个匿名函数,接收一个整数,返回参数乘以2的结果. scala> val f: Function1[Int,String] = argInt => "my int: "+argInt.toString f: Int => String = &lt;function1> // Int => String 等价 Function1[Int,String] scala> val f2: Int => String = myInt => "my int v2: "+myInt.toString f2: Int => String = &lt;function1> //注意,匿名函数没有参数也要括号 ()=>{}； //() => Unit表示没有返回值的函数 call-by-name parameter 在函数的参数声明中使用=>(e.g. def f(arg: => T))表示这个参数是"by-name parameter",表示这个参数只有在函数体中包含这个参数的语句被执行才会被evaluate.
这个特点叫call-by-name,arg可以是一个代码块,甚至函数,在传递给f时不会evaluate,只有f函数体内部调用arg时,arg才会被执行.
scala> def now()={println("nano time:");System.nanoTime} scala> def callByName(p: => Long):Long = {println("call-by-name:"+p);p;} callByName: (p: => Long)Long scala> def justCall(p : Long) :Long = {println("just-call:"+p);p;} justCall: (p: Long)Long scala> callByName(now()) nano time: call-by-name:5664511571389 nano time: res2: Long = 5664511727048 //now()在callByName的函数体的每个出现的地方都执行了 scala> justCall(now()) nano time: just-call:5667489483159 res3: Long = 5667489483159 //now()只在传递参数的时候被执行了. 模式匹配中分隔case模式和返回值 在case语句中,=> 分隔模式和返回表达式.
var a = 1 a match{ case 1 => println("One") case 2 => println("Two") case _ => println("No") } () {} in method call // 规则1:{}表示code block,你可以在里面放几乎任何语句,block的返回值是由最后一句决定 // 规则2:block内容如果只有一句可以省略{},但是case clause除外:{case ...} // 规则3: 单参数方法如果实参是code block,那么可以省略() { import util.Try println{"hello"} 5 } val tupleList = List[(String, String)]() //规则2 tupleList takeWhile( { case(t1,t2) => t1==t2 } ) // 规则2 List(1, 2, 3).reduceLeft(_+_) // 一种特殊情况,提示:隐式转换 val r = List(1, 2, 3).foldLeft(0) {_+_} //val l = r{"hello"} //不要调用这个方法 def loopf(x: Int): Int = loopf {x} //使用{}的特殊情况:for推导可以和()互换,一般建议是除了yield的其他情况都用() for{tpl &lt;-tupleList} yield tpl._2 //不建议 for{tpl &lt;-tupleList} { println(tpl) } //推荐 for(tpl &lt;-tupleList) { println(tpl) } //补充, 方法定义时如果没有返回值可以省略=,称为procedure,scala 2.13已经废弃,不要这么写 //don't def p(in:String ){ println(s"hello $in") } implicit implicit分为隐式参数和隐式转换方法.
隐式参数 //1.隐式参数 class Prefixer(val prefix: String) def addPrefix(s: String)(implicit p: Prefixer) = p.prefix + s // addPrefix需要提供一个隐式实际参数,否则报错.当然可以在调用时显式传递一个参数 implicit val myImplicitPrefixer = new Prefixer("***") addPrefix("abc") // returns "***abc" 隐式转换 //1. 定义一个含有目标方法的class class BlingString(s:String) { def bling = "*"+s+"*" } //2. 定义隐式转换方法 implicit def str2BlingString(s:String) = new BlingString(s) //3. 使用目标方法 val s = "hello" s.bling // *hello* //在scala.Predef中定义了大量的隐式转换,例如RichInt,StringOps这些,提供类似mkString这些方法 //太阳底下无新事,scala常用对象的灵活丰富的语法都是通过隐式转换添加的. implicit class 可以看到上面的第1,2步非常的繁琐,于是SIP-13提出一个implicit class,将上面的2步合并:
implicit class BlingString(s:String) { def bling = "*"+s+"*" } //implicit def str2BlingString(s:String) = new BlingString(s) val hi = "hello" hi.bling // *hello* 注意,这个只是一个语法糖.去糖后就是上面的那个形式. implicit class有3个约束和一个注解问题：
必须要有主一个构造函数且只能一个构造参数（implicit参数除外）.构造参数就是源类型. 这个构造函数即等价上面第2步的隐式转换方法：
implicit class RichDate(date: java.util.Date) // OK! implicit class Indexer[T](collecton: Seq[T], index: Int) // BAD! implicit class Indexer[T](collecton: Seq[T])(implicit index: Index) // OK! 只能定义在其他trait/class/object中：
object Helpers { implicit class RichInt(x: Int) // OK! } implicit class RichDouble(x: Double) // BAD! 在当前scope内,不允许有和implicit class同名的方法,对象,变量.因为case class会自动生成同名object对象,所以implicit class不能是case class.
object Bar implicit class Bar(x: Int) // BAD! val x = 5 implicit class x(y: Int) // BAD! //cuz case class has companion object by default implicit case class Baz(x: Int) // BAD! conflict with the companion object 还有就是implicit class的注解在去语法糖后会自动添加到类和方法,除非在注解中指明范围：
@bar implicit class Foo(n: Int) //desugar @bar implicit def Foo(n: Int): Foo = new Foo(n) @bar class Foo(n:Int) //除非在注解中指明：genClass / method @(bar @genClass) implicit class Foo(n: Int) //desugar得到 @bar class Foo(n: Int) implicit def Foo(n: Int): Foo = new Foo(n) value class scala 还有一个概念：value class
class Wrapper(val underlying: Int) extends AnyVal //1. 一个public val参数表示runtime类型,这里是Int. 编译时是Wrapper类型,所以value class目的是降低分配开销. //2. value class 需要 extends AnyVal //3. value class 只能有 defs, 不能有vals, vars, or nested traits, classes or objects, // 因为def是通过静态方法实现的,而val,var这些则必须创建相应类型了. //4. value class 只能扩展通用trait（universal traits）, // universal traits是A universal trait is a trait that extends Any, only has defs as members, and does no initialization. // extension method 当implicit class类型参数是AnyVal子类时,value class和上面的implicit class形式相近,所以可以通过value class降低implicit class的分配开销.例如RichtInt
implicit class RichInt(val self: Int) extends AnyVal { def toHexString: String = java.lang.Integer.toHexString(self) } 因为RichInt是value class,在运行时（runtime）不会有RichInt这个类,而是Int,而3.toHexString实际是通过静态方法实现的： RichInt$.MODULE$.extension$toHexString(3),这么做好处是减少对象分配开销(avoid the overhead of allocation).如果implicit class的类型参数不是AnyVal子类,那么在runtime时会有相应类型对象被创建,用户察觉不到区别.
value class还有其他作用和局限性,可以参考上面链接.如果发现错误,请指出,先谢过.
Implicit Design Patterns in Scala​www.lihaoyi.com
The Neophyte&rsquo;s Guide to Scala​
集合类的implicit转换 //scala集合和java集合的转换是scala编程最常用的,毕竟java有大量第三方库. //scala提供了两种方法,第一种方法就是隐式转换collection.JavaConversions(scala 2.8) //很快意识到隐式转换对于使用者的代码阅读比较复杂,在2.8.1提供了显示转换collection.JavaConverters, //先看JavaConversions隐式转换: object JavaConversions extends WrapAsScala with WrapAsJava //在WrapAsJava implicit def mapAsJavaMap[A, B](m: Map[A, B]): ju.Map[A, B] = m match { case null => null case JMapWrapper(wrapped) => wrapped.asInstanceOf[ju.Map[A, B]] case _ => new MapWrapper(m) } //然后看下collection.JavaConverters._,稍微复杂一些,但是换汤不换药,底层还是隐式转换, object JavaConverters extends DecorateAsJava with DecorateAsScala //在DecorateAsJava中有很多隐式转换方法,这些方法将scala集合转换为AsJava对象 //(注意下面的ju,是java.util缩写,详情见[征服scala_1](https://zhuanlan.zhihu.com/p/22670426)) implicit def seqAsJavaListConverter[A](b : Seq[A]): AsJava[ju.List[A]] = new AsJava(seqAsJavaList(b)) // 而AsJava中定义了asJava方法,这样我们就可以在scala集合上面调用asJava class AsJava[A](op: => A) { /** Converts a Scala collection to the corresponding Java collection */ def asJava: A = op } //并且asJava方法的实现是作为构造参数传入AsJava的 //上面的seqAsJavaList就是将scala.Seq转换为ju.List的具体实现 def seqAsJavaList[A](s: Seq[A]): ju.List[A] = s match { case null => null case JListWrapper(wrapped) => wrapped.asInstanceOf[ju.List[A]] case _ => new SeqWrapper(s) } //综上,JavaConverters用的还是隐式转换,只不过增加了一个中间类AsJava/AsScala. 隐式转换的scope //无论是隐式参数还是隐式转换,编译器都要知道去哪里查找这些implicit参数或者方法, //例如import collection.JavaConverters._ //由于scala import可以出现在任何地方,这为控制implicit的scope提供了灵活性 //这一块我不是完全清楚,只提供一个自己的理解 // 1.首先是当前scope的Implicits定义,例如,当前方法内,class内 // 2.显式导入 import collection.JavaConversions.asScalaIterator // 3.通配符导入 import collection.JavaConverters._ // 4.类型的伴生对象内(这个常用) // 5.参数类型的隐式scope (2.9.1添加):class构造参数的隐式转换搜索返回会被应用到 class A(val n: Int) { def +(other: A) = new A(n + other.n) } object A { implicit def fromInt(n: Int) = new A(n) } new A(1) + 2 // new A(1) + A.fromInt(2) //6.类型参数的隐式转换,下面的sorted方法期望有一个Ordering[A], //在伴生对象中提供了一个 A -> Ordering[A] , class A(val n: Int) object A { implicit val ord = new Ordering[A] { def compare(x: A, y: A) = implicitly[Ordering[Int]].compare(x.n, y.n) } } List(new A(5), new A(2)).sorted // 注意implicitly[Ordering[Int]] 表示在当前scope内搜索一个隐式参数值 def implicitly[T](implicit e: T): T = e string // The s String Interpolator: val name = "James" println(s"Hello, $name") // Hello, James // The f Interpolator val height = 1.9d val name = "James" println(f"$name%s is $height%2.2f meters tall") // James is 1.90 meters tall // The raw Interpolator // The raw interpolator is similar to the s interpolator except that // it performs no escaping of literals within the string. // Here’s an example processed string // 即不翻译转义字符 scala>raw"a\nb" res1: String = a\nb // """ triple quotes string // triple quotes """ to escape characters val donutJson4: String = """ |{ |"donut_name":"Glazed Donut", |"taste_level":"Very Tasty", |"price":2.50 |} """ .stripMargin // |会被忽略 // """还有个很好的用处,正则表达式: // 在java中表示一个或多个空格,"\\s+" // 在scala中只要 """\s+""",对于复杂正则表达式非常有用. links https://www.btbytes.com/scala.html
https://booksites.artima.com/programming_in_scala_2ed/examples/index.html
http://blog.higher-order.com/assets/fpiscompanion.pdf
https://courses.cs.washington.edu/courses/cse341/09au/notes/scala.html
https://github.com/dnvriend/my-scala-notes
https://gist.github.com/jamesyang124/d65b067327452792287a</content></entry><entry><title>使用redis的hash优化内存使用[翻译]</title><url>https://zhimoe.github.io/post/%E4%BD%BF%E7%94%A8redis%E7%9A%84hash%E4%BC%98%E5%8C%96%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8/</url><categories><category>翻译</category></categories><tags><tag>code</tag><tag>redis</tag></tags><content type="html"> 使用redis的hash优化内存使用
问题和方案 场景: 有3亿张图片放在对象存储(DELL ECS/AMAZON EC2)上面,现在需要保存图片的id->用户id的映射.最直接的思路是:
set "media:1155220" "user1" set "media:1155221" "user2" 这样设计key之后3亿张图片需要21GB的内存,因为redis的string是线性增长的.
此时可以使用hash优化内存使用.hash是类似java hashmap的数据结构: key field1 value1 field2 value2 &hellip;
hash的强大在于它可以只获取一个field的value,而无需返回整个key.
再仔细想想,hash的key可以类比于分库分表的bucket概念.
回到上面的问题,Mike Krieger,Instagram的创始人提出将图片的id除以1000分片(sharding)到1000个hash key上:
HSET "mda-bkt:1155" "1155220" "user1" "1155221" "user2" # mda-bkt:1155 是1155220/1000之后得到的bucket. HGET "mda-bkt:1155" "1155220" # 这里key的前缀*mda-bkt:)只重复了1000次,而上面的string方式重复了3亿次. 因为redis针对hash list zset三种结构使用了ziplist高效存储方案.
新的问题又来了,redis对于ziplist结构的key数量有限制的,即hash-max-ziplist-entries的含义是: 可使用内部空间优化存储的最多hash key
使用ziplist的数据结构有三个list hash zset:
list-max-ziplist-entries 512 list-max-ziplist-value 64 #Limits for ziplist use with LISTs. hash-max-ziplist-entries 512 hash-max-ziplist-value 64 #Limits for ziplist use with HASHes (previous versions of Redis used a different name and encoding for this) #hash-max-zipmap-entries 512 (for Redis &lt; 2.6). zset-max-ziplist-entries 128 zset-max-ziplist-value 64 #Limits for ziplist use with ZSETs. 你可以使用debug_object(key)查看你的key是否使用了ziplist结构.
建议hash-max-ziplist-entries最大设置为1000,过大会影响redis性能.
参考资料 redis moemory optimize
9.1.1 The ziplist representation-EBOOK – REDIS IN ACTION
source:Understanding Redis hash-max-ziplist-entries</content></entry><entry><title>Scala 2 Implicit</title><url>https://zhimoe.github.io/post/scala-implicit/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> 隐式参数 //隐式参数是在调用时可以自动填充的参数, 需要在调用范围内（scope)有一个隐式变量可供填充. def addInt(i:Int)(implicit n: Int) = i + n //需要提供一个隐式变量n implicit val sn = 1 addInt(2) // 3 //如果有两个满足类型的隐式变量,则在编译addInt(2)时报错 //scala的方法中ExecutionContext一般作为implicit参数. 隐式转换方法 如果想要给String实现一个mkStr方法,简单的给String添加一个Ops!前缀再返回.
//1. 首先实现一个包含目标方法的类型,实现该方法 class StrOps(s:String) { def mkStr(): String = { return "Ops! " + s } } //2. 告诉scala编译器String可以通过类型转换获得mkStr这个方法： implicit final def string2StrOps(s: String) = new StrOps(s) //3. 现在用户可以直接认为String有mkStr方法 val s = "who changed my string" s.mkStr() //res2: String = Ops! who changed my string //在scala.Predef中定义了大量的隐式转换,例如RichInt,RichDouble,StringOps这些 implicit class 可以看到第2步非常的冗余,于是SIP-13提出一个implicit class,将上面的1,2步合并:
implicit class StrOps(s:String) { def mkStr(): String = { return "Ops! " + s } } 注意,这个只是一个语法糖.去糖后就是上面的那个形式. implicit class有3个约束和一个注解问题：
必须要有主一个构造函数且只能一个构造参数（implicit参数除外）.构造参数就是源类型. 这个构造函数即等价上面第2步的隐式转换方法：
implicit class RichDate(date: java.util.Date) // OK! implicit class Indexer[T](collecton: Seq[T], index: Int) // BAD! implicit class Indexer[T](collecton: Seq[T])(implicit index: Index) // OK! 只能定义在其他trait/class/object中：
object Helpers { implicit class RichInt(x: Int) // OK! } implicit class RichDouble(x: Double) // BAD! 在当前scope内,不允许有和implicit class同名的方法,对象,变量.因为case class会自动生成同名object对象,所以implicit class不能是case class.
object Bar implicit class Bar(x: Int) // BAD! val x = 5 implicit class x(y: Int) // BAD! //cuz case class has companion object by default implicit case class Baz(x: Int) // BAD! conflict with the companion object 还有就是implicit class的注解在去语法糖后会自动添加到类和方法,除非在注解中指明范围：
@bar implicit class Foo(n: Int) //desugar @bar implicit def Foo(n: Int): Foo = new Foo(n) @bar class Foo(n:Int) //除非在注解中指明：genClass / method @(bar @genClass) implicit class Foo(n: Int) //desugar得到 @bar class Foo(n: Int) implicit def Foo(n: Int): Foo = new Foo(n) implicitly方法 scala的PreDef中有有一个implicitly方法,表示在当前scope征召一个隐式变量并返回该变量.
//PreDef @inline def implicitly[T](implicit e: T) = e implitly[T] means return implicit value of type T in the context
implicit class Foo(val i: Int) { def addValue(v: Int): Int = i + v } implicit val foo:Foo = Foo(1) val fooImplicitly = implicitly[Foo] // Foo(1) value class scala 还有一个概念：value class
class Wrapper(val underlying: Int) extends AnyVal //1. 一个public val参数表示runtime类型,这里是Int. 编译时是Wrapper类型,所以value class目的是降低分配开销. //2. value class 需要 extends AnyVal //3. value class 只能有 defs, 不能有vals, vars, or nested traits, classes or objects, // 因为def是通过静态方法实现的,而val,var这些则必须创建相应类型了. //4. value class 只能扩展 通用trait（universal traits）, // universal traits是A universal trait is a trait that extends Any, only has defs as members, and does no initialization. extension method 当implicit class类型参数是AnyVal子类时,value class和上面的implicit class形式相近,所以可以通过value class降低implicit class的分配开销.例如RichtInt
implicit class RichInt(val self: Int) extends AnyVal { def toHexString: String = java.lang.Integer.toHexString(self) } 因为RichInt是value class,在运行时（runtime）不会有RichInt这个类,而是Int,而3.toHexString实际是通过静态方法实现的： RichInt$.MODULE$.extension$toHexString(3),这么做好处是减少对象分配开销（avoid the overhead of allocation）.如果implicit class的类型参数不是AnyVal子类,那么在runtime时会有相应类型对象被创建,用户察觉不到区别.
value class还有其他作用和局限性,可以参考上面链接.</content></entry><entry><title>使用travis自动发布markdown到博客</title><url>https://zhimoe.github.io/post/%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83markdown%E5%88%B0%E5%8D%9A%E5%AE%A2/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>github</tag></tags><content type="html"> 如何使用github pages和github actions构建静态个人博客站点
update at 2021 更新：github开放action功能后,travis-ci已经没有必要了,目前博客使用zhimoe仓库管理源码,使用action编译后将public目录同步到zhimoe.github.io仓库的gh-pages分支.
注意,由于使用了jsdelivr的cdn功能,切换分支后theme的相关静态文件的path也要修改.
github给个人和组织免费提供github pages功能. 就是说如果有个repo的名字为 zhimoe.github.io (zhimoe 为你的github username), 那么这个repo里面的master或者gh-pages分支的内容如果存在index.html, 那么其他人可以通过 https://zhimoe.github.io 访问这个站点.
借助于一些static gen工具,你可以将你的markdown转换为一个静态网站(html,js,css). 然后把静态网站的内容上传到刚说的repo中, 就有一个自己的博客站点了. static gen工具非常多, github推荐的是Jekyll(ruby), 主流的还有hexo(js)和hugo(go), hexo因为是基于js的,所以高质量的主题多(因为做主题是需要js,css技能), hugo的编译快些, 但是好看的主题不多. 高质量的主题除了美观可能还需要考虑移动端(responsive),评论, 访问统计等各种功能. 每个gen工具都有自己的主题站点. hugo的主题在这里找: hugo themes.
制作github pages站点的一般做法是把代码(放图片和markdown)放在master分支,static gen编译后的(html,js,css,image)内容放在gh-pages分支.然后在settings里面设置. 这样就可以得到一个站点了. 这么做有个缺点,就是markdown文件会被别人整个下载过去,之前就遇到过一次. 正好github现在有3个免费私有仓库. 所以我把源码放在私有仓库zhimoe.github.io.src里面,而编译后的内容发布的 https://zhimoe.github.io上面去.
自动编译发布这个过程就是持续集成(continue integration,CI)了, 即我提交一个markdown文件,我的主页会自动看到这篇文章, 不需要我在本地编译再提交编译结果文件.travis-ci 提供了免费的github CI服务. 使用github账号登录就会有提示操作. 这里勾选私有仓库zhimoe.github.io.src, 然后在项目里面添加.travis.yml文件告诉travis如何编译和发布内容到个人站点.
markdown渲染设置 hugo使用BlackFriday渲染markdown文件,默认的设置有几个过于严格:
没有硬换行,需要使用\来表示换行 标题和#之间必须有空格 代码块前面必须有空行 在config.toml可以修改这些配置:
# markdown解析引擎blackfriday配置, # extensions : noEmptyLineBeforeBlock-代码块前面无需空行,hardLineBreak-换行无需使用backslash # extensionsmask spaceHeaders-标题之间无需空格 [blackfriday] angledQuotes = true extensions = ["hardLineBreak","noEmptyLineBeforeBlock"] extensionsmask = ["spaceHeaders"] fractions = false plainIDAnchors = true travis-ci配置 就是从一个私有的源码仓库编译,然后将编译后的文件强制覆盖到个人主页(即username.github.io这个仓库)的仓库中.具体的配置就不说了,注意是需要一个github的personal-access-key. 下面是.travis.yml内容:
dist: xenial language: python python: 3.7 # Handle git submodules yourself git: submodules: false # Use sed to replace the SSH URL with the public URL, then initialize submodules before_install: - sudo apt update -qq - sudo apt -yq install apt-transport-https - echo -e "Host github.com\n\tStrictHostKeyChecking no\n" >> ~/.ssh/config - git config --global user.email ${GITHUB_EMAIL} - git config --global user.name ${GITHUB_USERNAME} - sed -i 's/git@github.com:/https:\/\/github.com\//' .gitmodules - git submodule update --init --recursive install: # install latest hugo release version # - wget -qO- https://api.github.com/repos/gohugoio/hugo/releases/latest | sed -r -n '/browser_download_url/{/Linux-64bit.deb/{s@[^:]*:[[:space:]]*"([^"]*)".*@\1@g;p;q}}' | xargs wget # use local hugo pkg for speed - sudo dpkg -i hugo*.deb - rm -rf public 2> /dev/null # compile src to dist script: - hugo -d ./dist/ after_success: - git clone https://zhimoe:${GITHUB_TOKEN}@github.com/zhimoe/zhimoe.github.io.git - cd zhimoe.github.io - git rm -rf . &amp;&amp; git clean -fxd - mv -v ../dist/* . - git add . - git commit -m "update site" - git remote set-url origin https://zhimoe:${GITHUB_TOKEN}@github.com/zhimoe/zhimoe.github.io.git - git remote -v - git push -q -f 要点:
在项目的源码中放了hugo的deb安装包,省去下载的过程 主题以submodules放在themes目录中,所以编译前一定要git submodule update --init --recursive更新主题到本地. 目标repo的远程仓库一定要在push前重新设置:git remote set-url origin xxx</content></entry><entry><title>wsl-docker-environment</title><url>https://zhimoe.github.io/post/wsl-docker-environment/</url><categories><category>编程</category></categories><tags><tag>wsl</tag><tag>code</tag></tags><content type="html"> 使用wsl,MobaXterm,cmder,docker打造可视化的linux开发环境
离不开Windows的理由很多,作为后端开发需要使用linux的情况也很多,双系统总归是不方便,而且linux下的GUI体验也没用Win 10好.
如果使用虚拟机,那么文件交换和网络等各种问题也需要解决,对系统的内存要求也更高一些.微软为了让更多的开发人员留在Win10上面,开发了WSL,目前的实际体验已经很棒,
今天介绍一下如何打造一个可视化的linux开发环境&ndash;即在Win10启动linux的GUI软件,例如vs code等.在wsl启动vs code写代码可以有效避免一些Windows和linux的编码和换行问题.
本教程分为2部分:
配置wsl可视化 在wsl使用docker 以下内容中 wsl和ubuntu含义相同,console和命令行含义相同.
配置wsl可视化 系统要求是Win 10 1803+版本(低于1803的wsl功能有问题),必须是专业版或教育版才有wsl功能.以下内容的命令行如果开头有>字符请忽略.
windows开启wsl功能 控制面板\程序\程序和功能\开发或关闭Windows功能 > 勾选 &lsquo;适用于linux的Windows子系统&rsquo;和 &lsquo;hyper-V&rsquo;(docker for Windows需要这个功能,也可以使用virtualbox代替), 重启电脑.
windows下载wsl Windows store搜索"wsl"或者"ubuntu"下载ubuntu版本. ubuntu和ubuntu1804是一个版本,ubuntu1604是旧的版本.安装完成你的Windows应用列表会有一个ubuntu应用,点击图标即可打开ubuntu命令行.第一次启动需要等待初始化,然后设置用户名和密码.由于字体难看,所以不用这个自带的命令行而使用下面的cmder.
windws下载cmder软件 cmder是Windows下最强的命令行功能. 不要下载mini那个,里面没用vim和git.第一次启动cmder记得修改cmder启动目录(默认是c盘)和显示中文设置,具体方法请google.
wsl修改软件源,使用阿里云的源. > sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak > sudo sed -i 's/archive.ubuntu.com/mirrors.aliyun.com/g' /etc/apt/sources.list > sudo apt update > sudo apt upgrade -y wsl安装必要软件 # 安装你需要的软件,git和vim是必须的,后面的编辑命令是使用vim >sudo apt install openjdk-8-jdk-headless openjdk-8-jre-headless maven git unzip vim -y 修改wsl下Windows磁盘挂载点 默认的Windows磁盘在wsl的访问方式是/mnt/d/开头,d表示d盘.但是docker on linux的访问路径是 /d,所以这里需要修改挂载点路径.
sudo vim /etc/wsl.conf ##添加3行内容 [automount] root = / options = "metadata" 退出wsl重启,发现/mnt已经没了,当前目录应该是/c/xxx或者/d/xxx.
wsl安装vs code和中文字体 因为wsl没用中文字体将显示豆腐块.
# install chinese fonts for wsl,font name: 'Noto Sans Mono CJK SC' sudo apt install -y fonts-noto-cjk fonts-noto-cjk-extra # Win10下载vs code的deb包,cd到该目录,使用下面命令安装 sudo apt install ./code_1.31.1-1549938243_amd64.deb # 在wsl要启动code必要依赖 sudo apt install libgtk2.0-0 libxss1 libasound2 wsl设置SSH功能 这样可以借助VcXsrv的X11转发功能打开GUI软件
>sudo vim /etc/ssh/sshd_config #取消Port的注释,并将端口改为2222 (端口需要大于1000) #将PasswordAuthentication的值改为yes. #重启 ssh server: sudo service ssh --full-restart #将ssh server设置为服务: sudo service ssh start windows安装VcXsrv 用它的X11转发功能.安装后默认选项即可,可以设置为开机启动.
启动wsl的vs code 在wsl输入code .,等待2秒,你会发现Windows任务栏启动了一个vs code,如果没用启动成功,说明你的VcXsrv的X11转发功能有问题.
配置vs code. 上面打开的vs code有2个问题:中文显示豆腐块,和不能全屏. 打开vs code的设置
#在字体里面先设置你想要英文字体,逗号跟上'Noto Sans Mono CJK SC' #搜索titleBarStyle,将'Window: title Bar Style'设置为 native #上面2个设置也可通过直接编辑文件设置,例如我的vs code文件设置是 > cat ~/.config/Code/User/settings.json { "Window.titleBarStyle": "native", "editor.fontFamily": "monospace,'Noto Sans Mono CJK SC'" } 至此,已经可以在linux下面开发了.当然,其他GUI软件没用测试不确定是不是会有小问题.但是vs code已经可以应付很多开发工作了.
在wsl使用docker 目前的wsl是不支持运行docker的,但是可以在wsl使用Windows的docker,在使用上面是无感的.
安装docker for Windows. 这个就不细说了,注意docker社区版也是需要注册才能下载的.
启动docker for Windows,右键任务栏的docker图标,&ldquo;settings&rdquo;,勾上 &ldquo;expose the daemon on tcp:/localhost:2375 without TLS&rdquo;,这样在wsl可以访问这个docker服务.
wsl安装docker,详细内容可以参考官方文档,下面仅列出必要bash命令.
#安装必要组件 sudo apt install -y apt-transport-https ca-certificates curl software-properties-common #gpg签名 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo apt-key fingerprint 0EBFCD88 #添加docker安装源 sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable" sudo apt update sudo apt install -y docker-ce #通过pip安装docker-compose sudo apt install -y python python-pip sudo usermod -aG docker $USER pip install --user docker-compose #验证docker安装是否成功 docker info docker-compose --version #修改docker服务为Windows的docker echo "export DOCKER_HOST=tcp://localhost:2375" >> ~/.bashrc &amp;&amp; source ~/.bashrc #验证是否可以访问Windows的docker服务,看image list命令输出和Windows的命令行下面的image list输出是不是完全一样. 可以先在Windows下用docker拉几个镜像.然后在wsl验证 docker image list 至此,wsl的docker服务也配置完成.</content></entry><entry><title>Neo4j入门</title><url>https://zhimoe.github.io/post/neo4j-intro/</url><categories><category>编程</category></categories><tags><tag>neo4j</tag><tag>code</tag><tag>database</tag></tags><content type="html"> neo4j图数据库介绍 neo4j是目前排名最高的图数据库,分为商业和社区版本,社区版只支持单机,而且查询的运行时(runtime)不同(cypher runtime:interpreted(社区版),slotted(企业版)). 数据库排名可以在 https://db-engines.com/en/ranking/graph+dbms 查看,下一代最有前景的开源图数据库是dgraph,目前还积极开发中,生产未就绪,等他的Java客户端再成熟一点可以试用.
neo4j数据库中只有3个概念: Node, Relationship, Properties. Node表示实体类别,使用Label区分,例如一个节点可以有Person/Father等多个标签,Relationship即关系,雇佣关系,父子关系,投资关系,交易关系等. Node和Relationship都可以有Proerties,属性自身不分是属于节点还是属于关系,例如Person可以有属性name,关系也可以用属性name.你可以在neo4j browser左侧看到当前数据库的所有Node Label,Relationship Type,Properties.
本地安装和在线沙箱 neo4j背后的公司为了吸引用户,提供了一些好玩的数据库沙箱,这些沙箱数据库已经提前放了一些主题数据,例如购物数据,国会关系数据.你可以通过注册登录 https://neo4j.com/sandbox-v2/, 选择一个数据沙箱实例进行学习试玩.当然你也可以下载社区版,命令行 neo4j.bat console启动,打开127.0.0.1:7474开始学习.
一个neo4j支持多个数据库但是一次只能激活一个数据库,一个数据库所有文件都在$neo4j_home\data\databases目录的独立文件夹,在conf/neo4j.conf的dbms.active_database=graph.db指定激活那个数据库.
cypher查询语言 neo4j使用cypher语言作为查询语言.这是一种模式匹配的声明式语言.基本语法和SQL相似.
cypher中常用的子句(clause)有: MATCH,RETURN,WITH,WHERE,UNWIND,LIMIT,UNION,SKIP,SET. RETURN,LIMIT WHERE和SQL中是一样的,UNWIND这些需要用到再查看文档,这里介绍MATCH和WITH.
MTACH用于指定搜索的模式.例如希望找到&rsquo;Tom Hanks&rsquo;在2018演过的所有电影:MATCH (p:ACTOR {name:'Tom Hanks' }) -[r: ACT_IN]->(m:MOVIE {time: '2018'}),这是一个模式,可以直接REUREN返回p,r,m等变量.可以看到模式中的节点(Node Label)使用();关系类型(Relationship Type)使用[]指定,如果不关心type,那么[]可以省略.使用&ndash;; 属性(Properties) 使用{pname: pvalue}指定.
WITH的作用和python的with非常相似(实际上cypher语言借鉴了python的list处理语法),用于修改一些变量,变量一般都是上一个子句的查询结果,修改之后传给下一个子句.例如下面的语句找到和Anders有关系的人的年龄最大的那个人,返回那个人的所有认识的人的名字.
MATCH (n { name: 'Anders' })--(m) WITH m ORDER BY m.age DESC LIMIT 1 MATCH (m)--(o) RETURN o.name cypher手册: https://neo4j.com/docs/cypher-manual/3.5/clauses/
cypher的操作符 如果需要进行cypher调优,有必要了解一下cypher的操作符. 一般编程语言的代码在被执行前都会被编译得到抽象语法树(AST). 例如Java代码,一个Java文件会被抽象为一个package,class, method,variable declare等不同部分得到一个Class对象. cypher语句一样会被编译得到一棵语法树(AST),每个树节点是一个操作符. 从叶节点的操作符开始执行,得到的结果依次返回给父节点进一步处理.常见的操作符有:AllNodesScan(全局扫描,只能作为叶节点),NodeByLabelScan,Apply等.例如MATCH (n) return n会得到一个AllNodesScan和ProduceResults操作符构成的AST, 你可以通过PROFILE查看你语句编译后得到的操作符构成的执行计划.
# 执行语句得到下面的表格 PROFILE MATCH (p:Person { name: 'Tom Hanks' }) RETURN p # 省略了部分列 +-----------------+----------------+------+---------+-----------------+ | Operator | Estimated Rows | Rows | DB Hits | Page Cache Hits | +-----------------+----------------+------+---------+-----------------+ | +ProduceResults | 1 | 1 | 0 | 0 | | | +----------------+------+---------+-----------------+ | +NodeIndexSeek | 1 | 1 | 2 | 0 | +-----------------+----------------+------+---------+-----------------+ cypher runtime pass
neo4j browser介绍 和大多数数据库一样,neo4j是server-client的数据库,支持http和bolt2中协议.neo4j自带一个基于浏览器的客户端,只需在浏览器输入serverIp:7474即可使用.
neo4j browser自带一个教程和电影关系的数据库初始化脚本.方便你可以学习.下面介绍几个常用的命令.
:help help命令显示各种帮助提示. 常见的topic有 :help cypher :help commands :help keys :help param :play 交互式学习命令. 例如,:play movie graph 进入基于电影数据库的教程. :param 命令,设置变量. :param usrname => &ldquo;zhimoe&rdquo;,注意,变量名和=>之间有空格.设置变量之后可以使用变量MATCH (n:Person) WHERE n.name = $usrname :params 显示当前已经设置的所有变量. 也可以使用:params {name: &lsquo;Stella&rsquo;, age: 24} 覆盖目前的变量. 但是这个命令没用类型安全. spring-neo4j配置 pass
cypher调优 cypher是一种声明式的,模式匹配的查询语言.模式在cypher语言中非常重要.如何合理地设计查询中的模式是cypher性能可调优空间最大的地方.下面给出常见的优化建议.
需要说明的是,后面的这些建议其实大都可以在cypher手册找到,如果感兴趣,建议通读这份长文档&hellip;
避免全局scan cypher 是一种模式匹配的语言,默认会进行全局扫描,除非你告诉它不要.所以起始节点的label非常重要.起始的模式匹配基数大小也非常重要.
缓存和硬盘IO neo4j数据库将数据文件和Page Cache作了映射,如果在缓存中没有查询到,neo4j会从硬盘加载数据文件.第二次查询就可以走缓存.所以需要充分利用Page Cache.记住第一次查询总是会比较慢,因为没用缓存.neo4j 有2级缓存:string cache和AST cache
string cache
默认neo4j在cache中保留1000个查询计划,可在conf/neo4j.conf中参数 dbms.query_cache_size修改这个设置. 需要注意的是cache是根据语句的string hash值判断的,所以一样的语句仅仅是大小写不一样或者空白符不一样对缓存来说也是2个语句.
PROFILE/EXPLAIN语句只会cache其去掉PROFILE/EXPLAIN之后的部分.例如:MATCH (n) return COUNT(n);和PROFILE MATCH (n) return COUNT(n);的cache是一致的.
AST cache
编程语言都有语法树.如果在string cache中没有找到缓存.那么会将查询正规化,得到语法树并将其缓存.正规化的同时也会做一些优化,例如
match (n:Person {id:101}) return n;在正规化之后得到match (n:Person) where n.id={param1} return n; {param1: 101},AST cache不区分大小写,空格等,所以以下查询是一致的: match (n:Person) where n.id=101 return n; match (n:Person {id:101}) return n; MATCH ( n:Person { id : 101 } ) RETURN n; execution plan 当cypher引擎收到查询语句后如果没用找到对应的缓存,那么Cypher query planner会将语句规范化,优化后编译得到一个执行计划(execution plan).这个执行计划会缓存一切且可以复用. 当查询缓存过多,或者数据库的数据变化大时(设置参数是)这个执行计划则失效被移除.在查询中使用参数而不是字面量值,可以提高一个执行计划的复用率.
更多信息参考文档:https://neo4j.com/docs/cypher-manual/3.5/execution-plans/#execution-plan-introduction
查看查询计划 如果想要查看查询语句的执行计划,可以在查询语句前加上 EXPLANIN OR PROFILE 关键字, 你可以在neo4j browser查看query plan找到性能瓶颈.结果左侧边里面第3个tab会给出详细的性能警告(warn).
EXPLAIN只会给出语句的分析结果;而PROFILE则会执行你的查询语句把给出耗时最多的报告,以及每个操作符返回了多少行记录. 注意,profiling会消耗很多资源,所以不要在生产环境中频繁使用.调优的基础是基于cypher的操作符,所以需要你对操作符有基本的了解.
索引 数据库离不开索引.这里有个小陷阱,最早谱系的节点是企业客户(label: COR_CUSTOMER)+和几十个零售客户节点(label:RTL_CUSTOMER),我在查询语句起始节点没有指定label,没用遇到性能问题,后来加入了3百万的个人节点数据后,原来1s的查询变成了1分半钟. 所以在干扰的label比较少时,你不会察觉到性能问题.务必在起始节点指定label,即使目前只有一个label,最好也提前加上.
然而,cypher语句目前不允许在一个节点指定多个label,例如你希望起点label是COR_CUSTOMER|RTL_CUSTOMER,这个是不允许的. 只能在where语句指定.
MATCH n WHERE n:COR_CUSTOMER OR n:RTL_CUSTOMER RETURN n 在3.0之前的neo4j中使用上面的语句,会导致一个AllNodesScan,在3.0之后,该语句则是将2个NodeByLabelScan匹配结果UNION然后DISTINCT的结果. 所以是搜索2次再合并结果.你可以在上面的cypher语句前面添加EXPLAIN查看执行计划,已确定你的语句是否会导致全局扫描.
SO上关于多个label匹配的讨论
大结果集 如果你的查询返回结果集太大,例如几M大小,那么你可能需要考虑你的设计了. 过大的结果集会导致查询返回变慢,要注意,这些结果会占用你的缓存空间,而如果在网络情况不好时,情况更加糟糕了.
目前谱系对这一块并没有优化,最大的谱系的返回接口可能达到1M多,加上ES的数据,前端接收数据会有4M多.
锁 当你修改节点的信息时,节点会被锁定;如果修改关系,关系会被锁定;如果增加/删除关系,那么2个节点和这个关系都会被锁定.而如果此时有节点/关系的相关查询请求,这些请求会等待.所以,如果你需要将50个节点加入一个组(group)&ndash;即添加50个关系,如果你调用50次方法,那么这个group节点被lock的时间较长,此时可以通过UNWIND和列表(list)参数处理这个问题.
MATCH (g:Group { uuid: $groupUuid }) UNWIND $personUuidList as personUuid MATCH (p:Person { uuid : personUuid }) MERGE (p)-[:IS_MEMBER]->(g) 常见查询错误 变量名 label忘记添加冒号,例如MATCH (Person) 和 MATCH (:Person) 是完全不一样的,前者Person是变量,不走索引. 有过大的中间结果集,优化你的语句时思考:尽早distinct,尽早limit,使用collect减少结果的行数,在正确地方使用order by; 多个UNWIND语句导致笛卡尔积 多个UNWIND会导致一个笛卡尔积的结果,这个结果可能会很大.例如下面的结果会得到3*3=9行,所以尽量避免笛卡尔积.
with ['a','b','c'] as lts, [1,2,3] as nrs unwind lts as char unwind nrs as nr return char,nr 在MATCH中使用多个模式笛卡尔积 在MATCH中使用多个模式也会导致笛卡尔积,比较下面的2个结果相同的语句,第一个耗时80s,第二个只需8ms.
# 1. 笛卡尔积 80000 ms w/ ~900 players, ~40 teams, ~1200 games MATCH (pl:Player),(t:Team),(g:Game) RETURN COUNT(DISTINCT pl), COUNT(DISTINCT t), COUNT(DISTINCT g) # 2. 8ms w/~900 players, ~40 teams, ~1200 games MATCH (pl:Player) WITH COUNT(pl) as players MATCH (t:Team) WITH COUNT(t) as teams, players MATCH (g:Game) RETURN COUNT(g) as games, teams, players 模式中的方向 下面的查询中,如果给关系ACTED_IN添加上方向,可以提高查询速度.
MATCH (p:Person)-[:ACTED_IN]-(m) WHERE p.name = "Tom Hanks" RETURN m</content></entry><entry><title>Jupyter Notebook Install New Package[翻译]</title><url>https://zhimoe.github.io/post/jupyter-notebook-install-new-package/</url><categories><category>翻译</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> notes 在pycharm写代码中如果使用到新的package,例如numpy,只需要输入import numpy 然后ALT+ENTER在提示中选择install new package即可.
在notebook中,网上的教程都说是!pip install numpy. 但是这个可能有坑.究其原因是因为:
通过bash启动的notebook的python pip conda这几个命令的环境和实际执行notebook代码的python环境可能不是同一个. 这种情况一般发生在系统有好几个python的情况,例如系统自带python和用户安装的anaconda python. 可以通过对比以下两个notebook命令的输出判断pip执行环境和notebook代码执行环境是否一致： # pip执行环境python !type python # notebook 代码执行环境的python import sys sys.executable 如果不一样,那么需要使用下面命令安装才能在notebook中生效： import sys !{sys.executable} -m pip install numpy sys和os区别 os: 操作系统的抽象. sys: 代码和python解释器交互的接口.提供一系列函数来访问修改python解释器环境设置. source:installing new python package from jupyter notebook</content></entry><entry><title>Java Thread Pool Hierachy</title><url>https://zhimoe.github.io/post/java-threadpool-hierachy/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>java</tag><tag>threadpool</tag></tags><content type="html"> thread pool classes hierachy java thread pool class hierarchy Executor (java.util.concurrent) |---ExecutorService (java.util.concurrent) |---AbstractExecutorService (java.util.concurrent) | |---AbstractEventExecutor (io.netty.util.concurrent) | |---ForkJoinPool (java.util.concurrent) | |---ThreadPoolExecutor (java.util.concurrent) | | |---ScheduledThreadPoolExecutor (java.util.concurrent) |---DelegatedExecutorService in Executors (java.util.concurrent) |---ScheduledExecutorService (java.util.concurrent) three thread pool interfaces Executor, a simple interface that supports launching new tasks.
ExecutorService, a subinterface of Executor, which adds features that help manage the life cycle, both of the
individual tasks and of the executor itself.
ScheduledExecutorService, a subinterface of ExecutorService, supports future and/or periodic execution of tasks.
common thread pool implements ThreadPoolExecutor是thread pool 最常用的实现. 一般通过Executors静态工厂方法来创建.
//Executors.newFixedThreadPool //Executors.newCachedThreadPool //Executors.newSingleThreadExecutor //同样的,Executors还提供了ScheduledExecutorService的工具方法 // Executors.newSingleThreadScheduledExecutor /** * corePoolSize - 保留存活的线程个数 * maximumPoolSize - 最大线程个数 * keepAliveTime - 线程数超过corePoolSize时,空闲线程存活时间 * unit - keepAliveTime的单位,毫秒秒分等 * workQueue – 任务队列,只保存通过 execute()方法提交的 Runnable任务 * threadFactory – 给自己创建一个线程的工厂方法 * handler – 当线程池达到数量限制或者任务队列满了,对新任务提交的处理策略 */ class ThreadPoolExecutor { public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable> workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) {} } JDK默认的拒绝策略RejectedExecutionHandler有：
/** * ThreadPoolExecutor.AbortPolicy - 默认的handler,抛出一个RejectedExecutionException * ThreadPoolExecutor.CallerRunsPolicy - 提交任务的线程自己执行这个任务 * ThreadPoolExecutor.DiscardPolicy - 抛弃这个任务 * ThreadPoolExecutor.DiscardOldestPolicy - 抛弃任务队列中最早提交上来的任务,然后尝试重新提交当前这个任务 */ 任务提交执行流程 fork/join 框架 fork/join和上面ThreadPoolExecutor的区别在于使用了任务窃取算法,工作线程完成自己的任务后可以从其他线程偷取任务,提高整体的任务效率.
核心是一个ForkJoinPool class和一个扩展的AbstractExecutorService. 执行ForkJoinTask 任务.
在JDK8中有个java.util.Arrays.parallelSort()使用的就是 fork/join.
当然,不是所有人都满意JDK7引入的Fork/Join框架.</content></entry><entry><title>Spark Basic</title><url>https://zhimoe.github.io/post/spark-basic/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>spark</tag></tags><content type="html"> 引言 大数据计算和普通的程序并无本质区别：数据输入=>计算=>输出和结果的持久化.这里的挑战在于计算的效率和容错性.由于数据输入巨大,计算的效率是基本的要求.为了在通用硬件上高效完成大量计算,唯一的途径就是将计算任务拆分分布式计算.这就引出了新的问题：分布式计算资源的管理（Mesos,YARN）,分布式计算失败后的恢复（容错性）（Spark RDD）,以及分布式的数据输入和保存（分布式文件HDFS）.hadoop生态圈就是为了解决几个问题设计的(YARN,MapR,HDFS).只不过在计算这一环节Spark做的更加高效取代了MapR.所以先看下hadoop的核心两个组件.
HDFS HDFS是hadoop的虚拟分布式文件系统.满足大数据问题下要求的：可扩展的,容错的,硬件通用的和高并发的特性.HDFS最重要的特性是不可变性&ndash;数据提交到HDFS后即不可更新了,也就是所谓的WORM(write once read many). 文件在HDFS中是以block构成,默认一个block是128M.block是是分布式的,即如果集群中如果有多于1个节点,那么有文件可能会被分布在多个节点上.block是被复制的,这主要是两个目的：1.容错,2.增加数据局部性的概率,有利于访问.block复制在数据节点接收（ingest：消化）block时同时发生.如图所示： NameNode：不知道怎么翻译,NameNode主要负责管理HDFS的元数据,包括directory,文件对象和相关属性（e.g. ACL),元数据是常驻内存中的,硬盘上也有备份以及日志保证持久性和崩溃后的一致性（和数据库相似）.还包括block的位置信息&ndash;block之间的关系.注意,数据（文件）并不经过NameNode,否则很容易成为性能瓶颈,数据是直接到达DataNode,并上报给NameNode管理. 数据节点（DataNode）负责：block复制；管理本节点的存储；向NameNode上报block信息.注意,数据节点不会意识到HDFS的目录（directory）和文件（Files）的概念,这些信息是NameNode管理保存的,客户端只会和NameNode交道. hdfs客户端分为：fs shell;hdfs java api;rest proxy接口（HttpFS等）. 常见命令： # 上传一个文件 -f表示覆盖 hadoop fs -put -f jour.txt /user/dahu/jour/ # 下载 hadoop fs -get /user/dahu/jour/jour.txt # ls hadoop fs -ls /user/dahu/ # 删除 -r表示递归,删除目录 hadoop fs -rm /user/dahu/jour/jour.txt hadoop fs -rm -r /user/dahu/jour YARN YARN:Yet Another Resource Negotiator是hadoop的资源管理器.YARN有个守护进程&ndash;ResourceManager,负责全局的资源管理和任务调度,把整个集群当作计算资源池,只关注分配,不管应用,且不负责容错.YARN将application（或者叫job）分发给各个NodeManager,NodeManager是实际的worker或者worker的代理.ResourceManager主要有两个组件：Scheduler 和 ApplicationsManager. 下图是YARN的结构示意图： 上图中ResourceManager负责管理和分配全局的计算资源.而NodeManager看着更复杂一些：1.用户提交一个app给RM（ResourceManager）；2.RM在资源充足的NodeManager上启动一个ApplicationMaster（也就是这个app对应的第一个container）.3.ApplicationMaster负责在所有NodeManagers中协调创建几个task container,也包括ApplicationMaster自己所在的NodeManager（上图中紫色2个和红色的4个分别表示2个app的task container和ApplicationMaster）.4. NodeManager向各个ApplicationMaster汇报task container的进展和状态.5. ApplicationMaster向RM汇报应用的进展和状态.6.RM向用户返回app的进度,状态,结果.用户一般可通过Web UI查看这些.
上面的示意图是YARN 的核心概念,Spark程序的运行结构示意图和上面的示意图相同.每个组件都可以近似一样的理解,例如,上面的Client在Spark中叫Driver程序;ResourceManager在Spark中叫Cluster Manager（为了理解方便,认为一样即可,Spark的ClusterManager目前主要有YARN,Mesos和Spark自带的三种）；NodeManager就是Spark中的Worker Node.
Spark基本概念 上图中的client程序在Spark中即Driver程序.Driver就是我们编写Spark程序app的主要部分,包括SparkContext的创建和关闭以及计算任务（Task）的计划（Planning,包括数据数据,转换,输出,持久化等).SparkContext负责和Cluster Manager通信,进行资源申请,任务的分配和监控.一般认为SparkContext代表Driver. ClusterManager：就是上面说的三种-Standalone,YARN,Mesos. ＷorkerNode: 集群中运行app代码的节点,也就是上图中YARN的NodeManager节点.一个节点运行一个/多个executor. Executor：app运行在worker节点的一个进程,进程负责执行task的planning.Spark On YARN 中这个进程叫CoarseGrainedExecutorBackend.每个进程能并行执行的task数量取决于分配给它的CPU个数了.下图是一个Spark程序集群概览图,和上图很相似. 仔细对比上面两个示意图,在YARN的结构示意图中,ResourceManager为程序在某个NodeManager上创建的第一个container叫ApplicationMaster,ApplicationMaster负责只是其他的task container.在Spark On YARN有两种运行模式：client和cluster模式.在cluster模式下,用户编写的driver程序运行在YARN的ApplicationMaster的内部.
*RDD:Spark的核心数据结构.后面详细介绍,可以简单的理解为一个Spark程序所有需要处理的数据在Spark中被抽象成一个RDD,数据需要被拆分分发到各个worker去计算,所以RDD有一个分区（Partation）概念.一般我们的数据是放在分布式文件系统上的(e.g. HDFS),可以简单理解为一个RDD包含一或多个Partation,每个Partation对应的就是HDFS的一个block.当然,Partation不是和HDFS的block绑定的,你也可以手动的对数据进行分区,即使他们只是待处理的一个本地文件或者一个小数组. 一个Partation包含一到多个Record,Record可以理解为文本中的一行,excel的一条记录或者是kafka的一条消息. Task：RDD的一个Patation对应一个Task,Task是单个分区上最小的处理单元. RDD pass
SparkStreaming pass
SparkStreaming+Kafka import org.apache.kafka.clients.consumer.ConsumerRecord import org.apache.kafka.common.serialization.StringDeserializer import org.apache.spark.streaming.kafka010._ import org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent import org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe val kafkaParams = Map[String, Object]( "bootstrap.servers" -> "localhost:9092,anotherhost:9092", "key.deserializer" -> classOf[StringDeserializer], "value.deserializer" -> classOf[StringDeserializer], "group.id" -> "use_a_separate_group_id_for_each_stream", "auto.offset.reset" -> "latest", "enable.auto.commit" -> (false: java.lang.Boolean) ) val topics = Array("topicA", "topicB") val stream = KafkaUtils.createDirectStream[String, String]( streamingContext, PreferConsistent, Subscribe[String, String](topics, kafkaParams) ) stream.map(record => (record.key, record.value)) DStream的elements:record is ConsumerRecord&lt;K,V>: A key/value pair to be received from Kafka. This consists of a topic name and a partition number, from which the record is being received and an offset that points to the record in a Kafka partition.包含key(),offset(),partation()方法等.
当一个StreamingContext中有多个input stream时,记得保证给程序分配了足够的资源（特别是core的数量,必须大于输入源的数量）. 本地执行程序时,不要使用“local” or “local[1]” as the master URL,streaming程序至少需要两个thread,一个接受数据,一个处理数据.直接使用local[n],n>输入源个数. DStream 和RDD一样支持各种trans和action DStream is batches of RDDs. 常见错误 数据库(mysql redis)连接的可序列化问题 dstream.foreachRDD { rdd => val connection = createNewConnection() // executed at the driver rdd.foreach { record => connection.send(record) // executed at the worker } } // 上面的写法会导致connection 不可序列化的错误: Task not serializable // RDD的函数(map,foreach)会被序列化发送到worker节点执行,但是connection是和tcp连接,和机器绑定的,无法序列化 dstream.foreachRDD { rdd => rdd.foreach { record => // on worker node val connection = createNewConnection() // 给每个record处理时新建一个连接,会导致严重的数据库连接性能问题 connection.send(record) connection.close() } } // 更好的方式是给每个partation新建一个连接 dstream.foreachRDD { rdd => rdd.foreachPartition { partitionOfRecords => val connection = createNewConnection() partitionOfRecords.foreach(record => connection.send(record)) connection.close() } } // 最好的方法是维护一个静态线程池： [ConnectionPool](https://github.com/RedisLabs/spark-redis/blob/master/src/main/scala/com/redislabs/provider/redis/ConnectionPool.scala) // then use in partition dstream.foreachRDD { rdd => rdd.foreachPartition { partitionOfRecords => // ConnectionPool is a static, lazily initialized pool of connections val connection = ConnectionPool.getConnection() partitionOfRecords.foreach(record => connection.send(record)) ConnectionPool.returnConnection(connection) // return to the pool for future reuse } } // Note that the connections in the pool should be lazily created on demand and timed out if not used for a while. // This achieves the most efficient sending of data to external systems. // 示例 case class RedisCluster(clusterHosts: String, password: String) extends Serializable { def this(conf: SparkConf) { this( conf.get("spark.redis.host", Protocol.DEFAULT_HOST), conf.get("spark.redis.auth", null) ) } /** * * @return use for JedisCluster or JedisPool */ def toSet(): java.util.Set[HostAndPort] = { val nodes: mutable.Set[HostAndPort] = mutable.Set() for (host_port &lt;- clusterHosts.split(",")) { val hp = host_port print(hp) nodes += HostAndPort.from(host_port) } nodes.asJava } } object RedisClusterUtils extends Serializable { @transient private lazy val pools: ConcurrentHashMap[RedisCluster, JedisCluster] = new ConcurrentHashMap[RedisCluster, JedisCluster]() /** * 获取一个JedisCluster * @param rc * @return */ def connect(rc: RedisCluster): JedisCluster = { pools.getOrElseUpdate(rc, { val poolConfig = new JedisPoolConfig(); poolConfig.setMaxTotal(250) poolConfig.setMaxIdle(32) poolConfig.setTestOnBorrow(false) poolConfig.setTestOnReturn(false) poolConfig.setTestWhileIdle(false) poolConfig.setNumTestsPerEvictionRun(-1) val jedisCluster = new JedisCluster(rc.toSet(), 3000, 3000, 5, rc.password, poolConfig) jedisCluster }) } /** * 查询币种对应汇率 * @param jedisCluster 目标redis * @param ccyCd 币种代码 * @return 折美元汇率 */ def getCcyRatio(jedisCluster: JedisCluster, ccyCd:String): Double ={ val res = jedisCluster.get("CCY:"+ccyCd) res.split(":")(2).toDouble } } 参考
Design Patterns for using foreachRDD
Redis on Spark:Task not serializable
How to create connection(s) to a Datasource in Spark Streaming for Lookups
DStream的RDD分区数是由topic分区数相同的. 最佳实践</content></entry><entry><title>单元测试如何Mock有参数的void方法</title><url>https://zhimoe.github.io/post/how-test-void-method-with-parameter/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>java</tag><tag>test</tag></tags><content type="html"> 测试中如果遇到被测试方法调用void方法，在Mockito中改如何处理?
假设有如下的服务依赖：
@Service class DepositSvc { @Autowired private AccountSvc accSvc; public List&lt;Account> dps(String user) { List&lt;Account> accounts = new ArrayList(); List&lt;Account> banks = getBanks(); accSvc.addLinkedAccounts(user, accounts, banks);//accounts被改动了如何mock? return accounts; } } @Service class AccountSvc { @Autowired private RestClient restClient; public void addLinkedAccounts(String user, List&lt;Account> accounts, List&lt;Account> banks) { acc = restClient.getAcc(user); accounts.add(acc); } } 这里的AccountSvc只是提供了一个void方法处理了入参accounts,虽然修改入参是被我所不齿的,但是有时改写这类方法挺麻烦的,特别如果方法修改了两个入参的话.
这种情况下如何测试DepositSvc.dps方法呢? mockito的 doAnswer就是用于模拟void方法回调的.
class DepositSvcTest { @InjectMocks private DepositSvc depositSvc; @Mock private AccountSvc accountSvc; void test_dps() { // ... arrange // mock void method with arguments doAnswer((invocation) -> { Object[] args = invocation.getArguments(); List&lt;Account> accounts = (List&lt;Account>) args[1]; //这里可以拿到入参 accounts.add(new Account(911); //修改入参 return null; }).when(accountSvc).addLinkedAccounts(any(), anyList(), anyList()); // ...assert } }</content></entry><entry><title>熊打虎</title><url>https://zhimoe.github.io/about/</url><categories/><tags/><content type="html"> A JVM lang programmer, use Java/Scala/Clojure, also know a little Python and Rust, yeah, I like learning new programming language.
Most time I write user stories in the daily job.
I make programming fonts, and I&rsquo;m proud of the Aurulent font, try it!</content></entry><entry><title>java generic</title><url>https://zhimoe.github.io/post/java-generic/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 泛型 // 类 class Tuple&lt;T, S> { private T first; private S second; } // 泛型方法也可在非泛型类里面 class ArrayAlg { public static &lt;T> T getMiddle(T... a) { return a[a.length / 2]; } } String middle = ArrayAlg.&lt;String>getMiddle("]ohnM, "Q.n, "Public");// right,&lt;String>可以省略 String middle = GenericCls.getMiddle("hello",0,null);// error // Errr:(7, 45) java: 不兼容的类型: 推断类型不符合上限 // 推断: java.lang.Object&amp;java.io.Serializable&amp;java.lang.Comparable&lt;? extends java.lang.Object&amp;java.io.Serializable&amp;java.lang.Comparable&lt;?>> // 上限: java.lang.String,java.lang.Object 类型限定 public static &lt;T extends Comparable> T min(T a) // 如果多个类型,则：T extends Comparable &amp; Serializable // 只能有一个类,且类必须紧跟extends,但是可以有多个接口 类型擦除 //Tuple&lt;T,S>在虚拟机变为 class Tuple { private Object first;//当调用getFirst时,则发生强制转换 private Object second; } //泛型方法同样有擦除 public static &lt;T extends Comparable> T min(T a) // => public static Comparable min(Comparable a) 约束 不能用基本类型实例化泛型,Pair&lt;double>不允许 运行时参数类型检查只能检查原始类型 if (a instanceof Pair&lt;String>) // Error if (a instanceof Pair&lt;T>) // Error Pair&lt;String> p = (Pair&lt;String>) a; //warning 不能创建参数化类型的数组 Pair&lt;String>[] table = new Pair&lt;String>[10]; // Error Pair&lt;String>[] table; //声明是合法的,只是无法实例化 借助@SafeVarargs参数化类型的数组 @SafeVarargs public static &lt;T> void addAll(Collection&lt;T> coll, T... ts) Class类本身是泛型. 例如,String.daSS 是一个 Class 的实例（事实上,它是唯一的实例.) 因此,makePair 方法能够推断出 pair 的类型 泛型类的静态上下文中类型变量无效 public class Singleton&lt;T> { private static T singlelnstance; // Error public static T getSinglelnstance{// Error if (singleinstance == null) {//construct new instance of T return singlelnstance; } } } 不能抛出或捕获泛型类的实例 public class Problem&lt;T> extends Exception { /* . . . */ } // Error can't extend Throwable 泛型擦除的方法冲突 public class Pair&lt;T> { T first; T second; public boolean equals(T value) { //error 和Object.equals冲突 return first.equals(value) &amp;&amp; second, equals(value); } } 泛型继承 class Employee class Manager extends Employee //Pair&lt;Employee> 和Pair&lt;Manager> 没用任何继承关系 通配符 和 PECS Pair&lt;? extends Employee〉 Pair&lt;? super Manager 反射和泛型</content></entry><entry><title>IO-Java-Stream-Write-Reader</title><url>https://zhimoe.github.io/post/io-java-stream-write-reader/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 上次总结了java中不同读写文件的方法,这次总结一下基本的IO流.网上的总结大部分是以Stream和Reader、Writer来介绍的.这次从封装层次来介绍.
java reader writer stream 首先是byte流,每次read()读取8 bits,并用一个int的低八位保存：
FileInputStream in = null; FileOutputStream out = null; try { in = new FileInputStream("xanadu.txt"); out = new FileOutputStream("outagain.txt"); int c; while ((c = in.read()) != -1) { out.write(c); } } finally { if (in != null) { in.close(); } if (out != null) { out.close(); } } byte流是很基础的流,接下来是字符流,使用int的低16位保存读取内容,一个汉字,使用上面那个字节流,需要读取2次,使用下面的字符流,只用一次.其实背后还是一个桥接
具体的对象体现：
FileReader extemds InputStreamReader,
FileWriter extends OutputStreamWriter
InputStreamReader:字节到字符的桥梁
OutputStreamWriter:字符到字节的桥梁：
FileReader inputStream = null; FileWriter outputStream = null; try { inputStream = new FileReader("xanadu.txt"); outputStream = new FileWriter("characteroutput.txt"); int c; while ((c = inputStream.read()) != -1) { outputStream.write(c); } } finally { if (inputStream != null) { inputStream.close(); } if (outputStream != null) { outputStream.close(); } } ByteArrayInputStream、StringBufferInputStream、FileInputStream 是三种基本的介质流,它们分别从Byte 数组、StringBuffer、和本地文件中读取数据.StringBufferInputStream 已经被Deprecated,设计错误,只是为了兼容.
File I/O现在已经不推荐使用了,推荐nio2的Path及其工具类Files,Paths;
Path 官方教程
ObjectInputStream 和所有FilterInputStream 的子类都是装饰流（装饰器模式的主角）
注意：OutputStream子类中没有StringBuffer为目的地的.ObjectOutputStream 和所有FilterOutputStream 的子类都是装饰流.
几个特殊的类：
PushbackInputStream 的功能是查看最后一个字节,不满意就放入缓冲区.主要用在编译器的语法、词法分析部分.输出部分的BufferedOutputStream 几乎实现相近的功能.
PrintStream 也可以认为是一个辅助工具.主要可以向其他输出流,或者FileInputStream 写入数据,本身内部实现还是带缓冲的.本质上是对其它流的综合运用的一个工具而已.一样可以踢出IO 包！System.out 和System.err 就是PrintStream 的实例！ System.in是inputStream的实例！
你永远不应该new PrintStream,请用PrintWriter
看看字符流的对比：
CharReader、StringReader 是两种基本的介质流,它们分别将Char 数组、String中读取数据.PipedReader 是从与其它线程共用的管道中读取数据.
BufferedReader 很明显就是一个装饰器,它和其子类负责装饰其它Reader 对象.
FilterReader 是所有自定义具体装饰流的父类,其子类PushbackReader 对Reader 对象进行装饰,会增加一个行号.
InputStreamReader 是一个连接字节流和字符流的桥梁,它将字节流转变为字符流.FileReader 可以说是一个达到此功能、常用的工具类,在其源代码中明显使用了将FileInputStream 转变为Reader 的方法.我们可以从这个类中得到一定的技巧.Reader 中各个类的用途和使用方法基本和InputStream 中的类使用一致.后面会有Reader 与InputStream 的对应关系.
OutputStreamWriter 是OutputStream 到Writer 转换的桥梁,它的子类FileWriter 其实就是一个实现此功能的具体类（具体可以研究一SourceCode）.功能和使用和OutputStream 极其类似,后面会有它们的对应图.
PrintWriter 和PrintStream 极其类似,功能和使用也非常相似.但是还是有不同的,PrintStream prints to an OutputStream, and PrintWriter prints to a Writer.
你永远不应该new PrintStream,请用PrintWriter
PrintStream stream = new PrintStream(outputStream); //With the PrintWriter you can however pass an OutputStreamWriter with a specific encoding. PrintWriter writer = new PrintWriter(new OutputStreamWriter(outputStream, "UTF-8")); Piped流 这是线程之间通信使用的.后面介绍.
RandomAccessFile类 该对象并不是流体系中的一员,其封装了字节流,同时还封装了一个缓冲区（字符数组）,通过内部的指针来操作字符数组中的数据. 该对象特点：
该对象只能操作文件,所以构造函数接收两种类型的参数：a.字符串文件路径；b.File对象.
该对象既可以对文件进行读操作,也能进行写操作,在进行对象实例化时可指定操作模式(r,rw)
注意：该对象在实例化时,如果要操作的文件不存在,会自动创建；如果文件存在,写数据未指定位置,会从头开始写,即覆盖原有的内容. 可以用于多线程下载或多个线程同时写数据到文件.
Scanning and formatting The scanner API breaks input into individual tokens associated with bits of data,The formatting API assembles data into nicely formatted, human-readable form.
formatting
int i = 2; double r = Math.sqrt(i); System.out.format("The square root of %d is %f.%n", i, r); Scanner s = new Scanner(new BufferedReader(new FileReader("xanadu.txt"))); By default, a scanner uses white space to separate tokens. also,u can set :
s.useDelimiter(",\\s*");
I/O from commandline You might expect the Standard Streams to be character streams, but, for historical reasons, they are byte streams. System.out and System.err are defined as PrintStream objects. Although it is technically a byte stream, PrintStream utilizes an internal character stream object to emulate many of the features of character streams.
By contrast, System.in is a byte stream with no character stream features. To use Standard Input as a character stream, wrap System.in in InputStreamReader.
InputStreamReader cin = new InputStreamReader(System.in);
！！！！妈的,老子开始就困惑很久了,一直不明白System.out怎么可以直接打印出中文.
jdk1.5开始读写控制台以前常用的是Scanner：
Scanner scanner = new Scanner(System.in); scanner.nextLine(); 从 JDK1.6开始,基本类库中增加了java.io.Console 类,用于获得与当前 Java 虚拟机关联的基于字符的控制台设备.在纯字符的控制台界面下,可以更加方便地读取数据.
Console console = System.console(); if (console == null) { throw new IllegalStateException("不能使用控制台"); } return console.readLine(prompt); Data Streams Data streams support binary I/O of primitive data type values (boolean, char, byte, short, int, long, float, and double) as well as String values. All data streams implement either the DataInput interface or the DataOutput interface. This section focuses on the most widely-used implementations of these interfaces, DataInputStream and DataOutputStream.
致谢：Oubo的博客</content></entry><entry><title>Java 6/7/8中文件读写</title><url>https://zhimoe.github.io/post/io-java-6-7-8-%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 如何在Java中读写文件,这里保留Java6/7版本,但是你永远不应该使用它们,优先使用Path,Files,Paths三个类.
资料：Reading and writing text files
Java8最佳实践 不要用File对象,改用Path对象,该对象既表示文件路径,也表示文件文本（应该认为文件也是路径的一部分）,对于以前的File,可以File.toPath()得到一个Path对象.
Files是一个静态类,操作文件内容.Paths是静态工具类,操作文件路径,例如拼接文件路径,以前要使用平台无关的分隔符表示：File.pathSeparator, File.separator.
例如,构建一个文件对象:Path path = Paths.get("~/test/", "foo", "bar", "a.txt");
read file to string in java 6/7/8 package angus.java.interview; import java.io.BufferedReader; import java.io.FileInputStream; import java.io.IOException; import java.io.InputStream; import java.io.InputStreamReader; import java.nio.charset.StandardCharsets; import java.nio.file.Files; import java.nio.file.Paths; public class FileToStringJava678 { public static void main(String[] args) throws IOException { // How to read file into String before Java 7 InputStream is = new FileInputStream("filetoStringjava678.txt"); BufferedReader buf = new BufferedReader(new InputStreamReader(is)); String line = buf.readLine(); StringBuilder sb = new StringBuilder(); while (line != null) { sb.append(line).append("\n"); line = buf.readLine(); } String fileAsString = sb.toString(); System.out.println("Contents (before Java 7) : " + fileAsString); // Reading file into Stirng in one line in JDK 7 with using proper character encoding String fileString = new String(Files.readAllBytes(Paths.get("filetoStringjava678.txt")), StandardCharsets.UTF_8); System.out.println("Contents (Java 7 with character encoding ) : " + fileString); //java 7 按行读取 BufferedReader br = new BufferedReader(new FileReader(file)); String line; while((line = br.readLine()) != null) { // do something with line. } //java 8 按行读取 String fileName = "c:/lines.txt"; try (Stream&lt;String> stream = Files.lines(Paths.get(fileName))) { stream.forEach(System.out::println);//or other thing you do with stream } catch (IOException e) { e.printStackTrace(); } // It's even easier in Java 8 Files.lines(Paths.get("filetoStringjava678.txt"), StandardCharsets.UTF_8).forEach(System.out::println); } } java 8 file io demo public class Java8IO { public static void main(String[] args) throws IOException { //读取所有字节： Path path = Paths.get("alice.txt"); String content = new String(Files.readAllBytes(path), StandardCharsets.UTF_8); System.out.println("Characters: " + content.length()); // 读取所有行： List&lt;String> lines = Files.readAllLines(path, StandardCharsets.UTF_8); System.out.println("Lines: " + lines.size()); // JAVA 8 延迟处理： try (Stream&lt;String> lineStream = Files.lines(path, StandardCharsets.UTF_8)) { System.out.println("Average line length: " + lineStream.mapToInt(String::length).average().orElse(0)); } // 按单词读取： try (Scanner in = new Scanner(path, "UTF-8")) { in.useDelimiter("\\PL+");//？ int words = 0; while (in.hasNext()) { in.next(); words++; } System.out.println("Words: " + words); } // 读取一个网页： URL url = new URL("https://horstmann.com/index.html"); try (BufferedReader reader = new BufferedReader(new InputStreamReader(url.openStream()))) { Stream&lt;String> lineStream = reader.lines();////!!!! BufferedReader TO Stream System.out.println("Average line length: " + lineStream.mapToInt(String::length).average().orElse(0)); } // PrintWriter 向文本写文件： path = Paths.get("hello.txt"); try (PrintWriter out = new PrintWriter(Files.newBufferedWriter(path, StandardCharsets.UTF_8))) { out.println("Hello"); } // Files.write向文本写文件： content = "World\n"; Files.write(path, content.getBytes(StandardCharsets.UTF_8), StandardOpenOption.APPEND); // 多行写入 String fileName = "file.txt"; Path path = Paths.get("file1.txt"); List&lt;String> list = new ArrayList&lt;>(); try (Stream&lt;String> lines = Files.lines(Paths.get(fileName))) { lines.forEach(list::add); Files.write(path, list, StandardCharsets.UTF_8); } catch (IOException e) { e.printStackTrace(); } // 打印错误栈： StringWriter writer = new StringWriter(); Throwable throwable = new IllegalStateException(); throwable.printStackTrace(new PrintWriter(writer)); String stackTrace = writer.toString(); System.out.println("Stack trace: " + stackTrace); // 输入流保存到文件： Files.copy(inputStream,filepath,StandardCopyOption.REPLACE_EXISTING); // 直接将url中的pdf保存下来： // 适用于任何二进制文件： URL url = new URL("http://www.cninfo.com.cn/1202417936.PDF"); try (InputStream in = new BufferedInputStream(url.openStream())) { Files.copy(in, Paths.get(url.getFile().substring(1)),StandardCopyOption.REPLACE_EXISTING); } // url.getFile().substring(1)去掉起始地斜杠符 // copy()有三种形式 // 还有一种方式用于jdk7之前： URL website = new URL("XXX.pdf"); ReadableByteChannel rbc = Channels.newChannel(website.openStream()); FileOutputStream fos = new FileOutputStream(url.getFile().substring(1)); fos.getChannel().transferFrom(rbc, 0, Long.MAX_VALUE); // FileChannel的抽象方法abstract long transferFrom(ReadableByteChannel src, long position, long count) } }</content></entry><entry><title>Java AOP example</title><url>https://zhimoe.github.io/post/java-aop-example/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>aop</tag></tags><content type="html"> Java AOP: 找到一个最简单的介绍,不怎么想翻译,直接看原文吧:
A Simple Introduction to AOP
提醒个点,使用注解的方式写切面时,增加了一个空方法,即：
class Test{ @Pointcut("execution(* org.bk.inventory.service.*.*(..))") public void serviceMethods(){ //... } } 在使用xml配置的话,就不需要这个方法了,serviceMethods方法名是后面配置切点的引用.
如果不想引入spring的话,可以直接使用aspectj或者jboss aop.</content></entry><entry><title>Java concurrency 1 basic</title><url>https://zhimoe.github.io/post/java-concurrency-1-basic/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag><tag>concurrency</tag></tags><content type="html"> 知识点太多了.先列举一些知识点,然后在分别做一点笔记.
模式 共享可变性 隔离可变性 纯粹不可变性:STM, IO密集型任务和计算密集型任务 读写文件和网络请求这种算IO密集型任务,阻塞时间长,任务阻塞系数接近1；线程池大一点好,
判断质数的这种任务属于计算密集型任务,阻塞系数约为0.
poolSize = cores/(1-blockingCofficient); cores 是处理器核心数.
场景：
根据网络服务api计算给定股票代码和股票数的资产总值.-IO密集
判断n以内的所有素数. &ndash; 计算密集
Java5以前的一些同步方法api 尽量不要使用,但是要理解.wait/notify、join等函数,synchronized volatile关键字的理解.笔记
用ExecutorService代替Thread及其方法.笔记 用Lock和子类的方法代替synchronized.但是不绝对. 笔记 以前用wait/notify的地方,现在可以用CyclicBaerrier和CountDownLatch同步工具代替.笔记 同步容器和并发容器 同步容器包括Vector和Hashtable(java.util.Properties 也是一个HashTable),使用synchronized同步.不建议使用,但是要知道HashTable和HashMap区别：
Java 中 HashMap 和 HashTable 有几个不同点：
Hashtable 是同步的,然而 HashMap 不是. 这使得HashMap更适合非多线程应用,因为非同步对象通常执行效率优于同步对象. Hashtable 不允许 null 值和键.HashMap允许有一个 null 键和一个 NULL 值. HashMap的一个子类是LinkedHashMap.所以,如果想预知迭代顺序（默认的插入顺序）,只需将HashMap转换成一个LinkedHashMap.用Hashtable就不会这么简单. 如果同步对你来说不是个问题,我推荐使用HashMap.如果同步成为问题,你可能还要看看ConcurrentHashMap. 迭代hashmap最佳方式：
Iterator it = mp.entrySet().iterator(); while (it.hasNext()) { Map.Entry pair = (Map.Entry)it.next(); System.out.println(pair.getKey() + " = " + pair.getValue()); it.remove(); // avoids a ConcurrentModificationException } } 并发容器是和java.util.concurrent包一块发布的.包括很多新的并发容器：
并发容器架构图
图中最底部的都是jdk1.5增加的并发容器：主要有：ConcurrentHashMap,CopyOnWriteList, BlockingQueue等.
参考书籍： Doug Lea 《Concurrent Programming in Java》 2004
Brian Goetz 《java concurrency in practice》 2007
Venkat 《Programming concurrency on the JVM》</content></entry><entry><title>Java concurrency 2 Runnable Callable FutureExecutor</title><url>https://zhimoe.github.io/post/java-concurrency-2-runnable-callable-future-executor/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 定义任务的内容 多线程编程的核心元素就是任务,任务是独立的活动.不依赖其他任务的状态,结果,以及边界效应.
定义任务的内容使用Runnable和Callable.
Runnable 接口表示没有返回的一个过程（procedure）,没有受检异常.
Callabe 接口的call方法会返回一个结果,并有可能抛出受检异常.如果要表示没有返回值,可以使用Callable&lt;Void> ,但是不鼓励使用这个代替Runable,但一个任务内容没有返回值,只是利用副作用时,应该优先使用Runable,使得含义清晰,并且JDK中ScheduledExecutorService也有只能接收Runable的方法.
可以将Runnable定义的任务提交给Thread直接运行,但是这个线程是不可重用的.更好的方法是提交给执行器ExecutorService.
Future接口描述了任务的生命周期,并提供方法获得任务执行的结果.该接口有一个实现类：FutureTask.该类的实例一定和一个具体任务相关.ExecutorService所有的submit方法都会返回一个Future实例.你也可以直接通过FutureTask构造函数将Runnable/Callable构建一个FutureTask实例.该实例将管理该任务的生命周期
注意,FutureTask 实现了Runnable和Future（通过实现RunnableFuture 接口,如下）,所以既可以使用ExecutorService,也可以使用Thread执行任务内容.
public class FutureTask&lt;V> implements RunnableFuture&lt;V> public interface RunnableFuture&lt;V> extends Runnable, Future&lt;V> Future.get是一个阻塞方法,如果任务没有结束或者没有抛出异常,那么会一直等待下去,如果需要异步的使用ComletionService.
ExecutorService 执行器框架,root 接口是Executor,只有一个execute方法执行runnable实例.更常用是子接口ExecutorService,除了可以执行runnable,callable,还可以invoke一callable集合：
&lt;T> List&lt;Future&lt;T>> invokeAll(Collection&lt;? extends Callable&lt;T>> tasks) &lt;T> T invokeAny(Collection&lt;? extends Callable&lt;T>> tasks) &lt;T> Future&lt;T> submit(Callable&lt;T> task) Future&lt;?> submit(Runnable task) ScheduledExecutorService The ScheduledExecutorService interface supplements the methods of its parent ExecutorService with schedule, which executes a Runnable or Callable task after a specified delay. In addition, the interface defines scheduleAtFixedRate and scheduleWithFixedDelay, which executes specified tasks repeatedly, at defined intervals.
scheduleAtFixedRate: 第一次是initialDelay 后执行,第二次是initialDelay + 1 * period 后执行,类推.
scheduleWithFixedDelay: 是前面任务执行结束后开始计算间隔计时.
两个方法都不会并发执行任务,特别是第一个方法,如果任务时间比参数中等待时间period长,那么只会延期执行.对于第二个方法,本来就是要等前面结束才执行,所以没有这个问题.两个方法遇到异常,那么后面任务也不会执行,因为任务是重复的,后面也会遇到异常.周期任务可以取消,或者遇到执行器终结才结束.
CompletionService 如果有多个任务,那么ExecutorService只能不停的轮询Future看是否有任务结束,并取得结果.CompletionService则是另外是自动的告诉你那些任务结果已经准备好.注意构造方法需要一个ExecutorService
ExecutorService = incoming queue + worker threads CompletionService = incoming queue + worker threads + output queue
参考
ExecutorService executor = Executors.newFixedThreadPool(numberOfThreadsInThePool); CompletionService&lt;String> completionService = new ExecutorCompletionService&lt;String>(executor); for (final String num: nums) { completionService.submit(new Task(num)); //Task is Callable } try { for (int t = 0, n = nums.size(); t &lt; n; t++) { Future&lt;String> f = completionService.take(); System.out.print(f.get()); } } catch (InterruptedException e) { Thread.currentThread().interrupt(); } catch (ExecutionException e) { Thread.currentThread().interrupt(); } finally { if (executor != null) { executor.shutdownNow(); } }</content></entry><entry><title>Java concurrency 3 synchronized or Lock</title><url>https://zhimoe.github.io/post/java-concurrency-3-synchronized-or-lock/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> synchronized method和synchronized block的区别 如果是synchronized(this),那么和synchronized 方法没有任何区别,锁定对象都是方法所在的对象.
synchronized void mymethod() { ... } void mymethod() { synchronized (this) { ... } } 但是synchronized block可以锁定其他对象,而且synchronized block的范围是可以控制更灵活,synchronized 方法的边界只能是整个方法
private void method() { // code here // code here // code here synchronized( lock ) { // very few lines of code here } // code here // code here // code here } 不要忘记synchronized 这个指令是JVM内置的,也是未来可以优化的.如果只是简单的同步一个资源对象,就使用synchronized,而且,使用Lock有就必须出现一堆的try/finally.
使用ReentrantLock场景：
需要以下高级特性时 ： 可定时的,可轮询的,可中断的锁,公平队列,非块结构.
stackoverflow回答</content></entry><entry><title>Java concurrency 4 CAS and atomic</title><url>https://zhimoe.github.io/post/java-concurrency-4-cas-and-atomic/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> AtomicLong code: public final long incrementAndGet() { for (;;) { long current = get(); long next = current + 1; if (compareAndSet(current, next)) return next; } } //in java 8: public final long incrementAndGet() { return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L; } 基础 第一个版本是基于cas的,cas基于一个基础：有三个值,新值N,预期内存中的值E,内存中需要更新的值V,如果V == E,那么将V设置为N,返回V,结束；如果V != E,说明有别的线程动了这个v,那么不做修改直接返回V.cas在X86下对应的是 CMPXCHG 汇编指令
java8中则使用了x86的优化指令atomic fetch-and-add ,上面的代码直接等价于cpu的一条指令atomic fetch-and-add .[性能更好](atomic fetch-and-add vs compare-and-swap)
而compareAndSet利用JNI来完成CPU指令的操作.
public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } 注意 java.util.concurrent.atomic中的原子类使用了很多cas,但是这个方法一个是自己实现和使用需要很仔细,另一个在真的高并发中可能陷入死循环,因为方法中本身就是一个死循环：for (;;).java8为此提供了LongAdder.
关于垃圾自动回收的语言不会出现cas中aba问题的原理：stackoverflow</content></entry><entry><title>Java concurrency 5 Synchronizer and AQS</title><url>https://zhimoe.github.io/post/java-concurrency-5-synchronizer-and-aqs/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> CountDownLatch和CyclicBarrier示例
先自己写一个CountDownLatch的示例： CountDownLatch是管理一组线程和一个主线程的先后.主线程wait后就阻塞,直到所有的CountDownLatch调用countDown后主线程接着开始.
package angus.intrview.concurrent; import java.util.concurrent.CountDownLatch; import java.util.concurrent.TimeUnit; public class CountDownLatchTest { // 这个方法将启动多个任务,并让它们同时执行,计算完成的时间 public long timer(int taskNums) throws InterruptedException { CountDownLatch startLatch = new CountDownLatch(1); CountDownLatch finishLatch = new CountDownLatch(taskNums); for (int i = 0; i &lt; taskNums; i++) { Task task = new Task(startLatch, finishLatch, i); new Thread(task).start(); } long start = System.nanoTime(); startLatch.countDown();// 准备好线程后开始同时启动所有任务 finishLatch.await();// 等待任务完成 long end = System.nanoTime(); return end - start; } public static void main(String[] args) throws InterruptedException { CountDownLatchTest ct = new CountDownLatchTest(); long time = ct.timer(100); System.out.println(TimeUnit.NANOSECONDS.toSeconds(time) + " SENCODS"); } } class Task implements Runnable { CountDownLatch startLatch; CountDownLatch finishLatch; int time; Task(CountDownLatch startLatch, CountDownLatch finishLatch, int time) { this.startLatch = startLatch; this.finishLatch = finishLatch; this.time = time; } @Override public void run() { try { startLatch.await();// 等待主线程通知任务开始 System.out.println("doing the task!"); Thread.sleep(time * 100); // 模拟任务过程 } catch (InterruptedException e1) { // TODO Auto-generated catch block e1.printStackTrace(); } finally { System.out.println("task done"); finishLatch.countDown();// 告诉主线程任务完成 } } } CyclicBarrier // pass</content></entry><entry><title>Java-==-and-equals</title><url>https://zhimoe.github.io/post/java--and-equal/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> samples code and notes on java == and equals
/** * samples for == and equal() * @author zhimoe * */ class TestObj { // the class for test == and equal() } public class EqualAndCompare { public static void main(String[] args) { TestObj obj1 = new TestObj(); TestObj obj2 = new TestObj(); TestObj obj3 = obj1; System.out.println(obj1 == obj2);// false , // == Compares references, not values System.out.println(obj1 == obj3);// true System.out.println(obj1.equals(obj2));// false, // equal() method is derived from java.lang.Object, if not override,nor // in superclass,then equal behave as same as == // Always remember to override hashCode if you override equals so as not // to "break the contract". // As per the API, the result returned from the hashCode() method for // two objects must be the same if their equals methods shows that they // are equivalent. The converse is not necessarily true. String s1 = "haha";// constant pool String s2 = new String("haha");// defined in ?heap System.out.println(s1 == s2);// false ,== Compares references, not // values, there is a exception for // static field in class, static String // in class == and equal both always // return *true* // for more infomation,see : // http://stackoverflow.com/questions/7520432/what-is-the-difference-between-vs-equals-in-java System.out.println(s1.equals(s2)); // true compare the // value String s3 = s2.intern();// find the same value String in constant pool System.out.println(s1 == s3);// true int i1 = 2;// primitive type has no equal() method Integer i3 = Integer.valueOf(2); System.out.println(i1 == i3);// true, i3 automatic unboxing into int; System.out.println(i3.equals(i1));// auto boxing into Integer Integer i2 = 2; System.out.println(i3.compareTo(i2)); } /* * Comparable interface, a.compareTo(b) return -1：less,0:equal,1:greater. 0 * should always be returned for objects when the .equals() comparisons * return true. All Java classes that have a natural ordering implement this * (String, Double, BigInteger, ...). * * * Comparator interface: is a util for compare two instance,then you can use * the comparator to sort array and other things * */ }</content></entry><entry><title>Java动态代理</title><url>https://zhimoe.github.io/post/java%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 好文 Java 动态代理机制分析及扩展
更深入的一篇:
java设计模式-动态代理模式
优势 相比 静态代理,动态代理具有更强的 灵活性,因为它不用在我们设计实现的时候就指定 某一个代理类来代理哪一个被代理对象,我们可以把这种指定延迟到程序运行时由 JVM来实现.
实例 动态代理类接口,接口规范方法.
package angus.interview.proxy; public interface Subject { public void request(); } 需要被代理的真实的类:
package angus.interview.proxy; public class SubjectImpl implements Subject { @Override public void request() { System.out.println(" subject request"); } } 先创建一个代理类.然后利用反射创建一个用真实类加载器创建的一个对象.该对象调用request方法实际上调用的是代理类的invoke方法.
package angus.interview.proxy; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class DynamicProxy implements InvocationHandler { private Object target; public Object bind(Object target) { this.target = target; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); // 要绑定接口this(这是一个缺陷,cglib弥补了这一缺陷) } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println("------------------before------------------"); Object result = method.invoke(target, args); System.out.println("-------------------after------------------"); return result; } } static void main(){ DynamicProxy proxy = new DynamicProxy(); Subject subject= proxy.bind(SubjectImpl); subject.request(); } 和静态代理模式比较的好处
在静态代理模式时,一个真实角色必须对应一个代理角色,如果大量使用会导致类的急剧膨胀;而动态代理则不会有这个问题,我们将接口中的方法委托给invoke方法,并在invoke中实现拦截.
源码分析 参考:http://rejoy.iteye.com/blog/1627405 主要原来:生成了一个代理类的class文件. Proxy.newProInstance()方法
public static Object newProxyInstance(ClassLoader loader,Class&lt;?>[] interfaces,InvocationHandler h) throws IllegalArgumentException { if (h == null) { throw new NullPointerException(); } final Class&lt;?>[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) { checkProxyAccess(Reflection.getCallerClass(), loader, intfs); } // 这里是生成class的地方 Class&lt;?> cl = getProxyClass0(loader, intfs); // 使用我们实现的InvocationHandler作为参数调用构造方法来获得代理类的实例 try { final Constructor&lt;?> cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; if (sm != null &amp;&amp; ProxyAccessHelper.needsNewInstanceCheck(cl)) { return AccessController.doPrivileged(new PrivilegedAction&lt;Object>() { public Object run() { return newInstance(cons, ih); } }); } else { return newInstance(cons, ih); } } catch (NoSuchMethodException e) { throw new InternalError(e.toString()); } } 其中newInstance只是调用Constructor.newInstance来构造相应的代理类实例,这里重点是看getProxyClass0这个方法的实现:
private static Class&lt;?> getProxyClass0(ClassLoader loader, Class&lt;?>... interfaces) { // 代理的接口数量不能超过65535,这是class文件格式决定的 if (interfaces.length > 65535) { throw new IllegalArgumentException("interface limit exceeded"); } // JDK对代理进行了缓存,如果已经存在相应的代理类,则直接返回,否则才会通过ProxyClassFactory来创建代理 return proxyClassCache.get(loader, interfaces); } 其中代理缓存是使用WeakCache实现的,如下
private static final WeakCache&lt;ClassLoader, Class&lt;?>[], Class&lt;?>> proxyClassCache = new WeakCache&lt;>(new KeyFactory(), new ProxyClassFactory()); 具体的缓存逻辑这里暂不关心,只需要关心ProxyClassFactory是如何生成代理类的,ProxyClassFactory是Proxy的一个静态内部类,实现了WeakCache的内部接口BiFunction的apply方法:
private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?>[], Class&lt;?>> { // 所有代理类名字的前缀 private static final String proxyClassNamePrefix = "$Proxy"; // 用于生成代理类名字的计数器 private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?> apply(ClassLoader loader, Class&lt;?>[] interfaces) { // 省略验证代理接口的代码…… String proxyPkg = null; // 生成的代理类的包名 // 对于非公共接口,代理类的包名与接口的相同 for (Class&lt;?> intf : interfaces) { int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) { String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? "" : name.substring(0, n + 1)); if (proxyPkg == null) { proxyPkg = pkg; } else if (!pkg.equals(proxyPkg)) { throw new IllegalArgumentException( "non-public interfaces from different packages"); } } } // 对于公共接口的包名,默认为com.sun.proxy[源码](http://hg.openjdk.java.net/jdk6/jdk6/jdk/rev/695dd7ceb9e3) if (proxyPkg == null) { proxyPkg = ReflectUtil.PROXY_PACKAGE + "."; } // 获取计数 long num = nextUniqueNumber.getAndIncrement(); // 默认情况下,代理类的完全限定名为:com.sun.proxy.$Proxy0,com.sun.proxy.$Proxy1……依次递增 String proxyName = proxyPkg + proxyClassNamePrefix + num; // 这里才是真正的生成代理类的字节码的地方 byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces); try { // 根据二进制字节码返回相应的Class实例 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); } catch (ClassFormatError e) { throw new IllegalArgumentException(e.toString()); } } } ProxyGenerator是sun.misc包中的类,它没有开源,但是可以反编译来一探究竟:
public static byte[] generateProxyClass(final String var0, Class[] var1) { ProxyGenerator var2 = new ProxyGenerator(var0, var1); final byte[] var3 = var2.generateClassFile(); // 这里根据参数配置,决定是否把生成的字节码（.class文件）保存到本地磁盘, //我们可以通过把相应的class文件保存到本地,再反编译来看看具体的实现,这样更直观 if(saveGeneratedFiles) { AccessController.doPrivileged(new PrivilegedAction() { public Void run() { try { FileOutputStream var1 = new FileOutputStream(ProxyGenerator.dotToSlash(var0) + ".class"); var1.write(var3); var1.close(); return null; } catch (IOException var2) { throw new InternalError("I/O exception saving generated file: " + var2); } } }); } return var3; } saveGeneratedFiles这个属性的值从哪里来呢:
private static final boolean saveGeneratedFiles = ((Boolean)AccessController.doPrivileged( new GetBooleanAction("sun.misc.ProxyGenerator.saveGeneratedFiles"))).booleanValue(); GetBooleanAction实际上是调用Boolean.getBoolean(propName)来获得的,而Boolean.getBoolean(propName)调用了System.getProperty(name),所以我们可以设置sun.misc.ProxyGenerator.saveGeneratedFiles这个系统属性为true来把生成的class保存到本地文件来查看.
反编译class文件
自己创建文件写入生成的动态代理类:
package angus.interview.proxy; import java.io.FileOutputStream; import java.io.IOException; import sun.misc.ProxyGenerator; @SuppressWarnings("restriction") public class ProxyGeneratorUtils { public static void writeProxyClassToHardDisk(String path) { // 获取代理类的字节码 byte[] classFile = ProxyGenerator.generateProxyClass("$Proxy11", SubjectImpl.class.getInterfaces()); FileOutputStream out = null; try { out = new FileOutputStream(path); out.write(classFile); out.flush(); } catch (Exception e) { e.printStackTrace(); } finally { try { out.close(); } catch (IOException e) { e.printStackTrace(); } } } } 测试我们的工具类:
package angus.interview.proxy; public class TestProxy { public static void main(String[] args) { System.getProperties().put("sun.misc.ProxyGenerator.saveGeneratedFiles", "true"); DynamicProxy proxy = new DynamicProxy(); Subject sproxy = (Subject) proxy.bind(new SubjectImpl()); sproxy.request(); ProxyGeneratorUtils.writeProxyClassToHardDisk("$Proxy11.class"); } } 刷新目录,得到一个$Proxy11.class,反编译使用Java Decompiler,GUI傻瓜式,支持最新语法,编译慢,效果好:
可以看到 $Proxy11继承Proxy,并实现了Subject,同时我们写的那个InvocationHandler的子类DynamicProxy也被传递进去了.
重点看request方法的代码,只有一行 this.h.invoke(this, m3, null);其中h的引用就是DynamicProxy.
m3就是 m3 = Class.forName("angus.interview.proxy.Subject").getMethod("request", new Class[0]);
import angus.interview.proxy.Subject; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; public final class $Proxy11 extends Proxy implements Subject { private static Method m1; private static Method m2; private static Method m3; private static Method m0; public $Proxy11(InvocationHandler paramInvocationHandler) { super(paramInvocationHandler); } public final boolean equals(Object paramObject) { try { return ((Boolean)this.h.invoke(this, m1, new Object[] { paramObject })).booleanValue(); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } public final String toString() { try { return (String)this.h.invoke(this, m2, null); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } public final void request() { try { this.h.invoke(this, m3, null); return; } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } public final int hashCode() { try { return ((Integer)this.h.invoke(this, m0, null)).intValue(); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } static { try { m1 = Class.forName("java.lang.Object").getMethod("equals", new Class[] { Class.forName("java.lang.Object") }); m2 = Class.forName("java.lang.Object").getMethod("toString", new Class[0]); m3 = Class.forName("angus.interview.proxy.Subject").getMethod("request", new Class[0]); m0 = Class.forName("java.lang.Object").getMethod("hashCode", new Class[0]); return; } catch (NoSuchMethodException localNoSuchMethodException) { throw new NoSuchMethodError(localNoSuchMethodException.getMessage()); } catch (ClassNotFoundException localClassNotFoundException) { throw new NoClassDefFoundError(localClassNotFoundException.getMessage()); } } }</content></entry><entry><title>Java注解和注解处理器</title><url>https://zhimoe.github.io/post/java-annotation-processing/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 注解处理 注解是jdk1.5出现的,但是自定义处理注解的功能是1.6才有的.Element等关于注解源码抽象的支持类都是1.6出现的.
关于注解的定义就不说了,主要说说注解处理
本文根据以下资料并进行部分修改：
JavaAnnotationProcessing
基本知识 annotation processing integrated into javac compiler
– since Java 6.0; known as pluggable annotation processing
– compiler automatically searches for annotation processors
– unless disabled with -proc:none option for javac
– processors can be specified explicitly with -processor option for javac or -cp processor.jar,processor.jar include /META-INF/service/javax.annotation.processing.Processor file and your processor decalared in file;
implement a processor class
– must implement Processor interface
– typically derived from AbstractProcessor
– new package javax.annotation.processing
同时自定义注解处理器需要指定注解选项： specify supported annotation + options
– by means of annotations:
@SupportedAnnotationTypes
@SupportedOptions
@SupportedSourceVersion
编译器编译源码是会有很多轮(round)：
1st round：编译器得到所有的注解-获取所有的注解处理器-进行match并process,如果匹配的处理器中process方法的返回值是true,表示该注解被 claim,不再查询其他处理器.如果是false,接着查询匹配处理器处理,所以注解处理器在META-INF/services/javax.annotation.processing.Processor声明顺序是有关系的&ndash; 所有的注解都被claim后,注解处理完成.
如果注解处理器产生新的java文件,那么新的一轮处理开始,前面被调用的那些处理器又被调用,直到没有java文件产生.
最后一轮又要调用一遍所有处理器,完成他们的各自工作.
最最后,编译器编译源码和注解处理器生成的源码.
还有一个很重要的类AbstractProcessor： 有一个引用processingEnv 提供了两个重要工具类：
– Filer for creation of new source, class, or auxiliary files
– Messager to report errors, warnings, and other notices
此外,一个产生java文件的重要方法：
FileObject sourceFile = processingEnv.getFiler().createSourceFile(beanClassName); process() method takes 2 arguments: Set&lt;? extends TypeElement> annotations – the annotation types requested to be processed – subset of the supported annotations RoundEnvironment roundenv – environment for information about the current and prior round – supplies elements annotated with a given annotation or all root elements in the source 一个自定义的注解处理器格式如下：
@SupportedAnnotationTypes({"Property"}) @SupportedSourceVersion(SourceVersion.RELEASE_6) public class PropertyAnnotationProcessor extends AbstractProcessor { public boolean process(Set&lt;? extends TypeElement> annotations, RoundEnvironment env) { // process the source file elements using the mirror API } } jdk1.6 对注解的处理支持建立在对源码的抽象,Element是javax.lang.model.*中定义的,各种Element是对源码抽象数据结构,如：
package com.example; // PackageElement public class Foo { // TypeElement private int a; // VariableElement private Foo other; // VariableElement public Foo () {} // ExecuteableElement } TypeElement不能提供父类的信息,如果需要这些信息,需要从Element中得到TypeMirror.TypeMirror::element.asType()
实例： 动手写注解处理器：3个类,一个定义注解Comparator.java,一个使用注解的类Name.java,一个处理注解MyProcessor.java.
我将定义一个注解@Comparator,使用在方法上,被注释的方法能够返回一个Comparator.
一个注解处理器,解析所有被注释的方法,为每一个方法产生一个Comparator类.
！！！注意,这里的内容和连接中资料的已经不一样了,资料里给的process方法并不能产生比较器类.
给出注解定义前看看注解怎么使用：
// ./Name.java // ./ 表示当前命令行文件夹,后面所有的javc命令都以这个文件夹为准 package java.interview.annotation; public class Name { private final String first; private final String last; public Name(String f, String l) { first = f; last = l; } @Comparator("NameByFirstNameComparator") public int compareToByFirstName(Name other) { if (this == other) return 0; int result; if ((result = this.first.compareTo(other.first)) != 0) return result; return this.last.compareTo(other.last); } } 其中被注解注释的方法将产生一个NameByFirstNameComparator.java文件：
// ./angus/initerview/annotation/NameByFirstNameComparator.java public class NameByFirstNameComparator implements java.util.Comparator&lt;Name> { public int compare(Name o1, Name o2) { return o1.compareToByFirstName(o2); } public boolean equals(Object other) { return this.getClass() == other.getClass(); } } 我们定义注解：
// ./Comparator.java package angus.interview.annotation; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Documented @Target(ElementType.METHOD) @Retention(RetentionPolicy.SOURCE) public @interface Comparator { String value(); } 接下来定义我们的注解处理器,有详细注解,特别注意generate源码中的空格和分号不要弄丢了：
package angus.interview.annotation; import java.io.IOException; import java.io.PrintWriter; import java.util.Set; import javax.annotation.processing.AbstractProcessor; import javax.annotation.processing.RoundEnvironment; import javax.annotation.processing.SupportedAnnotationTypes; import javax.annotation.processing.SupportedSourceVersion; import javax.lang.model.SourceVersion; import javax.lang.model.element.Element; import javax.lang.model.element.ExecutableElement; import javax.lang.model.element.TypeElement; import javax.lang.model.type.PrimitiveType; import javax.lang.model.type.TypeKind; import javax.lang.model.type.TypeMirror; import javax.tools.Diagnostic; import javax.tools.FileObject; @SupportedAnnotationTypes({ "angus.interview.annotation.Comparator" }) @SupportedSourceVersion(SourceVersion.RELEASE_8) public class MyProcessor extends AbstractProcessor { @Override public boolean process(Set&lt;? extends TypeElement> annotations, RoundEnvironment roundEnv) { for( final Element element: roundEnv.getElementsAnnotatedWith( Comparator.class ) ) { if(element instanceof ExecutableElement){ ExecutableElement m = (ExecutableElement) element; TypeElement className = (TypeElement)m.getEnclosingElement(); Comparator a = m.getAnnotation(Comparator.class); if (a != null) { TypeMirror returnType = m.getReturnType(); if (!(returnType instanceof PrimitiveType) || ((PrimitiveType) returnType).getKind() != TypeKind.INT) { processingEnv.getMessager().printMessage(Diagnostic.Kind.ERROR, "@Comparator can only be applied to methods that return int"); continue; } // prepare for java file generation // t m a mean ? String comparatorClassName = a.value(); String comparetoMethodName = m.getSimpleName().toString(); String theProcessedClassesName = className.getQualifiedName().toString(); try { writeComparatorFile(theProcessedClassesName, comparatorClassName, comparetoMethodName); } catch (IOException e) { e.printStackTrace(); } } } } return true;// claimed now,no need next processor } /* * * public class NameByFirstNameComparator implements java.util.Comparator&lt;Name> { * public int compare(Name o1, Nameo2) { return o1.compareToByFirstName(o2); } * * public boolean equals(Object other) { return this.getClass() == other.getClass(); } } */ //!!!careful with spaces and ";"!!! private void writeComparatorFile(String fullClassName, String comparatorClassName, String compareToMethodName) throws IOException { int i = fullClassName.lastIndexOf("."); String packageName = fullClassName.substring(0, i); FileObject sourceFile = processingEnv.getFiler().createSourceFile(packageName + "." + comparatorClassName); if (sourceFile == null) { System.out.println("create source file failed"); } PrintWriter out = new PrintWriter(sourceFile.openWriter()); if (i > 0) { out.println("package " + packageName + ";"); } String parametrizedType = fullClassName.substring(i + 1);//!! out.println( "public class " + comparatorClassName + " implements java.util.Comparator&lt;" + parametrizedType + "> {"); out.println(); out.println("public int compare( " + parametrizedType + " o1 , " + parametrizedType + " o2 ){"); out.println("return o1." + compareToMethodName + "(o2);"); out.println("}"); out.println(); out.println(); out.println("public boolean equals(Object other) {"); out.println("return this.getClass() == other.getClass();"); out.println("}"); out.println("}"); out.close(); } } 测试处理器 两种方法,
一种是使用 -cp：
在项目的根目录中（pom.xml同级目录）新建META-INF文件夹,并在里面新建services文件夹,再在里面新建一个文件 javax.annotation.processing.Processor,并在该文件中注册我们的处理器,第一行写入：angus.interview.annotation.MyProcessor.
然后用eclipse将项目export得到一个jar包,jar必须包含target文件夹（处理器class文件）和META-INF文件夹（注册处理器）.这里将jar包命名为process.jar. 复制jar包到Name.java目录中,并在该目录打开终端,输入：
javac -cp process.jar Name.java
将会得到Name.class文件和一个angus文件夹,最里面是NameByFirstNameComparator.java和NameByFirstNameComparator.class.
打开NameByFirstNameComparator.java,发现内容和上面给出的一模一样.
第二种方法是使用-processor参数,但是还没搞懂MyProcessor.class应该放在哪里.暂时先到这.</content></entry><entry><title>单例模式和序列化</title><url>https://zhimoe.github.io/post/java%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%92%8C%E5%BA%8F%E5%88%97%E5%8C%96/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> Java单例模式的各种写法和序列化
参考资料
饱汉式 public class Singleton { private static Singleton instance = null private Singleton (){} public static Singleton getInstance() { if(instance == null) instance = new Singleton(); return instance; } } //饱汉式,使用时创建 饿汉式 //加载时创建对象 static public class Singleton { private Singleton instance = null; static { instance = new Singleton(); } private Singleton (){} public static Singleton getInstance() { return this.instance; } } 静态内部类 public class Singleton { private Singleton (){} private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } } //这个比较好,线程安全,也达到了延迟加载效果. 枚举类 //这个是最好的 这种方式是Effective Java作者Josh Bloch 提倡的方式,它不仅能避免多线程同步问题,而且还能防止反序列化重新创建新的对象,可谓是很坚强的壁垒啊 public enum Singleton { INSTANCE; public void whateverMethod() { } } 访问这个单例 Singleton.INSTANCE 双重校验锁 其实是不安全的,多线程开销很大,甚至死锁.原因在于指令重排序.
public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 序列化 使用静态内部类举例,只要提供一个readResolve方法
public class Singleton { private Singleton (){} private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } private Object readResolve() throws ObjectStreamException{ return SingletonHolder.INSTANCE; } } 无论是实现Serializable接口,或是Externalizable接口,当从I/O流中读取对象时,readResolve()方法都会被调用到.实际上就是用readResolve()中返回的对象直接替换在反序列化过程中创建的对象,而被创建的对象则会被垃圾回收掉.</content></entry><entry><title>理解Gradle build脚本结构与语法</title><url>https://zhimoe.github.io/post/understanding-gradle-buildscript/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>groovy</tag><tag>gradle</tag></tags><content type="html"> 在看这个之前,希望你有用ant或者maven的使用经验,还有,对groovy的语法有一个简单的了解,不懂也没关系,下面会介绍.
理解gradle文件的前提是理解一个重要的groovy概念:closure
closure 一个closure是一个定义在groovy文件中的{}代码块,这个代码块类似js中的匿名函数,它可以被赋值给变量,可以被调用,可以接收参数,还可以作为参数传递给别的函数.
closure中最重要的两个概念是委托对象和作为参数传递的语法格式（理解gradle文件很重要）.
groovy方法调用括号的省略 groovy提供非常优雅的方法调用格式,总结起来是:
//可以省略参数括号,并且链式调用 // equivalent to: turn(left).then(right) turn left then right //groovy数字可以直接转换成字符串 // equivalent to: take(2.pills).of(chloroquinine).after(6.hours) take 2.pills of chloroquinine after 6.hours //两个参数用逗号隔开 // equivalent to: paint(wall).with(red, green).and(yellow) paint wall with red, green and yellow //命名参数用冒号 // with named parameters too // equivalent to: check(that: margarita).tastes(good) check that: margarita tastes good //闭包作为参数也可以省略括号 // with closures as parameters // equivalent to: given({}).when({}).then({}) given { } when { } then { } //没有参数的方法必须有括号 // equivalent to: select(all).unique().from(names) select all unique() from names //如果调用链元素为奇数,那么最后一个元素是前面方法链返回对象的属性 //cookies 是take(3)返回值的一个属性 // equivalent to: take(3).cookies // and also this: take(3).getCookies() take 3 cookies 上面调用的格式是dsl的基础.也是看懂gradle文件格式的基础.
让我们再深入一点,上面讲的是调用格式,那么怎么创建这种可以链式调用的方法呢？
groovy和scala的方法返回值不需要return,最后一行就是返回值. closure是一个匿名函数,格式{ [closureParameters -> ] statements },默认自带一个名为it的参数,所以只接受一个参数时可以省略->. closure可以访问scope（作用域）内任何变量.并且这个scope是可以通过委托来改变的. groovy中Map对象的value如果是closure,那么可以接着调用:mapp.keyy({closure}) 有了上面的基础,我们看一个简单的例子: //将closure赋值给一个变量,这个closure接收一个参数,参数名是默认的,it show = { println it } square_root = { Math.sqrt(it) } //为了容易理解,我将参数的type都添加上了, //please方法需要一个closure,接着返回一个map,map的key是the,value是一个closure, //这个closure接收一个closure,并返回一个map,这个map的of的value又是一个closure(不要晕了) //最后一个closure接收一个参数n. def please(Closure action) { [the: { Closure what -> [of: { n -> action(what(n)) }] }] } //调用: // 等价: please(show).the(square_root).of(100) please show the square_root of 100 // ==> 10.0 总结一下就是,将你需要的操作封装成一个closure,给一个直观的命名,保证整个DSL调用语句有语义,定义返回一个map的函数作为入口,map的key是方法名,value是closure,这样可以在key后面传递一个closure接着调用这个value.
委托对象 gradle脚本是一个配置脚本,类似maven中pom.xml文件,不过gradle脚本更为强大,因为.gradle文件就是groovy文件,所以还可以在脚本里面直接定义groovy对象让脚本使用.
委托对象就是一个groovy对象,用来执行gradle构建脚本中的closure.
as a build script executes, it configures an object of type Project. This object is called the delegate object of the script. The following table shows the delegate for each type of Gradle script. 三种不同的gradle脚本对应的委托对象 Build script（build.gradle） ->Project Init script ->Gradle Settings script(setting.gradle) ->Settings 构建中的每一个project,Gradle都会创建一个Project对象,并将这个对象与构建脚本相关联.
Project对象与build.gradle是一对一的关系.
Gradle的脚本是配置脚本,当脚本执行时,它是在配置某一个特殊类型的对象.比如一个构建脚本的执行,它就是在配置一个Project类型的对象.这个对象叫做脚本的代理对象.
委托有个重要的概念就是scope,指closure的变量引用范围:有时变量不在当前scope中,但是可以通过委托,改变closure的委托对象,这样就拥有了委托者的scope,从而可以在closure中使用委托者的变量.
关于groovy closure 的委托有三个重要属性
• this: refers to the instance of the class that the closure was defined in. • owner: is the same as this, unless the closure was defined inside another closure in which case the owner refers to the outer closure. • delegate: is the same as owner. But, it is the only one that can be programmatically changed, and it is the one that makes Groovy closures really powerful. the closure itself will be checked first, followed by the closure's this scope, then the closure's owner, then its delegate. However, Groovy is so flexible this strategy can be changed. Every closure has a property called resolvedStrategy. This can be set to: • Closure.OWNER_FIRST • Closure.DELEGATE_FIRST • Closure.OWNER_ONLY • Closure.DELEGATE_ONLY 来自 &lt;https://dzone.com/articles/groovy-closures-owner-delegate> gradle是dsl解析工具,是对groovy语法的扩展,build.gradle可以理解为就是一个.groovy文件,gradle会解析这个文件,发现里面的closure,并将这些closure委托给一个对象去执行.
gradle将groovy的委托机制发挥到极致,要理解gradle内部,就要理解closure的委托！
closure作为参数传递 将closure作为参数传递的方法有多种:
//method accepts 1 parameter - closure myMethod(myClosure) //if method accepts only 1 parameter - parentheses can be omitted myMethod myClosure //I can create in-line closure myMethod {println 'Hello World'} //method accepts 2 parameters myMethod(arg1, myClosure) //or the same as '4', but closure is in-line myMethod(arg1, { println 'Hello World' }) //if last parameter is closure - it can be moved out of parentheses myMethod(arg1) { println 'Hello World' } 注意第三种和最后一种调用方式,是不是和gradle文件中很眼熟？只不过在gradle脚本中出现的closure更加复杂,因为有closure嵌套！！！但是万变不离其宗.下面我们会介绍嵌套不过是委托链的表现.
看一个脚本代码:
buildscript { repositories { jcenter() } dependencies { classpath 'com.android.tools.build:gradle:1.2.3' } } buildscript是一个方法,接收一个closure.至于这个方法在哪,可以定义在任何地方,但是可以肯定的是,这个方法一定能够被Project对象调用.
因为build.gradle脚本就是委托给Project对象执行的.事实上,Project对象也不是亲自执行这个方法,而是委托给ScriptHandler执行.
这里,我们ScriptHandler对象会搜索到两个配置closure:repositories和dependencies.我们可以在ScriptHandler api中搜索到这两个方法.从api中我们又发现:
传递给dependencies的closure又被委托给了DependencyHandler对象&hellip;&hellip;. 这就是委托链.
ScriptHandler api
Project api
注意:这里buildscript {&hellip;}整体称为一个 script block. 脚本块就是一个接受closure参数的方法调用.还有的方法是不接受closure的,那些称为statement（看下面解释）.
A script block is a method call which takes a closure as a parameter
插件 先看看构建脚本的构成:
A build script is made up of zero or more statements and script blocks. Statements can include method calls, property assignments, and local variable definitions. A script block is a method call which takes a closure as a parameter. The closure is treated as a configuration closure which configures some delegate object as it executes.
就是说脚本有两种内容:script block和statement.
Project接口预先定义了几个block:
allprojects { } Configures this project and each of its sub-projects. artifacts { } Configures the published artifacts for this project. buildscript { } Configures the build script classpath for this project. configurations { } Configures the dependency configurations for this project. dependencies { } Configures the dependencies for this project. repositories { } Configures the repositories for this project. sourceSets { } Configures the source sets of this project. subprojects { } Configures the sub-projects of this project. publishing { } Configures the PublishingExtension added by the publishing plugin. 这些closure参数基本都是委托给其他对象执行的.
可以看到,Project对象的方法是有限而且通用的.真正有用的是插件,gradle的很多功能也是通过官方写的插件提供的.
如果你看到一个顶级层的something { ... }block,但是在Project源码中没有找到something block的任何信息.那么这个方法就是通过插件提供的.gradle自带很多插件,像java,eclipse,groovy,android等.
看一个实际的例子:
在android开发中的构建脚本:
apply plugin: 'com.android.application' android { compileSdkVersion 22 buildToolsVersion "22.0.1" defaultConfig { applicationId "com.trickyandroid.testapp" minSdkVersion 16 targetSdkVersion 22 versionCode 1 versionName "1.0" } buildTypes { release { minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' } } } 这里,出现了android{},Project对象并没有这个script block.所以,这其实是由插件提供的block.我们找到com.android.application入口代码
extension = project.extensions.create('android', AppExtension, this, (ProjectInternal) project, instantiator, buildTypeContainer, productFlavorContainer, signingConfigContainer) setDefaultConfig(extension.defaultConfig, extension.sourceSetsContainer) extensions是一个ExtensionContainer实例,其中create API:
&lt;T> T create(String name, Class&lt;T> type, Object... constructionArguments)
这里就创建了一个android属性,是一个AppExtension对象,我们在脚本中提供给android block的{}其实是配置了一个AppExtension对象.我们可以在AppExtension中找到compileSdkVersion等属性.
所以,插件扩展的Project对象,提供了很多方法,这样,可以在脚本中使用插件定义的方法（script block）了.
一个插件就是实现实现了org.gradle.api.Plugin接口的groovy类.
我们看怎么写一个插件:
//build.gradle apply plugin: GreetingPlugin //这里提供closure 来配置插件提供的greeting script block greeting { message = 'Hi' greeter = 'Gradle' } class GreetingPlugin implements Plugin&lt;Project> { void apply(Project project) {//注意我们是如果扩展Project对象的,通过extensions对象创建一个script block:greeting,而这个block关联的是一个对象 project.extensions.create("greeting", GreetingPluginExtension) project.task('hello') &lt;&lt; { //注意我们是如何使用greeting的,没有通过extensioins println "${project.greeting.message} from ${project.greeting.greeter}" } } } class GreetingPluginExtension { String message String greeter } /* project.task('hello') &lt;&lt; { println "${project.greeting.message} from ${project.greeting.greeter}" } 使用了重载操作符,等价: project.task('hello').leftShift({ println "${project.greeting.message} from ${project.greeting.greeter}" }) */ 官方文档:如何自己写一个插件
#####参考:
gradle-tip-2
Gradle深入与实战（六）Gradle的背后是什么？
DSL语法 gradle使用的基于groovy中的DSL语法,所谓的dsl,就是基于groovy发明的新的“编程语言”,gradle dsl是groovy的超集,就是你可以完全使用groovy的语法,但是你还是会看到很多不是groovy语法,这时不要困惑,这些语法不过是gradle利用groovy提供的元编程能力提供的新语法.
以新建task的语法为例,在Project API中有四个重载形式:
Task task(String name, Closure configureClosure); Task task(Map&lt;String, ?> args, String name, Closure configureClosure); Task task(Map&lt;String, ?> args, String name) throws InvalidUserDataException; Task task(String name) throws InvalidUserDataException; 但是你会看到这样的调用方式:
task intro(dependsOn: hello) { doLast { println "I'm Gradle" } } 这是dsl,具体的解析方式在TaskDefinitionScriptTransformer
具体见我在sf的提问gradle task method syntax in build.gradle
more tips gradle-tips</content></entry><entry><title>面试题-类加载过程和子类重写父类方法的调用</title><url>https://zhimoe.github.io/post/java%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%E5%92%8C%E5%AD%90%E7%B1%BB%E9%87%8D%E5%86%99%E7%88%B6%E7%B1%BB%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 最近非常火的一道携程面试题Java
public class Base { private String baseName = "base"; public Base() { callName(); } public void callName() { System.out.println(baseName); } static class Sub extends Base { private String baseName = "sub"; public void callName() { System.out.println(baseName); } } public static void main(String[] args) { Base b = new Sub(); // 输出？ } } 我的理解：
先理解两个方法:
class 的(clinit)方法和(init)方法不同：这两个方法一个是虚拟机在装载一个类初始化的时候调用的（&lt;clinit>）.另一个是在类实例化时调用的（&lt;init>）.
在加载类时需要类的初始化,JVM对应的字节码方法是&lt;clinit>,这个方法会初始化static变量和执行static{}代码块,按源码定义的顺序执行.注意：如果static{}代码块中引用了static 变量,那么一定要使用之前定义static变量.ide会提示的.
这时,class的其他成员变量和方法都没有被执行.变量的内存都已经分配,值为null或者0（基本类型）,false(布尔类型).
当创建一个类的实例时,此时会调用&lt;init>方法,这个方法会初始化非static变量和执行{}代码块.注意,这两个也是按源码顺序执行的.所以代码块如果要使用非static变量,一定要先定义.同样ide一般会提示的.但是要明白这个顺序.
以上说的执行顺序通过eclipse调试可以确定是正确的.
所以组合起来 创建一个类的实例对象需要下面的顺序：
父类P static代码块和static变量初始化 -> 子类S static代码块和static变量初始化 -> 父类P 非static代码块和非static变量初始化 -> 父类P构造函数 -> 子类S非static代码块和非static变量初始化 -> 子类S构造函数 回到面试题：我们看看创建一个实例对象的调用栈：
可以看到依次进入16, 8, 21行代码:
16行： static class Sub extends Base
8行： callName();//Base()构造函数中
21行： System.out.println (baseName) ;//Sub的callName()
根据前面的分析,这个类没有static代码块和static变量,也没有代码块.所以第一个执行的是父类非静态成员的base=&ldquo;base&rdquo;;接着执行构造函数Base();这里到了魔法的一步,调用的callName()是子类（21行）的方法.这个行为就是动态单分派.详细资料看最后.由于子类的非static变量初始化没有完成,所有子类中的base变量是null.输出也是null.
！！！所以,不要再构造函数中调用可能会被子类覆盖的方法.
有的面试题会出现陷阱:在调用callName()方法改为this.callName(). 其实都是一样的.在调用Base构造函数时没有Base的实例对象,调用者其实还是Base$Sub这个类.
还有一个进阶版：
public class Basic { public void add(int i) { System.out.println("Basic add"); } public Basic() { add('a'); } public static void main(String[] args) { Basic a = new A(); B b = new B(); } } class A extends Basic { public void add(int i) { System.out.println("A add"); } } class B extends Basic { public void add(char i) { System.out.println("B add"); } } 不仅考察单分派,还有重载的静态多分派. 进阶版问题的解释需以下知识点-java的静态分派和动态单分派.
CSDN-类加载机制-深入java虚拟机 读书笔记
方法分派
重载是静态多分派,编译时期确定.
覆盖是动态单分派,运行时通过实际类型绑定.
静态多分派: 所有依赖静态类型来定位方法执行版本的分派过程就叫做静态分派,静态分派最典型的应用就是方法重载.
动态单分派: 根据运行期实际类型确定方法执行版本的分派过程叫做动态分派,动态分派最典型的应用就是方法重写.
同时理解:动态单分派就是多态,java的面向接口编程的根基就是多态.</content></entry><entry><title>Java新手如何学习SpringMVC框架</title><url>https://zhimoe.github.io/post/how-do-newbie-learn-spring/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>spring</tag><tag>java</tag></tags><content type="html"> 知乎回答备份,原答案写于15年.
6,404 人赞同了该回答
4年之后感觉自己当年写的真好.O(∩_∩)O哈哈~
评论里面有人写到现在都用spring boot,个人觉得boot 只要搞清楚一个autoconfig就懂了小半了.
学习框架的同时还是需要针对性地深入学习一些Java基础,例如反射,CDI, JDBC,Class类和MySQL 以及 http（nginx的使用）.求精不求多,新手也不要搞什么mongodb,etcd,zk这些,有了前面的基础,后面上手使用新东西会很快的. 举个例子,很多人学习mybatis的使用,但是JDBC只会一个Class.forName+Statement,显然也不知道mybatis的好处和底层的.
还是要多写,不要复制,单个项目去掉复制代码还有5000行的话,其实就能够理解到课本上的“高内聚,低耦合”是什么意思了.
&mdash;&mdash;&mdash;&mdash;&ndash;原回答&mdash;&mdash;&mdash;&mdash;&ndash;
1 想说说自己Spring的学习路程.课余自学Spring将近一年了,还是不得其道.起初是去年（14年）暑假学习了一下JSP,并没有深入理解,所以导致学习Spring时对着书本写一些demo,感觉自己理解了,其实并不知道内部时什么原理,出了问题不停的百度,一个小问题好几天解决不了.
学习一种框架最先需要知道的是为什么需要使用这个框架,任何一个框架的发明都是为了解决编程中的一些痛点,打开任何一本hibernate或者其他框架的入门书,第一章都是介绍框架的理念和优势.如果需要理解这些理念和优势,那么你需要知道不使用这个框架之前是怎么处理的,才能知道框架做了一些什么事情.
针对Spring的学习,第一步就是了解没有spring和struts框架之前的Java web是如何开发的.你会知道那时候使用JSP和Servlet.然后你就知道,Servlet是一个规范,那在Spring里面,Servlet去哪了？ 这时候你知道了DispatchServlet.然后你会了解到IoC和AOP.
很多新的技术只不过是引入了新的编程元素对原来技术进行了封装.
2 其实Java Web开发,spring不是第一步,首先需要理解的是 HTTP协议. chrome的DevTools和curl,postman要有基本使用.
还要知道服务器发送给浏览器的响应是没有没有JS,CSS和图片等外部资源的,浏览器在解析响应时才会再次请求这些资源,这里会出现一些静态资源请求不到的问题,SpringMVC是怎么配置的？还有chrome并发请求数量限制,如何合并雪碧图提高网页加载速度等知识点,属于http知识了.
接下来,学习Servlet和JSP.这个步骤不是可以跳过的,现在流行的框架Spring MVC和Struts2其实都是基于Servlet的,只有深入理解了Servlet才能理解后面的新技术.
下面几个知识点可以检测你是否理解了Servlet：
1、什么是ServletContext,和tomcat等web容器的关系时什么？Servlet 工作原理解析
简单的说,我们在浏览器点击链接和按钮产生的消息不是发送给Servlet的,而是发送给web容器的(在JSP出现之前,web容器也叫Servlet容器),web容器接收消息后不知道怎么处理,转交给我们编写的Servlet处理,那么web容器怎么和Servlet交流呢？于是就出现了Servlet接口,接口是定义一种规范的良好表达形式. 只要我们编写的Java类符合Servlet规范,那么就能被Web容器识别并被容器管理.
2、什么是Session？Session在实际工程中的应用场景.以及@SessionAttribute注解的局限性.
3、JSP是面向服务器的,它并不知道浏览器是什么鬼,是我们在写JSP时预设客户端是浏览器,JSP就是一个Servlet.JSP的常用对象和指令.
4、JSP的中文编码乱码有几种情况？各自的解决方法？提示： JSP文件的编码,浏览器的解析编码,GET请求的编码,POST的编码.
5、Servlet是一种接口规范,其中请求和响应是Servlet容器通过向方法的参数赋值HttpServletRequest或者HttpServletResponse传递的.在Struts1里面,将doGet()方法里的响应移到返回值里.在Struts2里则:
在Controller中彻底杜绝引入HttpServletRequest或者HttpServletResponse这样的原生Servlet对象.
同时将请求参数和响应数据都从响应方法中剥离到了Controller中的属性变量.
这是一个很大的技术改造,也造成了Struts2的盛行.Spring MVC走的是中间路线,Spring的2.0.8之前的版本甚至直接使用Servlet的doGet的.Spring MVC现在开始流行主要还是因为Schema xml的精简和基于注解的配置.所以这里出现了新的知识点：Schema Based XML的相关知识和Java5引入的注解原理.
书籍：推荐许令波的书《深入分析Java Web技术内幕(修订版)》和计文柯的《深入理解spring技术内幕》,特别是第二本,对spring的分析很是彻底.</content></entry></search>