<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Python @contextlib.contextmanager 的使用</title><url>https://zhimoe.github.io/post/python-contextlib/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> 日常开发中使用这个注解的情况比较少，今天发现其实有一个临时环境变量设置的使用方式。
with set_environ(env_name, value): # 使用后自动清除 env_name 变量 ... # env_name 已失效 可关闭资源的管理 with self._operation_context() as conn: ... # 使用数据库 connection @contextlib.contextmanager def _operation_context(self) -> Generator[Connection, None, None]: """Return a context that optimizes for multiple operations on a single transaction. This essentially allows connect()/close() to be called if we detected that we're against an :class:`_engine.Engine` and not a :class:`_engine.Connection`. """ conn: Connection if self._op_context_requires_connect: conn = self.bind.connect() # type: ignore[union-attr] else: conn = self.bind # type: ignore[assignment] try: yield conn finally: if self._op_context_requires_connect: conn.close() 临时环境变量的设置与清除 with set_environ('LOCAL_PROXY', value): # LOCAL_PROXY now is value ... # 环境变量中 LOCAL_PROXY 已恢复（删除或者前值） @contextlib.contextmanager def set_environ(env_name, value): """Set the environment variable 'env_name' to 'value' Save previous value, yield, and then restore the previous value stored in the environment variable 'env_name'. If 'value' is None, do nothing""" value_changed = value is not None old_value = os.environ.get(env_name) if value_changed: os.environ[env_name] = value try: yield # 这里无需 yield 具体值，只是利用副作用 finally: # 需要恢复原来的变量 if value_changed: if old_value is None: del os.environ[env_name] else: os.environ[env_name] = old_value</content></entry><entry><title>支持中文的等宽编程字体：FangSongCode</title><url>https://zhimoe.github.io/post/programming-font-fangsongcode/</url><categories><category>编程</category></categories><tags><tag>font</tag><tag>fangsongcode</tag></tags><content type="html"> 个人对于字体有严重的强迫症，在过去十年里（以后应该也会）一直在换各种编程字体，也会使用 fontforge 对字体做一些小修改，甚至在 reddit 上面看的咨询编程字体的图片可以一眼认出。
对于编程等宽字体，曾经用过比较久的有 Fira Code，Aurulent，TheSansMono，Go Mono，Source Code Pro，Plex Mono，Drafting Mono。也用过一些收费字体例如 MonoLisa，PragmataPro，Operator Mono，Gintronic 等。目前最喜欢的还是 Fira Code（MonoLisa 第二），只是 Fira Code 个性突出，在中英文混排中看着非常显眼。
而对于中文部分，就更加困难了。目前的黑体和宋体都有各自的问题：黑体字形过大，如果是 0.5 宽度的英文（Ubuntu Mono，PragmataPro，Iosevka 等），中文注释过于显眼；宋体则是横笔太细，好看的编程字体都是非衬线的，搭配不是很协调，在显示器上面宋体也不适合长时间阅读。
去年偶然发现网友推荐的聚珍新仿。这是一个民国设计字体，可以说是宋体、行楷的融合体。笔画粗细介于黑体和宋体之间。从此就一直使用这个字体。在 JetBrains IDE 和 VS Code 中设置 fallback 字体非常简单，但是在其他软件和系统上面设置 fallback 就非常费劲，于是决定合并一个字体。
对于英文部分，虽然 Fira Code 是我最喜欢的字体，但是从协调性来看，仿宋字体属于衬线字体，显然和 IBM Plex Mono 最合适。可惜 Plex Mono 等宽字符缺失较多，最终我选择了 Source Code Pro 并对字符 l,r,4,0,1 做了替换或者修改，使其更加适合正文。
对于中英字符宽度问题，中文字体的宽度一般等于 em-size（假设 1000），即 1000，英文字体的宽度就比较多，主流的是 600，半宽的是 500（Iosevka 或者 PragmataPro）,Fira Code 宽度是 1200/1950（em-size），SF Mono 是 1266/2048（em-size），会更加宽一点。
目前唯一支持 CJK 的等宽字体 Sarasa Gothic 的方案是将思源黑体和 Iosevka 合并，中文宽度 1000，英文 500，但是由于黑体字形过大过黑，显得英文偏小，而且由于窄宽字体设计比较难，个人感觉 Iosevka 和 PramataPro 美感不足。最终选了 Source Code Pro，宽度 600，中文宽度 1000，这样好处是 5 个英文字符和 3 个汉字等宽，勉强能用。
最终的效果如下：</content></entry><entry><title>Python 异步编程</title><url>https://zhimoe.github.io/post/python-async-programming/</url><categories><category>编程</category></categories><tags><tag>async</tag><tag>python</tag></tags><content type="html"> 异步编程很难，但却是最近十年所有编程语言在发力的方向。
在面向 CPU 计算的场景下，多线程基本都能吃满 CPU 资源。但是在 IO 场景下，多线程并不能解决问题，大部分时间线程都在等待 IO 调用的返回。
实际上 python 的官方教程里面并没有 async 编程的内容，而是在std lib doc 中网络编程章节介绍了 asyncio 这个 lib，实际上这也是异步编程的最佳使用场景。
此外经常会看到 &ldquo;Use async sparingly&rdquo;，因为异步编程存在染色问题，一旦使用 async，会要求你全链路全部为 async，否则在 block 时 cpu 并无法让出线程资源。
大多数情况，如果出于性能原因不需要异步，线程通常是更简单的替代方案。
An event loop essentially manages and distributes the execution of different tasks. It registers them and handles distributing the flow of control between them.
Coroutines are special functions that work similarly to Python generators, on await they release the flow of control back to the event loop. A coroutine needs to be scheduled to run on the event loop, once scheduled coroutines are wrapped in Tasks which is a type of Future.
Futures are objects that represent the result of a task that may or may not have been executed. This result may be an exception.
event loop The event loop is the core of every asyncio application. Event loops run asynchronous tasks and callbacks, perform network IO operations, and run subprocesses.
get_event_loop已经废弃，应该使用get_running_loop
coroutine and future and task coroutines declared with the async/await syntax, is awaitable object. For an object to be awaitable, it must implement the special __await__() method that returns an iterable.
an object is an awaitable object if it can be used in an await expression. Many asyncio APIs are designed to accept awaitable objects. There are three main types of awaitable objects: coroutine, Task, and Future.
a coroutine function: an async def function; a coroutine object: an object returned by calling a coroutine function.
The asyncio.create_task() function to run coroutines concurrently as asyncio Tasks.
Tasks are used to schedule coroutines concurrently.
A Future is a special low-level awaitable object that represents an eventual result of an asynchronous operation.
Normally there is no need to create Future objects at the application level code.
Future objects in asyncio are needed to allow callback-based code to be used with async/await.(重要)
A good example of a low-level function that returns a Future object is loop.run_in_executor().
coroutine 简单示例：
import asyncio import time async def say_after(delay, what): await asyncio.sleep(delay) print(what) async def main(): print(f"started at {time.strftime('%X')}") await say_after(1, 'hello') await say_after(2, 'world') print(f"finished at {time.strftime('%X')}") asyncio.run(main()) future 和 coroutine 同时使用：
async def main(): await function_that_returns_a_future_object() # this is also valid: await asyncio.gather( function_that_returns_a_future_object(), some_python_coroutine() ) 可以通过注解将普通方法变成 awaitable object
from types import coroutine # NEW: this is an awaitable object! @coroutine def nice(): yield 常用的 api：
# coroutine asyncio.sleep(delay, result=None) # awaitable asyncio.gather(*aws, return_exceptions=False) # loop = asyncio.get_running_loop() # awaitable asyncio.shield(aw): Protect an awaitable object from being cancelled. # asyncio.timeout(delay)/timeout_at(when)/wait_for(aw, timeout): # example async def main(): async with asyncio.timeout(10): await long_running_task() runner runners are built on top of an event loop with the aim to simplify async code usage for common wide-spread scenarios.
asyncio.run(coro, *, debug=None) # class asyncio.Runner(*, debug=None, loop_factory=None) # Runner is a context manager that simplifies multiple async function calls in the same context async def main(): await asyncio.sleep(1) print('hello') with asyncio.Runner() as runner: runner.run(main()) future Future objects are used to bridge low-level callback-based code with high-level async/await code.
The rule of thumb is to never expose Future objects in user-facing APIs, and the recommended way to create a Future object is to call loop.create_future().
This way alternative event loop implementations can inject their own optimized implementations of a Future object.
f: asyncio.Future[R] = asyncio.get_running_loop().create_future() 实际项目中使用 future 的例子：
# 参考 aiohttp # TBD stream Streams are high-level async/await-ready primitives to work with network connections. Streams allow sending and receiving data without using callbacks or low-level protocols and transports.
stream 可以理解成 channel。主要包含 asyncio.open_connection asyncio.start_server asyncio.open_unix_connection asyncio.start_unix_server
多线程并发[相关内容] threading version import concurrent.futures import requests import threading import time thread_local = threading.local() def get_session(): if not hasattr(thread_local, "session"): thread_local.session = requests.Session() return thread_local.session def download_site(url): session = get_session() with session.get(url) as response: print(f"Read {len(response.content)} from {url}") def download_all_sites(sites): with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor: executor.map(download_site, sites) if __name__ == "__main__": sites = [ "https://www.jython.org", "http://olympus.realpython.org/dice", ] * 80 start_time = time.time() download_all_sites(sites) duration = time.time() - start_time print(f"Downloaded {len(sites)} in {duration} seconds") multiprocessing version import multiprocessing import time def cpu_bound(number): return sum(i * i for i in range(number)) def find_sums(numbers): with multiprocessing.Pool() as pool: pool.map(cpu_bound, numbers) if __name__ == "__main__": numbers = [5_000_000 + x for x in range(20)] start_time = time.time() find_sums(numbers) duration = time.time() - start_time print(f"Duration {duration} seconds") generator generator 示例：
>>> def multi_yield(): ... yield_str = "This will print the first string" ... yield yield_str ... yield_str = "This will print the second string" ... yield yield_str ... >>> multi_obj = multi_yield() >>> print(next(multi_obj)) This will print the first string >>> print(next(multi_obj)) This will print the second string >>> print(next(multi_obj)) Traceback (most recent call last): File "&lt;stdin>", line 1, in &lt;module> StopIteration def infinite_sequence(): num = 0 while True: yield num num += 1 参考 asyncio cheatsheet
pymotw.com Waiting for a Future
AsyncIO for the Working Python Developer
Some thoughts on asynchronous API design in a post-async/await world
a-tale-of-event-loops</content></entry><entry><title>Java 并发 5-虚拟线程（VirtualThread）</title><url>https://zhimoe.github.io/post/java-concurrency-5-virtualthread/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>并发</tag><tag>virtual thread</tag></tags><content type="html"> 回调和反应式编程都可以实现系统吞吐量有效提升，但是这两种编程模式存在阅读、编写、调试困难的问题，所以实际项目中还是以线程池为主。但是 java 的线程是平台线程，可以理解为并行线程数最多等于 CPU 核数 (macOS 查看核数sysctl hw.physicalcpu hw.logicalcpu)，并且存在线程内存占用大，上下文切换耗时高问题，所以在高并发请求中表现不如前面两种模式（spring reactive 和 vertx 模式并没有流行起来）。
JEP 444: Virtual Threads 主要目标在优化 IO 密集型任务时创建平台线程会消耗过多内存以及线程上下文切换耗时问题。
虚拟线程的优势：1. 和线程 API 兼容（大部分兼容）2. 降低应用内存使用，提升系统可用性，减少内存不足异常 OutOfMemoryError: unable to create new native thread 3. 提升代码可读性（相比 reactive 编程）。
本文是 VirtualThread 快速笔记，包含 API 使用、限制和在 Spring Boot 的实际使用以及与 Kotlin 协程的对比。
VirtualThread API 创建虚拟线程有以下方法
// 1 Runnable task = () -> { System.out.println("Hello Virtual Thread!"); }; Thread.startVirtualThread(task); // 2 Thread vThread = Thread.ofVirtual().start(task); // 3 Thread vThread = Thread.ofVirtual().unstarted(task); vThread.start(); // 4 Executor vExecutor = Executors.newVirtualThreadPerTaskExecutor(); vExecutor.execute(task); // unlimited virtual threads // 5 newThreadPerTaskExecutor but with VirtualThreadFactory ThreadFactory vThreadFactory = Thread.ofVirtual().name("vt-", 1).factory(); Executor vExecutor = Executors.newThreadPerTaskExecutor(vThreadFactory); vExecutor.execute(task); 虚拟线程相比平台线程，在创建耗时和内存占用具有很大优势。作为对比，同一台机器上创建 1W 个平台线程和虚拟线程。
类型 创建时间 内存占用 virtual thread 91 ms 4.4mb platform thread 998 ms 14.3gb limitations of VirtualThread 下面说的 carrier thread 就是执行虚拟线程的系统线程（platform thread）。
Avoid synchronized blocks/methods, use ReentrantLock.
Object monitor = new Object(); //... public void aMethodThatPinTheCarrierThread() throws Exception { // The virtual thread cannot be unmounted because it holds a lock, // so the carrier thread is blocked. // also called pinned thread or pinning synchronized(monitor) { Thread.sleep(1000); } } Avoid monopolization. 即避免 CPU 密集型的任务使用虚拟线程。如果一个 task 耗时非常长，那么该虚拟线程对应的 platform thread（即 the carrier thread）无法让出去执行其他任务，JVM 会创建新的线程。这种场景应该使用线程池技术。
Cation the carrier thread pool elasticity. 当前发生 1 或者 2 的情况时，JVM 会创建新的系统线程，容易导致系统内存被耗尽。
Avoid Object pooling, or reduce ThreadLocal Usage: 因为线程池数量有限制且线程会复用，所以创建比较耗时的对象会被池化以复用。但是虚拟线程不满足线程的这两个假设，池化对象并不能被复用。更糟糕的是，由于虚拟线程个数一般没有限制，每个虚拟线程都有 ThreadLocal 对象的话，可能耗尽 JVM 堆内存。JEP 429: Scoped Values will fix this.
关注线程安全，虚拟线程本质还是多线程编程，和多线程一样需要关注共享状态问题。
use VirtualThread in Spring Boot @SpringBootApplication @Slf4j public class VirtualthreadApplication { public static void main(String[] args) { SpringApplication.run(VirtualthreadApplication.class, args); } @Bean public TomcatProtocolHandlerCustomizer&lt;?> protocolHandlerVirtualThreadExecutorCustomizer() { return protocolHandler -> { log.info("Configuring " + protocolHandler + " to use VirtualThreadPerTaskExecutor"); protocolHandler.setExecutor(Executors.newVirtualThreadPerTaskExecutor()); }; } } use VirtualThread in Quarkus Using virtual threads in Quarkus is straightforward. You only need to use the @RunOnVirtualThread annotation. It indicates to Quarkus to invoke the annotated method on a virtual thread instead of a regular platform thread.
@Path("/greetings") public class VirtualThreadApp { @RestClient RemoteService service; @GET @RunOnVirtualThread public String process() { // Runs on a virtual thread because the // method uses the @RunOnVirtualThread annotation. // `service` is a rest client, it executes an I/O operation var response = service.greetings(); // Blocking, but this time, it // does neither block the carrier thread // nor the OS thread. // Only the virtual thread is blocked. return response.toUpperCase(); } } When Quarkus meets Virtual Threads)
internal and compare to kotlin coroutine A coroutine is an instance of suspendable computation. - Kotlin doc
和 kotlin 的协程类似，java 的虚拟线程同样不能自己执行，而是需要挂载到平台线程上面才能执行。下面是虚拟线程的生命周期：
/* * Virtual thread state and transitions: * * NEW -> STARTED // Thread.start * STARTED -> TERMINATED // failed to start * STARTED -> RUNNING // first run * * RUNNING -> PARKING // Thread attempts to park * PARKING -> PARKED // cont.yield successful, thread is parked * PARKING -> PINNED // cont.yield failed, thread is pinned * * PARKED -> RUNNABLE // unpark or interrupted * PINNED -> RUNNABLE // unpark or interrupted * * RUNNABLE -> RUNNING // continue execution * * RUNNING -> YIELDING // Thread.yield * YIELDING -> RUNNABLE // yield successful * YIELDING -> RUNNING // yield failed * * RUNNING -> TERMINATED // done */ private static final int NEW = 0; private static final int STARTED = 1; private static final int RUNNABLE = 2; // runnable-unmounted private static final int RUNNING = 3; // runnable-mounted private static final int PARKING = 4; private static final int PARKED = 5; // unmounted private static final int PINNED = 6; // mounted private static final int YIELDING = 7; // Thread.yield private static final int TERMINATED = 99; // final state 绿色表示虚拟线程挂载（mounted）在 平台线程（carrier thread）。蓝色表示 unmounted 并让出线程（去执行其他虚拟线程或者任务）。紫色表示 pinned。
核心代码解读参考Some Virtual Threads InternalsPermalink
参考 java 21 doc
JEP 444: Virtual Threads
Why are Thread.stop, Thread.suspend and Thread.resume Deprecated?
The Ultimate Guide to Java Virtual Threads
When Quarkus meets Virtual Threads)</content></entry><entry><title>Git 内部原理图解——对象、分支以及如何从零开始建仓库[翻译]</title><url>https://zhimoe.github.io/post/git-internal/</url><categories><category>编程</category></categories><tags><tag>git</tag><tag>翻译</tag></tags><content type="html"> 我们中的许多人每天都在使用 git，但是有多少人知道它的内部是怎么运作的呢？
例如我们使用 git commit 时发生了什么？提交（commit）与提交之间保存的是什么？两次提交之间难道只是文件的差异（diff）吗？如果是，这个差异是如何编码的？还是说每次提交都会保存一个当前仓库的完整快照（snapshot）呢？我们使用 git init 时到底发生了什么？
发现一篇非常精彩的 Git 内部原理文章Git 内部原理图解——对象、分支以及如何从零开始建仓库，中文翻译。文章作者甚至制作了配套讲解视频
Git 对象 git 内部有三种对象：
blob: 文件的内容，不包含 metadata 信息（创建时间，修改时间，作者等） tree: 一个目录，包含 blobs 或者 trees commit: a snapshot of the working tree，一个 tree 的快照 三种 git 对象都是通过 SHA-1 哈希值来唯一标识，如下图所示。每个 commit 对象中，对于 tree 里面那些没有改动的内容，继续通过原 hash 引用。
分支 A branch is just a named reference to a commit.
在上面的图片中，可以通过哈希值来引用一个 commit，但是不方便，所以分支用来引用 commit。可以理解为分支是一个指针，指向一个 commit，一般默认是指向最后一个 commit（也可以不是最后一个 commit）。
git 通过HEAD指针来确认当前所在分支。HEAD指针其实是.git目录下的一个HEAD文件，内容如下
> cat .git/HEAD ref: refs/heads/master git 如何记录变化 repository 是一系列 commit 的集合 working dir 是一个包含.git的目录 staging area 是存放那些被 git 跟踪但是没有 commit 的内容 三者的关系如下图所示
git 底层命令 (plumbing) 和上层命令 (porcelain) 区分 底层（plumbing）和 上层（porcelain）两类 git 命令会对你很有帮助。这两个术语的应用奇怪地来自于马桶（没错，就是🚽）。马桶通常是用陶瓷（porcelain）做的，它的基本结构是管道（plumbing，上水道和下水道）。
上层命令就是git init、git add、 git commit等，下面介绍一下底层命令。
# 创建git对象 >echo "git is awesome" | git hash-object --stdin -w # 查看.git目录的变化 >tree .git # 查看一个git object类型 -t type >git cat-file -t [obj-hash] # blob|tree|commit # 查看一个git object内容 -p pretty-print >git cat-file -p [obj-hash] # 添加object到staging area >git update-index --add --cacheinfo 100644 &lt;blob-hash> &lt;filename> # 创建一个tree对象 在tree对象中记录index内容 >git write-tree # 为tree对象创建一个commit对象 >git commit-tree &lt;tree-hash> -m &lt;commit message> git 实际上是使用 SHA-1 哈希值的前两个字符作为目录的名字，剩余字符用作 blob 所在文件的文件名。
.git 目录 一个.git目录至少包含三个内容
✔ tree .git .git ├── HEAD 当前指向分支，默认内容是 ref: refs/heads/main ├── objects git对象 blob、tree、commit的一种，其中对象的hash值前两个字符用于目录名，剩余的用于对象名 └── refs 分支和tag └── heads 当前working dir所有分支 默认分支不展示，只有多于一个分支才会展示 添加一个文件并 commit，然后创建一个新分支，再次检查.git 目录
✔ tree .git .git ├── HEAD ├── index ├── objects │ ├── 8d │ │ └── 0e41234f24b6da002d962a26c2495ea16a425f │ ├── af │ │ └── 7e0d93b83f49f601f5ef35edf5f9330fb4d7fd │ └── c8 │ └── bcfef1da123a980537a5fa4cf9b7c4f387d451 └── refs └── heads ├── main └── test_branch 7 directories, 7 files 上面删除了 logs 目录，index 文件保存的是 staging area 信息。打印 objects 目录下的三个文件
✔ git cat-file -p 8d0e41234f24b6da002d962a26c2495ea16a425f hello git :~/code/temp (main) ✔ git cat-file -p c8bcfef1da123a980537a5fa4cf9b7c4f387d451 100644 blob 8d0e41234f24b6da002d962a26c2495ea16a425f file.txt :~/code/temp (main) ✔ git cat-file -p af7e0d93b83f49f601f5ef35edf5f9330fb4d7fd tree c8bcfef1da123a980537a5fa4cf9b7c4f387d451 author zhimoe &lt;xx@gmail.com> 1691313901 +0800 committer zhimoe &lt;xx@gmail.com> 1691313901 +0800 first commit 可以看到分别是一个 blob 对象（file.txt)、一个 tree 对象和一个 commit 对象，后者依次引用前者。
参考 文章里面提到了很多 git 内部原理和概念：
Git 内部原理 - 底层命令与上层命令
Git 内部原理 - Git 对象</content></entry><entry><title>Rust Error Handling Notes</title><url>https://zhimoe.github.io/post/rust-error-handling-notes/</url><categories><category>编程</category></categories><tags><tag>rust</tag><tag>notes</tag></tags><content type="html"> 初学 rust 的时候，上手写代码总是遇到很多不一样的 rust 的Result类型，不同 crate 中的函数返回的Result&lt;T, E>的E都不一样，刚开始都是unwrap或者expect来处理。如果使用try!或者?的话总是编译不通过，还是对 Error 转换和处理不熟练。
Error 转换 在一个方法中，调用不同的函数会返回不同的 error 类型，需要你将这些类型转换成统一的自定义 error 类型再返回。你有以下几种途径
使用 map_err fn cook_pasta() -> Result&lt;Pasta, CookingError> { let water = boil_water().map_err(|_| CookingError::BoilWaterError)?; let pasta = add_pasta(&amp;water).map_err(|_| CookingError::AddPastaError)?; Ok(pasta) } // 通过 map_err 将 boil_water() 和 add_pasta(&amp;water) 返回的 error 都转换成了 CookingError 类型 使用 std::error::Error+From trait 定义自己的 Error 类型并实现 From trait。From trait 用于将 boil_water() 和 add_pasta(&amp;water) 的 error 转换成自定义的 Error。其实就是将map_err的逻辑移动到 From trait 中实现，使得方法调用处看起来更简洁。
pub enum CookingError{ BoilWaterError(String), AddPastaError } impl std::error::Error for CookingError{ // ... } impl Display for CookingError{ // ... } // 假设 boil_water 返回的 error 是 NoWaterError impl From&lt;NoWaterError> for CookingError { fn from(s: NoWaterError) -> Self { CookingError::BoilWaterError(s) } } // 假设 add_pasta 返回的 error 是 IoError impl From&lt;IoError> for CustomError { fn from(s: std::io::Error) -> Self { CookingError::AddPastaError(s) } } // 无需 map_err fn cook_pasta() -> Result&lt;Pasta, CookingError> { let water = boil_water()?; // 如果抛出 NoWaterError，自动转成 CookingError::BoilWaterError，下面同理 let pasta = add_pasta(&amp;water)?; Ok(pasta) } thiserror thiserror 可以看作是定义 Error 的一个工具，它只帮你生成一些定义 Error 的代码，别的什么都不做，相当纯粹。如果你在开发一个 crate，那么建议使用 thiserror。
fn render() -> Result&lt;String, std::io::Error> { let file = std::env::var("MARKDOWN")?; let source = read_to_string(file)?; Ok(source) } 上面的代码无法通过编译，因为env::var() 返回的是 std::env::VarError，而 read_to_string() 返回的是 std::io::Error。
为了满足 render 函数的签名，我们就需要将 env::VarError 和 io::Error 归一化为同一种错误类型。要实现这个目的有三种方式：
使用特征对象 Box&lt;dyn Error>。实际上就是错误类型泛化，失去了具体错误类型的信息，类似于在 Java 中使用Object类型。 自定义错误类型。比较繁琐，上面的例子在自定义 Error 类型后，需要分别为env::VarError 和 io::Error实现From trait 才行。 使用 thiserror。简化自定义错误类型的繁琐： use std::fs::read_to_string; fn main() -> Result&lt;(), MyError> { let html = render()?; println!("{}", html); Ok(()) } fn render() -> Result&lt;String, MyError> { let file = std::env::var("MARKDOWN")?; let source = read_to_string(file)?; Ok(source) } #[derive(thiserror::Error, Debug)] enum MyError { #[error("Environment variable not found")] EnvironmentVariableNotFound(#[from] std::env::VarError), #[error(transparent)] IOError(#[from] std::io::Error), } thiserror提供#[from] #[error]等注解简化错误类型自定义工作。
#[derive(Error)] { // Attributes available to this derive: #[backtrace] // #[error] #[from] #[source] } error(transparent) 表示转发底层 error 的相关信息，不修改 source 和 Display 相关方法。
anyhow anyhow 为你定义好了一个 Error 类型，基本可以看作是一个 Box ，同时还提供了一些如 context 等扩展功能，用起来更加无脑。如果你在开发一个业务 app，建议使用 anyhow 更加方便。
use anyhow::Result; fn main() -> Result&lt;()> { let html = render()?; println!("{}", html); Ok(()) } fn render() -> Result&lt;String> { let file = std::env::var("MARKDOWN")?; let source = read_to_string(file).with_context(|| format!("read string from {} failed", &amp;file))? Ok(source) } 可以看到这里使用的是Result&lt;String>,实际上这是anyhow的 type alias：pub type Result&lt;T, E = Error> = core::result::Result&lt;T, E>;
anyhow 还提供了with_context给 error 添加信息，看上去和 expect 类似，只不过那是 panic。
对于一个 app 服务，一些核心登录等功能可能也需要自定义 error 类型，这时可以将anyhow::Error作为其中一种 error 类型，即 thiserror + anyhow：
#[derive(Error, Debug)] pub enum AppError { ... #[error(transparent)] Other(#[from] anyhow::Error), // source and Display delegate to anyhow::Error } 参考：
rust by example - 处理多种错误类型
Option 和 Result 的一些方法
rust doc Error Handling
简谈 Rust 中的错误处理
细说 rust 错误处理
?在 Result 中的使用
蚂蚁集团 CeresDB 团队 | 关于 Rust 错误处理的思考</content></entry><entry><title>使用 OpenPyXL 读写 excel 大文件</title><url>https://zhimoe.github.io/post/python-read-large-excel-file/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> 使用 python OpenPyXL 读写 excel 大文件时，有专门的 read_only write-only 模式来提升读写效率。
openpyxl read_only mode from openpyxl import load_workbook wb = load_workbook(filename='large_file.xlsx', read_only=True) ws = wb['big_data'] # min_col&amp;max_col: 只处理 B 列，min_row=2: 从第二行开始，只读取值 col_index_B = openpyxl.utils.column_index_from_string('B') for cell_value in ws.iter_rows(min_row=2, min_col=col_index_B, max_col=col_index_B, values_only=True): print(cell_value) # Close the workbook after reading wb.close() 只读取第一行的错误 如果你的 excel 文件是通过第三方软件 (数据库客户端) 或者代码生成的，很容易遇到一个问题就是上面的ws.iter_rows或ws.rows遍历只会读取第一行。这是因为 read only 模式在 load_workbook 时只读取了文件的元信息，在遍历时也依赖 worksheet 的元信息，很多非 office 生成的 excel 没有正确设置元信息。你可以通过ws.calculate_dimension()检查 excel 行列信息，如果返回的是A1:A1等与实际大小不一致的情况，可以通过ws.reset_dimensions()来重置ws的max_row and max_column属性。
注意，ws.reset_dimensions()会读取整个文件，效率会降低到非 read_only 模式一样。
哎，这个坑花了一下午的排查，就是不认真看一下文档
openpyxl write_only mode 确保安装了lxml openpyxl两个库 使用 write_only 写大数据 from openpyxl import Workbook wb = Workbook(write_only=True) ws = wb.create_sheet() # now we'll fill it with 100 rows x 200 columns for irow in range(100): ws.append(['%d' % i for i in range(200)]) # save the file wb.save('new_big_file.xlsx') # doctest: +SKIP 官方文档 openpyxl Optimised Modes
openpyxl vs xlsxwriter 两个常用功能和性能上差别不大，部分样式设置有差别。 pandas 支持两个，可以通过 engine 参数切换。 使用 polars polars 是使用 rust 语言编写的 DataFrame 库，基于 arrow 格式，提供 rust、python、nodejs 三种编程语言接口。目前 polars 支持读取整个 excel 文件，但是写文件不行，只能通过转换成 pandas 的 df 再处理。本地测试一下 polars 读取整个 excel 文件，速度大约是 pandas 普通模式的两倍，内存使用是 pandas 的 2/3，这个性能和内存，感觉在 python 领域希望不大，看 rust 那边的发展了。
polars 的 API 一般是尽可能和 pandas 保持一致，所以使用起来也比较简单，遇到 API 缺失的，可以直接转换成 pandas 的 df 使用df.to_pandas()
import pandas as pd import polars as pl # read_excel 还需要 xlsx2csv lib df = pl.read_excel( "test.xlsx", sheet_id=1, xlsx2csv_options={"skip_empty_lines": True}, read_csv_options={"has_header": True}, ) print(f'{type(df)=}') # class 'polars.dataframe.frame.DataFrame' print(f'{df.shape=}') print(f'{df.head()=}') for cell in df['Courses']: print(f'{cell=}') polars 的输出格式比 pandas 的好看多了，使用了 box-drawing 相关的 unicode 字符打印表格，不过需要编程字体支持才能对齐。</content></entry><entry><title>Kotlin Coroutine</title><url>https://zhimoe.github.io/post/kotlin-coroutine/</url><categories><category>编程</category></categories><tags><tag>code</tag></tags><content type="html"> A coroutine is an instance of suspendable computation. 协程是可被挂起的计算的实例。换句话说协程是一个对象，这个对象保存着一段可以切换线程的任务 + 当前执行的状态两部分信息。
日常涉及协程的编码，主要是描述协程的任务和管理多个协程的生命周期、异常处理等。
Kotlin 使用堆栈帧管理要运行哪个函数以及所有局部变量。挂起协程时，系统会复制并保存当前的堆栈帧以供稍后使用。恢复时，会将堆栈帧从其保存位置复制回来，然后函数再次开始运行。即使代码可能看起来像普通的顺序阻塞请求，协程也能确保网络请求避免阻塞主线程。
问题场景 假设现在有个场景，根据用户 id 调用两个外部接口获取用户的姓名和公司名称，拼接后返回。
由于两个外部接口耗时较高，直接的思路就是使用两个线程来发送请求然后等待请求全部响应后拼接响应值。
方式 1 Java 的 Callable // 定义两个 Callable 来异步执行方法 Callable&lt;String> getUserName = () -> { // 模拟调用耗时方法获取用户名 Thread.sleep(1000); return "John"; }; Callable&lt;String> getCompany = () -> { // 模拟调用耗时方法获取公司名 Thread.sleep(1000); return "Doe Corp."; }; // 使用 ExecutorService 执行两个 Callable 并获取 Future ExecutorService executor = Executors.newFixedThreadPool(2); Future&lt;String> nameFuture = executor.submit(getUserName); Future&lt;String> companyFuture = executor.submit(getCompany); // 在主线程中获取结果并合并 String name = nameFuture.get(); String company = companyFuture.get(); String info = name + ", " + company; System.out.println(info); // John, Doe Corp. executor.shutdown(); 方式 2 Java 的 CompletableFuture // 定义两个异步操作 CompletableFuture&lt;String> getUserName = CompletableFuture.supplyAsync(() -> { Thread.sleep(1000); return "John"; }); CompletableFuture&lt;String> getCompany = CompletableFuture.supplyAsync(() -> { Thread.sleep(1000); return "Doe Corp."; }); // 使用 thenCombine 合并两个异步操作的结果 CompletableFuture&lt;String> combined = getUserName.thenCombine(getCompany, (name, company) -> name + ", " + company); // 获取最终结果 String result = combined.get(); System.out.println(result); // John, Doe Corp. 方式 3 Kotlin 的 Coroutine suspend fun getUserName(): String { delay(1000) // 模拟调用耗时方法 return "John" } suspend fun getCompany(): String { delay(1000) // 模拟调用耗时方法 return "Doe Corp." } fun main() { // 使用 async 并发调用两个 suspend 函数 val name = async { getUserName() } val company = async { getCompany() } // 使用 await 等待两个任务完成并获取结果 val nameResult = name.await() val companyResult = company.await() println("$nameResult, $companyResult") // John, Doe Corp. } // 或者使用 awaitAll suspend fun fetchTwoDocs() = // called on any Dispatcher (any thread, possibly Main) coroutineScope { val deferreds = listOf( // fetch two docs at the same time async { fetchDoc(1) }, // async returns a result for the first doc async { fetchDoc(2) } // async returns a result for the second doc ) deferreds.awaitAll() // use awaitAll to wait for both network requests // The awaitAll function should be preferred over map { it.await() } } suspend 关键字 suspend 函数是协程中的任务描述部分，suspend 关键字只是一个语法提示，告诉函数调用者该函数可能被切换线程，同理，也只能在 suspend 函数内部调用其他 suspend 函数，例如上面的 delay.
编译器和 IDE 根据 suspend 关键字来做一个语法提示与校验。
coroutine builder 利用 suspend fun 只能描述任务/函数，还需要使用 coroutine builder 来创建协程。
launch函数会创建一个协程返回一个Job不包含协程结果信息。async函数也创建一个协程返回Deferred-类似 Future 包含协程的未来计算结果。可以通过Deferred对象的 await 方法获取结果值。
所有的 coroutine builder 都是CoroutineScope的扩展函数，因为任何协程的生命周期都由对应的CoroutineScope对象管理。后面会看到有些方法会默认创建CoroutineScope对象。
val time = measureTimeMillis { val one = async { doSomethingUsefulOne() } val two = async { doSomethingUsefulTwo() } println("The answer is ${one.await() + two.await()}") } println("Completed in $time ms") start = CoroutineStart.LAZY的 async 协程只有在被调用start或者await时才会启动。
val time = measureTimeMillis { val one = async(start = CoroutineStart.LAZY) { doSomethingUsefulOne() } val two = async(start = CoroutineStart.LAZY) { doSomethingUsefulTwo() } one.start() // 不会阻塞，直接下一行执行 two.start() println("The answer is ${one.await() + two.await()}") //注意，如果没有上面两个 start 的话，那么这两个 await 是先后调用，导致两个协程顺序执行而不是异步 } println("Completed in $time ms") 结构化并发 还是上面方式 3 的两个 suspend 函数，如果其中一个方法异常，另一个方法也就没有必要继续执行了，在 Java 多线程目前难以做到（JEP 428 已经实现，参考 jdk19 的 StructuredTaskScope 类）,
而在 kotlin 协程中，只需要将两个线程放在同一个CoroutineScope即可实现：
fun main() = runBlocking&lt;Unit> { try { failedConcurrentSum() } catch(e: ArithmeticException) { println("Computation failed with ArithmeticException") } } suspend fun failedConcurrentSum(): Int = coroutineScope { //coroutineScope 函数创建一个新的 scope val one = async&lt;Int> { try { delay(Long.MAX_VALUE) // Emulates very long computation 42 } finally { println("First child was cancelled") } } val two = async&lt;Int> { println("Second child throws an exception") throw ArithmeticException() } one.await() + two.await() } 结构化并发是 kotlin 协程的核心优势之一，只有在你遇到复杂的场景时才能感受到结构化并发的威力与优雅。
Dispatcher CoroutineDispatcher 用来决定哪个（或几个）线程来运行该协程，可以将协程的执行限制在一个线程或者某个线程池，或者不限制。自带的几个 dispatcher:
Dispatchers.Main: A coroutine dispatcher that is confined to the Main thread operating with UI objects. Usually such dispatcher is single-threaded.
Dispatchers.Default: The default CoroutineDispatcher that is used by all standard builders like launch, async, etc. if no dispatcher nor any other ContinuationInterceptor is specified in their context.
Dispatchers.IO: The CoroutineDispatcher that is designed for offloading blocking IO tasks to a shared pool of threads.
Dispatchers.Unconfined: A coroutine dispatcher that is not confined to any specific thread. It executes initial continuation of the coroutine in the current call-frame and lets the coroutine resume in whatever thread that is used by the corresponding suspending function, without mandating any specific threading policy.
注意，即使是同一个函数内的不同行代码也不一定在同一个线程上面执行。
注意，Dispatcher 实现了 CoroutineContext 接口，所以会看到withContext(Dispatchers.IO) {}用法。
CoroutineContext 协程执行时总有带有一个 CoroutineContext，可以理解为就是一个元信息 Map，保存了 Job、coroutine dispatcher 等信息：
Job: 控制协程的生命周期。
CoroutineDispatcher: 将工作分派到适当的线程。
CoroutineName: 协程的名称，可用于调试。
CoroutineExceptionHandler: 处理未捕获的异常。
coroutine builder（async、launch）接收可选的 CoroutineContext 对象参数。CoroutineContext 最常见的用途就是指定协程的 dispatcher.
在 kotlin 中，CoroutineContext表示协程的 context，包含了多个元素。而CoroutineContext.Element表示 context 的一个元素。类似 map 和 kv 的关系。
但是CoroutineContext.Element继承了CoroutineContext，即一个 element 也是一个 context. 这种抽象可以简化一些 API 设计，例如，withContext 函数的参数类型是 CoroutineContext，但是我们常常会传入一个 CoroutineContext.Element 的实现类如 Dispatchers. 由于后者继承了前者，所以这样的使用方式也是被允许的。
由于实现了 plus 操作符方法，Job() + Dispatchers.Main也表示一个CoroutineContext。
CoroutineScope CoroutineScope 是协程最重要也是最难理解的点。CoroutineScope 给每个协程都定义了一个 scope，用来组织和管理一组协程的生命周期。
async 和 launch 也是 CoroutineScope 的扩展函数。很多教程里面直接调用 async 函数其实是使用了 GlobalScope 对象。
获取独立的 scope 对象最佳实践是通过 CoroutineScope() 和 MainScope() 工厂函数。一般不建议自己实现CoroutineScope接口。
suspend withContext和suspend coroutineScope函数也叫 scoping function.
withContext: Calls the specified suspending block with a given coroutine context, suspends until it completes, and returns the result.
coroutineScope: Creates a CoroutineScope and calls the specified suspend block with this scope. The provided scope inherits its coroutineContext from the outer scope, but overrides the context&rsquo;s Job.
withContext比coroutineScope多了一个 context:CoroutineContext 参数。
withContext几个使用示例
切换到 IO 上下文执行 IO 操作 suspend fun doSomething() { withContext(Dispatchers.IO) { // 在 IO 上下文中执行 IO 密集型代码 doNetworkRequest() } } 切换到主线程更新 UI suspend fun doSomething() { val result = withContext(Dispatchers.Default) { // 在默认上下文中进行计算 calculateResult() } withContext(Dispatchers.Main) { // 在主线程中更新 UI updateUI(result) } } 同时在两个不同上下文中执行任务 suspend fun doSomething() { val job1 = GlobalScope.launch(Dispatchers.IO) { // ... } val job2 = GlobalScope.launch(Dispatchers.Main) { // ... } withContext(Dispatchers.IO) { job1.join() // 等待 IO 上下文的任务结束 } withContext(Dispatchers.Main) { job2.join() // 等待主线程的任务结束 } } 取消上下文切换 suspend fun doSomething() { withContext(NonCancellable) { // 使用 NonCancellable 上下文 // 这里的代码块不会被取消 doSomething() } // ... } withContext vs async 看上去除了返回值不一样，两者的功能非常相似，都是接收 context 和 block 参数。
// async fun asyncDemo() = runBlocking { println("I am working") val opOne = async(IO) { operationOne() }.await() //注意 这里会阻塞等到 operationOne 返回才能继续下一行执行 val opTwo = async(IO) { operationTwo() }.await() println("Done working.") println("The multiplied result is ${opOne * opTwo}") } // withContext fun withContextDemo() = runBlocking { println("I am working") val opOne = withContext(IO) { operationOne() } val opTwo = withContext(IO) { operationTwo() } println("Done working.") println("The multiplied result is ${opOne * opTwo}") } 其实 async 是用于并发异步编程的，上面的 async 使用方式是不推荐的，因为在创建一个协程后立即调用 await 会阻塞当前线程，所以上面 opOne 和 opTwo 是顺序执行。
withContext 只是用于 Context 切换。上面的代码其实也可以写成
val result = withContext(IO) { operationOne() + operationTwo() } Flow fun simple(): Flow&lt;Int> = flow { // flow builder, no suspend keyword before fun for (i in 1..3) { delay(1000) // pretend we are doing something useful here emit(i) // emit next value } } // Collect the flow simple().collect { value -> println(value) } // We can replace delay with Thread.sleep in the body of simple's flow { ... } and see that the main thread is blocked in this case. Flow 只有在 collect 调用时才计算，也可以中途取消：
fun simple(): Flow&lt;Int> = flow { for (i in 1..3) { delay(100) println("Emitting $i") emit(i) } } fun main() = runBlocking&lt;Unit> { withTimeoutOrNull(250) { // Timeout after 250ms simple().collect { value -> println(value) } } println("Done") } // only collected 1 2 除了 flow 还有 flowOf(1,2,3) 、 coll.asFlow() 等 flow builder 函数。
operator: transform take collect toList/toSet first reduce fold - reduce with initial value
flowOn change the context of a flow:
fun simple(): Flow&lt;Int> = flow { for (i in 1..3) { Thread.sleep(100) // pretend we are computing it in CPU-consuming way log("Emitting $i") emit(i) // emit next value } }.flowOn(Dispatchers.Default) // RIGHT way to change context for CPU-consuming code in flow builder fun main() = runBlocking&lt;Unit> { simple().collect { value -> log("Collected $value") } } 如果 collect 函数比 flow 的 emit 还慢的话，可以使用buffer将 flow 提前生成
val time = measureTimeMillis { simple() // 100ms for each element .buffer() // buffer emissions, don't wait .collect { value -> delay(300) // pretend we are processing it for 300 ms println(value) } } println("Collected in $time ms") Channel val channel = Channel&lt;Int>() launch { for (x in 1..5) channel.send(x * x) channel.close() // we're done sending } // here we print received values using `for` loop (until the channel is closed) for (y in channel) println(y) println("Done!") 其他常用函数 runBlocking的签名actual fun &lt;T> runBlocking(context: CoroutineContext = EmptyCoroutineContext, block: suspend CoroutineScope.() -> T): T
看着和 withContext 非常相似，但是 withContext 是 suspend 函数，runBlocking 不是。
runBlocking 运行一个新的协程，并可中断地阻塞当前线程，直到协程完成。此函数不应在协程中使用。它旨在将常规的阻塞代码与挂起风格编写的库连接起来，以便在 main 函数和测试中使用。
前面说过，所有的协程都应该在一个 CoroutineScope 下面被管理。在runBlocking {}大括号内部写代码时 IDE 会提示你当前 this 的 type 是 CoroutineScope，这个 scope 实际是 runBlocking 方法内构建的 BlockingCoroutine 对象。
由于AbstractCoroutine接口继承了CoroutineScope，所以 BlockingCoroutine 也是一个 CoroutineScope 实例。
kotlin.system.measureTimeMillis Executes the given block and returns elapsed time in milliseconds.
delay Delays coroutine for a given time without blocking a thread and resumes it after a specified time.
suspend fun yield() Yields the thread (or thread pool) of the current coroutine dispatcher to other coroutines on the same dispatcher to run if possible.
Coroutine.start 函数 public fun &lt;R> start(start: CoroutineStart, receiver: R, block: suspend R.() -> T) { start(block, receiver, this) //这里实际调用的是 CoroutineStart.invoke 方法。this 指的是当前 coroutine }</content></entry><entry><title>在 macOS 通过 SSH 访问 Windows 的 WSL2 Ubuntu</title><url>https://zhimoe.github.io/post/access-into-wsl2-ubuntu-from-macos/</url><categories><category>编程</category></categories><tags><tag>macOS</tag><tag>WSL2</tag></tags><content type="html"> 配置 Windows 和 WSL2，使得能通过其他电脑远程 SSH 到 WSL2 Ubuntu。
背景 之前的电脑配置是 LinuxMint 台式机 + M1 macbook 笔记本。使用 Linux 主要原因是命令行和 Docker. 最近由于二十大，工作 VPN 在 macOS 不让用，只能将台式机安装上 Win10，发现 docker 在 WSL2 运行非常丝滑，这样正好可以当作 macbook 的 Docker 服务器。切换到 Windows 还有一个原因就是，Linux 的桌面真的不行，最近三年各种版本的桌面使用一圈，Budgie，Gnome，Cinnamon，Xfce 这些桌面总是偶尔界面失去响应，KDE 用的不多，卡顿没遇到但是启动总是慢半秒。Win10 除了没有 Bash/Zsh，中文字体垃圾点，其他的都完胜 Linux。
下面的教程主要参考：Configuring SSH access into WSL 1 and WSL 2
1 Win10 安装 WSL2 Ubuntu 注意，是安装 WSL2，方法参考这个enable-virtual-machine-feature：
以管理员身份打开 PowerShell（“开始”菜单 >“PowerShell” >单击右键 >“以管理员身份运行”），然后输入以下命令：
dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart； 安装 &ldquo;适用于 x64 计算机的 WSL2 Linux 内核更新包&rdquo;； 将 WSL 设置默认 version 2，in PowerShell: wsl --set-default-version 2； 安装 Ubuntu，in PowerShell: wsl --install -d Ubuntu-22.04。 更多参考
2 配置 SSH server（在 Ubuntu 执行） 进入 Ubuntu
#修改软件源 sudo sed -i "s@http://.*archive.ubuntu.com@https://mirrors.tuna.tsinghua.edu.cn@g" /etc/apt/sources.list sudo sed -i "s@http://.*security.ubuntu.com@https://mirrors.tuna.tsinghua.edu.cn@g" /etc/apt/sources.list sudo apt update &amp;&amp; sudo apt upgrade -y 安装配置 ssh 服务
sudo apt install openssh-server sudo vim /etc/ssh/sshd_config # 修改下面几个配置 # Port 2222 # AddressFamily any # ListenAddress 0.0.0.0 # PasswordAuthentication yes # 如果启动遇到这个错误 请执行下面命令: sshd: no hostkeys available -- exiting sudo ssh-keygen -A # 启动ssh服务 sudo /usr/sbin/service ssh start 3 Win10 防火墙设置 打开控制面板\系统和安全\Windows Defender 防火墙。
最左边有高级设置 右键点击入站规则 新建入站规则 点击端口，特定端口设置 2222 然后命名之后一路下一步就行 或者通过 shell 设置，以管理员身份打开 PowerShell:
New-NetFirewallRule -Name sshd -DisplayName 'sshd for WSL' -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 2222 4 本地验证 SSH 访问 Ubuntu 打开 Windows Terminal，尝试 ssh 访问 Ubuntu
ssh -p 2222 wsluser@localhost 如果连接上说明 ssh 配置已经完成。
5 Ubuntu ssh 服务开机自动启动 WSL2 Ubuntu 的 ssh 服务不是跟着 Win10 开机自动启动的。在 Win10 的%USERPROFILE%目录下面新建文件sshd.bat
rem sshd.bat @echo off setlocal C:\Windows\System32\bash.exe -c "sudo /usr/sbin/service ssh start" rem C:\Windows\System32\wsl.exe -e "sudo /usr/sbin/service ssh start" endlocal 注意上面 bash.exe -c 和 wsl.exe -e 两个功能是一样的。bash 后面不维护了，wsl 是官方推荐命令，但是 bash 有输出。
接下来把上面的脚本配置成开机自动执行：
按下 Win 键，搜索“任务计划程序”，右边点击“创建任务”。 常规：设置任务名字“Start WSL SSH”，勾选上“使用最高权限运行”（这是给后面网卡映射命令的权限） 触发器：新建，选择“启动时” 操作：选择上面的 sshd.bat 脚本文件。 保存，重启电脑，打开 Terminal，重新试试ssh -p 2222 wsluser@localhost
6 网卡映射 到目前为止，在 Win10 本地已经可以在开机后直接通过 SSH 访问 Ubuntu 了，但是你如果在局域网内的其他电脑访问，还是连不上的。这是因为 WSL2 是个虚拟机。
WSL 2 is a well-hidden virtual machine, but it is still a virtual machine—and the consequences of this design are leaky. The network interface we see within WSL is a virtual interface that does not match the physical interface that Windows manages. Windows does a good job at hiding this fact when operating directly on the local machine (e.g. you can SSH into WSL from localhost and it will work), but attempts to reach WSL from a separate machine will fail.
设置开机自动执行网卡映射命令，将上面的 sshd.bat 文件改成如下：
rem sshd.bat @echo off setlocal C:\Windows\System32\bash.exe -c "sudo /usr/sbin/service ssh start" rem C:\Windows\System32\wsl.exe -e "sudo /usr/sbin/service ssh start" C:\Windows\System32\netsh.exe interface portproxy delete v4tov4 listenport=2222 listenaddress=0.0.0.0 protocol=tcp for /f %%i in ('wsl hostname -I') do set IP=%%i C:\Windows\System32\netsh.exe interface portproxy add v4tov4 listenport=2222 listenaddress=0.0.0.0 connectport=2222 connectaddress=%IP% endlocal 保存后启动，在 macbook 试试，成功。</content></entry><entry><title>云原生 Java 开发框架 Quarkus 学习笔记</title><url>https://zhimoe.github.io/post/java-quarkus-notes/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>quarkus</tag></tags><content type="html"> 什么是 MicroProfile MicroProfile 是一个微服务的平台定义，目标是针对微服务架构优化企业 Java 开发。由于 JavaEE 的标准更新越来越慢，跟不上 Web 技术与 K8S 的发展，于是一组供应商（包括 Tomitribe）决定创建 MicroProfile, 这是一个优化的微服务架构平台，在 2016 年加入 Eclipse 基金会。
MicroProfile是一组规范，包含如 OpenTracing、OpenAPI、RestClient、Config、FaultTolerance、CDI 等一组标准。当前最新标准是 5.0. 各大 Java 厂商有很多实现，最有名的就是红帽的 Quarkus, 其他实现有 Open Liberty 和 Payara Enterprise.
注意 SpringBoot 不是 MicroProfile 规范实现，Boot 是独立于 MicroProfile 和 JavaEE 规范的，但是功能上大同小异，Quarkus 也提供了 Spring 注解的支持。
Quarkus Quarkus是一个 MicroProfile 规范的实现，专门为云时代打造。有：启动时间短，内存占用小，支持 native 编译（部署在 GraalVM), 支持 K8S 特性 (不仅是部署，还包括自动生成 K8S 资源文件等) 优势。本质上是精选了一些优质组件，通过扩展 (extensions) 模式提供快速业务开发的能力。
创建项目 Quarkus 提供了强大 Cli、Maven 插件、Gradle 插件支持。以下主要使用 maven.
mvn io.quarkus.platform:quarkus-maven-plugin:2.10.2.Final:create \ -DprojectGroupId=moe.zhi \ -DprojectArtifactId=quarkus-demo \ -Dextensions="resteasy-reactive-jackson" cd quarkus-demo 打开 IDE，可以看到自动包含 pom.xml 和 Dockerfile(分为不同目标部署环境，每个文件提供了详细使用说明).项目直接运行就是一个 hello world api 服务。如果需要增加一个扩展，通过 maven add-extension 插件的 extensions 参数添加，插件自动会修改 pom.xml 文件，添加对应的 maven lib.
# add Caffeine cache support mvn quarkus:add-extension -Dextensions="cache" quarkus 目前已经有上百个 extension, 可以通过mvn quarkus:list-extensions查看所有。也可以在quarkus doc查看。
注解 Quarkus 的注解符合 Java CDI 规范。DI 部分的注解基本可以和 Spring 的做一一对上。
//Spring -> CDI/MicroProfile @Autowired -> @Inject @Qualifier -> @Named @Value -> @ConfigProperty(ConfigMap 用于分组配置 key 的公共前缀，ConfigProperties 已经废弃) @Component -> @Singleton @Configuration -> @ApplicationScoped @Bean -> @Produces 配置 和 Spring 类似，Quarkus 使用一个 application.properties 文件配置属性。
使用@ConfigProperty 读取配置属性。如果属性是 list, 使用逗号分隔。
配置文件中都是 String 和 Int, MicroProfile Configuration 自带了一系列的转换器：
boolean: true、1、YES、Y、ON为true, 其他为false Byte,Short,Integer,Long,Float,Double,Character,Class(Class.forName)自动转换 目标类型有 public static T of(String) 或者public static T valueOf(String) 方法 目标类型有 public static T parse(CharSequence) 方法 目标类型有 public constructor(String)构造函数 自定义转换器参考org.eclipse.microprofile.config.spi.Converter
配置属性的验证 需要quarkus-hibernate-validator扩展，然后使用@Max、@Digits、@Email、@NotNull 和@NotBlank 等校验注解。
自定义校验器需要实现javax.validation.ConstraintValidator接口。
自定义配置源 参考org.eclipse.microprofile.config.spi.ConfigSource
获取环境变量 使用@Inject Config config 的 getPropertyNames() 获得所有属性。
属性来源优先级 Profile Quarkus 自带三个 profile 环境:dev, test, prod.
设置不同的 profile 属性使用%{profile}.config.key=value.例如
%dev.quarkus.http.port=8181 logging level Quarkus 内部使用 JBoss Logging, 如果需要使用 Slf4j，添加依赖：
&lt;dependency> &lt;groupId>org.jboss.slf4j&lt;/groupId> &lt;artifactId>slf4j-jboss-logmanager&lt;/artifactId> &lt;/dependency> quarkus.log.level=DEBUG quarkus.log.file.enable=true # 调整package下面的log level, 注意双引号 quarkus.log.category."io.undertow.request.security".level=TRACE 支持集中管理日志，参考 logging-json 扩展。
quarkus 生命周期事件 注入io.quarkus.runtime.StartupEvent和io.quarkus.runtime.ShutdownEvent事件即可响应。
@ApplicationScoped @Slf4j public class AppEventListener { void onStart(@Observes StartupEvent event) { log.info("#### app started..."); } void onShutdown(@Observes ShutdownEvent event) { log.info("### app shutdown..."); } } 拦截器 首先通过@javax.interceptor.InterceptorBinding创建一个拦截器注解。
@Inherited @InterceptorBinding @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD, ElementType.TYPE}) public @interface Logit { } 然后通过@javax.init.AroundInvoke和@javax.init.AroundConstruct两个具有相应拦截绑定功能的拦截器。
@Logit @Interceptor public class LogitInterceptor { @AroundInvoke public Object invoke(InvocationContext ctx) throws Exception { System.out.println("#### interceptor" + ctx.getMethod().getName()); return ctx.proceed(); } } Restful 服务 Quarkus 实现了 JAX-RS 规范，支持@GET,@POST, @PUT 等 http 动词注解。默认设置下，quarkus 使用 RESTEasy 和 Vertx 框架，而不是 Servlet 规范。如果需要使用 Servlet, 则增加quarkus-undertow扩展，这是 JBOSS（wildfly) 的 Servlet 服务器的引擎。
通过@Path注解匹配 URI.
通过@Context UriInfo uriInfo获取 url 内容。
通过@QueryParam("p")参数注解获取 QueryString 中的参数。
其他参数：表单参数 (@FormParam)、矩阵参数 (@MatrixParam) 或 cookie 值 (@CookieParam).
此外，使用@Context注解，你还可以注入其他与 JAX-RS 相关的元素，如javax.ws.rs.core.SecurityContext、
javax.ws.rs.sse.SseEventSink或javax.ws.rs.sse.Sse.
json-p(processing) 和 json-b(binding) 是 JavaEE 规范。如果 API 需要返回 json，需要增加quarkus-testeasy-jsonb扩展。
如果 data model 的字段与 json 字段不同名，需要使用javax.json.bind.annotation.JsonbProperty注解绑定。
class Stu { @Jsonbproperty("first-name") String firstNm; } 如果使用 jackson, 则需要quarkus-resteasy-jackon扩展，使用com.fasterxml.jackson.databind.ObjectMapper做 json 转换。
Rest 客户端 使用 rest 客户端调用外部服务接口，需要增加"rest-client"和"resteasy-jsonb"扩展。
private Client rest=ClientBuilder.newClient(); public String getTime(){ Response resp=rest.target("http://worldclockapi.com") .path("/api/json/{timezone}/now") .resolveTemplate("timezone","GMT") .request(MediaType.APPLICATION_JSON) .get(Response.class); return resp.readEntity(String.class); } 持久化 Agroal 是 Quarkus 中首选的数据源和连接池实现，与安全、事务管 理和健康指标进行了集成。虽然它是一个扩展程序，但如果你正在使 用 Hibernate ORM 或 Panache,Agroal 扩展会被顺带加载进来。之后你 还需要一个数据库驱动扩展，目前，H2、PostgreSQL、MariaDB、MySQL、Microsoft SQL Server 和 Derby 都有支持的扩展，可以通过 Maven add-extension 添加正确的数据库驱动扩展
如果你想要使用响应式编程，也可以使用 Vert.x reactive drivers.
# 配置多个数据源的话在 quarkus.datasource后面跟着一个自定义的ds name即可.例如 # configure your datasource quarkus.datasource.url = jdbc:postgresql://localhost:5432/library-database quarkus.datasource.driver = org.postgresql.Driver quarkus.datasource.username = melvil quarkus.datasource.password = dewey # 配置第二个数据源 指定ds name 为 orders quarkus.datasource.orders.url = jdbc:postgresql://localhost:5432/library-database quarkus.datasource.orders.driver = org.postgresql.Driver quarkus.datasource.orders.username = melvil quarkus.datasource.orders.password = dewey 非默认数据源需要使用@DataSource(&ldquo;ds name&rdquo;) 指定：
import javax.inject.Inject; @Inject DataSource("orders") AgroalDatasource ordersDs; 容错 需要添加quarkus-smallrye-fault-tolerance扩展。
回退与重试：@org.eclipse.microprofile.faulttolerance.Retry, @org.eclipse.microprofile.faulttolerance.Fallback. Fallback 的 handler 需要实现org.eclipse.micropro file.faulttolerance.FallbackHandler接口
超时： @org.eclipse.microprofile.faultttoler ance.Timeout.
过载保护 (并发请求个数)： @org.eclipse.microprofile.faultttolerance.Bulkhead.
压测 >siege -r 1 -c 4 -v http:localhost:8080/hello/bulkhead
断路器： @CircuitBreaker
@CircuitBreaker(requestVolumeThreshold = 4, // &lt;1> 滚动窗口 failureRatio = 0.75, // &lt;2>断路阈值 delay = 2000) // &lt;3> 重新打开时长 ms 如果使用@Fallback, 且 CircuitBreakerOpenException 被抛出，回 退逻辑将被执行。 如果使用@Retry, 每次重试都由断路器处理，并记录成功或失 败。 如果使用@Bulkhead, 则在试图进入 bulkhead 之前检查断路器。 可观察 health health：添加了quarkus-smallrye-health自动注册 q/health/live和q/health/ready两个探针 自定义：实现一个 org.eclipse.microprofile.health.HealthCheck接口，并加上@org.eclipse.microprofile.health.Liveness
或@org.eclipse.microprofile.health.Readiness注解 指标 添加quarkus-smallrye-metrics扩展，自动暴露q/metrics端点。 自定义指标： @Counted @Gauge @Metered @Timed OpenTelemetry Quarkus Opentelemetry configuration
Reactive 编程 Quarkus 支持两种响应式编程方式：
Reactive Programming with Mutiny Coroutines with Kotlin Quarkus 支持混合命令式与响应式编程，所以不需要刻意将所有代码改造成响应式就可以享受到高性能。更多见：
unification-of-imperative-and-reactive
class loading in quarkus production 模式和 native image 模式下，quarkus 的类加载器都是 system ClassLoader(native 模式不支持多 ClassLoaders)
所有 quarkus app 都是通过QuarkusBootstrap class 创建。这个类解析 app 所有的相关依赖 (编译或运行时的依赖),最终得到一个CuratedApplication class, 这个类包含这个 app 所有的类加载信息。
CuratedApplication 可以用于创建一个AugmentAction 实例，这个实例用于创建 app 并启动/重启。
在 dev 模式下，quarkus 通过 classloader 支持热加载，在 prod 模式下，只有 system ClassLoader.
除了热加载，在 dev 模式下，提供了q/dev DEV UI，支持配置应用，查看缓存，查看类信息，查看/执行定时任务，查看健康状态，执行数据脚本迁移等等。</content></entry><entry><title>Git 的 detatched Head 模式和解决问题方法</title><url>https://zhimoe.github.io/post/git-detatched-head/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>git</tag></tags><content type="html"> 有时候 commit 完代码后git push会遇到下面的错误
To push the history leading to the current (detached HEAD) 错误提示说当前 HEAD 没有指向任何分支，但是你记得明明有指向一个分支的
复现问题 1、假设你当前在 master 分支，且有两次提交
Prj on  master ❯ git log --oneline --graph --decorate * 314c9df (HEAD -> master) 2nd commit * ae15845 initial commit 2、切回到第一次提交
Prj on  master ❯ git checkout ae15845 Note: switching to 'ae15845'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -c with the switch command. Example: git switch -c &lt;new-branch-name> Or undo this operation with: git switch - Turn off this advice by setting config variable advice.detachedHead to false HEAD is now at ae15845 initial commit git 直接会提示你当前 HEAD 已经 detached。这是因为当 HEAD 离开当前分支（master）的末端 commit 时，Git 会默认你想要离开当前分支，但是 Git 不会自动创建一个新分支（因为没有提供分支名称）。
所以 HEAD 变成没有指向任何分支的窘境，即使你再次回到刚才那个分支的末端 commit，还是处于 detached 状态。
3、切回 master 分支的末端 commit 并提交新内容
Prj (ae15845) # 注意 zsh配置这里展示的是当前HEAD，下面也给了提示 ❯ git checkout 314c9df Previous HEAD position was ae15845 initial commit HEAD is now at 314c9df 2nd commit # 提交点新东西 Prj (314c9df) ❯ echo "3nd file " > 3.txt Prj (314c9df) [?] ❯ git add . &amp;&amp; git commit -m "3nd commit" [detached HEAD 09fb4a5] 3nd commit 1 file changed, 1 insertion(+) create mode 100644 3.txt Prj (09fb4a5) ❯ git log --oneline --graph --decorate * 09fb4a5 (HEAD) 3nd commit * 314c9df (master) 2nd commit * ae15845 initial commit 可以看到此时 HEAD 和 master 分支还是分离的。
真实场景复现 上面复现的方式很刻意，毕竟极少情况你会 checkout 一个具体的 commit 而不手动创建一个分支。日常工作中最可能遇到这个 detached HEAD 的场景是你使用Git submodule的时候。
敢说每个新手在使用 submodule 都会碰到 detached HEAD 问题。
原因是你的 submodule 没有记录正确的分支，即你在使用git submodule add时没有指定-b &lt;branch>参数。
git submodule add -b main https://github.com/zhimoe/hugo-theme-next.git themes/next 或者直接在项目根目录下的.gitmodules文件中加上一行
branch = main # or branch = master 解决方法 1、预防的方法就是没有 commit 的时候及时切回一个具体分支git checkout master
2、如果已经提交了的话，给当前游离的 commit 创建一个分支，切换到该分支
Prj (09fb4a5) ❯ git branch oops 09fb4a5 Prj (09fb4a5) ❯ git log --oneline --graph --decorate * 09fb4a5 (HEAD, oops) 3nd commit * 314c9df (master) 2nd commit * ae15845 initial commit Prj (09fb4a5) ❯ git checkout oops Switched to branch 'oops' 接着使用 rebase 将 oops 分支接在 master 分支的末尾 commit 之后
Prj on  oops ❯ git rebase master Current branch oops is up to date. Prj on  oops ❯ git log --oneline --graph --decorate * 09fb4a5 (HEAD -> oops) 3nd commit * 314c9df (master) 2nd commit * ae15845 initial commit Prj on  oops ❯ git checkout master &amp;&amp; git merge oops Switched to branch 'master' Updating 314c9df..09fb4a5 Fast-forward 3.txt | 1 + 1 file changed, 1 insertion(+) create mode 100644 3.txt Prj on  master ❯ git log --oneline --graph --decorate * 09fb4a5 (HEAD -> master, oops) 3nd commit * 314c9df 2nd commit * ae15845 initial commit 最后删除 oops 分支：git branch -d oops.
参考一个完美的 GitFlow 模型</content></entry><entry><title>Scala3 缩进语法总结表</title><url>https://zhimoe.github.io/post/scala3-indent-syntax/</url><categories><category>编程</category></categories><tags><tag>scala3</tag><tag>cheatsheet</tag></tags><content type="html"> Scala 3 在语法上面新增了一种 Python 的缩进格式，两种格式都可以使用。但是目前部分情况还是需要使用括号。
个人对新语法是支持的。缩进可以极大地提供代码的可读性和整洁，最大的体会就是 SparkStreaming 的 rdd 处理代码，新手容易写出十几个}括号嵌套代码。
当然缺点是缩进不利于代码复制和格式化。
下面是书本上关于 Scala3 的语法对比。注意，两个语法格式都是支持的。for 和 if 去掉小括号真的是太棒了。</content></entry><entry><title>Python Tips for Impatient Dev</title><url>https://zhimoe.github.io/post/python-tips-for-impatient-dev/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> Python tricks f-string 的妙用 py3.6 开始，推荐使用 f-string，不要使用 %s或者 "".format().如果接收用户输入，使用 Template 做安全校验。
在 python f-string 中可以通过变量或者表达式后面加=实现打印变量名或者表达式：
print(f'{v=}') # 等价 print(f'v={v}') print(f'{(len(arr),v)=}') 参考：调式时icecream比print log更好。
python 注解 Python 对注解所做的唯一的事情，就是将它们存储在函数的 annotations 属性中
>>> def foo(a: 'x', b: 5 + 6, c: list) -> max(2, 9): ... >>> foo.__annotations__ {'a': 'x', 'b': 11, 'c': &lt;class 'list'>, 'return': 9} 单例模式 参考creating-a-singleton-in-python
,建议是 metaclass 模式，里面很多回答是错误的。
# 下面其实不是单例，因为可以再次调用 Foo(), 只是一个全局变量 class Foo(object): pass some_global_variable = Foo() # 利用缓存可以实现单例模式，前提是__init__没有参数，因为 cache 是根据参数列表生成缓存的 key from functools import cache @cache class CustomClass(object): def __init__(self): #这里不能有参数，因为会导致 key 不一样 self.instance = ... # 另外一种方法是 metaclass, 和上面的@cache 原理近似，只不过一个是外部缓存，一个是 mataclass 内缓存，同理，__init__不能有参数 class Singleton(type): _instances = {} def __call__(cls, *args, **kwargs): if cls not in cls._instances: cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs) return cls._instances[cls] class ESClient(metaclass=Singleton): pass assert id(ESClient()) == id(ESClient()) # 一种取巧的方式 def _singleton(c): c() @_singleton class ESClient(object): def __init__(self): self.client = Elasticsearch([{'host': es_config.host, 'port': es_config.port}]) def get_instance(self): """get es client instance""" return self.client # 原理是通过装饰器改写后得到的 wat 实际是一个对象，不是一个 class: wat = _singleton(wat) # 这样就阻止你通过 another_instance = wat() 获取新实例 # 当然你可以通过 another_instance = wat.__class__() 创建新的实例 # 当然这种方式也要求__init__不能有其他参数，对于无参的单例模式其实挺巧妙 # 补充阅读 python es client 是否应该全局变量： # https://elasticsearch-py.readthedocs.io/en/7.x/#thread-safety 枚举类 Enum 略去 value 方法 假设你想要获得下面Color的#000, 需要使用Color.WHITE.value。但是可以通过StrEnum省去这个.value
class Color(Enum): WHITE = "#000" # tips from enum import StrEnum class Directions(StrEnum): NORTH = 'north', SOUTH = 'south', # notice the trailing comma, it's ok and recommend print(Directions.NORTH) # no need .value # 缺点：StrEnum 成员不能有 int 类型 使用 with 管理需要关闭的资源，无需多个 with with open(file_path, 'w') as file, get_connection(config) as conn: file.write('Hello, World!') 简化 if 的一些技巧 if variable == a or variable == b: res = do_something(variable) # better if variable in {a, b}: res = do_something(variable) if 'a' in v or 'b' in v or 'c' in v: pass # better if any(char in v for char in ('a', 'b', 'c')): pass if b > 10: a = 0 else: a = 5 # better a = 0 if b > 10 else 5 if data: lst = data else: lst = [0, 0, 0] # better, only use this when data type is collection, # cuz if data is int, then data=0 will make lst = [0,0,0] lst = data or [0, 0, 0] Instead of asking for permission, ask for forgiveness Python 的异常比较轻量，所以一般推荐的写法是与其提前判断条件是否满足，不如在 try catch 中处理异常
try: with open(filename, 'w') as file: file.write('Hello, World!') except FileNotFoundError: print('File does not exist.') except PermissionError: print('You dont have write permission.') except OSError as exc: print(f'An OSError has occurred:\n{exc}') isinstance isinstance 可以一次判断多个 Class 类型：
# no need or conditions isinstance(foo, (Class1, Class2, ...)) 海象运算符 (walrus operator) python 3.8 引入海象运算符，解决一个场景：获取一个值，检查它是否为非零，然后使用它。在 python3.8 之前需要三行：
count = fresh_fruit.get('lemon', 0) if count: make_lemonade(count) else: out_of_stock() 上面的代码会引入一个看上去非常重要的变量count，但实际情况并非如此，count 只在一个分支里面使用到。使用海象运算符可以解决这个问题。
if count := fresh_fruit.get('lemon', 0): make_lemonade(count) else: out_of_stock() 虽然只是减少了一行代码，但是可读性提升了巨大，可以清楚地知道 count 只有在 if 成立时才使用到。甚至还可以在 if 中判断
if (count := fresh_fruit.get('apple', 0)) >= 4: make_cider(count) else: out_of_stock() 另一个常见的场景是 do-while，例如处理一个分页请求，直到请求返回为 None，由于 python 不支持 do-while 语法，一般有两种写法：
page_data = get_page() while page_data: process_page(page_data) page_data = get_page() # 方法 2 loop-and-a-half while True: page_data = get_page() if not page_data: break process_page(page_data) 海象运算符完美解决了这个问题：
while page_data := get_page(): process_page(page_data) 读写文件时也经常遇到这个场景：
fp = open("test.txt", "r") while line := fp.readline(): print(line.strip()) 多进程的使用 from multiprocessing import Pool requests = [req1, req2] with Pool as p: results = p.map(process_request, requests) python 的 dict 中关于 equal 和 hash 计算方式会有意外的效果 ['no', 'yes'][True] # output? {True: 'yes', 1: 'no', 1.0: 'maybe'} # output? “布尔类型是整数类型的子类型，布尔值在几乎所有环境中的行为都类似于值 0 和 1，但在转换为字符串时，分别得到的是字符串 False
或 True.”
&ndash; The Standard Type Hierarchy
由于 True,1, 1.0 的__eq__和__hash__都一样，所以出现了神奇的结果。
(1) != (1,) 第一个是 int，第二个是 tuple 避免可变的默认参数，例如： def fun(count=[]): count.append(2) #这里 count 两次调用如果都使用默认参数的话，则是同一个数组，非常危险！ return count fun() #[2] fun() #[2,2] 同理，需要避免在 tuple 中放入可变类型元素，例如 list。
flat seq: str, bytes, bytesarray, memeoryview, array.array container seq: list, tuple, collections.deque immutable: bytes, str, tuple mutable: list dict set bytesarray staticmethod classmethod staticmethod 和 classmethod 都可以通过 Cls.m() 或 instance.m() 方式访问，都可以被继承，都可以访问全局变量。区别是
classmethod 访问的 class 变量信息会自动在 Derive 子类中改变，而 staticmethod 因为缺少第一个 cls 参数，所以访问的全局变量始终是父类的变量。
staticmethod 可以理解为 Java 的 StringUtils 类，只是和 Cls 放在一起方便代码阅读和组织。
classmethod 则是可以通过 cls 参数访问到当前类信息的。
容器方法 合并字典 d1.update(d2) # 遍历 d2，更新到 d1 d = dict(**profile, **ext_info) #解构重新创建 dict，右边的优先级高 d = dict(profile.items() | ext_info.items()) #同理 d = d1 | d2 # 新语法 {k: v for d in [profile, ext_info] for k, v in d.items()} # 推导式 py3.6 开始 dict 默认插入有序，如果只是希望插入有序则无需使用 OrderDict
dict get and pop d.get(k,default) d.setdefault(k,default) d.pop(k) #删除不存在的键时，使用 del d[k] 有异常抛出，pop 则不会 自定义 dict 自定义自己的 dict 不能继承 dict，而是 collections.abc.MutableMapping, 因为自带的 list 和 dict 有一些特殊行为无法覆盖
sort dict by key: print(sorted(dic, key=dic.get)) #output: key in asc order
带索引遍历 for idx, item in enumerate(x):
浅复制 list(l) 等方式构建的 list dict set 属于浅复制，如果容器的元素还是容器，那么元素属于引用。
深度复制需要使用 copy module
import copy xs = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] zs = copy.deepcopy(xs) # 对象同样可以使用 copy，还有__copy__等魔法方法可以探索 使用 namedtuple namedtuple 可以让代码更容易阅读，当然现在可以是所有 dataclass，特性更丰富
from collections import namedtuple class Car: """you do not modify the name and date attributes """ def __init__(self, name, date): self._name = name self._date = date # use namedtuple Car = namedtuple('Car', 'name date') # 注意，这里多个属性可以一次性传入，使用空格分割 # 然后你可以将 Car 作为 data class 使用 #还有一个 type hint 的版本 from typing import NamedTuple list vs array list 的元素可以不同，更为紧凑的单一类型是 array 类型。
list 通过 append pop 两个方法可以实现 stack 效果。
Counter Counter(string).most_common(3)
deque from collections import deque names = deque(['raymond', 'rachel', 'matthew', 'roger', 'betty', 'melissa', 'judith', 'charlie']) names.popleft() names.appendleft('mark') 一些不常用的容器 CountedObject,ChainMap,MappingProxyType,frozenset,defaultdict
在遍历中修改 list 使用 for i in range(len(a)) 或者 for i, v in enumerate(a) 都是危险的。
# 方法 1 将 list 拷贝一下，遍历新数组的过程中，修改原 list: num_list = [1, 2, 3, 4, 5] print(num_list) for item in num_list[:]: # 这里 list[:] 是对原数组的拷贝，trick!!! if item == 2: num_list.remove(item) else: print(item) print(num_list) # 方法 2 如果数组很大，那应该使用倒序遍历： for i in range(len(num_list)-1, -1, -1): if num_list[i] == 2: num_list.pop(i) else: print(num_list[i]) # 方法 3 还是使用 for 推导式 [4 if x==3 else x for x in num_list] 打印容器可以使用 pprint.pprint
str 和 bytes bytes 和 bytesarray bytes 是不可变的数组，每个元素必须在 0～255 之间。
bytearray 是可变的，可以修改，增加，删除元素。
转换 bytes(ba)
多行 string my_very_big_string = ( "For a long time I used to go to bed early. Sometimes, " "when I had put out my candle, my eyes would close so quickly " "that I had not even time to say “I’m going to sleep.”" ) 多行文本去除缩进可以使用 textwrap.deden("""\your text""")
str 重复 n 次 print(s * n);
int/string intern 小整数池是[-5,256], string 也有 string intern
str.partition/str.translate 有时使用 str.partition 方法拆分 str 或者 str.translate 批量 replace 子串更方便
NamedTuple, typing.NamedTuple, dataclass from collections import namedtuple Coordinate = namedtuple('Coordinate', 'lat long') issubclass(Coordinate, tuple) # True moscow = Coordinate(55.756, 37.617) moscow == Coordinate(lat=55.756, long=37.617) # True __eq__ # typing.NamedTyple also is subclass tuple, not new type import typing Coordinate = typing.NamedTuple('Coordinate', [('lat', float), ('long', float)]) # or with type: Coordinate = typing.NamedTuple('Coordinate', lat=float, long=float) issubclass(Coordinate, tuple) # True Coordinate.__annotations__ # {'lat': &lt;class 'float'>, 'long': &lt;class 'float'>}” issubclass(Coordinate, typing.NamedTuple) # False issubclass(Coordinate, tuple) # True ### class style from typing import NamedTuple class Coordinate(NamedTuple): lat: float long: float def __str__(self): ns = 'N' if self.lat >= 0 else 'S' we = 'E' if self.long >= 0 else 'W' return f'{abs(self.lat):.1f}°{ns}, {abs(self.long):.1f}°{we}' ### dataclass from dataclasses import dataclass @dataclass(frozen=True) # frozen=True: exception if re-assign fields after instance initialized class Coordinate: lat: float long: float def __str__(self): ... dataclasses.asdict(c) 重要标准库 functools contextlib atexit pathlib collections itertools inspect: e.g. inspect the function signature bisect: 二分查找 pathlib vs os.path use pathlib over os.path. 后者方法不全。
def project_root() -> Path: return Path(__file__).parent.parent.parent def file_abspath(relative_path: str) -> str: """get file absolute path from project root""" return (project_root() / relative_path).as_posix() os vs sys os module is for system, sys this module provides access to some variables used or maintained by
the interpreter and to functions that interact strongly with the interpreter.
迭代器 迭代器：__iter__ 和 __next__ 两个方法 可迭代对象：__iter__ 方法 如果希望可迭代对象可以重复使用，应该在 __iter__ 每次返回新的迭代器对象。 yield 生成器也是迭代器。itertools 简化循环，例如 product pythonic 的代码 使用 for 推导式，不要 for..in 遍历，也少用 map,filter
多使用 destructing，这点在 Java/Go 都不支持，可以在方法内部省很多代码
long_list = [x for x in range(100)] a, b, *c, d, e, f = long_list #e==98 f=99 使用if x is None,而不是 if x == None 异常处理
清楚 except 和 assert 场合，logging.error(&lsquo;xxxxxxx&rsquo;, exc_info=True).
自定义异常必须重写__init__() 和 str()
use reversed(lis) over lis[::-1]
@property make a method to class&rsquo;s property. can not use () when access the method cuz it is prop.
use assert protect your code. 不要使用 assert 检查数据，断言可能被全局禁用，导致数据检查（或者更恐怖的权限检查）被跳过
@functools.wraps(func)
__var 在 class 环境中会被改写
使用 abc 模块可以避免抽象类只有在未实现方法被调用时才抛出 NotImplementedError
理解 python 的 dunder 方法，可以写出超级简洁的方法：
import collections Card = collections.namedtuple('Card', ['rank', 'suit']) class FrenchDeck: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] deck = new FrenchDeck() from random import choice choice(deck) # Card(rank='3', suit='hearts') 上面的例子我们使用了__len__方法和__getitem__方法，好处就是你可以使用 python 的 len(deck),deck[1]
这种语法，也就是说FrenchDeck几乎就是一个容器类型，还可以使用 for 遍历。
更多查看&lt;fluent python 2nd>.
其他 数据校验pydantic 日志 loguru 异常现场stackprinter，打印上下文icecream 命令行click 或者defopt 时间处理 arrow 查看字节码dis 使用 help(),dir() 获取信息 python 中的每个函数都有__code__属性，包含字节码信息 使用 dis 模块的 dis 函数可以查看更容易阅读的汇编 (dis == disassembler) sys.getsizeof(x) 获取对象大小 ...和pass几乎等效的，这是一个 ellipsis type 的单例。 无限大 float(&lsquo;inf&rsquo;) float(&rsquo;-inf&rsquo;) ==会被__eq__方法改变，判断是否 None 时应该使用 is 判断 id 是否一致 python 的 try 可以配合 else:当没有任何异常或者 try 里面没有 return break，才执行 else 部分。这个和 finally 有很重要的不同 使用 with 需要实现__enter__ __exit__两个方法 with 语句可以同时打开多个文件，不要嵌套 with，更多功能查看contextlib 不要自己手动做数据校验，使用pydantic这个库 不要使用 assert 校验参数合法性，因为可以通过-O 参数跳过 代码执行可视化 https://pythontutor.com/ .pyi 文件 存根文件，i 可以理解成 interface。在 PyCharm 中，如果某一行的左边有 * 号标识，则说明这一行（可以是类、属性或函数）在存根文件中有定义，你可以点击 * 号跳转到该文件对应的存根文件，通常是存放在 Python 库文件的 Typeshed Stubs 目录中，文件名以 .pyi 后缀结尾。 参考资料 Python 工匠系列
RealPython 学习路径
一份非常详尽的 Python 小抄
Fluent Python 2nd</content></entry><entry><title>使用 speed-measure-webpack-plugin 和 Happypack 优化 webpack 打包速度</title><url>https://zhimoe.github.io/post/ts-speed-up-angular-build/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>JS</tag><tag>webpack</tag></tags><content type="html"> 问题 一个 ionic app 本地编译需要 8 分钟，提交到流水线编译耗时需要近 40 分钟，从日志看到 webpack 打包步骤耗时最严重。
排查与解决 初步判断是流水线使用的容器 CPU 性能较弱或者存储 mount 性能导致的。找流水线同事支持配置了一个纯内存编译流水线，发现还是很慢。接下来使用 webpack 的插件speed-measure-webpack-plugin监控性能。
在 webpack.config.js 配置：
// webpack.config.js // npm i --save-dev speed-measure-webpack-plugin const SpeedMeasurePlugin = require("speed-measure-webpack-plugin"); const smp = new SpeedMeasurePlugin(); // ...the webpack configuration const prodConfig = {/*...*/} module.exports = { prod: smp.wrap(prodConfig) }; 得到下图左侧的结果，可以看到主要耗时都在 angular 的 PurifyPlugin 上。搜索了一番后找到 HappPack 这个多核执行的插件。
配置 happypack，由于主要耗时都在const PurifyPlugin = require('@angular-devkit/build-optimizer').PurifyPlugin;插件上，这里只需要针对这一个插件配置 happypack 即可。
// webpack.config.js // const HappyPack = require('happypack'); const os = require('os');//获取 cpu core 数量 //loaders 配置 { test: /\.ts$/, use: [ { loader: 'happypack/loader?id=ts', // 在所有 loader 之前加上 happypack/loader,id 是 plugins 中定义的 }, { loader: process.env.IONIC_CACHE_LOADER }, { loader: '@angular-devkit/build-optimizer/webpack-loader', options: { sourceMap: true } }, { loader: process.env.IONIC_WEBPACK_LOADER } ] } // 在 plugins 中配置 happypack 插件 plugins: [ ionicWebpackFactory.getIonicEnvironmentPlugin(), ionicWebpackFactory.getCommonChunksPlugin(), new ModuleConcatPlugin(), new PurifyPlugin(), new HappyPack({ id: 'js', threads: os.cpus().length, loaders: ['@angular-devkit/build-optimizer/webpack-loader'] }), new HappyPack({ id: 'ts', // 在 loader 中使用 threads: os.cpus().length, // 开启操作系统 cpu 的最大核心数 loaders: ['@angular-devkit/build-optimizer/webpack-loader'] }) ] 再次本地执行，性能提升巨大。在流水线上测试，两次 build 都在 15 分钟左右。</content></entry><entry><title>在 githook 中调用 nodejs 脚本</title><url>https://zhimoe.github.io/post/nodejs-as-githook/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>nodejs</tag></tags><content type="html"> 如何在 git hook 中调用 nodejs 脚本。主要踩坑在于不知道如何在 bash 中获取 node 脚本返回值，搜了好大一圈。
背景 微服务模式开发中，每个小组维护自己的应用，通过一个 nginx 入口反向代理所有的子应用，向用户开放一个站点.nginx 应用中需要维护各个子应用的代理，即 ng.conf 中的 location.
此外，一个应用需要配置 DEV,ST,UAT,PRD 四个环境的 location.目前的做法是 www/ngconf/目录下面分为 dev、st、uat、prd 四个文件夹，在文件夹内部每个小组各自维护一个 conf 文件。
每增加一个应用，需要在四个文件夹中自己小组的配置文件添加配置。随着应用越来越多，以及人员流动，会发生不同文件配置相同的 location entry.
例如 A 应用上线一个功能需要依赖 B 应用，但是新人不知道 B 已经配置过了，所以又重复添加了一个，导致启动报错。
需求 入口应用是一个 nodejs 应用，自然选择了 js 脚本检查 conf 文件 location path 配置是否重复。
实现 在 git hook 目录下，新增一个pre-commit文件，添加内容：
#!/usr/bin/sh # 检查项目中同一个目录下面的nginx conf 所有location是否重复 if [ -e ./ngconf_check.js ]; then node ngconf_check.js if [[ $? != 0 ]]; then echo >&amp;2 fix duplicate location entry in nginx conf exit 1 fi fi # 如果项目有自定义pre-commit,执行 if [ -e ./.git/hooks/pre-commit ]; then ./.git/hooks/pre-commit "$@" fi exit 0 要点：bash 中$?表示获取上命令的返回值。这里获得的是 js 脚本的 process.exit(code) 返回的 code. 默认返回是 0.
ngconf_check.js:
// 检查 ng conf 是否有重复的 location entry const fs = require('fs'); const path = require('path'); const ConfEnvDirs = new Set(); ConfEnvDirs.add('dev'); ConfEnvDirs.add('st'); ConfEnvDirs.add('uat'); ConfEnvDirs.add('prd'); const NgconfPath = 'www/ngconf'; let result = 'pass'; countLocationInDir(NgconfPath); if(result !== 'pass'){ process.exit(1);//向 bash 返回 1 } /** * * @param rootPath */ function countLocationInDir(rootPath) { if (!fs.existsSync(rootPath)) return; let dirs = fs.readdirSync(rootPath); dirs.forEach(dir => { let envDir = path.join(rootPath, dir); //只处理四个环境目录下的 conf 文件，每个目录用一个 map 记录 const LocationEntryMap = new Map();//location entry -> file,line if (!(fs.statSync(envDir).isDirectory() &amp;&amp; ConfEnvDirs.has(dir))) { return; } let confFiles = fs.readdirSync(envDir); confFiles.forEach(filename => { let fullPath = path.join(envDir, filename); if (fs.lstatSync(fullPath).isFile() &amp;&amp; /[\w\W.].conf$/.test(filename)) { countLocationsInFile(fullPath, LocationEntryMap); } }); }); } /** * * @param confFile * @param countMap */ function countLocationsInFile(confFile, countMap) { let lines = fs.readFileSync(confFile, "utf-8") .split("\n") .filter(Boolean); lines.forEach((line, lineNumber) => { if (line.trim().startsWith("location")) { const arr = line.trim().split(' '); const locationEntry = arr[1]; const entryInfo = `${confFile}, at line:${lineNumber}`; if (countMap.has(locationEntry)) { console.log(`ERROR: duplicate location entry: ${locationEntry}`); console.log(`location 1:${countMap.get(locationEntry)}`); console.log(`location 2:${entryInfo}`); //修改 result 变量 result='error'; } else { countMap.set(locationEntry, entryInfo); } } }); }</content></entry><entry><title>Typescript Comprehensive Cheatsheet</title><url>https://zhimoe.github.io/post/ts-comprehensive-notes/</url><categories><category>编程</category></categories><tags><tag>typescript</tag></tags><content type="html"> 一份详尽的 ts 语法笔记。这周在看组里前端同事的代码，感觉完全还是在写 JS，以我有限的 JS/TS 知识，也知道可以写得更加规范一点。但是一上手开始改，还真是手生。
又重新过了一遍文档，做了一点笔记。
install # Install npm install typescript # Run npx tsc # Run with a specific config npx tsc --project configs/my_tsconfig.json # Triple slash directives # Reference built-in types /// &lt;reference lib="es2016.array.include" /> # Reference other types /// &lt;reference path="../my_types" /> /// &lt;reference types="jquery" /> # AMD /// &lt;amd-module name="Name" /> /// &lt;amd-dependency path="app/foo" name="foo" /> # Compiler comments # Don’t check this file // @ts-nocheck # Check this file (JS) // @ts-check # Ignore the next line // @ts-ignore # Expect an error on the next line // @ts-expect-error # ignore ts type error tsc --noEmitOnError hello.ts # tsconfig.json "strict": true "noImplicitAny" "strictNullChecks" ts syntax cheatsheet //-------------------------------- Basic type any // untyped, use as js, disables all further type checking unknown // The unknown type represents any value. This is similar to the any type, but is safer because it’s not legal to do anything with an unknown value: void // void is not the same as undefined. // a contextual function type with a void return type (type vf = () => void), when implemented, can return any other value, but it will be ignored. null // prefer use undefined undefined // check optional param? if undefined before use it never // unreachable see: https://www.typescriptlang.org/docs/handbook/2/narrowing.html#exhaustiveness-checking object // object is not Object. Always use object! object also diff from {} // In compile time {} doesn't have Object's members and Object has more strict behavior boolean number string // The type names String , Number , and Boolean (starting with capital letters) are legal, but refer to // some special built-in types that will very rarely appear in your code. Always use string , number , or // boolean for types. bigint //ES2020 // Creating a bigint via the BigInt function const oneHundred: bigint = BigInt(100); // Creating a BigInt via the literal syntax const anotherHundred: bigint = 100n; string[] // or Array&lt;string> // ReadonlyArray // error: new ReadonlyArray("red", "green", "blue"); // use: const roArray: ReadonlyArray&lt;string> = ["red", "green", "blue"]; // Just as TypeScript provides a shorthand syntax for Array&lt;Type> with Type[], // it also provides a shorthand syntax for ReadonlyArray&lt;Type> with readonly Type[] let x: readonly string[] = []; let y: string[] = []; [string, number] // tuple string | null | undefined // union type // use isArray function narrowing the array type function welcomePeople(x: string[] | string) { if (Array.isArray(x)) { console.log("Hello, " + x.join(" and ")); } else { console.log("Welcome lone traveler " + x); } } // use in operator narrowing method structual type // instanceof narrowing type direction= 'left' | 'right'; // Literal types type roll= 1 | 2 | 3 | 4 | 5 | 6; // ?? (nullish coalescing) function getValue(val?: number): number | 'nil' { // Will only return 'nil' if `val` is null or undefined return val ?? 'nil'; } // ?. (optional chaining) function countCaps(value?: string) { // The `value` expression be undefined if `value` is null or // undefined, or if the `match` call doesn't find anything. return value?.match(/[A-Z]/g)?.length ?? 0; } // ! (null assertion) skip the null/undefined check let value: string | undefined; // ... Code that we're sure will initialize `value` ... // Assert that `value` is defined console.log(`value is ${value!.length} characters long`); // &amp;&amp;= assign a value only if current value is truthy let a; let b = 1; a &amp;&amp;= 'default'; // a is still undefined b &amp;&amp;= 5; // b is now 5 // ||= assign a value only if current value is falsy let a; let b = 1; a ||= 'default'; // a is 'default' now b ||= 5; // b is still 1 // ??= assign a value only if current value is null or undefined let a; let b = 0; a ??= 'default'; // a is now 'default' b ??= 5; // b is still 0 // Object { requiredStringVal: string; optionalNum?: number; readonly readOnlyBool: bool; } // Index signature: object with arbitrary string properties (like a hashmap or dictionary) { [key: string]: Type; } { [key: number]: Type; } { [key: symbol]: Type; } { [key: `data-${string}`]: Type; } // Array of functions that return strings (() => string)[] // or { (): string; }[] // or Array&lt;() => string> // Basic tuples let myTuple: [ string, number, boolean? ]; myTuple = [ 'test', 42 ]; // Variadic tuples type Numbers = [number, number]; type Strings = [string, string]; type NumbersAndStrings = [...Numbers, ...Strings]; // [number, number, string, string] type NumberAndRest = [number, ...string[]]; // [number, varying number of string] type RestAndBoolean = [...any[], boolean]; // [varying number of any, boolean] // Named tuples type Vector2D = [x: number, y: number]; function createVector2d(...args: Vector2D) {} // function createVector2d(x: number, y: number): void // !!!cation, you can not use v2d.x the name is just for hint, not for compiler // Interface interface Child extends Parent, SomeClass { property: Type; optionalProp?: Type; optionalMethod?(arg1: Type): ReturnType; } // Class class Child extends Parent implements Child, OtherChild { property: Type; defaultProperty = 'default value'; private _privateProperty: Type; private readonly _privateReadonlyProperty: Type; static staticProperty: Type; static { try { Child.staticProperty = calcStaticProp(); } catch { Child.staticProperty = defaultValue; } } constructor(arg1: Type) { super(arg1); } private _privateMethod(): Type {} methodProperty: (arg1: Type) => ReturnType; overloadedMethod(arg1: Type): ReturnType; overloadedMethod(arg1: OtherType): ReturnType; overloadedMethod(arg1: CommonT): CommonReturnT {} static staticMethod(): ReturnType {} subclassedMethod(arg1: Type): ReturnType { super.subclassedMethod(arg1); } } //-------------------------------- Function // Function type (arg1: Type, argN: Type) => Type; // or { (arg1: Type, argN: Type): Type; } // Function type with optional param (arg1: Type, optional?: Type) => ReturnType // Function type with rest param (arg1: Type, ...allOtherArgs: Type[]) => ReturnType // Function type with static property { (): Type; staticProp: Type; } // Default argument function fn(arg1 = 'default'): ReturnType {} // Arrow function (arg1: Type): ReturnType => { ...; return value; } // or (arg1: Type): ReturnType => value; // this typing function fn(this: Foo, arg1: string) {} // Overloads function conv(a: string): number; function conv(a: number): string; function conv(a: string | number): string | number { ... } // Call Signatures type DescribableFunction = { description: string; (someArg: number): boolean; }; function doSomething(fn: DescribableFunction) { console.log(fn.description + " returned " + fn(6)); } // Construct Signatures type SomeConstructor = { new (s: string): SomeObject; }; function fn(ctor: SomeConstructor) { return new ctor("hello"); } // Generic Functions function firstElement&lt;Type>(arr: Type[]): Type | undefined { return arr[0]; } // Constraints function longest&lt;Type extends { length: number }>(a: Type, b: Type) { if (a.length >= b.length) { return a; } else { return b; } } // longerArray is of type 'number[]' const longerArray = longest([1, 2], [1, 2, 3]); // longerString is of type 'alice' | 'bob' const longerString = longest("alice", "bob"); // Error! Numbers don't have a 'length' property const notOK = longest(10, 100); // Working with Constrained Values // 期望返回 Type，而不是具有{ length: number }约束的类型。即期望子类，返回了父类，会导致属性变少 function minimumLength&lt;Type extends { length: number }>( obj: Type, minimum: number ): Type { if (obj.length >= minimum) { return obj; } else { return { length: minimum }; // Type '{ length: number; }' is not assignable to type 'Type'. // '{ length: number; }' is assignable to the constraint of type 'Type', but 'Type' could be instantiated with a different subtype of constraint '{ length: number; }' } } // Rule: If a type parameter only appears in one location, strongly reconsider if you actually need it // Rule: Always use as few type parameters as possible // Rule: When possible, use the type parameter itself rather than constraining it // 函数重载 function makeDate(timestamp: number): Date; function makeDate(m: number, d: number, y: number): Date; // 上面两个为函数重载签名 function makeDate(mOrTimestamp: number, d?: number, y?: number): Date { if (d !== undefined &amp;&amp; y !== undefined) { return new Date(y, mOrTimestamp, d); } else { return new Date(mOrTimestamp); } } const d1 = makeDate(12345678); const d2 = makeDate(5, 5, 5); const d3 = makeDate(1, 3); // Always prefer parameters with union types instead of overloads when possible //-------------------------------- Enum // Unlike most TypeScript features, this is not a type-level addition to JavaScript but something added to the language and runtime. // Because of this, it’s a feature which you should know exists, but maybe hold off on using unless you are sure enum Color {Red, Green, Blue = 4} // default get Red=0, all of the following members are auto-incremented Green=1, except you give. let c: Color = Color.Green // enum 有两种，value 是 number（默认）或 string 的。 // !!!numeric enums members also get a reverse mapping from enum values to enum names, for example: // !!! careful with numeric enum iteration enum LogLevel { ERROR, WARN, INFO } for (let element in LogLevel) { // 先遍历 index，再遍历 value console.log(element +" - "+ LogLevel[element]);// output // [LOG]: "0 - ERROR" // [LOG]: "1 - WARN" // [LOG]: "2 - INFO" // [LOG]: "ERROR - 0" // [LOG]: "WARN - 1" // [LOG]: "INFO - 2" } // string value enum 没有上面这个问题。 // 在编译内部，ts 编译得到一个 name->value value->name 的双向 map enum Enum { VAL, } // tsc output "use strict"; var Enum; (function (Enum) { Enum[Enum["VAL"] = 0] = "VAL"; })(Enum || (Enum = {})); // for in 是 ES5 标准，遍历 key. in 会遍历原型链 prototype 上面的属性。非底层代码，禁止使用 for..in. // for of 是 ES6 标准，遍历 value. // 语法上 enum 允许 string value 和 numeric value 并存，但是代码业务含义 enum BooleanLikeHeterogeneousEnum { No = 0, Yes = "YES", } // Try to use ts.forEach, ts.map, and ts.filter instead of loops when it is not strongly inconvenient. //-------------------------------- Type alias type Name = string; type Direction = 'left' | 'right'; type ElementCreator = (type: string) => Element; type Point = { x: number, y: number }; type Point3D = Point &amp; { z: number }; type PointProp = keyof Point; // 'x' | 'y' const point: Point = { x: 1, y: 2 }; type PtValProp = keyof typeof point; // 'x' | 'y' // Extending a type via intersections type Animal = { name: string } type Bear = Animal &amp; { honey: boolean } // type alias , interface 区别 //-------------------------------- Generics // Function using type parameters &lt;T>(items: T[], callback: (item: T) => T): T[] // Interface with multiple types interface Pair&lt;T1, T2> { first: T1; second: T2; } // Constrained type parameter &lt;T extends ConstrainedType>(): T // Default type parameter &lt;T = DefaultType>(): T // Constrained and default type parameter &lt;T extends ConstrainedType = DefaultType>(): T // Generic tuples type Arr = readonly any[]; function concat&lt;U extends Arr, V extends Arr>(a: U, b: V): [...U, ...V] { return [...a, ...b] } const strictResult = concat([1, 2] as const, ['3', '4'] as const); const relaxedResult = concat([1, 2], ['3', '4']); // strictResult is of type [1, 2, '3', '4'] // relaxedResult is of type (string | number)[] //-------------------------------- Index, mapped, and conditional types // Index type query (keyof) type Point = { x: number, y: number }; let pointProp: keyof Point = 'x'; function getProp&lt;T, K extends keyof T>( val: T, propName: K ): T[K] { ... } // Mapped types // see more: https://www.typescriptlang.org/docs/handbook/utility-types.html type Stringify&lt;T> = { [P in keyof T]: string; } type Partial&lt;T> = { [P in keyof T]?: T[P]; } // Conditional types type Swapper = &lt;T extends number | string> (value: T) => T extends number ? string : number; // is equivalent to (value: number) => string // if T is number, or (value: string) => number // if T is string // Conditional mapped types interface Person { firstName: string; lastName: string; age: number; } type StringProps&lt;T> = { [K in keyof T]: T[K] extends string ? K : never; }; type PersonStrings = StringProps&lt;Person>; // PersonStrings is "firstName" | "lastName" // Utility types // Partial Partial&lt;{ x: number; y: number; z: number; }> // is equivalent to { x?: number; y?: number; z?: number; } // Readonly Readonly&lt;{ x: number; y: number; z: number; }> // is equivalent to { readonly x: number; readonly y: number; readonly z: number; } //-------------------------------- Pick Pick&lt;{ x: number; y: number; z: number; }, 'x' | 'y'> // is equivalent to { x: number; y: number; } // Record, 和 index signature 区别是 后者 key 限制在 string number symbol Record&lt;'x' | 'y' | 'z', number> // is equivalent to { x: number; y: number; z: number; } // Exclude type Excluded = Exclude&lt;string | number, string>; // is equivalent to number // Extract type Extracted = Extract&lt;string | number, string>; // is equivalent to string // NonNullable type NonNull = NonNullable&lt;string | number | void>; // is equivalent to string | number // ReturnType type ReturnValue = ReturnType&lt;() => string>; // is equivalent to string // InstanceType class Renderer() {} type Instance = InstanceType&lt;typeof Renderer>; // is equivalent to Renderer // Type guards // Type predicates function isThing(val: unknown): val is Thing { // return true if val is a Thing } if (isThing(value)) { // value is of type Thing } //-------------------------------- typeof // "string" // "number" // "bigint" // "boolean" // "symbol" // "undefined" // "object" // "function" declare value: string | number | boolean; const isBoolean = typeof value === "boolean"; if (typeof value === "number") { // value is of type Number } else if (isBoolean) { // value is of type Boolean } else { // value is a string } // False // 0 // NaN // "" (the empty string) // 0n (the bigint version of zero) // null // undefined // instanceof declare value: Date | Error | MyClass; const isMyClass = value instanceof MyClass; if (value instanceof Date) { // value is a Date } else if (isMyClass) { // value is an instance of MyClass } else { // value is an Error } // in 属性和方法 interface Dog { woof(): void; } interface Cat { meow(): void; } function speak(pet: Dog | Cat) { if ('woof' in pet) { pet.woof() } else { pet.meow() } } //-------------------------------- Assertions // Type let val = someValue as string; // or let val = &lt;string>someValue; Const (immutable value) let point = { x: 20, y: 30 } as const; // or let point = &lt;const>{ x: 20, y: 30 }; function handle(url:string,method: "GET"|"POST"){ console.log("handle") } const req = { url: "https://example.com", method: "GET" }; handle(req.url, req.method as "GET"); // remove as "GET", throw: Argument of type 'string' is not assignable to parameter of type '"GET" | "POST"'.(2345) // or const req = { url: "https://example.com", method: "GET" as "GET" }; // or convert to type literals const req = { url: "https://example.com", method: "GET" } as const; //-------------------------------- Indexed Access Types type Person = { age: number; name: string; alive: boolean }; type Age = Person["age"]; // number type I1 = Person["age" | "name"]; // type I1 = string | number type I2 = Person[keyof Person]; // type I2 = string | number | boolean type AliveOrName = "alive" | "name"; type I3 = Person[AliveOrName]; // type I3 = string | boolean //-------------------------------- Ambient declarations // Global declare const $: JQueryStatic; // Module declare module "foo" { export class Bar { ... } } // Wildcard module declare module "text!*" { const value: string; export default value; }</content></entry><entry><title>开源与心理健康[翻译]</title><url>https://zhimoe.github.io/post/open-source-mental-health/</url><categories><category>翻译</category></categories><tags><tag>开源</tag><tag>心理健康</tag></tags><content type="html"> 我一位亲爱的朋友，也是高产的 Redox OS 贡献者 jD91mZM2 在 2021 年 3 月去世了，年仅 18 岁。他参与了 2018、2019 和 2020 年的 Redox OS 夏季代码活动。他在开发 Redox OS 的各个方面都做出了贡献，从内核，到 relibc，到移植程序。他的工作详细介绍可以在Redox OS 新闻中署名为 jD91mZM2 的帖子看到。
这个帖子可能是黑暗的、深沉的、沉重的、原始的、未经编辑的。如果你和我们中的许多人一样有自己的问题，请随时与我联系：https://twitter.com/jeremy_soller.在这种情况下，我不建议阅读这篇文章的其他内容。我的结论是，开源要成为可持续发展，还有大量的工作要做，而其中很大一部分是对社区及其成员的健康的关怀。
反思 昨天，另一个贡献者给我发了消息，说 jD91mZM2 已经长时间离线，而且也没有回复邮件。我通过我所掌握的信息进行了联系，但无济于事。我把他的真实姓名告诉了另一位贡献者，后者找到了他的讣告。我们验证了他的名字、地点和出生日期是否相符。虽然没有列出死因，但我相信我们找到的证据表明他是在精神疾病发作后自杀。
在得知这一切后，我感到很震惊。这样一个多产的贡献者，不仅对 Redox，而且对许多项目都有贡献，怎么会觉得死亡比生命更重要？这是一个能力无穷的人，而且直到最近，他似乎还能很好地把握自己的生活。但我活得越久，就越意识到这可能是一个极大的幻觉，事情会迅速恶化。
我最后一次与 jD91mZM2 交流是在二月，在他去世前一个月。这次交流纯粹是技术性的，关于 Redox 内核的 arch64 端口。我不禁想到，这也许是他决定选择死亡的一个因素。
在开源工作中，我们经常强调好代码的重要性。毕竟，每个开源项目的交付物，都是源代码，对吧？但我们常常忘记，好的代码是由优秀的人编写的，而留住这些人并让他们保持快乐，应该是任何项目维护者的首要考虑。
心理健康问题的发作有很多方面。一方面，精神疾病通常有遗传因素。另一方面，这些遗传的前兆通常需要慢性和急性的环境触发因素。这些慢性诱因可以是长期的不良家庭或工作环境，并导致精神疾病本身的表现。急性诱因可能是，例如，与某人发生争执，导致精神疾病发作。这些发作可能严重到足以克服生存的极端本能，导致自杀。
在这种情况下，自杀并不是一种软弱的表现。事实上，它是一种极端信念和力量的展示。即使在精神疾病的背景下，大脑的某些部分通常不受影响。这些部分在进化过程中非常原始，我们几乎没有意识到对它们的控制。企图自杀需要克服有意识的求生欲望。要成功，就是要克服极端的潜意识欲望。这意味着，对于自杀，往往是最聪明、最有能力的人才能够做到。
这种对有能力的人的反选择是一种可怕的流行病。人类总体上迫切需要人为地解决长期存在的问题。以气候变化为例。在每年 80 万自杀的人中，平均来说也许比我们其他人更有能力，如果有几个人在开发核聚变发电方面起到了作用，那会怎么样？
然而，我们作为一个社会已经采取了这样的立场：这些事件是一种不可阻挡的力量。导致自杀的因素是内部的，而不是外部的。原则上，我拒绝相信这一点。对于每一个问题，我们都必须寻找原因并加以缓解，即使最后不可能做到。
因此，我不得不审视自己的行为，看看有什么可以做得不同。看看我是否可以挽救一个人的生命，以及看看我在未来可以挽救哪些生命。
开源与心理健康 开源的某些方面似乎吸引了最奇怪的人类，包括我自己。这群人坚持所有的东西都是可检查的，这也许是由强迫症行为所驱动的。而那些容易出现这种行为的人，往往会从其他疾病中继承下来。多动症、自闭症、双相情感障碍、抑郁症和其他疾病在开放源码贡献者中非常普遍。
因此，开源社区中也明显缺乏软技能。这显然有分裂社区和将开源本身与 &ldquo;正常 &ldquo;世界隔离的效果。对我们来说，幸运的是，开放源代码最终成为一个有利可图的行业。这种资本的注入导致了开源领域人才的显著多样化。
然而，这也是有代价的。那些不符合开源项目新的商业利益的人往往被抛在一边。由于与原始维护者的分歧导致项目本身出现难以克服的变化，项目被进一步划分为分叉上的分叉。我自己也参与了所有这些方面的工作。
在大多数情况下，都缺乏对人类成本的调查。调查开源贡献者中众多的心理健康事件，并试图找出一些共同的因素。有时这些事件会导致新的项目，有时会导致贡献者精疲力尽，然后离开开放源码，有时会导致自杀。
我们必须认识到我们在创造导致精神疾病的慢性压力以及导致危险发作的急性压力方面的作用。
我自己的旅程 我对精神疾病没有免疫力。我经常收到这样的信息：&ldquo;你似乎把你的事情都控制住了，你是怎么做到的？&rdquo; 残酷的事实是，我怀疑我们中是否有人真的做到了。而我们对 &ldquo;控制 &ldquo;的定义可能是非常不同的。拥有成功的项目并不等同于拥有普遍的幸福。
我不得不承认，我现在比以前幸福多了。因此，也许与一般人相比，我确实有事情在控制之中。我的生活一直是治疗师、精神病医生、药物和隔离的奥德赛。它本来很容易像其他人一样结束。我很幸运地找到了我的慢性压力源，并尽职尽责地消除它们。
我的大学一年&ndash;与 jD91mZM2 决定结束自己生命的时间差不&ndash;特别艰难。我的体重增加了近 50 磅。我和另外三个室友住在一起，其中两个也早逝了。我交替使用多动症药物、抗抑郁药，甚至吸烟&ndash;以寻找能 &ldquo;修复 &ldquo;我的方法。在整个过程中，我一直在编程，为此常常忽略了我的学校工作。
在上大学之前，我曾在卓尔医疗公司担任实习生，编写除颤器软件。我在这项工作中拥有两项专利。老实说，在对计算机的理解上，我比别人高出一截。我也对自己说实话，在对人的理解方面，我比别人差了一大截，包括我自己。
在那段时间里，我与研发部的副总裁建立了关系，他成了我事实上的老板。大一快结束时，他联系我，问我是否想继续工作。我答应了。
大二的时候，我的情况非常不同。我把大部分时间花在写软件上，并且赚了不少钱。我对学校没有兴趣。我有几门课不及格，但高分通过了许多高水平的 CS 课程。我很快就从大学退学，全职从事软件工程。
这对我的心理健康产生了巨大的积极影响。我降了体重。与我大学的其他校友保持联系，并最终通过他们认识了我的妻子。我们一起买了一套房子。我开始了 Redox 操作系统。我的妻子和我结婚了。我开始在 System76 工作。我的妻子和我有一个漂亮的女儿。从大二开始，我从来没有想过自己的心理健康问题，也不需要去治疗或用药。我所有的压力都消失了。
一个人的心理健康成功并不总是能复刻成其他人的成功。在这一历程中，我创造和破坏了（通过忽视）数百种关系。我不得不承认，虽然我很快乐，但我有一种倾向，会在别人身上造成相当大的反差。我保留了给我带来快乐的关系，而忽略了那些需要努力的关系。而在某些时候，也许我忘记了与 jD91mZM2 保持联系，确保他找到与我一样的幸福。
一个解决方案？ 没有解决方案，每个案例都是不同的。但我觉得有必要检查一下这些年来我失去的许多人，我希望你也这样做。我们仍然处于了解人类思想的黑暗时代，我们越是互相检查，我们就会做得越好。我知道我本可以有所作为，如果我多做一点的话。也许不是为了 jD91mZM2，而是为了有同样感觉的人。我不会再以他们所写的代码来评价贡献者。代码不会自己写，而写代码的人甚至比 &ldquo;开源 &ldquo;本身更需要维护。
原文-Open Source and Mental Health</content></entry><entry><title>买房装修总结</title><url>https://zhimoe.github.io/post/hangzhou-house-tip/</url><categories><category>生活</category></categories><tags><tag>买房</tag></tags><content type="html"> 简单记录一下自己买房和装修的一点经验。
买房 自己买房比较离奇，杭州开始实行摇号的半年后，端午节在老家刷微信，看到有个红盘有 6000 多人报名，感觉买房都要开始碰运气了想到了车牌的悲剧，于是返杭后下车就去那个楼盘看了一下，小区旁边在修地铁，看了几眼沙盘，第二天就借钱登记摇号了，没想到第一次就中了。现在回想起就做梦一样。网上关于如何买房的经验特别多，例如杭州房产知识扫盲,上海买房等等。这些我都没用上。这里说说自己的一些经验和踩坑。
户型方正通透干湿分离这些网上都会说。提醒的是认真看沙盘旁边每栋楼的说明挂幅。挂幅下面会有小字，说明每栋楼的一些坑，例如一些设备平台在哪栋楼（噪音），楼的腰线在几楼（腰线只是为了楼外观好看，但是非常影响该层的采光），选的时候要避开那些楼层。至于楼栋位置，一般都体现在价格上了，置业经理都会介绍。 如果选择低层的话，或者你的号码靠后只能买低层，看下光照时间测评，同一栋楼的不同单元的光照时间都会有所不同的，特别是一些凹凸造型的楼面。我自己的房子就是客厅采光不好，卧室很好。优先应该考虑客厅采光好的户型。 买房的时候如果预算足够，一定买边套，因为中间套的小户型客厅采光和隔音（楼上楼下电梯过道的走路说话声都会从厨房或者厕所窗户闯进来，非常清晰），厕所隐私性等都有很大问题。这点是我最后悔的，当时不知道中间套噪音这么大而且首付借的多总想着总价低一些。其实隔壁夹边套（两栋楼连在一起的边套，南北通透但是没有侧面窗）才多 10 平，总价多 25 万而已，客厅采光，私密性都好很多。 当然边套很多是 90 方以上的，除了总价，契税和卖出时各种费用会高 0.5% 个点，自己量力而行，如果边套/夹边套是 89 方的，不要犹豫，总价多个三五十万的换来的是完全不一样的体验。 如果小区靠近地铁或者交通比较便利，投资客又比较多，建议开盘不要买车位，交房后会有投资客或者开发商打折卖车位。 装修 因为限价，杭州的新房精装修等于毛坯，我这个交付的时候没有空调，灯还是白炽灯。
第一次买房务必请一个验房师，术业有专攻，千万不要网上看了点收房验房攻略就自信满满自己去收房，等到装修一半又发现一堆问题。 装修顺序很重要，优先考虑打孔，很多业主都是装修尾声去买空调，安装时发现需要重新打孔，墙布已经贴好了，弄破很心疼。还有业主给阳台贴了瓷砖（交付是乳胶漆），买了带新风的客厅空调管道太大需要重新打孔，不小心打破水管，需要重新敲掉 2 块瓷砖。非常费事。 拿到水电图，如果没有，打孔和物业 (或者房修) 说一声，让他们告诉哪里打孔，这样打破水管让他们修。 网上买家电不一定比实体店便宜，我在国美买了美的 colmo 的空调，比淘宝最便宜的还便宜三千。 如果不懂设计，千万不要乱选墙的颜色，自己当时晚上在灯光下面选了一个灰蓝墙布做主色，结果施工当天发现在日光下是水蓝，只能施工当天临时加钱换颜色，还耽误了进度。墙布样品因为面积小，颜色和实际上墙效果相差甚远，日光和灯光下也不一样。而且，墙面的颜色对于后期买家具，沙发和窗帘的影响非常大。没有十足把握的直接选白色或者极浅灰。采光特别好的才建议选浅灰，因为上墙后灰色会变重！ 优先考虑乳胶漆，自己选了硅藻泥质感的墙布，确实质感很好，也好看。但是感觉容易积灰，虽然防水，但是布面不平凹处根本擦不掉。而且油漆的优势还可以单面墙修复。 现在都是智能家具，门锁冰箱空调都有 app，手机遥控聊胜于无，所以家里宽带可以提前开通。 如果是自己布置家具，建议不要着急安装防倒装置，等家具全部摆放完适应几天再决定，极大可能会调整家具位置。 2021.11.11 蒸汽拖把毫无用处，蒸汽是向上的，地板很难加热。买一个好点的拖把，带水桶的那种可以方便洗抹布和挤干的。 买东西要有预算，买 colmo 和墙布都是严重超预算的。卖家很心机地介绍贵的，一上手质感确实不一样。预算就是这么超的。 买一些米箱，保鲜盒，置物架。厨房是最难收拾的，第一步尽量保证不要把超市的东西连着塑料袋放进冰箱/柜子。只有这样后续才能不乱。 提前规划一个工具间，目前家里有戴森，拖把，扫把畚斗，就已经乱放了，戴森没地方挂着充电每次扣电池充电。还有螺丝刀，锤子，扳手等到处乱扔。 很多人安装电动升降晾衣架，那玩意很容易坏，而且阳台挂满衣服非常不好看。我是买了一个伸缩杆卡在阳台侧面，同时买了烘干机。现在两个人住基本不用烘干机，整体阳台会好看很多。 餐桌配套的椅子不要买牛角椅。牛角椅是看好，但是不方便侧坐，日常使用反而闹心，直款靠背就挺好的。 无论靠不靠墙，买靠背较低的那种沙发，像美剧那种不靠墙的低沙发有利于增大空间，方便交流，偶尔还能移动沙发换个布局。 普通家庭不要安装玻璃门的餐边柜，毫无美感。小区里面见过太多的失败的设计。也不要装吊灯，占用空间，吸顶灯就很好。如果确实有灯光需求，建议自己研究灯带，而不是买吊灯。 还是再说下颜色搭配，如果不是全屋定制，颜色真的很难搭配的。首先墙布和餐边柜门尽量选百搭白色（南北通透有大飘窗采光极好的可以选淡灰），这样能给沙发餐桌书柜电视柜窗帘等留下颜色选择余地。客厅颜色尽量少一点，我自己是餐桌书柜沙发是深色（深棕和深蓝灰），窗帘是主灰 + 黄色，餐厅吊灯罩是牛油果绿和黑色、黄色。</content></entry><entry><title>Tour of Rusts Standard Library Traits[翻译]</title><url>https://zhimoe.github.io/post/rust-standard-library-traits-tour/</url><categories><category>翻译</category></categories><tags><tag>code</tag><tag>rust</tag></tags><content type="html"> 关于 rust trait 非常好的介绍，比 rust book 详细，系统。
Tour of Rust&rsquo;s Standard Library Traits Table of Contents
Tour of Rust&rsquo;s Standard Library Traits Intro Trait Basics Trait Items Self Functions Methods Associated Types Generic Parameters Generic Types vs Associated Types Scope Derive Macros Default Impls Generic Blanket Impls Subtraits &amp; Supertraits Trait Objects Marker Traits Auto Traits Unsafe Traits Auto Traits Send &amp; Sync Sized General traits Default Clone Copy Any Formatting Traits Display &amp; ToString Debug Operator Traits Comparison Traits PartialEq &amp; Eq Hash PartialOrd &amp; Ord Arithmetic Traits Add &amp; AddAssign Closure Traits FnOnce, FnMut, &amp; Fn Other Traits Deref &amp; DerefMut Index &amp; IndexMut Drop Conversion Traits From &amp; Into Error Handling Error Conversion Traits Continued TryFrom &amp; TryInto FromStr AsRef &amp; AsMut Borrow &amp; BorrowMut ToOwned Iteration Traits Iterator IntoIterator FromIterator I/O Traits Read &amp; Write Conclusion Discuss Notifications Further Reading Intro Have you ever wondered what&rsquo;s the difference between:
Deref&lt;Target = T>, AsRef&lt;T>, and Borrow&lt;T>? Clone, Copy, and ToOwned? From&lt;T> and Into&lt;T>? TryFrom&lt;&amp;str> and FromStr? FnOnce, FnMut, Fn, and fn? Or ever asked yourself the questions:
&ldquo;When do I use associated types vs generic types in my trait?&rdquo; &ldquo;What are generic blanket impls?&rdquo; &ldquo;How do subtraits and supertraits work?&rdquo; &ldquo;Why does this trait not have any methods?&rdquo; Well then this is the article for you! It answers all of the above questions and much much more. Together we&rsquo;ll do a quick flyby tour of all of the most popular and commonly used traits from the Rust standard library!
You can read this article in order section by section or jump around to whichever traits interest you the most because each trait section begins with a list of links to Prerequisite sections that you should read to have adequate context to understand the current section&rsquo;s explanations.
Trait Basics We&rsquo;ll cover just enough of the basics so that the rest of the article can be streamlined without having to repeat the same explanations of the same concepts over and over as they reappear in different traits.
Trait Items Trait items are any items that are part of a trait declaration.
Self Self always refers to the implementing type.
trait Trait { // always returns i32 fn returns_num() -> i32; // returns implementing type fn returns_self() -> Self; } struct SomeType; struct OtherType; impl Trait for SomeType { fn returns_num() -> i32 { 5 } // Self == SomeType fn returns_self() -> Self { SomeType } } impl Trait for OtherType { fn returns_num() -> i32 { 6 } // Self == OtherType fn returns_self() -> Self { OtherType } } Functions A trait function is any function whose first parameter does not use the self keyword.
trait Default { // function fn default() -> Self; } Trait functions can be called namespaced by the trait or implementing type:
fn main() { let zero: i32 = Default::default(); let zero = i32::default(); } Methods A trait method is any function whose first parameter uses the self keyword and is of type Self, &amp;Self, &amp;mut Self. The former types can also be wrapped with a Box, Rc, Arc, or Pin.
trait Trait { // methods fn takes_self(self); fn takes_immut_self(&amp;self); fn takes_mut_self(&amp;mut self); // above methods desugared fn takes_self(self: Self); fn takes_immut_self(self: &amp;Self); fn takes_mut_self(self: &amp;mut Self); } // example from standard library trait ToString { fn to_string(&amp;self) -> String; } Methods can be called using the dot operator on the implementing type:
fn main() { let five = 5.to_string(); } However, similarly to functions, they can also be called namespaced by the trait or implementing type:
fn main() { let five = ToString::to_string(&amp;5); let five = i32::to_string(&amp;5); } Associated Types A trait can have associated types. This is useful when we need to use some type other than Self within function signatures but would still like the type to be chosen by the implementer rather than being hardcoded in the trait declaration:
trait Trait { type AssociatedType; fn func(arg: Self::AssociatedType); } struct SomeType; struct OtherType; // any type implementing Trait can // choose the type of AssociatedType impl Trait for SomeType { type AssociatedType = i8; // chooses i8 fn func(arg: Self::AssociatedType) {} } impl Trait for OtherType { type AssociatedType = u8; // chooses u8 fn func(arg: Self::AssociatedType) {} } fn main() { SomeType::func(-1_i8); // can only call func with i8 on SomeType OtherType::func(1_u8); // can only call func with u8 on OtherType } Generic Parameters &ldquo;Generic parameters&rdquo; broadly refers to generic type parameters, generic lifetime parameters, and generic const parameters. Since all of those are a mouthful to say people commonly abbreviate them to &ldquo;generic types&rdquo;, &ldquo;lifetimes&rdquo;, and &ldquo;generic consts&rdquo;. Since generic consts are not used in any of the standard library traits we&rsquo;ll be covering they&rsquo;re outside the scope of this article.
We can generalize a trait declaration using parameters:
// trait declaration generalized with lifetime &amp; type parameters trait Trait&lt;'a, T> { // signature uses generic type fn func1(arg: T); // signature uses lifetime fn func2(arg: &amp;'a i32); // signature uses generic type &amp; lifetime fn func3(arg: &amp;'a T); } struct SomeType; impl&lt;'a> Trait&lt;'a, i8> for SomeType { fn func1(arg: i8) {} fn func2(arg: &amp;'a i32) {} fn func3(arg: &amp;'a i8) {} } impl&lt;'b> Trait&lt;'b, u8> for SomeType { fn func1(arg: u8) {} fn func2(arg: &amp;'b i32) {} fn func3(arg: &amp;'b u8) {} } It&rsquo;s possible to provide default values for generic types. The most commonly used default value is Self but any type works:
// make T = Self by default trait Trait&lt;T = Self> { fn func(t: T) {} } // any type can be used as the default trait Trait2&lt;T = i32> { fn func2(t: T) {} } struct SomeType; // omitting the generic type will // cause the impl to use the default // value, which is Self here impl Trait for SomeType { fn func(t: SomeType) {} } // default value here is i32 impl Trait2 for SomeType { fn func2(t: i32) {} } // the default is overridable as we'd expect impl Trait&lt;String> for SomeType { fn func(t: String) {} } // overridable here too impl Trait2&lt;String> for SomeType { fn func2(t: String) {} } Aside from parameterizing the trait it&rsquo;s also possible to parameterize individual functions and methods:
trait Trait { fn func&lt;'a, T>(t: &amp;'a T); } Generic Types vs Associated Types Both generic types and associated types defer the decision to the implementer on which concrete types should be used in the trait&rsquo;s functions and methods, so this section seeks to explain when to use one over the other.
The general rule-of-thumb is:
Use associated types when there should only be a single impl of the trait per type. Use generic types when there can be many possible impls of the trait per type. Let&rsquo;s say we want to define a trait called Add which allows us to add values together. Here&rsquo;s an initial design and impl that only uses associated types:
trait Add { type Rhs; type Output; fn add(self, rhs: Self::Rhs) -> Self::Output; } struct Point { x: i32, y: i32, } impl Add for Point { type Rhs = Point; type Output = Point; fn add(self, rhs: Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } fn main() { let p1 = Point { x: 1, y: 1 }; let p2 = Point { x: 2, y: 2 }; let p3 = p1.add(p2); assert_eq!(p3.x, 3); assert_eq!(p3.y, 3); } Let&rsquo;s say we wanted to add the ability to add i32s to Points where the i32 would be added to both the x and y members:
trait Add { type Rhs; type Output; fn add(self, rhs: Self::Rhs) -> Self::Output; } struct Point { x: i32, y: i32, } impl Add for Point { type Rhs = Point; type Output = Point; fn add(self, rhs: Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } impl Add for Point { // ❌ type Rhs = i32; type Output = Point; fn add(self, rhs: i32) -> Point { Point { x: self.x + rhs, y: self.y + rhs, } } } fn main() { let p1 = Point { x: 1, y: 1 }; let p2 = Point { x: 2, y: 2 }; let p3 = p1.add(p2); assert_eq!(p3.x, 3); assert_eq!(p3.y, 3); let p1 = Point { x: 1, y: 1 }; let int2 = 2; let p3 = p1.add(int2); // ❌ assert_eq!(p3.x, 3); assert_eq!(p3.y, 3); } Throws:
error[E0119]: conflicting implementations of trait `Add` for type `Point`: --> src/main.rs:23:1 | 12 | impl Add for Point { | ------------------ first implementation here ... 23 | impl Add for Point { | ^^^^^^^^^^^^^^^^^^ conflicting implementation for `Point` Since the Add trait is not parameterized by any generic types we can only impl it once per type, which means we can only pick the types for both Rhs and Output once! To allow adding both Pointss and i32s to Point we have to refactor Rhs from an associated type to a generic type, which would allow us to impl the trait multiple times for Point with different type arguments for Rhs:
trait Add&lt;Rhs> { type Output; fn add(self, rhs: Rhs) -> Self::Output; } struct Point { x: i32, y: i32, } impl Add&lt;Point> for Point { type Output = Self; fn add(self, rhs: Point) -> Self::Output { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } impl Add&lt;i32> for Point { // ✅ type Output = Self; fn add(self, rhs: i32) -> Self::Output { Point { x: self.x + rhs, y: self.y + rhs, } } } fn main() { let p1 = Point { x: 1, y: 1 }; let p2 = Point { x: 2, y: 2 }; let p3 = p1.add(p2); assert_eq!(p3.x, 3); assert_eq!(p3.y, 3); let p1 = Point { x: 1, y: 1 }; let int2 = 2; let p3 = p1.add(int2); // ✅ assert_eq!(p3.x, 3); assert_eq!(p3.y, 3); } Let&rsquo;s say we add a new type called Line which contains two Points, and now there are contexts within our program where adding two Points should produce a Line instead of a Point. This is not possible given the current design of the Add trait where Output is an associated type but we can satisfy these new requirements by refactoring Output from an associated type into a generic type:
trait Add&lt;Rhs, Output> { fn add(self, rhs: Rhs) -> Output; } struct Point { x: i32, y: i32, } impl Add&lt;Point, Point> for Point { fn add(self, rhs: Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } impl Add&lt;i32, Point> for Point { fn add(self, rhs: i32) -> Point { Point { x: self.x + rhs, y: self.y + rhs, } } } struct Line { start: Point, end: Point, } impl Add&lt;Point, Line> for Point { // ✅ fn add(self, rhs: Point) -> Line { Line { start: self, end: rhs, } } } fn main() { let p1 = Point { x: 1, y: 1 }; let p2 = Point { x: 2, y: 2 }; let p3: Point = p1.add(p2); assert!(p3.x == 3 &amp;&amp; p3.y == 3); let p1 = Point { x: 1, y: 1 }; let int2 = 2; let p3 = p1.add(int2); assert!(p3.x == 3 &amp;&amp; p3.y == 3); let p1 = Point { x: 1, y: 1 }; let p2 = Point { x: 2, y: 2 }; let l: Line = p1.add(p2); // ✅ assert!(l.start.x == 1 &amp;&amp; l.start.y == 1 &amp;&amp; l.end.x == 2 &amp;&amp; l.end.y == 2) } So which Add trait above is the best? It really depends on the requirements of your program! They&rsquo;re all good in the right situations.
Scope Trait items cannot be used unless the trait is in scope. Most Rustaceans learn this the hard way the first time they try to write a program that does anything with I/O because the Read and Write traits are not in the standard library prelude:
use std::fs::File; use std::io; fn main() -> Result&lt;(), io::Error> { let mut file = File::open("Cargo.toml")?; let mut buffer = String::new(); file.read_to_string(&amp;mut buffer)?; // ❌ read_to_string not found in File Ok(()) } read_to_string(buf: &amp;mut String) is declared by the std::io::Read trait and implemented by the std::fs::File struct but in order to call it std::io::Read must be in scope:
use std::fs::File; use std::io; use std::io::Read; // ✅ fn main() -> Result&lt;(), io::Error> { let mut file = File::open("Cargo.toml")?; let mut buffer = String::new(); file.read_to_string(&amp;mut buffer)?; // ✅ Ok(()) } The standard library prelude is a module in the standard library, i.e. std::prelude::v1, that gets auto imported at the top of every other module, i.e. use std::prelude::v1::*. Thus the following traits are always in scope and we never have to explicitly import them ourselves because they&rsquo;re part of the prelude:
AsMut AsRef Clone Copy Default Drop Eq Fn FnMut FnOnce From Into ToOwned IntoIterator Iterator PartialEq PartialOrd Send Sized Sync ToString Ord Derive Macros The standard library exports a handful of derive macros which we can use to quickly and conveniently impl a trait on a type if all of its members also impl the trait. The derive macros are named after the traits they impl:
Clone Copy Debug Default Eq Hash Ord PartialEq PartialOrd Example usage:
// macro derives Copy &amp; Clone impl for SomeType #[derive(Copy, Clone)] struct SomeType; Note: derive macros are just procedural macros and can do anything, there&rsquo;s no hard rule that they must impl a trait or that they can only work if all the members of the type impl a trait, these are just the conventions followed by the derive macros in the standard library.
Default Impls Traits can provide default impls for their functions and methods.
trait Trait { fn method(&amp;self) { println!("default impl"); } } struct SomeType; struct OtherType; // use default impl for Trait::method impl Trait for SomeType {} impl Trait for OtherType { // use our own impl for Trait::method fn method(&amp;self) { println!("OtherType impl"); } } fn main() { SomeType.method(); // prints "default impl" OtherType.method(); // prints "OtherType impl" } This is especially handy if some of the trait methods can be implemented solely using other trait methods.
trait Greet { fn greet(&amp;self, name: &amp;str) -> String; fn greet_loudly(&amp;self, name: &amp;str) -> String { self.greet(name) + "!" } } struct Hello; struct Hola; impl Greet for Hello { fn greet(&amp;self, name: &amp;str) -> String { format!("Hello {}", name) } // use default impl for greet_loudly } impl Greet for Hola { fn greet(&amp;self, name: &amp;str) -> String { format!("Hola {}", name) } // override default impl fn greet_loudly(&amp;self, name: &amp;str) -> String { let mut greeting = self.greet(name); greeting.insert_str(0, "¡"); greeting + "!" } } fn main() { println!("{}", Hello.greet("John")); // prints "Hello John" println!("{}", Hello.greet_loudly("John")); // prints "Hello John!" println!("{}", Hola.greet("John")); // prints "Hola John" println!("{}", Hola.greet_loudly("John")); // prints "¡Hola John!" } Many traits in the standard library provide default impls for many of their methods.
Generic Blanket Impls A generic blanket impl is an impl on a generic type instead of a concrete type. To explain why and how we&rsquo;d use one let&rsquo;s start by writing an is_even method for number types:
trait Even { fn is_even(self) -> bool; } impl Even for i8 { fn is_even(self) -> bool { self % 2_i8 == 0_i8 } } impl Even for u8 { fn is_even(self) -> bool { self % 2_u8 == 0_u8 } } impl Even for i16 { fn is_even(self) -> bool { self % 2_i16 == 0_i16 } } // etc #[test] // ✅ fn test_is_even() { assert!(2_i8.is_even()); assert!(4_u8.is_even()); assert!(6_i16.is_even()); // etc } Obviously, this is very verbose. Also, all of our impls are almost identical. Furthermore, in the unlikely but still possible event that Rust decides to add more number types in the future we have to remember to come back to this code and update it with the new number types. We can solve all these problems using a generic blanket impl:
use std::fmt::Debug; use std::convert::TryInto; use std::ops::Rem; trait Even { fn is_even(self) -> bool; } // generic blanket impl impl&lt;T> Even for T where T: Rem&lt;Output = T> + PartialEq&lt;T> + Sized, u8: TryInto&lt;T>, &lt;u8 as TryInto&lt;T>>::Error: Debug, { fn is_even(self) -> bool { // these unwraps will never panic self % 2.try_into().unwrap() == 0.try_into().unwrap() } } #[test] // ✅ fn test_is_even() { assert!(2_i8.is_even()); assert!(4_u8.is_even()); assert!(6_i16.is_even()); // etc } Unlike default impls, which provide an impl, generic blanket impls provide the impl, so they are not overridable.
use std::fmt::Debug; use std::convert::TryInto; use std::ops::Rem; trait Even { fn is_even(self) -> bool; } impl&lt;T> Even for T where T: Rem&lt;Output = T> + PartialEq&lt;T> + Sized, u8: TryInto&lt;T>, &lt;u8 as TryInto&lt;T>>::Error: Debug, { fn is_even(self) -> bool { self % 2.try_into().unwrap() == 0.try_into().unwrap() } } impl Even for u8 { // ❌ fn is_even(self) -> bool { self % 2_u8 == 0_u8 } } Throws:
error[E0119]: conflicting implementations of trait `Even` for type `u8`: --> src/lib.rs:22:1 | 10 | / impl&lt;T> Even for T 11 | | where 12 | | T: Rem&lt;Output = T> + PartialEq&lt;T> + Sized, 13 | | u8: TryInto&lt;T>, ... | 19 | | } 20 | | } | |_- first implementation here 21 | 22 | impl Even for u8 { | ^^^^^^^^^^^^^^^^ conflicting implementation for `u8` These impls overlap, hence they conflict, hence Rust rejects the code to ensure trait coherence. Trait coherence is the property that there exists at most one impl of a trait for any given type. The rules Rust uses to enforce trait coherence, the implications of those rules, and workarounds for the implications are outside the scope of this article.
Subtraits &amp; Supertraits The &ldquo;sub&rdquo; in &ldquo;subtrait&rdquo; refers to subset and the &ldquo;super&rdquo; in &ldquo;supertrait&rdquo; refers to superset. If we have this trait declaration:
trait Subtrait: Supertrait {} All of the types which impl Subtrait are a subset of all the types which impl Supertrait, or to put it in opposite but equivalent terms: all the types which impl Supertrait are a superset of all the types which impl Subtrait.
Also, the above is just syntax sugar for:
trait Subtrait where Self: Supertrait {} It&rsquo;s a subtle yet important distinction to understand that the bound is on Self, i.e. the type impling Subtrait, and not on Subtrait itself. The latter would not make any sense, since trait bounds can only be applied to concrete types which can impl traits. Traits cannot impl other traits:
trait Supertrait { fn method(&amp;self) { println!("in supertrait"); } } trait Subtrait: Supertrait { // this looks like it might impl or // override Supertrait::method but it // does not fn method(&amp;self) { println!("in subtrait") } } struct SomeType; // adds Supertrait::method to SomeType impl Supertrait for SomeType {} // adds Subtrait::method to SomeType impl Subtrait for SomeType {} // both methods exist on SomeType simultaneously // neither overriding or shadowing the other fn main() { SomeType.method(); // ❌ ambiguous method call // must disambiguate using fully-qualified syntax &lt;SomeType as Supertrait>::method(&amp;st); // ✅ prints "in supertrait" &lt;SomeType as Subtrait>::method(&amp;st); // ✅ prints "in subtrait" } Furthermore, there are no rules for how a type must impl both a subtrait and a supertrait. It can use the methods from either in the impl of the other.
trait Supertrait { fn super_method(&amp;mut self); } trait Subtrait: Supertrait { fn sub_method(&amp;mut self); } struct CallSuperFromSub; impl Supertrait for CallSuperFromSub { fn super_method(&amp;mut self) { println!("in super"); } } impl Subtrait for CallSuperFromSub { fn sub_method(&amp;mut self) { println!("in sub"); self.super_method(); } } struct CallSubFromSuper; impl Supertrait for CallSubFromSuper { fn super_method(&amp;mut self) { println!("in super"); self.sub_method(); } } impl Subtrait for CallSubFromSuper { fn sub_method(&amp;mut self) { println!("in sub"); } } struct CallEachOther(bool); impl Supertrait for CallEachOther { fn super_method(&amp;mut self) { println!("in super"); if self.0 { self.0 = false; self.sub_method(); } } } impl Subtrait for CallEachOther { fn sub_method(&amp;mut self) { println!("in sub"); if self.0 { self.0 = false; self.super_method(); } } } fn main() { CallSuperFromSub.super_method(); // prints "in super" CallSuperFromSub.sub_method(); // prints "in sub", "in super" CallSubFromSuper.super_method(); // prints "in super", "in sub" CallSubFromSuper.sub_method(); // prints "in sub" CallEachOther(true).super_method(); // prints "in super", "in sub" CallEachOther(true).sub_method(); // prints "in sub", "in super" } Hopefully the examples above show that the relationship between subtraits and supertraits can be complex. Before introducing a mental model that neatly encapsulates all of that complexity let&rsquo;s quickly review and establish the mental model we use for understanding trait bounds on generic types:
fn function&lt;T: Clone>(t: T) { // impl } Without knowing anything about the impl of this function we could reasonably guess that t.clone() gets called at some point because when a generic type is bounded by a trait that strongly implies it has a dependency on the trait. The mental model for understanding the relationship between generic types and their trait bounds is a simple and intuitive one: generic types depend on their trait bounds.
Now let&rsquo;s look the trait declaration for Copy:
trait Copy: Clone {} The syntax above looks very similar to the syntax for applying a trait bound on a generic type and yet Copy doesn&rsquo;t depend on Clone at all. The mental model we developed earlier doesn&rsquo;t help us here. In my opinion, the most simple and elegant mental model for understanding the relationship between subtraits and supertraits is: subtraits refine their supertraits.
&ldquo;Refinement&rdquo; is intentionally kept somewhat vague because it can mean different things in different contexts:
a subtrait might make its supertrait&rsquo;s methods&rsquo; impls more specialized, faster, use less memory, e.g. Copy: Clone a subtrait might make additional guarantees about the supertrait&rsquo;s methods&rsquo; impls, e.g. Eq: PartialEq, Ord: PartialOrd, ExactSizeIterator: Iterator a subtrait might make the supertrait&rsquo;s methods more flexible or easier to call, e.g. FnMut: FnOnce, Fn: FnMut a subtrait might extend a supertrait and add new methods, e.g. DoubleEndedIterator: Iterator, ExactSizeIterator: Iterator Trait Objects Generics give us compile-time polymorphism where trait objects give us run-time polymorphism. We can use trait objects to allow functions to dynamically return different types at run-time:
fn example(condition: bool, vec: Vec&lt;i32>) -> Box&lt;dyn Iterator&lt;Item = i32>> { let iter = vec.into_iter(); if condition { // Has type: // Box&lt;Map&lt;IntoIter&lt;i32>, Fn(i32) -> i32>> // But is cast to: // Box&lt;dyn Iterator&lt;Item = i32>> Box::new(iter.map(|n| n * 2)) } else { // Has type: // Box&lt;Filter&lt;IntoIter&lt;i32>, Fn(&amp;i32) -> bool>> // But is cast to: // Box&lt;dyn Iterator&lt;Item = i32>> Box::new(iter.filter(|&amp;n| n >= 2)) } } Trait objects also allow us to store heterogeneous types in collections:
use std::f64::consts::PI; struct Circle { radius: f64, } struct Square { side: f64 } trait Shape { fn area(&amp;self) -> f64; } impl Shape for Circle { fn area(&amp;self) -> f64 { PI * self.radius * self.radius } } impl Shape for Square { fn area(&amp;self) -> f64 { self.side * self.side } } fn get_total_area(shapes: Vec&lt;Box&lt;dyn Shape>>) -> f64 { shapes.into_iter().map(|s| s.area()).sum() } fn example() { let shapes: Vec&lt;Box&lt;dyn Shape>> = vec![ Box::new(Circle { radius: 1.0 }), // Box&lt;Circle> cast to Box&lt;dyn Shape> Box::new(Square { side: 1.0 }), // Box&lt;Square> cast to Box&lt;dyn Shape> ]; assert_eq!(PI + 1.0, get_total_area(shapes)); // ✅ } Trait objects are unsized so they must always be behind a pointer. We can tell the difference between a concrete type and a trait object at the type level based on the presence of the dyn keyword within the type:
struct Struct; trait Trait {} // regular struct &amp;Struct Box&lt;Struct> Rc&lt;Struct> Arc&lt;Struct> // trait objects &amp;dyn Trait Box&lt;dyn Trait> Rc&lt;dyn Trait> Arc&lt;dyn Trait> Not all traits can be converted into trait objects. A trait is object-safe if it meets these requirements:
trait doesn&rsquo;t require Self: Sized all of the trait&rsquo;s methods are object-safe A trait method is object-safe if it meets these requirements:
method requires Self: Sized or method only uses a Self type in receiver position Understanding why the requirements are what they are is not relevant to the rest of this article, but if you&rsquo;re still curious it&rsquo;s covered in Sizedness in Rust.
Marker Traits Marker traits are traits that have no trait items. Their job is to &ldquo;mark&rdquo; the implementing type as having some property which is otherwise not possible to represent using the type system.
// Impling PartialEq for a type promises // that equality for the type has these properties: // - symmetry: a == b implies b == a, and // - transitivity: a == b &amp;&amp; b == c implies a == c // But DOES NOT promise this property: // - reflexivity: a == a trait PartialEq { fn eq(&amp;self, other: &amp;Self) -> bool; } // Eq has no trait items! The eq method is already // declared by PartialEq, but "impling" Eq // for a type promises this additional equality property: // - reflexivity: a == a trait Eq: PartialEq {} // f64 impls PartialEq but not Eq because NaN != NaN // i32 impls PartialEq &amp; Eq because there's no NaNs :) Auto Traits Auto traits are traits that get automatically implemented for a type if all of its members also impl the trait. What &ldquo;members&rdquo; means depends on the type, for example: fields of a struct, variants of an enum, elements of an array, items of a tuple, and so on.
All auto traits are marker traits but not all marker traits are auto traits. Auto traits must be marker traits so the compiler can provide an automatic default impl for them, which would not be possible if they had any trait items.
Examples of auto traits:
// implemented for types which are safe to send between threads unsafe auto trait Send {} // implemented for types whose references are safe to send between threads unsafe auto trait Sync {} Unsafe Traits Traits can be marked unsafe to indicate that impling the trait might require unsafe code. Both Send and Sync are marked unsafe because if they aren&rsquo;t automatically implemented for a type that means it must contains some non-Send or non-Sync member and we have to take extra care as the implementers to make sure there are no data races if we want to manually mark the type as Send and Sync.
// SomeType is not Send or Sync struct SomeType { not_send_or_sync: *const (), } // but if we're confident that our impl doesn't have any data // races we can explicitly mark it as Send and Sync using unsafe unsafe impl Send for SomeType {} unsafe impl Sync for SomeType {} Auto Traits Send &amp; Sync Prerequisites
Marker Traits Auto Traits Unsafe Traits unsafe auto trait Send {} unsafe auto trait Sync {} If a type is Send that means it&rsquo;s safe to send between threads. If a type is Sync that means it&rsquo;s safe to share references of it between threads. In more precise terms some type T is Sync if and only if &amp;T is Send.
Almost all types are Send and Sync. The only notable Send exception is Rc and the only notable Sync exceptions are Rc, Cell, RefCell. If we need a Send version of Rc we can use Arc. If we need a Sync version of Cell or RefCell we can Mutex or RwLock. Although if we&rsquo;re using the Mutex or RwLock to just wrap a primitive type it&rsquo;s often better to use the atomic primitive types provided by the standard library such as AtomicBool, AtomicI32, AtomicUsize, and so on.
That almost all types are Sync might be a surprise to some people, but yup, it&rsquo;s true even for types without any internal synchronization. This is possible thanks to Rust&rsquo;s strict borrowing rules.
We can pass many immutable references to the same data to many threads and we&rsquo;re guaranteed there are no data races because as long as any immutable references exist Rust statically guarantees the underlying data cannot be mutated:
use crossbeam::thread; fn main() { let mut greeting = String::from("Hello"); let greeting_ref = &amp;greeting; thread::scope(|scoped_thread| { // spawn 3 threads for n in 1..=3 { // greeting_ref copied into every thread scoped_thread.spawn(move |_| { println!("{} {}", greeting_ref, n); // prints "Hello {n}" }); } // line below could cause UB or data races but compiler rejects it greeting += " world"; // ❌ cannot mutate greeting while immutable refs exist }); // can mutate greeting after every thread has joined greeting += " world"; // ✅ println!("{}", greeting); // prints "Hello world" } Likewise we can pass a single mutable reference to some data to a single thread and we&rsquo;re guaranteed there will be no data races because Rust statically guarantees aliased mutable references cannot exist and the underlying data cannot be mutated through anything other than the single existing mutable reference:
use crossbeam::thread; fn main() { let mut greeting = String::from("Hello"); let greeting_ref = &amp;mut greeting; thread::scope(|scoped_thread| { // greeting_ref moved into thread scoped_thread.spawn(move |_| { *greeting_ref += " world"; println!("{}", greeting_ref); // prints "Hello world" }); // line below could cause UB or data races but compiler rejects it greeting += "!!!"; // ❌ cannot mutate greeting while mutable refs exist }); // can mutate greeting after the thread has joined greeting += "!!!"; // ✅ println!("{}", greeting); // prints "Hello world!!!" } This is why most types are Sync without requiring any explicit synchronization. In the event we need to simultaneously mutate some data T across multiple threads the compiler won&rsquo;t let us until we wrap the data in a Arc&lt;Mutex&lt;T>> or Arc&lt;RwLock&lt;T>> so the compiler enforces that explicit synchronization is used when it&rsquo;s needed.
Sized Prerequisites
Marker Traits Auto Traits If a type is Sized that means its size in bytes is known at compile-time and it&rsquo;s possible to put instances of the type on the stack.
Sizedness of types and its implications is a subtle yet huge topic that affects a lot of different aspects of the language. It&rsquo;s so important that I wrote an entire article on it called Sizedness in Rust which I highly recommend reading for anyone who would like to understand sizedness in-depth. I&rsquo;ll summarize a few key things which are relevant to this article.
All generic types get an implicit Sized bound. fn func&lt;T>(t: &amp;T) {} // example above desugared fn func&lt;T: Sized>(t: &amp;T) {} Since there&rsquo;s an implicit Sized bound on all generic types, if we want to opt-out of this implicit bound we need to use the special &ldquo;relaxed bound&rdquo; syntax ?Sized which currently only exists for the Sized trait: // now T can be unsized fn func&lt;T: ?Sized>(t: &amp;T) {} There&rsquo;s an implicit ?Sized bound on all traits. trait Trait {} // example above desugared trait Trait: ?Sized {} This is so that trait objects can impl the trait. Again, all of the nitty gritty details are in Sizedness in Rust.
General traits Default Prerequisites
Self Functions Derive Macros trait Default { fn default() -> Self; } It&rsquo;s possible to construct default values of Default types.
struct Color { r: u8, g: u8, b: u8, } impl Default for Color { // default color is black fn default() -> Self { Color { r: 0, g: 0, b: 0, } } } This is useful for quick prototyping but also in any instance where we just need an instance of a type and aren&rsquo;t picky about what it is:
fn main() { // just give me some color! let color = Color::default(); } This is also an option we may want to explicitly expose to the users of our functions:
struct Canvas; enum Shape { Circle, Rectangle, } impl Canvas { // let user optionally pass a color fn paint(&amp;mut self, shape: Shape, color: Option&lt;Color>) { // if no color is passed use the default color let color = color.unwrap_or_default(); // etc } } Default is also useful in generic contexts where we need to construct generic types:
fn guarantee_length&lt;T: Default>(mut vec: Vec&lt;T>, min_len: usize) -> Vec&lt;T> { for _ in 0..min_len.saturating_sub(vec.len()) { vec.push(T::default()); } vec } Another way we can take advantage of Default types is for partial initialization of structs using Rust&rsquo;s struct update syntax. We may have a new constructor for Color which takes every member as an argument:
impl Color { fn new(r: u8, g: u8, b: u8) -> Self { Color { r, g, b, } } } However we can also have convenience constructors that only accept a particular struct member each and fall back to the default values for the other struct members:
impl Color { fn red(r: u8) -> Self { Color { r, ..Color::default() } } fn green(g: u8) -> Self { Color { g, ..Color::default() } } fn blue(b: u8) -> Self { Color { b, ..Color::default() } } } There&rsquo;s also a Default derive macro for so we can write Color like this:
// default color is still black // because u8::default() == 0 #[derive(Default)] struct Color { r: u8, g: u8, b: u8 } Clone Prerequisites
Self Methods Default Impls Derive Macros trait Clone { fn clone(&amp;self) -> Self; // provided default impls fn clone_from(&amp;mut self, source: &amp;Self); } We can convert immutable references of Clone types into owned values, i.e. &amp;T -> T. Clone makes no promises about the efficiency of this conversion so it can be slow and expensive. To quickly impl Clone on a type we can use the derive macro:
#[derive(Clone)] struct SomeType { cloneable_member1: CloneableType1, cloneable_member2: CloneableType2, // etc } // macro generates impl below impl Clone for SomeType { fn clone(&amp;self) -> Self { SomeType { cloneable_member1: self.cloneable_member1.clone(), cloneable_member2: self.cloneable_member2.clone(), // etc } } } Clone can also be useful in constructing instances of a type within a generic context. Here&rsquo;s an example from the previous section except using Clone instead of Default:
fn guarantee_length&lt;T: Clone>(mut vec: Vec&lt;T>, min_len: usize, fill_with: &amp;T) -> Vec&lt;T> { for _ in 0..min_len.saturating_sub(vec.len()) { vec.push(fill_with.clone()); } vec } People also commonly use cloning as an escape hatch to avoid dealing with the borrow checker. Managing structs with references can be challenging, but we can turn the references into owned values by cloning them.
// oof, we gotta worry about lifetimes 😟 struct SomeStruct&lt;'a> { data: &amp;'a Vec&lt;u8>, } // now we're on easy street 😎 struct SomeStruct { data: Vec&lt;u8>, } If we&rsquo;re working on a program where performance is not the utmost concern then we don&rsquo;t need to sweat cloning data. Rust is a low-level language that exposes a lot of low-level details so it&rsquo;s easy to get caught up in premature optimizations instead of actually solving the problem at hand. For many programs the best order of priorities is usually to build for correctness first, elegance second, and performance third, and only focus on performance after the program has been profiled and the performance bottlenecks have been identified. This is good general advice to follow, and if it doesn&rsquo;t apply to your particular program then you would know.
Copy Prerequisites
Marker Traits Subtraits &amp; Supertraits Derive Macros trait Copy: Clone {} We copy Copy types, e.g. T -> T. Copy promises the copy operation will be a simple bitwise copy so it will be very fast and efficient. We cannot impl Copy ourselves, only the compiler can provide an impl, but we can tell it to do so by using the Copy derive macro, together with the Clone derive macro since Copy is a subtrait of Clone:
#[derive(Copy, Clone)] struct SomeType; Copy refines Clone. A clone may be slow and expensive but a copy is guaranteed to be fast and cheap, so a copy is just a fast clone. If a type impls Copy that makes the Clone impl trivial:
// this is what the derive macro generates impl&lt;T: Copy> Clone for T { // the clone method becomes just a copy fn clone(&amp;self) -> Self { *self } } Impling Copy for a type changes its behavior when it gets moved. By default all types have move semantics but once a type impls Copy it gets copy semantics. To explain the difference between the two let&rsquo;s examine these simple scenarios:
// a "move", src: !Copy let dest = src; // a "copy", src: Copy let dest = src; In both cases, dest = src performs a simple bitwise copy of src&rsquo;s contents and moves the result into dest, the only difference is that in the case of &ldquo;a move&rdquo; the borrow checker invalidates the src variable and makes sure it&rsquo;s not used anywhere else later and in the case of &ldquo;a copy&rdquo; src remains valid and usable.
In a nutshell: Copies are moves. Moves are copies. The only difference is how they&rsquo;re treated by the borrow checker.
For a more concrete example of a move, imagine src was a Vec&lt;i32> and its contents looked something like this:
{ data: *mut [i32], length: usize, capacity: usize } When we write dest = src we end up with:
src = { data: *mut [i32], length: usize, capacity: usize } dest = { data: *mut [i32], length: usize, capacity: usize } At this point both src and dest have aliased mutable references to the same data, which is a big no-no, so the borrow checker invalidates the src variable so it can&rsquo;t be used again without throwing a compile error.
For a more concrete example of a copy, imagine src was an Option&lt;i32> and its contents looked something like this:
{ is_valid: bool, data: i32 } Now when we write dest = src we end up with:
src = { is_valid: bool, data: i32 } dest = { is_valid: bool, data: i32 } These are both usable simultaneously! Hence Option&lt;i32> is Copy.
Although Copy could be an auto trait the Rust language designers decided it&rsquo;s simpler and safer for types to explicitly opt into copy semantics rather than silently inheriting copy semantics whenever the type is eligible, as the latter can cause surprising confusing behavior which often leads to bugs.
Any Prerequisites
Self Generic Blanket Impls Subtraits &amp; Supertraits Trait Objects trait Any: 'static { fn type_id(&amp;self) -> TypeId; } Rust&rsquo;s style of polymorphism is parametric, but if we&rsquo;re looking to use a more ad-hoc style of polymorphism similar to dynamically-typed languages then we can emulate that using the Any trait. We don&rsquo;t have to manually impl this trait for our types because that&rsquo;s already covered by this generic blanket impl:
impl&lt;T: 'static + ?Sized> Any for T { fn type_id(&amp;self) -> TypeId { TypeId::of::&lt;T>() } } The way we get a T out of a dyn Any is by using the downcast_ref::&lt;T>() and downcast_mut::&lt;T>() methods:
use std::any::Any; #[derive(Default)] struct Point { x: i32, y: i32, } impl Point { fn inc(&amp;mut self) { self.x += 1; self.y += 1; } } fn map_any(mut any: Box&lt;dyn Any>) -> Box&lt;dyn Any> { if let Some(num) = any.downcast_mut::&lt;i32>() { *num += 1; } else if let Some(string) = any.downcast_mut::&lt;String>() { *string += "!"; } else if let Some(point) = any.downcast_mut::&lt;Point>() { point.inc(); } any } fn main() { let mut vec: Vec&lt;Box&lt;dyn Any>> = vec![ Box::new(0), Box::new(String::from("a")), Box::new(Point::default()), ]; // vec = [0, "a", Point { x: 0, y: 0 }] vec = vec.into_iter().map(map_any).collect(); // vec = [1, "a!", Point { x: 1, y: 1 }] } This trait rarely needs to be used because on top of parametric polymorphism being superior to ad-hoc polymorphism in most scenarios the latter can also be emulated using enums which are more type-safe and require less indirection. For example, we could have written the above example like this:
#[derive(Default)] struct Point { x: i32, y: i32, } impl Point { fn inc(&amp;mut self) { self.x += 1; self.y += 1; } } enum Stuff { Integer(i32), String(String), Point(Point), } fn map_stuff(mut stuff: Stuff) -> Stuff { match &amp;mut stuff { Stuff::Integer(num) => *num += 1, Stuff::String(string) => *string += "!", Stuff::Point(point) => point.inc(), } stuff } fn main() { let mut vec = vec![ Stuff::Integer(0), Stuff::String(String::from("a")), Stuff::Point(Point::default()), ]; // vec = [0, "a", Point { x: 0, y: 0 }] vec = vec.into_iter().map(map_stuff).collect(); // vec = [1, "a!", Point { x: 1, y: 1 }] } Despite Any rarely being needed it can still be convenient to use sometimes, as we&rsquo;ll later see in the Error Handling section.
Formatting Traits We can serialize types into strings using the formatting macros in std::fmt, the most well-known of the bunch being println!. We can pass formatting parameters to the {} placeholders used within format strs which are then used to select which trait impl to use to serialize the placeholder&rsquo;s argument.
Trait Placeholder Description Display {} display representation Debug {:?} debug representation Octal {:o} octal representation LowerHex {:x} lowercase hex representation UpperHex {:X} uppercase hex representation Pointer {:p} memory address Binary {:b} binary representation LowerExp {:e} lowercase exponential representation UpperExp {:E} uppercase exponential representation Display &amp; ToString Prerequisites
Self Methods Generic Blanket Impls trait Display { fn fmt(&amp;self, f: &amp;mut Formatter&lt;'_>) -> Result; } Display types can be serialized into Strings which are friendly to the end users of the program. Example impl for Point:
use std::fmt; #[derive(Default)] struct Point { x: i32, y: i32, } impl fmt::Display for Point { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { write!(f, "({}, {})", self.x, self.y) } } fn main() { println!("origin: {}", Point::default()); // prints "origin: (0, 0)" // get Point's Display representation as a String let stringified_point = format!("{}", Point::default()); assert_eq!("(0, 0)", stringified_point); // ✅ } Aside from using the format! macro to get a type&rsquo;s display representation as a String we can use the ToString trait:
trait ToString { fn to_string(&amp;self) -> String; } There&rsquo;s no need for us to impl this ourselves. In fact we can&rsquo;t, because of this generic blanket impl that automatically impls ToString for any type which impls Display:
impl&lt;T: Display + ?Sized> ToString for T; Using ToString with Point:
#[test] // ✅ fn display_point() { let origin = Point::default(); assert_eq!(format!("{}", origin), "(0, 0)"); } #[test] // ✅ fn point_to_string() { let origin = Point::default(); assert_eq!(origin.to_string(), "(0, 0)"); } #[test] // ✅ fn display_equals_to_string() { let origin = Point::default(); assert_eq!(format!("{}", origin), origin.to_string()); } Debug Prerequisites
Self Methods Derive Macros Display &amp; ToString trait Debug { fn fmt(&amp;self, f: &amp;mut Formatter&lt;'_>) -> Result; } Debug has an identical signature to Display. The only difference is that the Debug impl is called when we use the {:?} formatting specifier. Debug can be derived:
use std::fmt; #[derive(Debug)] struct Point { x: i32, y: i32, } // derive macro generates impl below impl fmt::Debug for Point { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { f.debug_struct("Point") .field("x", &amp;self.x) .field("y", &amp;self.y) .finish() } } Impling Debug for a type also allows it to be used within the dbg! macro which is superior to println! for quick and dirty print logging. Some of its advantages:
dbg! prints to stderr instead of stdout so the debug logs are easy to separate from the actual stdout output of our program. dbg! prints the expression passed to it as well as the value the expression evaluated to. dbg! takes ownership of its arguments and returns them so you can use it within expressions: fn some_condition() -> bool { true } // no logging fn example() { if some_condition() { // some code } } // println! logging fn example_println() { // 🤦 let result = some_condition(); println!("{}", result); // just prints "true" if result { // some code } } // dbg! logging fn example_dbg() { // 😍 if dbg!(some_condition()) { // prints "[src/main.rs:22] some_condition() = true" // some code } } The only downside is that dbg! isn&rsquo;t automatically stripped in release builds so we have to manually remove it from our code if we don&rsquo;t want to ship it in the final executable.
Operator Traits All operators in Rust are associated with traits. If we&rsquo;d like to impl operators for our types we have to impl the associated traits.
Trait(s) Category Operator(s) Description Eq, PartialEq comparison == equality Ord, PartialOrd comparison &lt;, >, &lt;=, >= comparison Add arithmetic + addition AddAssign arithmetic += addition assignment BitAnd arithmetic &amp; bitwise AND BitAndAssign arithmetic &amp;= bitwise assignment BitXor arithmetic ^ bitwise XOR BitXorAssign arithmetic ^= bitwise XOR assignment Div arithmetic / division DivAssign arithmetic /= division assignment Mul arithmetic * multiplication MulAssign arithmetic *= multiplication assignment Neg arithmetic - unary negation Not arithmetic ! unary logical negation Rem arithmetic % remainder RemAssign arithmetic %= remainder assignment Shl arithmetic &lt;&lt; left shift ShlAssign arithmetic &lt;&lt;= left shift assignment Shr arithmetic >> right shift ShrAssign arithmetic >>= right shift assignment Sub arithmetic - subtraction SubAssign arithmetic -= subtraction assignment Fn closure (...args) immutable closure invocation FnMut closure (...args) mutable closure invocation FnOnce closure (...args) one-time closure invocation Deref other * immutable dereference DerefMut other * mutable derenence Drop other - type destructor Index other [] immutable index IndexMut other [] mutable index RangeBounds other .. range Comparison Traits Trait(s) Category Operator(s) Description Eq, PartialEq comparison == equality Ord, PartialOrd comparison &lt;, >, &lt;=, >= comparison PartialEq &amp; Eq Prerequisites
Self Methods Generic Parameters Default Impls Generic Blanket Impls Marker Traits Subtraits &amp; Supertraits Sized trait PartialEq&lt;Rhs = Self> where Rhs: ?Sized, { fn eq(&amp;self, other: &amp;Rhs) -> bool; // provided default impls fn ne(&amp;self, other: &amp;Rhs) -> bool; } PartialEq&lt;Rhs> types can be checked for equality to Rhs types using the == operator.
All PartialEq&lt;Rhs> impls must ensure that equality is symmetric and transitive. That means for all a, b, and c:
a == b implies b == a (symmetry) a == b &amp;&amp; b == c implies a == c (transitivity) By default Rhs = Self because we almost always want to compare instances of a type to each other, and not to instances of different types. This also automatically guarantees our impl is symmetric and transitive.
struct Point { x: i32, y: i32 } // Rhs == Self == Point impl PartialEq for Point { // impl automatically symmetric &amp; transitive fn eq(&amp;self, other: &amp;Point) -> bool { self.x == other.x &amp;&amp; self.y == other.y } } If all the members of a type impl PartialEq then it can be derived:
#[derive(PartialEq)] struct Point { x: i32, y: i32 } #[derive(PartialEq)] enum Suit { Spade, Heart, Club, Diamond, } Once we impl PartialEq for our type we also get equality comparisons between references of our type for free thanks to these generic blanket impls:
// this impl only gives us: Point == Point #[derive(PartialEq)] struct Point { x: i32, y: i32 } // all of the generic blanket impls below // are provided by the standard library // this impl gives us: &amp;Point == &amp;Point impl&lt;A, B> PartialEq&lt;&amp;'_ B> for &amp;'_ A where A: PartialEq&lt;B> + ?Sized, B: ?Sized; // this impl gives us: &amp;mut Point == &amp;Point impl&lt;A, B> PartialEq&lt;&amp;'_ B> for &amp;'_ mut A where A: PartialEq&lt;B> + ?Sized, B: ?Sized; // this impl gives us: &amp;Point == &amp;mut Point impl&lt;A, B> PartialEq&lt;&amp;'_ mut B> for &amp;'_ A where A: PartialEq&lt;B> + ?Sized, B: ?Sized; // this impl gives us: &amp;mut Point == &amp;mut Point impl&lt;A, B> PartialEq&lt;&amp;'_ mut B> for &amp;'_ mut A where A: PartialEq&lt;B> + ?Sized, B: ?Sized; Since this trait is generic we can define equality between different types. The standard library leverages this to allow checking equality between the many string-like types such as String, &amp;str, PathBuf, &amp;Path, OsString, &amp;OsStr, and so on.
Generally, we should only impl equality between different types if they contain the same kind of data and the only difference between the types is how they represent the data or how they allow interacting with the data.
Here&rsquo;s a cute but bad example of how someone might be tempted to impl PartialEq to check equality between different types that don&rsquo;t meet the above criteria:
#[derive(PartialEq)] enum Suit { Spade, Club, Heart, Diamond, } #[derive(PartialEq)] enum Rank { Ace, Two, Three, Four, Five, Six, Seven, Eight, Nine, Ten, Jack, Queen, King, } #[derive(PartialEq)] struct Card { suit: Suit, rank: Rank, } // check equality of Card's suit impl PartialEq&lt;Suit> for Card { fn eq(&amp;self, other: &amp;Suit) -> bool { self.suit == *other } } // check equality of Card's rank impl PartialEq&lt;Rank> for Card { fn eq(&amp;self, other: &amp;Rank) -> bool { self.rank == *other } } fn main() { let AceOfSpades = Card { suit: Suit::Spade, rank: Rank::Ace, }; assert!(AceOfSpades == Suit::Spade); // ✅ assert!(AceOfSpades == Rank::Ace); // ✅ } It works and kinda makes sense. A card which is an Ace of Spades is both an Ace and a Spade, and if we&rsquo;re writing a library to handle playing cards it&rsquo;s reasonable that we&rsquo;d want to make it easy and convenient to individually check the suit and rank of a card. However, something&rsquo;s missing: symmetry! We can Card == Suit and Card == Rank but we cannot Suit == Card or Rank == Card so let&rsquo;s fix that:
// check equality of Card's suit impl PartialEq&lt;Suit> for Card { fn eq(&amp;self, other: &amp;Suit) -> bool { self.suit == *other } } // added for symmetry impl PartialEq&lt;Card> for Suit { fn eq(&amp;self, other: &amp;Card) -> bool { *self == other.suit } } // check equality of Card's rank impl PartialEq&lt;Rank> for Card { fn eq(&amp;self, other: &amp;Rank) -> bool { self.rank == *other } } // added for symmetry impl PartialEq&lt;Card> for Rank { fn eq(&amp;self, other: &amp;Card) -> bool { *self == other.rank } } We have symmetry! Great. Adding symmetry just broke transitivity! Oops. This is now possible:
fn main() { // Ace of Spades let a = Card { suit: Suit::Spade, rank: Rank::Ace, }; let b = Suit::Spade; // King of Spades let c = Card { suit: Suit::Spade, rank: Rank::King, }; assert!(a == b &amp;&amp; b == c); // ✅ assert!(a == c); // ❌ } A good example of impling PartialEq to check equality between different types would be a program that works with distances and uses different types to represent different units of measurement.
#[derive(PartialEq)] struct Foot(u32); #[derive(PartialEq)] struct Yard(u32); #[derive(PartialEq)] struct Mile(u32); impl PartialEq&lt;Mile> for Foot { fn eq(&amp;self, other: &amp;Mile) -> bool { self.0 == other.0 * 5280 } } impl PartialEq&lt;Foot> for Mile { fn eq(&amp;self, other: &amp;Foot) -> bool { self.0 * 5280 == other.0 } } impl PartialEq&lt;Mile> for Yard { fn eq(&amp;self, other: &amp;Mile) -> bool { self.0 == other.0 * 1760 } } impl PartialEq&lt;Yard> for Mile { fn eq(&amp;self, other: &amp;Yard) -> bool { self.0 * 1760 == other.0 } } impl PartialEq&lt;Foot> for Yard { fn eq(&amp;self, other: &amp;Foot) -> bool { self.0 * 3 == other.0 } } impl PartialEq&lt;Yard> for Foot { fn eq(&amp;self, other: &amp;Yard) -> bool { self.0 == other.0 * 3 } } fn main() { let a = Foot(5280); let b = Yard(1760); let c = Mile(1); // symmetry assert!(a == b &amp;&amp; b == a); // ✅ assert!(b == c &amp;&amp; c == b); // ✅ assert!(a == c &amp;&amp; c == a); // ✅ // transitivity assert!(a == b &amp;&amp; b == c &amp;&amp; a == c); // ✅ assert!(c == b &amp;&amp; b == a &amp;&amp; c == a); // ✅ } Eq is a marker trait and a subtrait of PartialEq&lt;Self>.
trait Eq: PartialEq&lt;Self> {} If we impl Eq for a type, on top of the symmetry &amp; transitivity properties required by PartialEq, we&rsquo;re also guaranteeing reflexivity, i.e. a == a for all a. In this sense Eq refines PartialEq because it represents a stricter version of equality. If all members of a type impl Eq then the Eq impl can be derived for the type.
Floats are PartialEq but not Eq because NaN != NaN. Almost all other PartialEq types are trivially Eq, unless of course if they contain floats.
Once a type impls PartialEq and Debug we can use it in the assert_eq! macro. We can also compare collections of PartialEq types.
#[derive(PartialEq, Debug)] struct Point { x: i32, y: i32, } fn example_assert(p1: Point, p2: Point) { assert_eq!(p1, p2); } fn example_compare_collections&lt;T: PartialEq>(vec1: Vec&lt;T>, vec2: Vec&lt;T>) { // if T: PartialEq this now works! if vec1 == vec2 { // some code } else { // other code } } Hash Prerequisites
Self Methods Generic Parameters Default Impls Derive Macros PartialEq &amp; Eq trait Hash { fn hash&lt;H: Hasher>(&amp;self, state: &amp;mut H); // provided default impls fn hash_slice&lt;H: Hasher>(data: &amp;[Self], state: &amp;mut H); } This trait is not associated with any operator, but the best time to talk about it is right after PartialEq &amp; Eq so here it is. Hash types can be hashed using a Hasher.
use std:#️⃣:Hasher; use std:#️⃣:Hash; struct Point { x: i32, y: i32, } impl Hash for Point { fn hash&lt;H: Hasher>(&amp;self, hasher: &amp;mut H) { hasher.write_i32(self.x); hasher.write_i32(self.y); } } There&rsquo;s a derive macro which generates the same impl as above:
#[derive(Hash)] struct Point { x: i32, y: i32, } If a type impls both Hash and Eq those impls must agree with each other such that for all a and b if a == b then a.hash() == b.hash(). So we should always use the derive macro to impl both or manually impl both, but not mix the two, otherwise we risk breaking the above invariant.
The main benefit of impling Eq and Hash for a type is that it allows us to store that type as keys in HashMaps and HashSets.
use std::collections::HashSet; // now our type can be stored // in HashSets and HashMaps! #[derive(PartialEq, Eq, Hash)] struct Point { x: i32, y: i32, } fn example_hashset() { let mut points = HashSet::new(); points.insert(Point { x: 0, y: 0 }); // ✅ } PartialOrd &amp; Ord Prerequisites
Self Methods Generic Parameters Default Impls Subtraits &amp; Supertraits Derive Macros Sized PartialEq &amp; Eq enum Ordering { Less, Equal, Greater, } trait PartialOrd&lt;Rhs = Self>: PartialEq&lt;Rhs> where Rhs: ?Sized, { fn partial_cmp(&amp;self, other: &amp;Rhs) -> Option&lt;Ordering>; // provided default impls fn lt(&amp;self, other: &amp;Rhs) -> bool; fn le(&amp;self, other: &amp;Rhs) -> bool; fn gt(&amp;self, other: &amp;Rhs) -> bool; fn ge(&amp;self, other: &amp;Rhs) -> bool; } PartialOrd&lt;Rhs> types can be compared to Rhs types using the &lt;, &lt;=, >, and >= operators.
All PartialOrd impls must ensure that comparisons are asymmetric and transitive. That means for all a, b, and c:
a &lt; b implies !(a > b) (asymmetry) a &lt; b &amp;&amp; b &lt; c implies a &lt; c (transitivity) PartialOrd is a subtrait of PartialEq and their impls must always agree with each other.
fn must_always_agree&lt;T: PartialOrd + PartialEq>(t1: T, t2: T) { assert_eq!(t1.partial_cmp(&amp;t2) == Some(Ordering::Equal), t1 == t2); } PartialOrd refines PartialEq in the sense that when comparing PartialEq types we can check if they are equal or not equal, but when comparing PartialOrd types we can check if they are equal or not equal, and if they are not equal we can check if they are unequal because the first item is less than or greater than the second item.
By default Rhs = Self because we almost always want to compare instances of a type to each other, and not to instances of different types. This also automatically guarantees our impl is symmetric and transitive.
use std::cmp::Ordering; #[derive(PartialEq, PartialOrd)] struct Point { x: i32, y: i32 } // Rhs == Self == Point impl PartialOrd for Point { // impl automatically symmetric &amp; transitive fn partial_cmp(&amp;self, other: &amp;Point) -> Option&lt;Ordering> { Some(match self.x.cmp(&amp;other.x) { Ordering::Equal => self.y.cmp(&amp;other.y), ordering => ordering, }) } } If all the members of a type impl PartialOrd then it can be derived:
#[derive(PartialEq, PartialOrd)] struct Point { x: i32, y: i32, } #[derive(PartialEq, PartialOrd)] enum Stoplight { Red, Yellow, Green, } The PartialOrd derive macro orders types based on the lexicographical order of their members:
// generates PartialOrd impl which orders // Points based on x member first and // y member second because that's the order // they appear in the source code #[derive(PartialOrd, PartialEq)] struct Point { x: i32, y: i32, } // generates DIFFERENT PartialOrd impl // which orders Points based on y member // first and x member second #[derive(PartialOrd, PartialEq)] struct Point { y: i32, x: i32, } Ord is a subtrait of Eq and PartialOrd&lt;Self>:
trait Ord: Eq + PartialOrd&lt;Self> { fn cmp(&amp;self, other: &amp;Self) -> Ordering; // provided default impls fn max(self, other: Self) -> Self; fn min(self, other: Self) -> Self; fn clamp(self, min: Self, max: Self) -> Self; } If we impl Ord for a type, on top of the asymmetry &amp; transitivity properties required by PartialOrd, we&rsquo;re also guaranteeing that the asymmetry is total, i.e. exactly one of a &lt; b, a == b or a > b is true for any given a and b. In this sense Ord refines Eq and PartialOrd because it represents a stricter version of comparisons. If a type impls Ord we can use that impl to trivially impl PartialOrd, PartialEq, and Eq:
use std::cmp::Ordering; // of course we can use the derive macros here #[derive(Ord, PartialOrd, Eq, PartialEq)] struct Point { x: i32, y: i32, } // note: as with PartialOrd, the Ord derive macro // orders a type based on the lexicographical order // of its members // but here's the impls if we wrote them out by hand impl Ord for Point { fn cmp(&amp;self, other: &amp;Self) -> Ordering { match self.x.cmp(&amp;self.y) { Ordering::Equal => self.y.cmp(&amp;self.y), ordering => ordering, } } } impl PartialOrd for Point { fn partial_cmp(&amp;self, other: &amp;Self) -> Option&lt;Ordering> { Some(self.cmp(other)) } } impl PartialEq for Point { fn eq(&amp;self, other: &amp;Self) -> bool { self.cmp(other) == Ordering::Equal } } impl Eq for Point {} Floats impl PartialOrd but not Ord because both NaN &lt; 0 == false and NaN >= 0 == false are simultaneously true. Almost all other PartialOrd types are trivially Ord, unless of course if they contain floats.
Once a type impls Ord we can store it in BTreeMaps and BTreeSets as well as easily sort it using the sort() method on slices and any types which deref to slices such as arrays, Vecs, and VecDeques.
use std::collections::BTreeSet; // now our type can be stored // in BTreeSets and BTreeMaps! #[derive(Ord, PartialOrd, PartialEq, Eq)] struct Point { x: i32, y: i32, } fn example_btreeset() { let mut points = BTreeSet::new(); points.insert(Point { x: 0, y: 0 }); // ✅ } // we can also .sort() Ord types in collections! fn example_sort&lt;T: Ord>(mut sortable: Vec&lt;T>) -> Vec&lt;T> { sortable.sort(); sortable } Arithmetic Traits Trait(s) Category Operator(s) Description Add arithmetic + addition AddAssign arithmetic += addition assignment BitAnd arithmetic &amp; bitwise AND BitAndAssign arithmetic &amp;= bitwise assignment BitXor arithmetic ^ bitwise XOR BitXorAssign arithmetic ^= bitwise XOR assignment Div arithmetic / division DivAssign arithmetic /= division assignment Mul arithmetic * multiplication MulAssign arithmetic *= multiplication assignment Neg arithmetic - unary negation Not arithmetic ! unary logical negation Rem arithmetic % remainder RemAssign arithmetic %= remainder assignment Shl arithmetic &lt;&lt; left shift ShlAssign arithmetic &lt;&lt;= left shift assignment Shr arithmetic >> right shift ShrAssign arithmetic >>= right shift assignment Sub arithmetic - subtraction SubAssign arithmetic -= subtraction assignment Going over all of these would be very redundant. Most of these only apply to number types anyway. We&rsquo;ll only go over Add and AddAssign since the + operator is commonly overloaded to do other stuff like adding items to collections or concatenating things together, that way we cover the most interesting ground and don&rsquo;t repeat ourselves.
Add &amp; AddAssign Prerequisites
Self Methods Associated Types Generic Parameters Generic Types vs Associated Types Derive Macros trait Add&lt;Rhs = Self> { type Output; fn add(self, rhs: Rhs) -> Self::Output; } Add&lt;Rhs, Output = T> types can be added to Rhs types and will produce T as output.
Example Add&lt;Point, Output = Point> impl for Point:
#[derive(Clone, Copy)] struct Point { x: i32, y: i32, } impl Add for Point { type Output = Point; fn add(self, rhs: Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } fn main() { let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let p3 = p1 + p2; assert_eq!(p3.x, p1.x + p2.x); // ✅ assert_eq!(p3.y, p1.y + p2.y); // ✅ } But what if we only had references to Points? Can we still add them then? Let&rsquo;s try:
fn main() { let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let p3 = &amp;p1 + &amp;p2; // ❌ } Unfortunately not. The compiler throws:
error[E0369]: cannot add `&amp;Point` to `&amp;Point` --> src/main.rs:50:25 | 50 | let p3: Point = &amp;p1 + &amp;p2; | --- ^ --- &amp;Point | | | &amp;Point | = note: an implementation of `std::ops::Add` might be missing for `&amp;Point` Within Rust&rsquo;s type system, for some type T, the types T, &amp;T, and &amp;mut T are all treated as unique distinct types which means we have to provide trait impls for each of them separately. Let&rsquo;s define an Add impl for &amp;Point:
impl Add for &amp;Point { type Output = Point; fn add(self, rhs: &amp;Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } fn main() { let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let p3 = &amp;p1 + &amp;p2; // ✅ assert_eq!(p3.x, p1.x + p2.x); // ✅ assert_eq!(p3.y, p1.y + p2.y); // ✅ } However, something still doesn&rsquo;t feel quite right. We have two separate impls of Add for Point and &amp;Point and they happen to do the same thing currently but there&rsquo;s no guarantee that they will in the future! For example, let&rsquo;s say we decide that when we add two Points together we want to create a Line containing those two Points instead of creating a new Point, we&rsquo;d update our Add impl like this:
use std::ops::Add; #[derive(Copy, Clone)] struct Point { x: i32, y: i32, } #[derive(Copy, Clone)] struct Line { start: Point, end: Point, } // we updated this impl impl Add for Point { type Output = Line; fn add(self, rhs: Point) -> Line { Line { start: self, end: rhs, } } } // but forgot to update this impl, uh oh! impl Add for &amp;Point { type Output = Point; fn add(self, rhs: &amp;Point) -> Point { Point { x: self.x + rhs.x, y: self.y + rhs.y, } } } fn main() { let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let line: Line = p1 + p2; // ✅ let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let line: Line = &amp;p1 + &amp;p2; // ❌ expected Line, found Point } Our current impl of Add for &amp;Point creates an unnecessary maintenance burden, we want the impl to match Point&rsquo;s impl without having to manually update it every time we change Point&rsquo;s impl. We&rsquo;d like to keep our code as DRY (Don&rsquo;t Repeat Yourself) as possible. Luckily this is achievable:
// updated, DRY impl impl Add for &amp;Point { type Output = &lt;Point as Add>::Output; fn add(self, rhs: &amp;Point) -> Self::Output { Point::add(*self, *rhs) } } fn main() { let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let line: Line = p1 + p2; // ✅ let p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; let line: Line = &amp;p1 + &amp;p2; // ✅ } AddAssign&lt;Rhs> types allow us to add + assign Rhs types to them. The trait declaration:
trait AddAssign&lt;Rhs = Self> { fn add_assign(&amp;mut self, rhs: Rhs); } Example impls for Point and &amp;Point:
use std::ops::AddAssign; #[derive(Copy, Clone)] struct Point { x: i32, y: i32 } impl AddAssign for Point { fn add_assign(&amp;mut self, rhs: Point) { self.x += rhs.x; self.y += rhs.y; } } impl AddAssign&lt;&amp;Point> for Point { fn add_assign(&amp;mut self, rhs: &amp;Point) { Point::add_assign(self, *rhs); } } fn main() { let mut p1 = Point { x: 1, y: 2 }; let p2 = Point { x: 3, y: 4 }; p1 += &amp;p2; p1 += p2; assert!(p1.x == 7 &amp;&amp; p1.y == 10); } Closure Traits Trait(s) Category Operator(s) Description Fn closure (...args) immutable closure invocation FnMut closure (...args) mutable closure invocation FnOnce closure (...args) one-time closure invocation FnOnce, FnMut, &amp; Fn Prerequisites
Self Methods Associated Types Generic Parameters Generic Types vs Associated Types Subtraits &amp; Supertraits trait FnOnce&lt;Args> { type Output; fn call_once(self, args: Args) -> Self::Output; } trait FnMut&lt;Args>: FnOnce&lt;Args> { fn call_mut(&amp;mut self, args: Args) -> Self::Output; } trait Fn&lt;Args>: FnMut&lt;Args> { fn call(&amp;self, args: Args) -> Self::Output; } Although these traits exist it&rsquo;s not possible to impl them for our own types in stable Rust. The only types we can create which impl these traits are closures. Depending on what the closure captures from its environment determines whether it impls FnOnce, FnMut, or Fn.
An FnOnce closure can only be called once because it consumes some value as part of its execution:
fn main() { let range = 0..10; let get_range_count = || range.count(); assert_eq!(get_range_count(), 10); // ✅ get_range_count(); // ❌ } The .count() method on iterators consumes the iterator so it can only be called once. Hence our closure can only be called once. Which is why when we try to call it a second time we get this error:
error[E0382]: use of moved value: `get_range_count` --> src/main.rs:5:5 | 4 | assert_eq!(get_range_count(), 10); | ----------------- `get_range_count` moved due to this call 5 | get_range_count(); | ^^^^^^^^^^^^^^^ value used here after move | note: closure cannot be invoked more than once because it moves the variable `range` out of its environment --> src/main.rs:3:30 | 3 | let get_range_count = || range.count(); | ^^^^^ note: this value implements `FnOnce`, which causes it to be moved when called --> src/main.rs:4:16 | 4 | assert_eq!(get_range_count(), 10); | ^^^^^^^^^^^^^^^ An FnMut closure can be called multiple times and can also mutate variables it has captured from its environment. We might say FnMut closures perform side-effects or are stateful. Here&rsquo;s an example of a closure that filters out all non-ascending values from an iterator by keeping track of the smallest value it has seen so far:
fn main() { let nums = vec![0, 4, 2, 8, 10, 7, 15, 18, 13]; let mut min = i32::MIN; let ascending = nums.into_iter().filter(|&amp;n| { if n &lt;= min { false } else { min = n; true } }).collect::&lt;Vec&lt;_>>(); assert_eq!(vec![0, 4, 8, 10, 15, 18], ascending); // ✅ } FnMut refines FnOnce in the sense that FnOnce requires taking ownership of its arguments and can only be called once, but FnMut requires only taking mutable references and can be called multiple times. FnMut can be used anywhere FnOnce can be used.
An Fn closure can be called multiple times and does not mutate any variables it has captured from its environment. We might say Fn closures have no side-effects or are stateless. Here&rsquo;s an example closure that filters out all values less than some stack variable it captures from its environment from an iterator:
fn main() { let nums = vec![0, 4, 2, 8, 10, 7, 15, 18, 13]; let min = 9; let greater_than_9 = nums.into_iter().filter(|&amp;n| n > min).collect::&lt;Vec&lt;_>>(); assert_eq!(vec![10, 15, 18, 13], greater_than_9); // ✅ } Fn refines FnMut in the sense that FnMut requires mutable references and can be called multiple times, but Fn only requires immutable references and can be called multiple times. Fn can be used anywhere FnMut can be used, which includes anywhere FnOnce can be used.
If a closure doesn&rsquo;t capture anything from its environment it&rsquo;s technically not a closure, but just an anonymously declared inline function, and can be casted to, used, and passed around as a regular function pointer, i.e. fn. Function pointers can be used anywhere Fn can be used, which includes anwhere FnMut and FnOnce can be used.
fn add_one(x: i32) -> i32 { x + 1 } fn main() { let mut fn_ptr: fn(i32) -> i32 = add_one; assert_eq!(fn_ptr(1), 2); // ✅ // capture-less closure cast to fn pointer fn_ptr = |x| x + 1; // same as add_one assert_eq!(fn_ptr(1), 2); // ✅ } Example of passing a regular function pointer in place of a closure:
fn main() { let nums = vec![-1, 1, -2, 2, -3, 3]; let absolutes: Vec&lt;i32> = nums.into_iter().map(i32::abs).collect(); assert_eq!(vec![1, 1, 2, 2, 3, 3], absolutes); // ✅ } Other Traits Trait(s) Category Operator(s) Description Deref other * immutable dereference DerefMut other * mutable derenence Drop other - type destructor Index other [] immutable index IndexMut other [] mutable index RangeBounds other .. range Deref &amp; DerefMut Prerequisites
Self Methods Associated Types Subtraits &amp; Supertraits Sized trait Deref { type Target: ?Sized; fn deref(&amp;self) -> &amp;Self::Target; } trait DerefMut: Deref { fn deref_mut(&amp;mut self) -> &amp;mut Self::Target; } Deref&lt;Target = T> types can dereferenced to T types using the dereference operator *. This has obvious use-cases for smart pointer types like Box and Rc. However, we rarely see the dereference operator explicitly used in Rust code, and that&rsquo;s because of a Rust feature called deref coercion.
Rust automatically dereferences types when they&rsquo;re being passed as function arguments, returned from a function, or used as part of a method call. This is the reason why we can pass &amp;String and &amp;Vec&lt;T> to functions expecting &amp;str and &amp;[T] because String impls Deref&lt;Target = str> and Vec&lt;T> impls Deref&lt;Target = [T]>.
Deref and DerefMut should only be implemented for smart pointer types. The most common way people attempt to misuse and abuse these traits is to try to shoehorn some kind of OOP-style data inheritance into Rust. This does not work. Rust is not OOP. Let&rsquo;s examine a few different situations where, how, and why it does not work. Let&rsquo;s start with this example:
use std::ops::Deref; struct Human { health_points: u32, } enum Weapon { Spear, Axe, Sword, } // a Soldier is just a Human with a Weapon struct Soldier { human: Human, weapon: Weapon, } impl Deref for Soldier { type Target = Human; fn deref(&amp;self) -> &amp;Human { &amp;self.human } } enum Mount { Horse, Donkey, Cow, } // a Knight is just a Soldier with a Mount struct Knight { soldier: Soldier, mount: Mount, } impl Deref for Knight { type Target = Soldier; fn deref(&amp;self) -> &amp;Soldier { &amp;self.soldier } } enum Spell { MagicMissile, FireBolt, ThornWhip, } // a Mage is just a Human who can cast Spells struct Mage { human: Human, spells: Vec&lt;Spell>, } impl Deref for Mage { type Target = Human; fn deref(&amp;self) -> &amp;Human { &amp;self.human } } enum Staff { Wooden, Metallic, Plastic, } // a Wizard is just a Mage with a Staff struct Wizard { mage: Mage, staff: Staff, } impl Deref for Wizard { type Target = Mage; fn deref(&amp;self) -> &amp;Mage { &amp;self.mage } } fn borrows_human(human: &amp;Human) {} fn borrows_soldier(soldier: &amp;Soldier) {} fn borrows_knight(knight: &amp;Knight) {} fn borrows_mage(mage: &amp;Mage) {} fn borrows_wizard(wizard: &amp;Wizard) {} fn example(human: Human, soldier: Soldier, knight: Knight, mage: Mage, wizard: Wizard) { // all types can be used as Humans borrows_human(&amp;human); borrows_human(&amp;soldier); borrows_human(&amp;knight); borrows_human(&amp;mage); borrows_human(&amp;wizard); // Knights can be used as Soldiers borrows_soldier(&amp;soldier); borrows_soldier(&amp;knight); // Wizards can be used as Mages borrows_mage(&amp;mage); borrows_mage(&amp;wizard); // Knights &amp; Wizards passed as themselves borrows_knight(&amp;knight); borrows_wizard(&amp;wizard); } So at first glance the above looks pretty good! However it quickly breaks down to scrutiny. First of all, deref coercion only works on references, so it doesn&rsquo;t work when we actually want to pass ownership:
fn takes_human(human: Human) {} fn example(human: Human, soldier: Soldier, knight: Knight, mage: Mage, wizard: Wizard) { // all types CANNOT be used as Humans takes_human(human); takes_human(soldier); // ❌ takes_human(knight); // ❌ takes_human(mage); // ❌ takes_human(wizard); // ❌ } Furthermore, deref coercion doesn&rsquo;t work in generic contexts. Let&rsquo;s say we impl some trait only on humans:
trait Rest { fn rest(&amp;self); } impl Rest for Human { fn rest(&amp;self) {} } fn take_rest&lt;T: Rest>(rester: &amp;T) { rester.rest() } fn example(human: Human, soldier: Soldier, knight: Knight, mage: Mage, wizard: Wizard) { // all types CANNOT be used as Rest types, only Human take_rest(&amp;human); take_rest(&amp;soldier); // ❌ take_rest(&amp;knight); // ❌ take_rest(&amp;mage); // ❌ take_rest(&amp;wizard); // ❌ } Also, although deref coercion works in a lot of places it doesn&rsquo;t work everywhere. It doesn&rsquo;t work on operands, even though operators are just syntax sugar for method calls. Let&rsquo;s say, to be cute, we wanted Mages to learn Spells using the += operator:
impl DerefMut for Wizard { fn deref_mut(&amp;mut self) -> &amp;mut Mage { &amp;mut self.mage } } impl AddAssign&lt;Spell> for Mage { fn add_assign(&amp;mut self, spell: Spell) { self.spells.push(spell); } } fn example(mut mage: Mage, mut wizard: Wizard, spell: Spell) { mage += spell; wizard += spell; // ❌ wizard not coerced to mage here wizard.add_assign(spell); // oof, we have to call it like this 🤦 } In languages with OOP-style data inheritance the value of self within a method is always equal to the type which called the method but in the case of Rust the value of self is always equal to the type which implemented the method:
struct Human { profession: &amp;'static str, health_points: u32, } impl Human { // self will always be a Human here, even if we call it on a Soldier fn state_profession(&amp;self) { println!("I'm a {}!", self.profession); } } struct Soldier { profession: &amp;'static str, human: Human, weapon: Weapon, } fn example(soldier: &amp;Soldier) { assert_eq!("servant", soldier.human.profession); assert_eq!("spearman", soldier.profession); soldier.human.state_profession(); // prints "I'm a servant!" soldier.state_profession(); // still prints "I'm a servant!" 🤦 } The above gotcha is especially damning when impling Deref or DerefMut on a newtype. Let&rsquo;s say we want to create a SortedVec type which is just a Vec but it&rsquo;s always in sorted order. Here&rsquo;s how we might do that:
struct SortedVec&lt;T: Ord>(Vec&lt;T>); impl&lt;T: Ord> SortedVec&lt;T> { fn new(mut vec: Vec&lt;T>) -> Self { vec.sort(); SortedVec(vec) } fn push(&amp;mut self, t: T) { self.0.push(t); self.0.sort(); } } Obviously we cannot impl DerefMut&lt;Target = Vec&lt;T>> here or anyone using SortedVec would be able to trivially break the sorted order. However, impling Deref&lt;Target = Vec&lt;T>> surely must be safe, right? Try to spot the bug in the program below:
use std::ops::Deref; struct SortedVec&lt;T: Ord>(Vec&lt;T>); impl&lt;T: Ord> SortedVec&lt;T> { fn new(mut vec: Vec&lt;T>) -> Self { vec.sort(); SortedVec(vec) } fn push(&amp;mut self, t: T) { self.0.push(t); self.0.sort(); } } impl&lt;T: Ord> Deref for SortedVec&lt;T> { type Target = Vec&lt;T>; fn deref(&amp;self) -> &amp;Vec&lt;T> { &amp;self.0 } } fn main() { let sorted = SortedVec::new(vec![2, 8, 6, 3]); sorted.push(1); let sortedClone = sorted.clone(); sortedClone.push(4); } We never implemented Clone for SortedVec so when we call the .clone() method the compiler is using deref coercion to resolve that method call on Vec and so it returns a Vec and not a SortedVec!
fn main() { let sorted: SortedVec&lt;i32> = SortedVec::new(vec![2, 8, 6, 3]); sorted.push(1); // still sorted // calling clone on SortedVec actually returns a Vec 🤦 let sortedClone: Vec&lt;i32> = sorted.clone(); sortedClone.push(4); // sortedClone no longer sorted 💀 } Anyway, none of the above limitations, constraints, or gotchas are faults of Rust because Rust was never designed to be an OO language or to support any OOP patterns in the first place.
The main takeaway from this section is do not try to be cute or clever with Deref and DerefMut impls. They&rsquo;re really only appropriate for smart pointer types, which can only be implemented within the standard library for now as smart pointer types currently require unstable features and compiler magic to work. If we want functionality and behavior similar to Deref and DerefMut then what we&rsquo;re actually probably looking for is AsRef and AsMut which we&rsquo;ll get to later.
Index &amp; IndexMut Prerequisites
Self Methods Associated Types Generic Parameters Generic Types vs Associated Types Subtraits &amp; Supertraits Sized trait Index&lt;Idx: ?Sized> { type Output: ?Sized; fn index(&amp;self, index: Idx) -> &amp;Self::Output; } trait IndexMut&lt;Idx>: Index&lt;Idx> where Idx: ?Sized { fn index_mut(&amp;mut self, index: Idx) -> &amp;mut Self::Output; } We can index [] into Index&lt;T, Output = U> types with T values and the index operation will return &amp;U values. For syntax sugar, the compiler auto inserts a deref operator * in front of any value returned from an index operation:
fn main() { // Vec&lt;i32> impls Index&lt;usize, Output = i32> so // indexing Vec&lt;i32> should produce &amp;i32s and yet... let vec = vec![1, 2, 3, 4, 5]; let num_ref: &amp;i32 = vec[0]; // ❌ expected &amp;i32 found i32 // above line actually desugars to let num_ref: &amp;i32 = *vec[0]; // ❌ expected &amp;i32 found i32 // both of these alternatives work let num: i32 = vec[0]; // ✅ let num_ref = &amp;vec[0]; // ✅ } It&rsquo;s kinda confusing at first, because it seems like the Index trait does not follow its own method signature, but really it&rsquo;s just questionable syntax sugar.
Since Idx is a generic type the Index trait can be implemented many times for a given type, and in the case of Vec&lt;T> not only can we index into it using usize but we can also index into its using Range&lt;usize>s to get slices.
fn main() { let vec = vec![1, 2, 3, 4, 5]; assert_eq!(&amp;vec[..], &amp;[1, 2, 3, 4, 5]); // ✅ assert_eq!(&amp;vec[1..], &amp;[2, 3, 4, 5]); // ✅ assert_eq!(&amp;vec[..4], &amp;[1, 2, 3, 4]); // ✅ assert_eq!(&amp;vec[1..4], &amp;[2, 3, 4]); // ✅ } To show off how we might impl Index ourselves here&rsquo;s a fun example which shows how we can use a newtype and the Index trait to impl wrapping indexes and negative indexes on a Vec:
use std::ops::Index; struct WrappingIndex&lt;T>(Vec&lt;T>); impl&lt;T> Index&lt;usize> for WrappingIndex&lt;T> { type Output = T; fn index(&amp;self, index: usize) -> &amp;T { &amp;self.0[index % self.0.len()] } } impl&lt;T> Index&lt;i128> for WrappingIndex&lt;T> { type Output = T; fn index(&amp;self, index: i128) -> &amp;T { let self_len = self.0.len() as i128; let idx = (((index % self_len) + self_len) % self_len) as usize; &amp;self.0[idx] } } #[test] // ✅ fn indexes() { let wrapping_vec = WrappingIndex(vec![1, 2, 3]); assert_eq!(1, wrapping_vec[0_usize]); assert_eq!(2, wrapping_vec[1_usize]); assert_eq!(3, wrapping_vec[2_usize]); } #[test] // ✅ fn wrapping_indexes() { let wrapping_vec = WrappingIndex(vec![1, 2, 3]); assert_eq!(1, wrapping_vec[3_usize]); assert_eq!(2, wrapping_vec[4_usize]); assert_eq!(3, wrapping_vec[5_usize]); } #[test] // ✅ fn neg_indexes() { let wrapping_vec = WrappingIndex(vec![1, 2, 3]); assert_eq!(1, wrapping_vec[-3_i128]); assert_eq!(2, wrapping_vec[-2_i128]); assert_eq!(3, wrapping_vec[-1_i128]); } #[test] // ✅ fn wrapping_neg_indexes() { let wrapping_vec = WrappingIndex(vec![1, 2, 3]); assert_eq!(1, wrapping_vec[-6_i128]); assert_eq!(2, wrapping_vec[-5_i128]); assert_eq!(3, wrapping_vec[-4_i128]); } There&rsquo;s no requirement that the Idx type has to be a number type or a Range, it could be an enum! Here&rsquo;s an example using basketball positions to index into a basketball team to retrieve players on the team:
use std::ops::Index; enum BasketballPosition { PointGuard, ShootingGuard, Center, PowerForward, SmallForward, } struct BasketballPlayer { name: &amp;'static str, position: BasketballPosition, } struct BasketballTeam { point_guard: BasketballPlayer, shooting_guard: BasketballPlayer, center: BasketballPlayer, power_forward: BasketballPlayer, small_forward: BasketballPlayer, } impl Index&lt;BasketballPosition> for BasketballTeam { type Output = BasketballPlayer; fn index(&amp;self, position: BasketballPosition) -> &amp;BasketballPlayer { match position { BasketballPosition::PointGuard => &amp;self.point_guard, BasketballPosition::ShootingGuard => &amp;self.shooting_guard, BasketballPosition::Center => &amp;self.center, BasketballPosition::PowerForward => &amp;self.power_forward, BasketballPosition::SmallForward => &amp;self.small_forward, } } } Drop Prerequisites
Self Methods trait Drop { fn drop(&amp;mut self); } If a type impls Drop then drop will be called on the type when it goes out of scope but before it&rsquo;s destroyed. We will rarely need to impl this for our types but a good example of where it&rsquo;s useful is if a type holds on to some external resources which needs to be cleaned up when the type is destroyed.
There&rsquo;s a BufWriter type in the standard library that allows us to buffer writes to Write types. However, what if the BufWriter gets destroyed before the content in its buffer has been flushed to the underlying Write type? Thankfully that&rsquo;s not possible! The BufWriter impls the Drop trait so that flush is always called on it whenever it goes out of scope!
impl&lt;W: Write> Drop for BufWriter&lt;W> { fn drop(&amp;mut self) { self.flush_buf(); } } Also, Mutexs in Rust don&rsquo;t have unlock() methods because they don&rsquo;t need them! Calling lock() on a Mutex returns a MutexGuard which automatically unlocks the Mutex when it goes out of scope thanks to its Drop impl:
impl&lt;T: ?Sized> Drop for MutexGuard&lt;'_, T> { fn drop(&amp;mut self) { unsafe { self.lock.inner.raw_unlock(); } } } In general, if you&rsquo;re impling an abstraction over some resource that needs to be cleaned up after use then that&rsquo;s a great reason to make use of the Drop trait.
Conversion Traits From &amp; Into Prerequisites
Self Functions Methods Generic Parameters Generic Blanket Impls trait From&lt;T> { fn from(T) -> Self; } From&lt;T> types allow us to convert T into Self.
trait Into&lt;T> { fn into(self) -> T; } Into&lt;T> types allow us to convert Self into T.
These traits are two different sides of the same coin. We can only impl From&lt;T> for our types because the Into&lt;T> impl is automatically provided by this generic blanket impl:
impl&lt;T, U> Into&lt;U> for T where U: From&lt;T>, { fn into(self) -> U { U::from(self) } } The reason both traits exist is because it allows us to write trait bounds on generic types slightly differently:
fn function&lt;T>(t: T) where // these bounds are equivalent T: From&lt;i32>, i32: Into&lt;T> { // these examples are equivalent let example: T = T::from(0); let example: T = 0.into(); } There are no hard rules about when to use one or the other, so go with whatever makes the most sense for each situation. Now let&rsquo;s look at some example impls on Point:
struct Point { x: i32, y: i32, } impl From&lt;(i32, i32)> for Point { fn from((x, y): (i32, i32)) -> Self { Point { x, y } } } impl From&lt;[i32; 2]> for Point { fn from([x, y]: [i32; 2]) -> Self { Point { x, y } } } fn example() { // using From let origin = Point::from((0, 0)); let origin = Point::from([0, 0]); // using Into let origin: Point = (0, 0).into(); let origin: Point = [0, 0].into(); } The impl is not symmetric, so if we&rsquo;d like to convert Points into tuples and arrays we have to explicitly add those as well:
struct Point { x: i32, y: i32, } impl From&lt;(i32, i32)> for Point { fn from((x, y): (i32, i32)) -> Self { Point { x, y } } } impl From&lt;Point> for (i32, i32) { fn from(Point { x, y }: Point) -> Self { (x, y) } } impl From&lt;[i32; 2]> for Point { fn from([x, y]: [i32; 2]) -> Self { Point { x, y } } } impl From&lt;Point> for [i32; 2] { fn from(Point { x, y }: Point) -> Self { [x, y] } } fn example() { // from (i32, i32) into Point let point = Point::from((0, 0)); let point: Point = (0, 0).into(); // from Point into (i32, i32) let tuple = &lt;(i32, i32)>::from(point); let tuple: (i32, i32) = point.into(); // from [i32; 2] into Point let point = Point::from([0, 0]); let point: Point = [0, 0].into(); // from Point into [i32; 2] let array = &lt;[i32; 2]>::from(point); let array: [i32; 2] = point.into(); } A popular use of From&lt;T> is to trim down boilerplate code. Let&rsquo;s say we add a Triangle type to our program which contains three Points, here&rsquo;s some of the many ways we can construct it:
struct Point { x: i32, y: i32, } impl Point { fn new(x: i32, y: i32) -> Point { Point { x, y } } } impl From&lt;(i32, i32)> for Point { fn from((x, y): (i32, i32)) -> Point { Point { x, y } } } struct Triangle { p1: Point, p2: Point, p3: Point, } impl Triangle { fn new(p1: Point, p2: Point, p3: Point) -> Triangle { Triangle { p1, p2, p3 } } } impl&lt;P> From&lt;[P; 3]> for Triangle where P: Into&lt;Point> { fn from([p1, p2, p3]: [P; 3]) -> Triangle { Triangle { p1: p1.into(), p2: p2.into(), p3: p3.into(), } } } fn example() { // manual construction let triangle = Triangle { p1: Point { x: 0, y: 0, }, p2: Point { x: 1, y: 1, }, p3: Point { x: 2, y: 2, }, }; // using Point::new let triangle = Triangle { p1: Point::new(0, 0), p2: Point::new(1, 1), p3: Point::new(2, 2), }; // using From&lt;(i32, i32)> for Point let triangle = Triangle { p1: (0, 0).into(), p2: (1, 1).into(), p3: (2, 2).into(), }; // using Triangle::new + From&lt;(i32, i32)> for Point let triangle = Triangle::new( (0, 0).into(), (1, 1).into(), (2, 2).into(), ); // using From&lt;[Into&lt;Point>; 3]> for Triangle let triangle: Triangle = [ (0, 0), (1, 1), (2, 2), ].into(); } There are no rules for when, how, or why we should impl From&lt;T> for our types so it&rsquo;s up to us to use our best judgement for every situation.
One popular use of Into&lt;T> is to make functions which need owned values generic over whether they take owned or borrowed values:
struct Person { name: String, } impl Person { // accepts: // - String fn new1(name: String) -> Person { Person { name } } // accepts: // - String // - &amp;String // - &amp;str // - Box&lt;str> // - Cow&lt;'_, str> // - char // since all of the above types can be converted into String fn new2&lt;N: Into&lt;String>>(name: N) -> Person { Person { name: name.into() } } } Error Handling The best time to talk about error handling and the Error trait is after going over Display, Debug, Any, and From but before getting to TryFrom hence why the Error Handling section awkwardly bisects the Conversion Traits section.
Error Prerequisites
Self Methods Default Impls Generic Blanket Impls Subtraits &amp; Supertraits Trait Objects Display &amp; ToString Debug Any From &amp; Into trait Error: Debug + Display { // provided default impls fn source(&amp;self) -> Option&lt;&amp;(dyn Error + 'static)>; fn backtrace(&amp;self) -> Option&lt;&amp;Backtrace>; fn description(&amp;self) -> &amp;str; fn cause(&amp;self) -> Option&lt;&amp;dyn Error>; } In Rust errors are returned, not thrown. Let&rsquo;s look at some examples.
Since dividing integer types by zero panics if we wanted to make our program safer and more explicit we could impl a safe_div function which returns a Result instead like this:
use std::fmt; use std::error; #[derive(Debug, PartialEq)] struct DivByZero; impl fmt::Display for DivByZero { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { write!(f, "division by zero error") } } impl error::Error for DivByZero {} fn safe_div(numerator: i32, denominator: i32) -> Result&lt;i32, DivByZero> { if denominator == 0 { return Err(DivByZero); } Ok(numerator / denominator) } #[test] // ✅ fn test_safe_div() { assert_eq!(safe_div(8, 2), Ok(4)); assert_eq!(safe_div(5, 0), Err(DivByZero)); } Since errors are returned and not thrown they must be explicitly handled, and if the current function cannot handle an error it should propagate it up to the caller. The most idiomatic way to propagate errors is to use the ? operator, which is just syntax sugar for the now deprecated try! macro which simply does this:
macro_rules! try { ($expr:expr) => { match $expr { // if Ok just unwrap the value Ok(val) => val, // if Err map the err value using From and return Err(err) => { return Err(From::from(err)); } } }; } If we wanted to write a function which reads a file into a String we could write it like this, propagating the io::Errors using ? everywhere they can appear:
use std::io::Read; use std::path::Path; use std::io; use std::fs::File; fn read_file_to_string(path: &amp;Path) -> Result&lt;String, io::Error> { let mut file = File::open(path)?; // ⬆️ io::Error let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; // ⬆️ io::Error Ok(contents) } But let&rsquo;s say the file we&rsquo;re reading is actually a list of numbers and we want to sum them together, we&rsquo;d update our function like this:
use std::io::Read; use std::path::Path; use std::io; use std::fs::File; fn sum_file(path: &amp;Path) -> Result&lt;i32, /* What to put here? */> { let mut file = File::open(path)?; // ⬆️ io::Error let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; // ⬆️ io::Error let mut sum = 0; for line in contents.lines() { sum += line.parse::&lt;i32>()?; // ⬆️ ParseIntError } Ok(sum) } But what&rsquo;s the error type of our Result now? It can return either an io::Error or a ParseIntError. We&rsquo;re going to look at three approaches for solving this problem, starting with the most quick &amp; dirty way and finishing with the most robust way.
The first approach is recognizing that all types which impl Error also impl Display so we can map all the errors to Strings and use String as our error type:
use std::fs::File; use std::io; use std::io::Read; use std::path::Path; fn sum_file(path: &amp;Path) -> Result&lt;i32, String> { let mut file = File::open(path) .map_err(|e| e.to_string())?; // ⬆️ io::Error -> String let mut contents = String::new(); file.read_to_string(&amp;mut contents) .map_err(|e| e.to_string())?; // ⬆️ io::Error -> String let mut sum = 0; for line in contents.lines() { sum += line.parse::&lt;i32>() .map_err(|e| e.to_string())?; // ⬆️ ParseIntError -> String } Ok(sum) } The obvious downside of stringifying every error is that we throw away type information which makes it harder for the caller to handle the errors.
One nonobvious upside to the above approach is we can customize the strings to provide more context-specific information. For example, ParseIntError usually stringifies to "invalid digit found in string" which is very vague and doesn&rsquo;t mention what the invalid string is or what integer type it was trying to parse into. If we were debugging this problem that error message would almost be useless. However we can make it significantly better by providing all the context relevant information ourselves:
sum += line.parse::&lt;i32>() .map_err(|_| format!("failed to parse {} into i32", line))?; The second approach takes advantage of this generic blanket impl from the standard library:
impl&lt;E: error::Error> From&lt;E> for Box&lt;dyn error::Error>; Which means that any Error type can be implicitly converted into a Box&lt;dyn error::Error> by the ? operator, so we can set to error type to Box&lt;dyn error::Error> in the Result return type of any function which produces errors and the ? operator will do the rest of the work for us:
use std::fs::File; use std::io::Read; use std::path::Path; use std::error; fn sum_file(path: &amp;Path) -> Result&lt;i32, Box&lt;dyn error::Error>> { let mut file = File::open(path)?; // ⬆️ io::Error -> Box&lt;dyn error::Error> let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; // ⬆️ io::Error -> Box&lt;dyn error::Error> let mut sum = 0; for line in contents.lines() { sum += line.parse::&lt;i32>()?; // ⬆️ ParseIntError -> Box&lt;dyn error::Error> } Ok(sum) } While being more concise, this seems to suffer from the same downside of the previous approach by throwing away type information. This is mostly true, but if the caller is aware of the impl details of our function they can still handle the different errors types using the downcast_ref() method on error::Error which works the same as it does on dyn Any types:
fn handle_sum_file_errors(path: &amp;Path) { match sum_file(path) { Ok(sum) => println!("the sum is {}", sum), Err(err) => { if let Some(e) = err.downcast_ref::&lt;io::Error>() { // handle io::Error } else if let Some(e) = err.downcast_ref::&lt;ParseIntError>() { // handle ParseIntError } else { // we know sum_file can only return one of the // above errors so this branch is unreachable unreachable!(); } } } } The third approach, which is the most robust and type-safe way to aggregate these different errors would be to build our own custom error type using an enum:
use std::num::ParseIntError; use std::fs::File; use std::io; use std::io::Read; use std::path::Path; use std::error; use std::fmt; #[derive(Debug)] enum SumFileError { Io(io::Error), Parse(ParseIntError), } impl From&lt;io::Error> for SumFileError { fn from(err: io::Error) -> Self { SumFileError::Io(err) } } impl From&lt;ParseIntError> for SumFileError { fn from(err: ParseIntError) -> Self { SumFileError::Parse(err) } } impl fmt::Display for SumFileError { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { match self { SumFileError::Io(err) => write!(f, "sum file error: {}", err), SumFileError::Parse(err) => write!(f, "sum file error: {}", err), } } } impl error::Error for SumFileError { // the default impl for this method always returns None // but we can now override it to make it way more useful! fn source(&amp;self) -> Option&lt;&amp;(dyn error::Error + 'static)> { Some(match self { SumFileError::Io(err) => err, SumFileError::Parse(err) => err, }) } } fn sum_file(path: &amp;Path) -> Result&lt;i32, SumFileError> { let mut file = File::open(path)?; // ⬆️ io::Error -> SumFileError let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; // ⬆️ io::Error -> SumFileError let mut sum = 0; for line in contents.lines() { sum += line.parse::&lt;i32>()?; // ⬆️ ParseIntError -> SumFileError } Ok(sum) } fn handle_sum_file_errors(path: &amp;Path) { match sum_file(path) { Ok(sum) => println!("the sum is {}", sum), Err(SumFileError::Io(err)) => { // handle io::Error }, Err(SumFileError::Parse(err)) => { // handle ParseIntError }, } } Conversion Traits Continued TryFrom &amp; TryInto Prerequisites
Self Functions Methods Associated Types Generic Parameters Generic Types vs Associated Types Generic Blanket Impls From &amp; Into Error TryFrom and TryInto are the fallible versions of From and Into.
trait TryFrom&lt;T> { type Error; fn try_from(value: T) -> Result&lt;Self, Self::Error>; } trait TryInto&lt;T> { type Error; fn try_into(self) -> Result&lt;T, Self::Error>; } Similarly to Into we cannot impl TryInto because its impl is provided by this generic blanket impl:
impl&lt;T, U> TryInto&lt;U> for T where U: TryFrom&lt;T>, { type Error = U::Error; fn try_into(self) -> Result&lt;U, U::Error> { U::try_from(self) } } Let&rsquo;s say that in the context of our program it doesn&rsquo;t make sense for Points to have x and y values that are less than -1000 or greater than 1000. This is how we&rsquo;d rewrite our earlier From impls using TryFrom to signal to the users of our type that this conversion can now fail:
use std::convert::TryFrom; use std::error; use std::fmt; struct Point { x: i32, y: i32, } #[derive(Debug)] struct OutOfBounds; impl fmt::Display for OutOfBounds { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { write!(f, "out of bounds") } } impl error::Error for OutOfBounds {} // now fallible impl TryFrom&lt;(i32, i32)> for Point { type Error = OutOfBounds; fn try_from((x, y): (i32, i32)) -> Result&lt;Point, OutOfBounds> { if x.abs() > 1000 || y.abs() > 1000 { return Err(OutOfBounds); } Ok(Point { x, y }) } } // still infallible impl From&lt;Point> for (i32, i32) { fn from(Point { x, y }: Point) -> Self { (x, y) } } And here&rsquo;s the refactored TryFrom&lt;[TryInto&lt;Point>; 3]> impl for Triangle:
use std::convert::{TryFrom, TryInto}; use std::error; use std::fmt; struct Point { x: i32, y: i32, } #[derive(Debug)] struct OutOfBounds; impl fmt::Display for OutOfBounds { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { write!(f, "out of bounds") } } impl error::Error for OutOfBounds {} impl TryFrom&lt;(i32, i32)> for Point { type Error = OutOfBounds; fn try_from((x, y): (i32, i32)) -> Result&lt;Self, Self::Error> { if x.abs() > 1000 || y.abs() > 1000 { return Err(OutOfBounds); } Ok(Point { x, y }) } } struct Triangle { p1: Point, p2: Point, p3: Point, } impl&lt;P> TryFrom&lt;[P; 3]> for Triangle where P: TryInto&lt;Point>, { type Error = P::Error; fn try_from([p1, p2, p3]: [P; 3]) -> Result&lt;Self, Self::Error> { Ok(Triangle { p1: p1.try_into()?, p2: p2.try_into()?, p3: p3.try_into()?, }) } } fn example() -> Result&lt;Triangle, OutOfBounds> { let t: Triangle = [(0, 0), (1, 1), (2, 2)].try_into()?; Ok(t) } FromStr Prerequisites
Self Functions Associated Types Error TryFrom &amp; TryInto trait FromStr { type Err; fn from_str(s: &amp;str) -> Result&lt;Self, Self::Err>; } FromStr types allow performing a fallible conversion from &amp;str into Self. The idiomatic way to use FromStr is to call the .parse() method on &amp;strs:
use std::str::FromStr; fn example&lt;T: FromStr>(s: &amp;'static str) { // these are all equivalent let t: Result&lt;T, _> = FromStr::from_str(s); let t = T::from_str(s); let t: Result&lt;T, _> = s.parse(); let t = s.parse::&lt;T>(); // most idiomatic } Example impl for Point:
use std::error; use std::fmt; use std::iter::Enumerate; use std::num::ParseIntError; use std::str::{Chars, FromStr}; #[derive(Debug, Eq, PartialEq)] struct Point { x: i32, y: i32, } impl Point { fn new(x: i32, y: i32) -> Self { Point { x, y } } } #[derive(Debug, PartialEq)] struct ParsePointError; impl fmt::Display for ParsePointError { fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_>) -> fmt::Result { write!(f, "failed to parse point") } } impl From&lt;ParseIntError> for ParsePointError { fn from(_e: ParseIntError) -> Self { ParsePointError } } impl error::Error for ParsePointError {} impl FromStr for Point { type Err = ParsePointError; fn from_str(s: &amp;str) -> Result&lt;Self, Self::Err> { let is_num = |(_, c): &amp;(usize, char)| matches!(c, '0'..='9' | '-'); let isnt_num = |t: &amp;(_, _)| !is_num(t); let get_num = |char_idxs: &amp;mut Enumerate&lt;Chars&lt;'_>>| -> Result&lt;(usize, usize), ParsePointError> { let (start, _) = char_idxs .skip_while(isnt_num) .next() .ok_or(ParsePointError)?; let (end, _) = char_idxs .skip_while(is_num) .next() .ok_or(ParsePointError)?; Ok((start, end)) }; let mut char_idxs = s.chars().enumerate(); let (x_start, x_end) = get_num(&amp;mut char_idxs)?; let (y_start, y_end) = get_num(&amp;mut char_idxs)?; let x = s[x_start..x_end].parse::&lt;i32>()?; let y = s[y_start..y_end].parse::&lt;i32>()?; Ok(Point { x, y }) } } #[test] // ✅ fn pos_x_y() { let p = "(4, 5)".parse::&lt;Point>(); assert_eq!(p, Ok(Point::new(4, 5))); } #[test] // ✅ fn neg_x_y() { let p = "(-6, -2)".parse::&lt;Point>(); assert_eq!(p, Ok(Point::new(-6, -2))); } #[test] // ✅ fn not_a_point() { let p = "not a point".parse::&lt;Point>(); assert_eq!(p, Err(ParsePointError)); } FromStr has the same signature as TryFrom&lt;&amp;str>. It doesn&rsquo;t matter which one we impl for a type first as long as we forward the impl to the other one. Here&rsquo;s a TryFrom&lt;&amp;str> impl for Point assuming it already has a FromStr impl:
impl TryFrom&lt;&amp;str> for Point { type Error = &lt;Point as FromStr>::Err; fn try_from(s: &amp;str) -> Result&lt;Point, Self::Error> { &lt;Point as FromStr>::from_str(s) } } AsRef &amp; AsMut Prerequisites
Self Methods Sized Generic Parameters Sized Deref &amp; DerefMut trait AsRef&lt;T: ?Sized> { fn as_ref(&amp;self) -> &amp;T; } trait AsMut&lt;T: ?Sized> { fn as_mut(&amp;mut self) -> &amp;mut T; } AsRef is for cheap reference to reference conversions. However, one of the most common ways it&rsquo;s used is to make functions generic over whether they take ownership or not:
// accepts: // - &amp;str // - &amp;String fn takes_str(s: &amp;str) { // use &amp;str } // accepts: // - &amp;str // - &amp;String // - String fn takes_asref_str&lt;S: AsRef&lt;str>>(s: S) { let s: &amp;str = s.as_ref(); // use &amp;str } fn example(slice: &amp;str, borrow: &amp;String, owned: String) { takes_str(slice); takes_str(borrow); takes_str(owned); // ❌ takes_asref_str(slice); takes_asref_str(borrow); takes_asref_str(owned); // ✅ } The other most common use-case is returning a reference to inner private data wrapped by a type which protects some invariant. A good example from the standard library is String which is just a wrapper around Vec&lt;u8>:
struct String { vec: Vec&lt;u8>, } This inner Vec cannot be made public because if it was people could mutate any byte and break the String&rsquo;s valid UTF-8 encoding. However, it&rsquo;s safe to expose an immutable read-only reference to the inner byte array, hence this impl:
impl AsRef&lt;[u8]> for String; Generally, it often only makes sense to impl AsRef for a type if it wraps some other type to either provide additional functionality around the inner type or protect some invariant on the inner type.
Let&rsquo;s examine a example of bad AsRef impls:
struct User { name: String, age: u32, } impl AsRef&lt;String> for User { fn as_ref(&amp;self) -> &amp;String { &amp;self.name } } impl AsRef&lt;u32> for User { fn as_ref(&amp;self) -> &amp;u32 { &amp;self.age } } This works and kinda makes sense at first, but quickly falls apart if we add more members to User:
struct User { name: String, email: String, age: u32, height: u32, } impl AsRef&lt;String> for User { fn as_ref(&amp;self) -> &amp;String { // uh, do we return name or email here? } } impl AsRef&lt;u32> for User { fn as_ref(&amp;self) -> &amp;u32 { // uh, do we return age or height here? } } A User is composed of Strings and u32s but it&rsquo;s not really the same thing as a String or a u32. Even if we had much more specific types:
struct User { name: Name, email: Email, age: Age, height: Height, } It wouldn&rsquo;t make much sense to impl AsRef for any of those because AsRef is for cheap reference to reference conversions between semantically equivalent things, and Name, Email, Age, and Height by themselves are not the same thing as a User.
A good example where we would impl AsRef would be if we introduced a new type Moderator that just wrapped a User and added some moderation specific privileges:
struct User { name: String, age: u32, } // unfortunately the standard library cannot provide // a generic blanket impl to save us from this boilerplate impl AsRef&lt;User> for User { fn as_ref(&amp;self) -> &amp;User { self } } enum Privilege { BanUsers, EditPosts, DeletePosts, } // although Moderators have some special // privileges they are still regular Users // and should be able to do all the same stuff struct Moderator { user: User, privileges: Vec&lt;Privilege> } impl AsRef&lt;Moderator> for Moderator { fn as_ref(&amp;self) -> &amp;Moderator { self } } impl AsRef&lt;User> for Moderator { fn as_ref(&amp;self) -> &amp;User { &amp;self.user } } // this should be callable with Users // and Moderators (who are also Users) fn create_post&lt;U: AsRef&lt;User>>(u: U) { let user = u.as_ref(); // etc } fn example(user: User, moderator: Moderator) { create_post(&amp;user); create_post(&amp;moderator); // ✅ } This works because Moderators are just Users. Here&rsquo;s the example from the Deref section except using AsRef instead:
use std::convert::AsRef; struct Human { health_points: u32, } impl AsRef&lt;Human> for Human { fn as_ref(&amp;self) -> &amp;Human { self } } enum Weapon { Spear, Axe, Sword, } // a Soldier is just a Human with a Weapon struct Soldier { human: Human, weapon: Weapon, } impl AsRef&lt;Soldier> for Soldier { fn as_ref(&amp;self) -> &amp;Soldier { self } } impl AsRef&lt;Human> for Soldier { fn as_ref(&amp;self) -> &amp;Human { &amp;self.human } } enum Mount { Horse, Donkey, Cow, } // a Knight is just a Soldier with a Mount struct Knight { soldier: Soldier, mount: Mount, } impl AsRef&lt;Knight> for Knight { fn as_ref(&amp;self) -> &amp;Knight { self } } impl AsRef&lt;Soldier> for Knight { fn as_ref(&amp;self) -> &amp;Soldier { &amp;self.soldier } } impl AsRef&lt;Human> for Knight { fn as_ref(&amp;self) -> &amp;Human { &amp;self.soldier.human } } enum Spell { MagicMissile, FireBolt, ThornWhip, } // a Mage is just a Human who can cast Spells struct Mage { human: Human, spells: Vec&lt;Spell>, } impl AsRef&lt;Mage> for Mage { fn as_ref(&amp;self) -> &amp;Mage { self } } impl AsRef&lt;Human> for Mage { fn as_ref(&amp;self) -> &amp;Human { &amp;self.human } } enum Staff { Wooden, Metallic, Plastic, } // a Wizard is just a Mage with a Staff struct Wizard { mage: Mage, staff: Staff, } impl AsRef&lt;Wizard> for Wizard { fn as_ref(&amp;self) -> &amp;Wizard { self } } impl AsRef&lt;Mage> for Wizard { fn as_ref(&amp;self) -> &amp;Mage { &amp;self.mage } } impl AsRef&lt;Human> for Wizard { fn as_ref(&amp;self) -> &amp;Human { &amp;self.mage.human } } fn borrows_human&lt;H: AsRef&lt;Human>>(human: H) {} fn borrows_soldier&lt;S: AsRef&lt;Soldier>>(soldier: S) {} fn borrows_knight&lt;K: AsRef&lt;Knight>>(knight: K) {} fn borrows_mage&lt;M: AsRef&lt;Mage>>(mage: M) {} fn borrows_wizard&lt;W: AsRef&lt;Wizard>>(wizard: W) {} fn example(human: Human, soldier: Soldier, knight: Knight, mage: Mage, wizard: Wizard) { // all types can be used as Humans borrows_human(&amp;human); borrows_human(&amp;soldier); borrows_human(&amp;knight); borrows_human(&amp;mage); borrows_human(&amp;wizard); // Knights can be used as Soldiers borrows_soldier(&amp;soldier); borrows_soldier(&amp;knight); // Wizards can be used as Mages borrows_mage(&amp;mage); borrows_mage(&amp;wizard); // Knights &amp; Wizards passed as themselves borrows_knight(&amp;knight); borrows_wizard(&amp;wizard); } Deref didn&rsquo;t work in the prior version of the example above because deref coercion is an implicit conversion between types which leaves room for people to mistakenly formulate the wrong ideas and expectations for how it will behave. AsRef works above because it makes the conversion between types explicit and there&rsquo;s no room leftover to develop any wrong ideas or expectations.
Borrow &amp; BorrowMut Prerequisites
Self Methods Generic Parameters Subtraits &amp; Supertraits Sized AsRef &amp; AsMut PartialEq &amp; Eq Hash PartialOrd &amp; Ord trait Borrow&lt;Borrowed> where Borrowed: ?Sized, { fn borrow(&amp;self) -> &amp;Borrowed; } trait BorrowMut&lt;Borrowed>: Borrow&lt;Borrowed> where Borrowed: ?Sized, { fn borrow_mut(&amp;mut self) -> &amp;mut Borrowed; } These traits were invented to solve the very specific problem of looking up String keys in HashSets, HashMaps, BTreeSets, and BTreeMaps using &amp;str values.
We can view Borrow&lt;T> and BorrowMut&lt;T> as stricter versions of AsRef&lt;T> and AsMut&lt;T>, where the returned reference &amp;T has equivalent Eq, Hash, and Ord impls to Self. This is more easily explained with a commented example:
use std::borrow::Borrow; use std:#️⃣:Hasher; use std::collections::hash_map::DefaultHasher; use std:#️⃣:Hash; fn get_hash&lt;T: Hash>(t: T) -> u64 { let mut hasher = DefaultHasher::new(); t.hash(&amp;mut hasher); hasher.finish() } fn asref_example&lt;Owned, Ref>(owned1: Owned, owned2: Owned) where Owned: Eq + Ord + Hash + AsRef&lt;Ref>, Ref: Eq + Ord + Hash { let ref1: &amp;Ref = owned1.as_ref(); let ref2: &amp;Ref = owned2.as_ref(); // refs aren't required to be equal if owned types are equal assert_eq!(owned1 == owned2, ref1 == ref2); // ❌ let owned1_hash = get_hash(&amp;owned1); let owned2_hash = get_hash(&amp;owned2); let ref1_hash = get_hash(&amp;ref1); let ref2_hash = get_hash(&amp;ref2); // ref hashes aren't required to be equal if owned type hashes are equal assert_eq!(owned1_hash == owned2_hash, ref1_hash == ref2_hash); // ❌ // ref comparisons aren't required to match owned type comparisons assert_eq!(owned1.cmp(&amp;owned2), ref1.cmp(&amp;ref2)); // ❌ } fn borrow_example&lt;Owned, Borrowed>(owned1: Owned, owned2: Owned) where Owned: Eq + Ord + Hash + Borrow&lt;Borrowed>, Borrowed: Eq + Ord + Hash { let borrow1: &amp;Borrowed = owned1.borrow(); let borrow2: &amp;Borrowed = owned2.borrow(); // borrows are required to be equal if owned types are equal assert_eq!(owned1 == owned2, borrow1 == borrow2); // ✅ let owned1_hash = get_hash(&amp;owned1); let owned2_hash = get_hash(&amp;owned2); let borrow1_hash = get_hash(&amp;borrow1); let borrow2_hash = get_hash(&amp;borrow2); // borrow hashes are required to be equal if owned type hashes are equal assert_eq!(owned1_hash == owned2_hash, borrow1_hash == borrow2_hash); // ✅ // borrow comparisons are required to match owned type comparisons assert_eq!(owned1.cmp(&amp;owned2), borrow1.cmp(&amp;borrow2)); // ✅ } It&rsquo;s good to be aware of these traits and understand why they exist since it helps demystify some of the methods on HashSet, HashMap, BTreeSet, and BTreeMap but it&rsquo;s very rare that we would ever need to impl these traits for any of our types because it&rsquo;s very rare that we would ever need create a pair of types where one is the &ldquo;borrowed&rdquo; version of the other in the first place. If we have some T then &amp;T will get the job done 99.99% of the time, and T: Borrow&lt;T> is already implemented for all T because of a generic blanket impl, so we don&rsquo;t need to manually impl it and we don&rsquo;t need to create some U such that T: Borrow&lt;U>.
ToOwned Prerequisites
Self Methods Default Impls Clone Borrow &amp; BorrowMut trait ToOwned { type Owned: Borrow&lt;Self>; fn to_owned(&amp;self) -> Self::Owned; // provided default impls fn clone_into(&amp;self, target: &amp;mut Self::Owned); } ToOwned is a more generic version of Clone. Clone allows us to take a &amp;T and turn it into an T but ToOwned allows us to take a &amp;Borrowed and turn it into a Owned where Owned: Borrow&lt;Borrowed>.
In other words, we can&rsquo;t &ldquo;clone&rdquo; a &amp;str into a String, or a &amp;Path into a PathBuf, or an &amp;OsStr into an OsString, since the clone method signature doesn&rsquo;t support this kind of cross-type cloning, and that&rsquo;s what ToOwned was made for.
For similar reasons as Borrow and BorrowMut, it&rsquo;s good to be aware of this trait and understand why it exists but it&rsquo;s very rare we&rsquo;ll ever need to impl it for any of our types.
Iteration Traits Iterator Prerequisites
Self Methods Associated Types Default Impls trait Iterator { type Item; fn next(&amp;mut self) -> Option&lt;Self::Item>; // provided default impls fn size_hint(&amp;self) -> (usize, Option&lt;usize>); fn count(self) -> usize; fn last(self) -> Option&lt;Self::Item>; fn advance_by(&amp;mut self, n: usize) -> Result&lt;(), usize>; fn nth(&amp;mut self, n: usize) -> Option&lt;Self::Item>; fn step_by(self, step: usize) -> StepBy&lt;Self>; fn chain&lt;U>( self, other: U ) -> Chain&lt;Self, &lt;U as IntoIterator>::IntoIter> where U: IntoIterator&lt;Item = Self::Item>; fn zip&lt;U>(self, other: U) -> Zip&lt;Self, &lt;U as IntoIterator>::IntoIter> where U: IntoIterator; fn map&lt;B, F>(self, f: F) -> Map&lt;Self, F> where F: FnMut(Self::Item) -> B; fn for_each&lt;F>(self, f: F) where F: FnMut(Self::Item); fn filter&lt;P>(self, predicate: P) -> Filter&lt;Self, P> where P: FnMut(&amp;Self::Item) -> bool; fn filter_map&lt;B, F>(self, f: F) -> FilterMap&lt;Self, F> where F: FnMut(Self::Item) -> Option&lt;B>; fn enumerate(self) -> Enumerate&lt;Self>; fn peekable(self) -> Peekable&lt;Self>; fn skip_while&lt;P>(self, predicate: P) -> SkipWhile&lt;Self, P> where P: FnMut(&amp;Self::Item) -> bool; fn take_while&lt;P>(self, predicate: P) -> TakeWhile&lt;Self, P> where P: FnMut(&amp;Self::Item) -> bool; fn map_while&lt;B, P>(self, predicate: P) -> MapWhile&lt;Self, P> where P: FnMut(Self::Item) -> Option&lt;B>; fn skip(self, n: usize) -> Skip&lt;Self>; fn take(self, n: usize) -> Take&lt;Self>; fn scan&lt;St, B, F>(self, initial_state: St, f: F) -> Scan&lt;Self, St, F> where F: FnMut(&amp;mut St, Self::Item) -> Option&lt;B>; fn flat_map&lt;U, F>(self, f: F) -> FlatMap&lt;Self, U, F> where F: FnMut(Self::Item) -> U, U: IntoIterator; fn flatten(self) -> Flatten&lt;Self> where Self::Item: IntoIterator; fn fuse(self) -> Fuse&lt;Self>; fn inspect&lt;F>(self, f: F) -> Inspect&lt;Self, F> where F: FnMut(&amp;Self::Item); fn by_ref(&amp;mut self) -> &amp;mut Self; fn collect&lt;B>(self) -> B where B: FromIterator&lt;Self::Item>; fn partition&lt;B, F>(self, f: F) -> (B, B) where F: FnMut(&amp;Self::Item) -> bool, B: Default + Extend&lt;Self::Item>; fn partition_in_place&lt;'a, T, P>(self, predicate: P) -> usize where Self: DoubleEndedIterator&lt;Item = &amp;'a mut T>, T: 'a, P: FnMut(&amp;T) -> bool; fn is_partitioned&lt;P>(self, predicate: P) -> bool where P: FnMut(Self::Item) -> bool; fn try_fold&lt;B, F, R>(&amp;mut self, init: B, f: F) -> R where F: FnMut(B, Self::Item) -> R, R: Try&lt;Ok = B>; fn try_for_each&lt;F, R>(&amp;mut self, f: F) -> R where F: FnMut(Self::Item) -> R, R: Try&lt;Ok = ()>; fn fold&lt;B, F>(self, init: B, f: F) -> B where F: FnMut(B, Self::Item) -> B; fn fold_first&lt;F>(self, f: F) -> Option&lt;Self::Item> where F: FnMut(Self::Item, Self::Item) -> Self::Item; fn all&lt;F>(&amp;mut self, f: F) -> bool where F: FnMut(Self::Item) -> bool; fn any&lt;F>(&amp;mut self, f: F) -> bool where F: FnMut(Self::Item) -> bool; fn find&lt;P>(&amp;mut self, predicate: P) -> Option&lt;Self::Item> where P: FnMut(&amp;Self::Item) -> bool; fn find_map&lt;B, F>(&amp;mut self, f: F) -> Option&lt;B> where F: FnMut(Self::Item) -> Option&lt;B>; fn try_find&lt;F, R>( &amp;mut self, f: F ) -> Result&lt;Option&lt;Self::Item>, &lt;R as Try>::Error> where F: FnMut(&amp;Self::Item) -> R, R: Try&lt;Ok = bool>; fn position&lt;P>(&amp;mut self, predicate: P) -> Option&lt;usize> where P: FnMut(Self::Item) -> bool; fn rposition&lt;P>(&amp;mut self, predicate: P) -> Option&lt;usize> where Self: ExactSizeIterator + DoubleEndedIterator, P: FnMut(Self::Item) -> bool; fn max(self) -> Option&lt;Self::Item> where Self::Item: Ord; fn min(self) -> Option&lt;Self::Item> where Self::Item: Ord; fn max_by_key&lt;B, F>(self, f: F) -> Option&lt;Self::Item> where F: FnMut(&amp;Self::Item) -> B, B: Ord; fn max_by&lt;F>(self, compare: F) -> Option&lt;Self::Item> where F: FnMut(&amp;Self::Item, &amp;Self::Item) -> Ordering; fn min_by_key&lt;B, F>(self, f: F) -> Option&lt;Self::Item> where F: FnMut(&amp;Self::Item) -> B, B: Ord; fn min_by&lt;F>(self, compare: F) -> Option&lt;Self::Item> where F: FnMut(&amp;Self::Item, &amp;Self::Item) -> Ordering; fn rev(self) -> Rev&lt;Self> where Self: DoubleEndedIterator; fn unzip&lt;A, B, FromA, FromB>(self) -> (FromA, FromB) where Self: Iterator&lt;Item = (A, B)>, FromA: Default + Extend&lt;A>, FromB: Default + Extend&lt;B>; fn copied&lt;'a, T>(self) -> Copied&lt;Self> where Self: Iterator&lt;Item = &amp;'a T>, T: 'a + Copy; fn cloned&lt;'a, T>(self) -> Cloned&lt;Self> where Self: Iterator&lt;Item = &amp;'a T>, T: 'a + Clone; fn cycle(self) -> Cycle&lt;Self> where Self: Clone; fn sum&lt;S>(self) -> S where S: Sum&lt;Self::Item>; fn product&lt;P>(self) -> P where P: Product&lt;Self::Item>; fn cmp&lt;I>(self, other: I) -> Ordering where I: IntoIterator&lt;Item = Self::Item>, Self::Item: Ord; fn cmp_by&lt;I, F>(self, other: I, cmp: F) -> Ordering where F: FnMut(Self::Item, &lt;I as IntoIterator>::Item) -> Ordering, I: IntoIterator; fn partial_cmp&lt;I>(self, other: I) -> Option&lt;Ordering> where I: IntoIterator, Self::Item: PartialOrd&lt;&lt;I as IntoIterator>::Item>; fn partial_cmp_by&lt;I, F>( self, other: I, partial_cmp: F ) -> Option&lt;Ordering> where F: FnMut(Self::Item, &lt;I as IntoIterator>::Item) -> Option&lt;Ordering>, I: IntoIterator; fn eq&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialEq&lt;&lt;I as IntoIterator>::Item>; fn eq_by&lt;I, F>(self, other: I, eq: F) -> bool where F: FnMut(Self::Item, &lt;I as IntoIterator>::Item) -> bool, I: IntoIterator; fn ne&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialEq&lt;&lt;I as IntoIterator>::Item>; fn lt&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialOrd&lt;&lt;I as IntoIterator>::Item>; fn le&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialOrd&lt;&lt;I as IntoIterator>::Item>; fn gt&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialOrd&lt;&lt;I as IntoIterator>::Item>; fn ge&lt;I>(self, other: I) -> bool where I: IntoIterator, Self::Item: PartialOrd&lt;&lt;I as IntoIterator>::Item>; fn is_sorted(self) -> bool where Self::Item: PartialOrd&lt;Self::Item>; fn is_sorted_by&lt;F>(self, compare: F) -> bool where F: FnMut(&amp;Self::Item, &amp;Self::Item) -> Option&lt;Ordering>; fn is_sorted_by_key&lt;F, K>(self, f: F) -> bool where F: FnMut(Self::Item) -> K, K: PartialOrd&lt;K>; } Iterator&lt;Item = T> types can be iterated and will produce T types. There&rsquo;s no IteratorMut trait. Each Iterator impl can specify whether it returns immutable references, mutable references, or owned values via the Item associated type.
Vec&lt;T> method Returns .iter() Iterator&lt;Item = &amp;T> .iter_mut() Iterator&lt;Item = &amp;mut T> .into_iter() Iterator&lt;Item = T> Something that is not immediately obvious to beginner Rustaceans but that intermediate Rustaceans take for granted is that most types are not their own iterators. If a type is iterable we almost always impl some custom iterator type which iterates over it rather than trying to make it iterate over itself:
struct MyType { items: Vec&lt;String> } impl MyType { fn iter(&amp;self) -> impl Iterator&lt;Item = &amp;String> { MyTypeIterator { index: 0, items: &amp;self.items } } } struct MyTypeIterator&lt;'a> { index: usize, items: &amp;'a Vec&lt;String> } impl&lt;'a> Iterator for MyTypeIterator&lt;'a> { type Item = &amp;'a String; fn next(&amp;mut self) -> Option&lt;Self::Item> { if self.index >= self.items.len() { None } else { let item = &amp;self.items[self.index]; self.index += 1; Some(item) } } } For the sake of teaching the above example shows how to impl an Iterator from scratch but the idiomatic solution in this situation would be to just defer to Vec&rsquo;s iter method:
struct MyType { items: Vec&lt;String> } impl MyType { fn iter(&amp;self) -> impl Iterator&lt;Item = &amp;String> { self.items.iter() } } Also this is a good generic blanket impl to be aware of:
impl&lt;I: Iterator + ?Sized> Iterator for &amp;mut I; It says that any mutable reference to an iterator is also an iterator. This is useful to know because it allows us to use iterator methods with self receivers as if they had &amp;mut self receivers.
As an example, imagine we have a function which processes an iterator of more than three items, but the first step of the function is to take out the first three items of the iterator and process them separately before iterating over the remaining items, here&rsquo;s how a beginner may attempt to write this function:
fn example&lt;I: Iterator&lt;Item = i32>>(mut iter: I) { let first3: Vec&lt;i32> = iter.take(3).collect(); for item in iter { // ❌ iter consumed in line above // process remaining items } } Well that&rsquo;s annoying. The take method has a self receiver so it seems like we cannot call it without consuming the whole iterator! Here&rsquo;s what a naive refactor of the above code might look like:
fn example&lt;I: Iterator&lt;Item = i32>>(mut iter: I) { let first3: Vec&lt;i32> = vec![ iter.next().unwrap(), iter.next().unwrap(), iter.next().unwrap(), ]; for item in iter { // ✅ // process remaining items } } Which is okay. However, the idiomatic refactor is actually:
fn example&lt;I: Iterator&lt;Item = i32>>(mut iter: I) { let first3: Vec&lt;i32> = iter.by_ref().take(3).collect(); for item in iter { // ✅ // process remaining items } } Not very easy to discover. But anyway, now we know.
Also, there are no rules or conventions on what can or cannot be an iterator. If the type impls Iterator then it&rsquo;s an iterator. Some creative examples from the standard library:
use std::sync::mpsc::channel; use std::thread; fn paths_can_be_iterated(path: &amp;Path) { for part in path { // iterate over parts of a path } } fn receivers_can_be_iterated() { let (send, recv) = channel(); thread::spawn(move || { send.send(1).unwrap(); send.send(2).unwrap(); send.send(3).unwrap(); }); for received in recv { // iterate over received values } } IntoIterator Prerequisites
Self Methods Associated Types Iterator trait IntoIterator where &lt;Self::IntoIter as Iterator>::Item == Self::Item, { type Item; type IntoIter: Iterator; fn into_iter(self) -> Self::IntoIter; } IntoIterator types can be converted into iterators, hence the name. The into_iter method is called on a type when it&rsquo;s used within a for-in loop:
// vec = Vec&lt;T> for v in vec {} // v = T // above line desugared for v in vec.into_iter() {} Not only does Vec impl IntoIterator but so does &amp;Vec and &amp;mut Vec if we&rsquo;d like to iterate over immutable or mutable references instead of owned values, respectively.
// vec = Vec&lt;T> for v in &amp;vec {} // v = &amp;T // above example desugared for v in (&amp;vec).into_iter() {} // vec = Vec&lt;T> for v in &amp;mut vec {} // v = &amp;mut T // above example desugared for v in (&amp;mut vec).into_iter() {} FromIterator Prerequisites
Self Functions Generic Parameters Iterator IntoIterator trait FromIterator&lt;A> { fn from_iter&lt;T>(iter: T) -> Self where T: IntoIterator&lt;Item = A>; } FromIterator types can be created from an iterator, hence the name. FromIterator is most commonly and idiomatically used by calling the collect method on Iterator:
fn collect&lt;B>(self) -> B where B: FromIterator&lt;Self::Item>; Example of collecting an Iterator&lt;Item = char> into a String:
fn filter_letters(string: &amp;str) -> String { string.chars().filter(|c| c.is_alphabetic()).collect() } All the collections in the standard library impl IntoIterator and FromIterator so that makes it easier to convert between them:
use std::collections::{BTreeSet, HashMap, HashSet, LinkedList}; // String -> HashSet&lt;char> fn unique_chars(string: &amp;str) -> HashSet&lt;char> { string.chars().collect() } // Vec&lt;T> -> BTreeSet&lt;T> fn ordered_unique_items&lt;T: Ord>(vec: Vec&lt;T>) -> BTreeSet&lt;T> { vec.into_iter().collect() } // HashMap&lt;K, V> -> LinkedList&lt;(K, V)> fn entry_list&lt;K, V>(map: HashMap&lt;K, V>) -> LinkedList&lt;(K, V)> { map.into_iter().collect() } // and countless more possible examples I/O Traits Read &amp; Write Prerequisites
Self Methods Scope Generic Blanket Impls trait Read { fn read(&amp;mut self, buf: &amp;mut [u8]) -> Result&lt;usize>; // provided default impls fn read_vectored(&amp;mut self, bufs: &amp;mut [IoSliceMut&lt;'_>]) -> Result&lt;usize>; fn is_read_vectored(&amp;self) -> bool; unsafe fn initializer(&amp;self) -> Initializer; fn read_to_end(&amp;mut self, buf: &amp;mut Vec&lt;u8>) -> Result&lt;usize>; fn read_to_string(&amp;mut self, buf: &amp;mut String) -> Result&lt;usize>; fn read_exact(&amp;mut self, buf: &amp;mut [u8]) -> Result&lt;()>; fn by_ref(&amp;mut self) -> &amp;mut Self where Self: Sized; fn bytes(self) -> Bytes&lt;Self> where Self: Sized; fn chain&lt;R: Read>(self, next: R) -> Chain&lt;Self, R> where Self: Sized; fn take(self, limit: u64) -> Take&lt;Self> where Self: Sized; } trait Write { fn write(&amp;mut self, buf: &amp;[u8]) -> Result&lt;usize>; fn flush(&amp;mut self) -> Result&lt;()>; // provided default impls fn write_vectored(&amp;mut self, bufs: &amp;[IoSlice&lt;'_>]) -> Result&lt;usize>; fn is_write_vectored(&amp;self) -> bool; fn write_all(&amp;mut self, buf: &amp;[u8]) -> Result&lt;()>; fn write_all_vectored(&amp;mut self, bufs: &amp;mut [IoSlice&lt;'_>]) -> Result&lt;()>; fn write_fmt(&amp;mut self, fmt: Arguments&lt;'_>) -> Result&lt;()>; fn by_ref(&amp;mut self) -> &amp;mut Self where Self: Sized; } Generic blanket impls worth knowing:
impl&lt;R: Read + ?Sized> Read for &amp;mut R; impl&lt;W: Write + ?Sized> Write for &amp;mut W; These say that any mutable reference to a Read type is also Read, and same with Write. This is useful to know because it allows us to use any method with a self receiver as if it had a &amp;mut self receiver. We already went over how to do this and why it&rsquo;s useful in the Iterator trait section so I&rsquo;m not going to repeat it again here.
I&rsquo;d like to point out that &amp;[u8] impls Read and that Vec&lt;u8> impls Write so we can easily unit test our file handling functions using Strings which are trivial to convert to &amp;[u8] and from Vec&lt;u8>:
use std::path::Path; use std::fs::File; use std::io::Read; use std::io::Write; use std::io; // function we want to test fn uppercase&lt;R: Read, W: Write>(mut read: R, mut write: W) -> Result&lt;(), io::Error> { let mut buffer = String::new(); read.read_to_string(&amp;mut buffer)?; let uppercase = buffer.to_uppercase(); write.write_all(uppercase.as_bytes())?; write.flush()?; Ok(()) } // in actual program we'd pass Files fn example(in_path: &amp;Path, out_path: &amp;Path) -> Result&lt;(), io::Error> { let in_file = File::open(in_path)?; let out_file = File::open(out_path)?; uppercase(in_file, out_file) } // however in unit tests we can use Strings! #[test] // ✅ fn example_test() { let in_file: String = "i am screaming".into(); let mut out_file: Vec&lt;u8> = Vec::new(); uppercase(in_file.as_bytes(), &amp;mut out_file).unwrap(); let out_result = String::from_utf8(out_file).unwrap(); assert_eq!(out_result, "I AM SCREAMING"); } Conclusion We learned a lot together! Too much in fact. This is us now:
Artist credit: The Jenkins Comic
Discuss Discuss this article on
Github learnrust subreddit official Rust users forum Twitter lobste.rs rust subreddit Notifications Get notified when the next blog post get published by
Following pretzelhammer on Twitter or Watching this repo&rsquo;s releases (click Watch -> click Custom -> select Releases -> click Apply) Further Reading Sizedness in Rust Common Rust Lifetime Misconceptions Learning Rust in 2020 Learn Assembly with Entirely Too Many Brainfuck Compilers source:Tour of Rust&rsquo;s Standard Library Traits</content></entry><entry><title>Python 如何实现一个拼写检查器[翻译]</title><url>https://zhimoe.github.io/post/python-spell-correct/</url><categories><category>翻译</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> 谷歌 AI 负责人 norvig 在 07 年写的如何实现一个拼写纠正器的经典博文How to Write a Spelling Corrector.
上面的链接已经是 16 年更新过了，程序也更新到了 python3.
中文版的翻译 如何实现一个拼写纠正器 还是基于 07 年版本的。
博文最有意思的地方是大牛记录了如何在飞机上面没有网络的条件下徒手写一个准确率超过 70% 的拼写纠正器。</content></entry><entry><title>Associated Type in Rust</title><url>https://zhimoe.github.io/post/rust-associated-types/</url><categories><category>编程</category></categories><tags><tag>rust</tag></tags><content type="html"> Associated Type and generic diff in rust
type outside impl a type Foo = Bar outside is just type alias. most used in generic type.
like: type Thunk = Box&lt;dyn Fn() + Send + 'static>;
type inside impl type in an impl defines an associated type. associated type 可以理解为一个类型占位符，在 trait 的方法声明中使用。
pub trait Iterator { type Item; // or type T: Display; fn next(&amp;mut self) -> Option&lt;Self::Item>; } 这里 Iterator 的 Implementors 将会指定 Item 的具体类型。例如：
impl Iterator for Counter { type Item = u32; fn next(&amp;mut self) -> Option&lt;Self::Item> { // --snip-- } } diff in associated type and generic 直接将上面的Iterator声明为如下泛型不是更简单么？
pub trait Iterator&lt;T> { fn next(&amp;mut self) -> Option&lt;T>; } // with generice, you can set default type: /// trait Iterator&lt;T = String> /// where T: Display, 主要的区别就是 generic 可是有任意多个实现，因为Iterator&lt;Foo>和Iterator&lt;Bar>是两个不同的类型。
而 associated type 只能有一个实现，因为Iterator只有一个类型，所以 associated type 可以用于限制类型。
when use The quick and dirty answer to when to use generics and when to use associated types is:
Use generics if it makes sense to have multiple implementations of a trait for a specific type (such as the From&lt;T> trait).
Otherwise, use associated types (like Iterator and Deref).
假设我们实现一个 redis 客户端，那么比较适合使用 associated types:
trait RedisCommand{ type Response; fn receive(&amp;self, message: String) -> Result&lt;Self::Response>; } impl RedisCommand for PingCommand { type Response = String fn receive(&amp;self, message: String) -> Result&lt;Self::Response>{ // -- snip -- } }</content></entry><entry><title>最佳编程字体</title><url>https://zhimoe.github.io/post/programming-fonts/</url><categories><category>随想</category></categories><tags><tag>font</tag><tag>aurulent</tag><tag>firacode</tag></tags><content type="html"> 个人对于编程字体有一点点洁癖，在尝试十几个字体后，终于使用 FontForge 和 fontline.py 动手修改制作自己的编程字体:Aurulent 和 Fira Code。
Aurulent 字体下载
小写字母来自 Aurulent Sans Mono，其他基于 Fira Code.Aurulent Sans Mono 风格和 SourceCodePro 非常像，胖宽型，大开大合，简单却有具有设计，特别是字符 g，a，p，y，s。 字母 r 的思路来自gintronic. 优点是在低分辨率屏，r 的末尾不会被 hint 只剩下尖尖。 问号？也来自 gintronic 字体，非常漂亮。 Aurulent 效果
Fira Code Fira Code 是全网最受欢迎的字体，但是这个 r 实在过于 fancy，所以重新构建了一个版本，只提供 regular 和 bold 两个字重
MonoLisa 目前在用也是最喜欢的收费字体， MonoLisa完美体现了官网上面的"font follows function"宣言，整个字体在代码阅读中有一种从左到右的流动感。也是自己第二次付费字体 (第一次是方正)
唯一不足的是和 fira code 相比，开发者在 hint 方面不太行，每个版本总是会有一些 hint 问题，在非 4K 显示器上面效果会很糟糕，例如"=>&ldquo;的等号会明显上下粗细不一致。因为自己都是 4K 显示器，干脆就使用 fontforge 进行 dehint 处理。
其他编程字体 个人比较喜欢的字体有
SourceCodePro，只是这个 r 在低分辨率下一塌糊涂，结合 office code pro 做了一个更适合正文的SourceCodePro 版本 Adobe LetterGothic：这是一个经典的 IBM 打字机字体。这个字体经典在于字符 r 是我认为所有字体里面设计的最漂亮的，在字体设计中，感觉 r 是最难设计的，像 fira code 这种 r，有点过于 fancy，很容易吸引你的目光; 像 source code pro 那种超级简洁，在 win 下面渲染除非是高分屏，否则一塌糊涂。除了字符 r，letter gothic 作为 1960 时代打字机默认字体之一，在字符 n，u 的角上，都保留了非常漂亮而含蓄的细节，这一点，我非常吐槽 jetbrains mono 字体，居然把小写 u 的尾巴去掉，声称可以加快阅读，或许能提速，但是丢了美感。LetterGothic 具体的效果看我之前的推文 Thread. TheSansMono: 经典等宽字体。你可以在很多书上面看到这个字体。斜体是所有字体最好看的，收费，作者也是 windows 经典的代码字体 Consolas 作者。 Letter Gothic 效果
非编程英文字体推荐 Sans 类 一般黑体中文适合搭配 Sans 英文字体，推荐经典的 Open Sans，Inter，Lato，Fira Sans。Inter 风头正盛，很多网站包括 2023 的 jetbrains IDE UI 字体都换成这个了，特点就是没有任何特色。个人认为 Lato 设计细节最佳，但确实不适合用于 UI，但是在网站正文中使用非常不错。
收费字体中Sana Sans在正文中效果也不错，播客网站 changelog 用的就是这个字体。
Serif 类 一般宋体中文适合搭配衬线英文字体，推荐 Palatino 和 Merriweather，后者是 google font 上面排名第一的 serif 字体，缺点是字体偏粗。
手写体 大部分手写体都不适合阅读，但是Alegreya Sans斜体比较合适，在手写风格和可读性达到较好平衡。</content></entry><entry><title>如何正确地系鞋带</title><url>https://zhimoe.github.io/post/how-to-tie-shoelace/</url><categories><category>生活</category></categories><tags><tag>鞋带</tag></tags><content type="html"> Ian 安全结是登山系鞋带的首选，它越穿越紧，不会松开。解鞋带轻轻一拉即开。而且对称美观，上手简单。值得每个人花十分钟学习。
本篇不仅给出 Ian 安全结示意图，还告诉大家如何让安全结和蝴蝶结水平对称，尽可能美观的秘诀。
以上是 Ian 结的步骤。下面是重点：
无论是 Ian 蝴蝶结还是安全结，如果你发现自己的鞋带系完是斜的而非水平，原因是第一个辅助结和第二个结上下关系反了。即图 1 的那个结是辅助结，黄色在上，蓝色在下，那么第二个结必须和图 2 中一样，黄色在上，蓝色在下，如果你在第二步黄蓝反了，最后成结就是斜的!!! 这是我毕生绝学了。
Ian 安全结想要好看的诀窍在于，在快要拉紧绳结之前，先拉住鞋带两端松一下结，假装要扯开鞋带，这样安全结内部会变整齐，然后抓住 8 字环两端拉紧鞋带。注意，是快要拉紧之前扯松一下，扯的时候绳结应该已经有点摩擦了，太松了外扯整理不到结的内部，太紧了外扯结也不会改变形状了，就是拉紧之前反复整理一下，注意，如果这里你辅助结上下关系错了，最后很难整理出来满意的效果。最后的效果应该是最后一幅图的效果，而不是第一幅的图 6 那么丑的。
作者：zhimoe
链接：https://www.zhihu.com/question/19728687/answer/501699533
补充：
实际上 Ian 结就是普通的蝴蝶结，也是目前最快的系鞋带方法，缺点就是会松动。而 Ian 安全结学名是双打结（Double Slip Knot）。
这里有Ian 结发明者的官方网站，里面有超级多系鞋带方法，我在 25 岁之前都是用的蝴蝶结，学会安全结之后就再也没有松鞋带的烦恼了。</content></entry><entry><title>Java 8 Lambda 笔记</title><url>https://zhimoe.github.io/post/java-lambda/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>java</tag><tag>lambda</tag></tags><content type="html"> 问题 Java 是 OOP 语言，使用对象封装。由于函数不是一等公民，无法在方法中传递函数/方法。在 Java 8 之前，使用匿名类表示行为：
// 监听器接口 public interface ActionListener { void actionPerformed(ActionEvent e); } // 使用匿名类传递一个行为 button.addActionListener(new ActionListener(){ public void actionPerformed(Event e){ System.out.println("button clicked"); } }); 上面的代码主要的问题在于addActionListener方法期望的是一个行为，为了描述这个行为（代码即数据的概念）,在 Java 中不得不传入一个对象。除了代码冗余，还存在下面问题
业务逻辑淹没在匿名类语法中，就像 Go 语言的if err != nil一样 匿名类中的 this 和变量名容易使人产生误解 类型载入和实例创建语义不够灵活 无法捕获非 final 的局部变量 lambda 表达式 为了解决上面的问题，Java8 推出了 lambda 表达式——当接口只有一个抽象方法时，称为函数式接口（也叫单抽象方法类型，SAM 类型）,可以使用 lambda 表达式表示这个接口的实现方法。
button.addActionListener(e -> System.out.println("button clicked")); 其中的e是actionPerformed(Event e)方法的参数，-> 后面的是方法体。注意这里我们并没有提供 e 的类型，这是由类型推导技术实现的——javac 根据addActionListener方法签名和actionPerformed方法签名推导出参数类型只能是Event.
不是所有情况都可以省略类型，但是请给 IDE 表现机会，只有在 IDE 提醒你有错误时再补充上类型信息。
下面都是合法的 lambda 表达式：
Runnable tsk = () -> println(""); Runnable tsk = name -> { println(name);} BinaryOperator&lt;Long> add = (Long x, Long y) -> x + y; BinaryOperator&lt;Long> add = (x, y) -> {return x + y;} //类型推断，return 和{}是冗余的 // &lt;!-- 参数括号和大括号省略规则 --> // 1. 参数 ()：无参数使用 (),1 个参数可以省略括号，其他使用 (). // 2. 函数体{}：单语句的可以省略{},多条语句必须有{} 在 Java 中，已经有大量的函数式接口：
java.lang.Runnable java.util.concurrent.Callable java.security.PrivilegedAction java.util.Comparator java.io.FileFilter java.beans.PropertyChangeListener this 指向调用者，也即是 button lambda 的类型是根据上下文来决定的，所以相同入参和返回值情况下，目标类型可能不同，在无法判断时，需要补充目标类型信息： Callable&lt;String> c = () -> "done"; PrivilegedAction&lt;String> a = () -> "done"; // error var add = (Long x, Long y) -> x + y; // 这里 add 会报错： // java: cannot infer type for local variable add // (lambda expression needs an explicit target-type) // 因为满足 (Long, Long) -> Long 的函数式接口很多，编译器无法知道 add 目标类型应该是什么。 当涉及到泛型时，类型推导总是有点力不从心，需要添加必要的类型信息： 函数式接口与@FunctionalInterface 有了 lambda 和函数式接口，框架方法在形参类型上面可以更加泛化了。例如你希望你的框架方法支持一个 T->R 的操作，你可能会定义一个
@FunctionalInterface public interface Transfer&lt;T, R> { R apply(T t); } 这里 T,R 是泛型，这是一个非常泛化的函数式接口。所以 Java8 在 util.function 包中新增了 43 个函数式接口，目的就是方便框架开发者能够减少新建自己的 FunctionalInterface.
基础的接口只有 6 个：
接口 函数签名 举例 UnaryOperator R apply(T t); String::toLocaerCase BinaryOperator R apply(T t, U u); BigInterger::add Predicate boolean test(T t); Collection::isEmpty Function R apply(T t); Arrays::asList Supplier T get(); Instant::now Consumer void accept(T t); System.out::println 上面的是基础接口，此外还有：
Consumer, Function, Predicate 各自有一个 2 个入参的版本，共 3 个:BiConsumer,BiFunction,BiPredicate. 6 个基础接口对应入参为基本类型 int,long,double 的接口，共 18 个:IntSupplier,LongFunction&hellip; 6 个基础接口对应返回值为基本类型 int,long,double 的 Function 和 BiFunction，共 6 个：ToIntBiFunction,ToIntFunction&hellip; int,long,double 基本类型互转的 Function 共 6 个：DoubleToIntFunction,DoubleToLongFunction,IntToDoubleFunction,IntToLongFuncion,LongToDoubleFunction,LongToIntFunction. Consumer 有同时接受一个 Object 和一个基本类型的版本，共 3 个：ObjDoubleConsumer{void accept(T t, int value);} 最后还有一个 BooleanSupplier{boolean getAsBoolean();} 第一次见到 BooleanSupplier 可能完全不知道使用场景，毕竟有 Supplier不就可以了么？
上面的基础接口虽然非常通用，但是如果有更好的接口名称时，应该使用更合适的那个。例如 Comparator{int compare(T o1, T o2);}和 ToIntBiFunction&lt;T, U> {int applyAsInt(T t, U u);}签名完全一致，但是还是在比较的时候使用 Comparator.
在构建自己的函数式接口时，务必使用注解@FunctionalInterface标注你的接口，这样可以给 IDE lint 和使用者提供更加充分信息。
方法引用 如果 lambda 表达式的方法体过长，那么需要抽取方法，Java8 提供了更近一步的语法——方法引用。方法引用表示一个 lambda 表达式。只需要引用的方法签名和 lambda 目标类型的抽象方法签名一致即可。
方法引用一共有 5 种类型，其中，静态方法是最常用的类型。
方法引用类型 方法引用 对应 lambda 表达式 静态方法 Integer::parseInt str-> Integer.parseInt(str) 有限制 (Bound receiver) 实例引用 Instant.now()::isAfter Instant then = Instant.now(); then.isAfter(t) 无限制 (Unbound receiver) 实例引用 String::toLowerCase str -> str.toLowerCase 类构造器 TreeMap&lt;K,V>::new ()-> new TreeMap&lt;K,V>() 数组构造器 int[]::new len->new int[len] Bound receiver 其实很好理解，方法的 receiver(上面的 then = Instant.now()) 是固定的。 Unbound receiver 的含义是方法的接收者 (上面的 str) 是不确定的，通过入参的形式传入。而在方法引用的形式上面反而像静态方法引用 (String::toLowerCase, toLowerCase 不是静态方法，所以不是静态方法引用). 更粗暴的理解就是入参是方法的引用对象，所以方法引用对象取决于入参（不确定）. 数组构造器的比较难以理解，可以看成如下代码： IntFunction&lt;int[]> arrayMaker = int[]::new; int[] array = arrayMaker.apply(len) // 创建数组 int[len]</content></entry><entry><title>基于 MDX 的 web 词典</title><url>https://zhimoe.github.io/post/python-mdict-web/</url><categories><category>随想</category></categories><tags><tag>python</tag><tag>rust</tag></tags><content type="html"> Mdict 项目是一个糅合了 MDX 词典、ES 例句搜索和 AI 模型翻译的多源搜索功能 Web 词典。特别适合部署在内网中学习使用或者给孩子学习使用。
python 版本增加了一个机器学习模型翻译.rust 版本也有模型，但是还没来得及加。
mdict-py mdict-py 源码
Mdict 项目是一个糅合了 MDX 词典、ES 例句搜索和 AI 模型翻译的多源搜索功能 Web 词典。特别适合部署在内网中学习使用或者给孩子学习使用。
特点：
自动识别中英文选择对应 mdx 词典，目前英文词典包含牛津 8 和朗文 4，中文词典包含汉语词典 3 英文尝试拼写纠错功能，动词时态纠错 如果配置了中文会尝试搜索朗文的例句，模糊搜索，对于有英语基础的同学很有用 如果配置了 AI 模型，会使用机器学习模型翻译，翻译结果比较粗糙，但是可以参考 mdict-rs mdict-rs 源码
和 python 版本相比目前只有基本功能：mdx 文件解析，查询。</content></entry><entry><title>Python 4 道笔试题</title><url>https://zhimoe.github.io/post/python-interview-questions/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> 4 道常见的 python 面试题和解答，以及一些 python 陷阱的链接。
问题 题目 1 def change(v): v[1] = 4 return v a = [1, 2, 3] print(change(a)) print(a) 题目 2 def append1(x=[]): x.append(1) return x def now(n=time.time()): time.sleep(1) return n print(append1(), append1()) #? print(now(), now()) #? 题目 3 def arr_multi(): x = [[0] * 3] * 3 x[0][0] = 42 return x print(arr_multi()) 题目 4 def fn_for(): f = [lambda x: x * i for i in range(3)] print(f[0](1), f[1](1), f[2](1)) print(fn_for()) 题目 5 >>> t = (1, 2, [30, 40]) >>> t[2] += [50, 60] run, what happen next? A. `t` becomes `(1, 2, [30, 40, 50, 60])`. B. `TypeError` is raised with the message `'tuple' object does not support item assignment`. C. Neither. D. Both *A* and *B*. 解答 [1, 4, 3] [1, 4, 3] # 就是简单的引用传递，但是很多人不自信，在选择题里面频频出错。 # python 中所有的都是对象，id(obj) 会返回地址。 # 但是如果新建对象是 short string,int [-5,256],不可变的空集合 (empty tuples) 等情况不会真的创建新对象。 from copy import copy, deepcopy arr1 = [1,2,3,[4,5,6]] arr2 = copy(arr1) # shallow copy, new id, but elements in array is same id id(arr1[0]) == id(arr2[0]) #deepcopy arr3 = deepcopy(arr1) # elements id is new # 结果： [1, 1] [1, 1] 1590544209.9695618 1590544209.9695618 # 不少人认为是：[1] [1, 1].其实还是没有深入理解引用的原理， # 翻译一下就很好理解了： y = append1() # id(y) == id(x), y=[1] y = append1() # id(y) == id(x), y=[1,1] print(y,y) # 最好不要使用 [] 作为默认参数，使用下面的形式： def my_func(working_list=None): if working_list is None: working_list = [] working_list.append("a") print(working_list) # 或者 def fun(count=[]): count.append(2) #这里 count 两次调用如果都使用默认参数的话，则是同一个数组，非常危险！ return count fun() #[2] fun() #[2,2] [[42, 0, 0], [42, 0, 0], [42, 0, 0]] # list 是 mutable, []*3 表示是引用复制三次。 # 赋值后为什么只改变列的值？ 2 2 2 None 本意其实是想得到一个函数列表[0x,1x,2*x],
但是 Python’s closures are late binding. This means that the values of variables used in closures are looked up at the time the inner function is called.
解决方案是偏函数 partial
from functools import partial def fix_fn_for(): f = [partial(lambda y, x: y * x, x=i) for i in range(3)] print(f[0](1), f[1](1), f[2](1)) 或：
fl=[lambda x, i=i: x*i for i in range(3)] 答案是D 可以使用dis.dis('s[a] += b')查看执行码 大概得流程是将s[a]加载到stack(tos: top of stack)， 执行tos + b，最后是赋值 s[a] = tos， 但是因为s是tuple，属于不可变类型，抛错。 1. 永远不在默认参数，tuple内等使用可变参数，同题目2。 可变类型包括：list set dict bytesarray四种 2. += 中赋值不是原子操作 3. dis模块其实没有那么复杂，尝试使用发现问题 常见 python 陷阱
The 10 Most Common Mistakes in Python
Some Common Gotchas in Python</content></entry><entry><title>Scala Python 文件读取跳过转义字符</title><url>https://zhimoe.github.io/post/scala-python-file-encoding-escape/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag><tag>python</tag></tags><content type="html"> 在文件读取的时候，会遇到非法转义字符，导致文件按行读取失败。此时可以通过忽略转义字符来解决。本文记录了 scala 和 python 的方法。
背景 有 50G 的服务器日志，拆分为几千个 txt 文件，编码是 utf8，使用 scala 和 python 按行处理：
scala def main(args: Array[String]): Unit = { for (line &lt;- Source.fromFile("./txt1.log","UTF8").getLines()) { if (line.contains("ABC")) { //do something } } } python with open('./txt1.log','r',encoding='utf-8') as f: for line in f: pass #do something 但是文本中有一些行包含非法的转义字符，例如：
http://bbc.com/search.html \xa3\xa9 404 \r\n 李晓明 导致程序异常：
#scala java.nio.charset.MalformedInputException: Input length = 1 #python 'utf-8' codec can't decode byte 0xa3 in position 168: invalid start byte 方案 一般遇到这种非法转义字符，可以跳过这个错误，看成 raw string 来处理。
scala import java.nio.charset.CodingErrorAction import scala.io.{Codec, Source} implicit val codec = Codec("UTF-8") codec.onMalformedInput(CodingErrorAction.REPLACE) codec.onUnmappableCharacter(CodingErrorAction.REPLACE) // 注意，fromFile 方法没有提供"UTF8"参数 def main(args: Array[String]): Unit = { for (line &lt;- Source.fromFile("./test.file").getLines()) { if (line.contains("ABC")) { //do something } } } python with open('./txt1.log','r',encoding='utf-8',errors='ignore') as f: for line in f: pass #do something 如果确认文本中没有中文的话，也可以使用下面的方式直接将其转义掉
with open('./txt1.log','r',encoding='unicode_escape') as f:</content></entry><entry><title>Matplotlib 图例中文乱码解决方案</title><url>https://zhimoe.github.io/post/python-matplotlib-chinese-garbled-solution/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> 很久以前写的一个答案，四年来一直有人评论感谢，说只有我的方法是有效的。非常意外也很高兴。也放到博客中里备份吧。
zhihu.com
# https://www.zhihu.com/question/25404709/answer/67672003 import matplotlib.font_manager as fm # 微软雅黑，如果需要宋体，可以用 simsun.ttc myfont = fm.FontProperties(fname='C:/Windows/Fonts/msyh.ttc') # Linux 字体在"/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc", # 需要先安装字体">sudo apt install fonts-noto-cjk -y" # MacOS 中文字体文件在"/System/Library/Fonts/PingFang.ttc" # Win10,Linux 已测试，MacOS 未验证 import matplotlib.pyplot as plt plt.clf() # 清空画布 plt.plot([1, 2, 3], [4, 5, 6]) plt.xlabel("横轴",fontproperties=myfont) plt.ylabel("纵轴",fontproperties=myfont) plt.title("pythoner.com",fontproperties=myfont) plt.legend(['图例'],prop=myfont) plt.show()</content></entry><entry><title>Rust Ownerships Lifetimes 教程</title><url>https://zhimoe.github.io/post/rust-ownership-lifetimes/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>rust</tag></tags><content type="html"> some notes on rust ownership,reference,string and &amp;str, and lifetimes
rust ownership //heap and stack: stack is store data that known,fixed size. //memory manager keeping track of what parts of code are using what data on the heap, //minimizing the amount of duplicate data on the heap, and cleaning up unused data on the heap //so you don’t run out of space are all problems that ownership addresses. //ownership rules: // Each value in Rust has a variable that’s called its owner. // There can only be one owner at a time. // When the owner goes out of scope, the value will be dropped. // stack only data(栈内数据) assignment will make a copy operation, since it is fixed size, the copy is fast // rust use h.clone() make a heap data deeply copy. // impl the Copy trait can make the original variable still usable after assignment. // Copy trait can not use with Drop trait, Drop 可以理解为 destructor，当数据超过自己的 scope 时，drop() 方法被调用; fn copy() { let x = 5; let y = x; //copy the value(5) in the stack,since it is fixed-size, the copy operation is fast let s1 = String::from("hello"); //String 和 &amp;str 区别见后文 let s2 = s1; //now s1 is invalid // println!("{}, world!", s1); //error, the "hello" ownership move to s2 let s3 = s2.clone(); //copy the heap value("hello"), String impl the Clone trait println!("{}, world!", s2); //s2 still usable } // passing function arguments or return value by function is same as // assigning a value to a variable, you need take care the ownership of heap value, fn ownership() { let x = 5; let x10 = plus10(x);//x still usable since the x is stack data println!("{}", x); println!("{}", x10); let s = String::from("hello"); takes_ownership(s); //s's value moves into the function and so is no longer valid here //println!(s) ;//error! } fn plus10(i: i32) -> i32 { // since the i is primitive in stack, so the function return a new value i + 10 } fn takes_ownership(some_string: String) { // some_string comes into scope println!("{}", some_string); } // Here, some_string goes out of scope and `drop()` is called. The backing memory is freed. 推荐阅读A closer look at Ownership in Rust
References and Borrowing: // since the ownership is too hard to track by coder's eye, rust introduce the ref and borrowing // a function that accept a ref will not takeover a value's ownership when the function is called // also will not drop the value's backend memory when function is return. // a variable can only have one mut ref or many immutable ref in a same scope; //dangling reference fn dangle() -> &amp;String { let s = String::from("dangle ref"); &amp;s //error }// the s is dropped, but the function try to return s reference ### String vs str vs &amp;String vs &amp;str //1. String is heap string buffer //2. &amp;String is a ref of String //3. str is unknown immutable sequence of utf8 bytes stored somewhere in memory. the memory may be: // 3a. in binary: a string literal "foo" is a &amp;'static str. The data is hardcoded into the executable and loaded into memory when the program runs. // 3b. in heap: String implement Deref&lt;Target=str>, and so inherit all of str's methods. // 3c. in stack: when use str::from_utf8(x).unwrap(); x is stack-value ref //> the &amp;str param can accept a &amp;String since the String implement Deref&lt;Target=str>. // 即接受&amp;str 的地方都可以使用&amp;String //!!! since the str is unknown size, one can only use it by &amp;str, called slice. slice is a view of some data. fn str_demo() { let s = "hello str";//The type of s here is &amp;str: it’s a slice pointing to that specific point of the binary. // This is also why string literals are immutable; &amp;str is an immutable reference. let mut string = s.to_string(); //&amp;str to String string.push_str(" append"); println!("{}", string); } //a slice has static lifetime let s = "hello"; //means let s: &amp;’static str = "hello"; lifetimes are only about reference a ref must die before its referent
in rust:
A resource can only have one owner at a time. When it goes out of the scope, Rust removes it from the Memory.
When we want to reuse the same resource, we are referencing it/ borrowing its content.
When dealing with references, we have to specify lifetime annotations to provide instructions for the compiler to set
how long those referenced resources should be alive.
⭐ But because of lifetime annotations make the code more verbose, in order to make common patterns more ergonomic,
Rust allows lifetimes to be elided/omitted in fn definitions. In this case, the compiler assigns lifetime annotations
implicitly.
// No inputs, return a reference fn function1&lt;'a>() -> &amp;'a str {} // Single input fn function2&lt;'a>(x: &amp;'a str) {} // Single input and output, both have the same lifetime // The output should live at least as long as input exists fn function3&lt;'a>(x: &amp;'a str) -> &amp;'a str {} // no need the lifetime annotation,lifetime elision // Multiple inputs, only one input and the output share same lifetime // The output should live at least as long as y exists fn function4&lt;'a>(x: i32, y: &amp;'a str) -> &amp;'a str {} // Multiple inputs, both inputs and the output share same lifetime // The output should live at least as long as x and y exist fn function5&lt;'a>(x: &amp;'a str, y: &amp;'a str) -> &amp;'a str {} // Multiple inputs, inputs can have different lifetimes 🔎 // The output should live at least as long as x exists fn function6&lt;'a, 'b>(x: &amp;'a str, y: &amp;'b str) -> &amp;'a str {} lifetimes in struct/enum // Single element // Data of x should live at least as long as Struct exists struct Struct1&lt;'a> { x: &amp;'a str } // Multiple elements // Data of x and y should live at least as long as Struct exists struct Struct2&lt;'a> { x: &amp;'a str, y: &amp;'a str } // Variant with a single element // Data of the variant should live at least as long as Enum exists enum Enum&lt;'a> { Variant(&amp;'a Type) }</content></entry><entry><title>SpringBoot 应用和 Rust 应用的 Dockerfile 最佳实践</title><url>https://zhimoe.github.io/post/dockerfile-best-practices/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>docker</tag><tag>spring</tag><tag>rust</tag></tags><content type="html"> 记录 spring boot 和 rust 项目的 Dockerfile 的最佳实践。
spring boot 应用 Dockerfile spring.io 提供了一个 boot 应用的Dockerfile指导。
不过有个问题，这个 Dockerfile 使用的 maven 是项目源码里面 copy 过去的。在一般企业项目中这么做显然不规范，直接使用 maven 基础镜像更合理。
Dockerfile 的最终版：
# syntax=docker/Dockerfile:experimental FROM maven:3-jdk-8-alpine as build WORKDIR /workspace/app COPY pom.xml . COPY src src RUN --mount=type=cache,target=/root/.m2 mvn package -DskipTests # app base image FROM openjdk:8-jdk-alpine VOLUME /tmp ARG BUILD=/workspace/app/target WORKDIR /app COPY --from=build ${BUILD}/*.jar . RUN jar -xf ./*.jar RUN rm ./*.jar ENTRYPOINT ["java","-cp","/app","org.springframework.boot.loader.JarLauncher"] 要点：
# syntax=docker/Dockerfile:experimental表示启用 docker 实验特性 BuildKit 的 mount cache 功能，这样可以利用 maven lib 的 cache 提高镜像构建速度。可以搜索 docker BuildKit 了解。
如果没有这一行，那么下面的--mount=type=cache,target=/root/.m2就是非法的。由于是实验特性，构建镜像的时候需要设置一个环境变量DOCKER_BUILDKIT=1才能运行： DOCKER_BUILDKIT=1 docker build -t zhimoe/boot-app . spring.io 的教程里面使用的 build 镜像是openjdk:8-jdk-alpine，这个镜像是没有 maven 的，因为教程中的 Dockerfile 从源码复制了mvnw和.mvn/到镜像去。所以这里替换为maven:3-jdk-8-alpine 使用了 docker 的multi-stage build功能，openjdk:8-jdk-alpine由于没有 maven，所以会比maven镜像少 20M. spring.io 的教程里面在 ENTRYPOINT 里面是直接设置 main class 启动应用的。这种硬编码方式不通用也不利于维护 (修改 main class name 后 Dockerfile 也要修改).只要将应用的 jar 包解压出来的 org 目录 (即 org.springframework.boot.loader.jar 解压内容，不到 1M) 保留，即可通过org.springframework.boot.loader.JarLauncher启动应用。 注意java -cp /app中的 classpath:/app 一定是绝对路径，否则 java 找不到 main class，报错：Error: Could not find or load main class org.springframework.boot.loader.JarLauncher rust 应用 Dockerfile # pull the latest version of Rust FROM rust:latest AS builder # create a new empty shell project RUN USER=root cargo new --bin prj WORKDIR /prj # copy the manifests to WORKDIR/src COPY ./Cargo.lock ./Cargo.toml ./ # change the crate.io source url if in China mainland COPY ./config $CARGO_HOME/ # build without project source code # this build step will cache your dependencies RUN cargo build --release # remove the WORKDIR/src RUN rm -r src/* # copy your source files to WORKDIR/src COPY ./src ./src COPY ./static ./static # build for release, # note! the Cargo.toml package name in deps is _, not - RUN rm ./target/release/deps/rs_notes* RUN cargo build --release RUN mv ./target/release/rs-notes . ## 2 stage build # our final base FROM debian:stretch-slim AS app # for connecting to postgres and TLS hosts # RUN apt update -y &amp;&amp; apt install -y libpq-dev openssl libssl1.0-dev ca-certificates # copy the build artifact and static resources from the build stage COPY --from=builder /prj/rs-notes ./ COPY --from=builder /prj/static ./static # set the startup command to run your binary CMD ["./rs-notes"] 要点：
如果使用 scratch 或者 alpine 镜像，那么需要将编译目标设置为MUSL，网络上有教程，感觉不需要考虑这个体积问题。rust 应用使用 debian-slim 基本在 60M 左右，只有 spring boot 应用镜像的一半大小。 在国内由于网络问题，所以修改了 cargo 的 crate.io mirror 地址：COPY ./config $CARGO_HOME/. config 内容如下： [source.crates-io] registry = "https://github.com/rust-lang/crates.io-index" replace-with = 'ustc' [source.ustc] registry = "git://mirrors.ustc.edu.cn/crates.io-index" build 中使用了 cargo 缓存，即先将项目 Cargo.toml 和 Cargo.lock 复制到一个空项目中编译，然后再将源码复制进去编译。 RUN rm ./target/release/deps/rs_notes*，注意这里的rs_notes是下划线，是 cargo 中 package name 转换为 crate name 的默认规则。</content></entry><entry><title>Docker CMD ENTRYPOINT 区别</title><url>https://zhimoe.github.io/post/docker-cmd-entrypoint-diff/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>docker</tag></tags><content type="html"> 记录 docker 中 exec form 和 shell form 的区别，CMD 和 ENTRYPOINT 区别，以及最佳实践。
exec form VS shell form # exec form &lt;instruction> ["executable", "param1", "param2", ...] # shell form &lt;instruction> &lt;command> exec form 以 JSON 格式解析，所以命令参数必须使用""双引号包裹。 exec form 不会 invoke shell. 所以CMD [ "echo", "$HOME" ]中$HOME变量不会被替换。 shell form 实际是执行/bin/sh -c "&lt;command>"。 优先使用 exec form，因为在 shell form 中spawns your application in a new process and you won’t receive signals from Docker,在 k8s 中会遇到问题。 在 shell form 也可以使用exec &lt;cmd>形式。 CMD VS ENTRYPOINT 直接翻译 SO 上面的回答，比较清楚
ENTRYPOINT 是容器执行入口，CMD 是参数设置。
Docker 有默认的 ENTRYPOINT:/bin/sh -c,但是没有默认的 CMD.但是一般镜像都会设置一个默认的 CMD.(注意是docker的默认 ENTRYPOINT，和镜像的默认CMD,基础镜像一般不设置 ENTRYPOINT)
docker run -i -t ubuntu bash the ENTRYPOINT is the default /bin/sh -c, the image is ubuntu and the command is bash.
所以上面的命令实际上在启动容器中执行了/bin/sh -c bash. 不是所有场景都需要"/bin/sh"的，所以引入了 ENTRYPOINT and --entrypoint.
docker run -i -t ubuntu中 ubuntu(镜像名) 后面跟的所有内容都作为参数传递给 entrypoint. 这和使用CMD指令是完全一样的，也即是CMD指令可以在docker run中覆盖。
由于 ubuntu 镜像设置了默认 CMD: CMD ["bash"],所以docker run -i -t ubuntu和docker run -i -t ubuntu bash是完全一样的效果。
所以到此，可以总结：ENTRYPOINT 是容器的执行入口，CMD 是参数设置，不过参数也可以是 bash 中的可执行命令 (例如，CMD ["echo","hello"],实际执行 /bin/sh -c "echo hello").
ENTRYPOINT 和 CMD 的搭配可以实现将容器作为一个可执行文件启动，这个特性也是我们日常使用 docker 的主要目的。例如在 Dockerfile 中设置：
ENTRYPOINT ["/bin/cat"] 运行docker run cat-img /etc/passwd,/etc/passwd 是 cmd, 实际执行的是/bin/cat /etc/passwd. 恭喜你，得到一个 cat 程序，假设你安装了一个 linux 系统，里面没有 cat 命令，cat-img 镜像就可以实现你想要的功能。
再例如你有个 redis 镜像，与其运行 docker run redis-img redis -H srv-host -u toto get key,
不如设置ENTRYPOINT ["redis", "-H", "srv-host", "-u", "toto"] 然后运行docker run redis-img get key.
Dockerfile 只有最后一个 CMD 会生效; 可以使用docker inspect &lt;img-id>查看默认的CMD参数; 取消默认 ENTRYPOINT，可以在 Dockerfile 中设置：ENTRYPOINT []</content></entry><entry><title>scala uniform access principle</title><url>https://zhimoe.github.io/post/scala-uniform-access-principle/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> 虽然代码写的很水，但是我对各种编程语言一直比较感兴趣。除了工作中使用的 Java 之外，自己也了解 Python,Groovy,Scala,Kotlin,Clojure,Go,Rust.其中 Python 和 Scala 在工作中也偶尔使用。了解不同的编程语言语法对于编程思维的影响还是蛮有意思的。
例如，只会 Java 的开发者可能没有听过模式匹配 (pattern match).在我学习了 Scala 之后，我对模式匹配的理解就是更强更优雅的 switch+if. 而在我看过 rust 和 elixir 语言中关于模式匹配之后，我对模式匹配的理解就完全不一样了。
这些语言中，论说对编程思维改变最大的当属 Clojure 莫属。Lisp 语言是一种非常优雅的语言。这种优雅的最大特点就是 Lisp(Clojure) 从语法上面做到了代码即数据。即 Clojure 的代码形式和其数据结构 list 的形式是一样的 (这也是 lisp 名字由来，LISt Processor).
这个特点的好处就是 Clojure 赋予了 list 这种数据结构强大的表达能力，可以在使用极其简练的语法在 list 数据结构实现复杂的逻辑。
&ldquo;It is better to have 100 functions operate on one data structure than 10 functions on 10 data structures.&rdquo; —Alan Perlis
尽可能的减少语法的规则，这种语法特点在 Scala 上面也有体现。
uniform access principle scala 中统一访问原则将 class 的方法和属性访问统一，都是通过obj.mbr访问。
这么做的好处是代码更加统一，而且重构更加方便。
A function that takes no parameters, which is defined without any empty parentheses.
Invocations of parameter less functions may not supply parentheses.
This supports the uniform access principle, which enables the def to be changed into a val without
requiring a change to client code.
class Person { private var privateName = "" def name = privateName def name_=(value: String) = privateName = value } val john = new Person john.name = "John Doe" println(john.name) 统一也体现在集合访问形式上，在 Scala 中，Map,List,Array 的元素访问都是通过coll(ki)形式。ki表示 key 或者 index.个人非常喜欢这种统一。</content></entry><entry><title>Highlights in Scala for Impatient 2nd</title><url>https://zhimoe.github.io/post/scala-for-impatient-2nd-highlights/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag><tag>scala-for-impatient</tag></tags><content type="html"> key points in scala-for-impatient 2nd book, best book for java developer to use scala in a rush.
scala-for-impatient 章节摘要，这本书对于 Java 开发者快速上手 Scala 帮助很大。
Functions • if expression has a value. • A block has a value — the value of its last expression. • The Scala for loop is like an “enhanced” Java for loop. • Semicolons are (mostly) optional. • The void type is Unit. • Avoid using `return` in a function. • Beware of missing = in a function definition. • Exceptions work just like in Java or C++, but you use a “pattern matching” syntax for catch. • Scala has no checked exceptions. Arrays • Use an Array if the length is fixed, and an ArrayBuffer if the length can vary. • Don’t use new when supplying initial values. • Use () to access elements. • Use for (elem &lt;- arr) to traverse the elements. • Use for (elem &lt;- arr if . . . ) . . . yield . . . to transform into a new array. • Scala and Java arrays are interoperable; with ArrayBuffer, use scala.collection.JavaConverters._ don't use scala.collection.JavaConversions. import scala.collection.mutable.ArrayBuffer val b = ArrayBuffer[Int]() // Or new ArrayBuffer[Int] // An empty array buffer, ready to hold integers b += 1 // ArrayBuffer(1) // Add an element at the end with += b += (1, 2, 3, 5) // ArrayBuffer(1, 1, 2, 3, 5) // Add multiple elements at the end by enclosing them in parentheses b ++= Array(8, 13, 21) // ArrayBuffer(1, 1, 2, 3, 5, 8, 13, 21) // You can append any collection with the ++= operator b.trimEnd(5) // ArrayBuffer(1, 1, 2) // Removes the last five elements b.insert(2, 6) // ArrayBuffer(1, 1, 6, 2) // Insert before index 2 // iterate array with index // use view or use index(it's faster) for (i&lt;-b.indices){val v = b(i)} Maps &amp; Tuples var scores = Map("Alice" -> 10, "Bob" -> 3, "Cindy" -> 8) val scores2 = Map(("Alice", 10), ("Bob", 3), ("Cindy", 8)) val bobsScore = scores("Bob") // Like scores.get("Bob") in Java val scores1 = scala.collection.mutable.Map("Alice" -> 10, "Bob" -> 3, "Cindy" -> 8) val scores3 = scala.collection.mutable.Map[String, Int]() scores1("Bob") = 10 val v = scores1("Bob") // NPE if key is not exists scores1.get("Bob") // None if key is not exists scores1.getOrElse("Bob",10)// 10 if key is not exists scores1 += ("Bob" -> 10, "Fred" -> 7) scores1 -= "Alice" // for immutable val newScores = scores + ("Bob" -> 10, "Fred" -> 7) // New map with update val scores4 = scores - "Alice" scores -= "Alice" for ((k, v) &lt;- scores){} for ((k, v) &lt;- scores) yield (v, k) // sorted map val sortedScores = scala.collection.mutable.SortedMap("Alice" -> 10,"Fred" -> 7, "Bob" -> 3, "Cindy" -> 8) // insert order val months = scala.collection.mutable.LinkedHashMap("January" -> 1,"February" -> 2, "March" -> 3, "April" -> 4, "May" -> 5) import scala.collection.JavaConverters._ // tuple val t = (1, 3.14, "Fred") val second = t._2 // Sets second to 3.14 val keys = Array() val values = Array() val kv = keys.zip(values).toMap() Object • Use objects for singletons and utility methods. • A class can have a companion object with the same name. • Objects can extend classes or traits. • The apply method of an object is usually used for constructing new instances of the companion class. • To avoid the main method, use an object that extends the App trait. • You can implement enumerations by extending the Enumeration object. Package The key points of this chapter are: • Packages nest just like inner classes. • Package paths are not absolute. • A chain x.y.z in a package clause leaves the intermediate packages x and x.y invisible. • Package statements without braces at the top of the file extend to the entire file. • A package object can hold functions and variables. • Import statements can import packages, classes, and objects. • Import statements can be anywhere. • Import statements can rename and hide members. • java.lang, scala, and Predef are always imported Inheritance • The `extends` and `final` keywords are as in Java. • You must use `override` when you override a method. • Only the primary constructor can call the primary superclass constructor. • You can `override` fields. Files • Source.fromFile(...).getLines.toArray yields all lines of a file. • Source.fromFile(...).mkString yields the file contents as a string. • To convert a string into a number, use the toInt or toDouble method. • Use the Java PrintWriter to write text files. • "regex".r is a Regex object. • Use """...""" if your regular expression contains backslashes or quotes. • If a regex pattern has groups, you can extract their contents using the syntax for (regex(var1, ...,varn) &lt;- string). Traits Key points of this chapter: • A class can implement any number of traits. • Traits can require implementing classes to have certain fields, methods, or superclasses. • Unlike Java interfaces, a Scala trait can provide implementations of methods and fields. • When you layer multiple traits, the order matters—the trait whose methods execute first goes to the back. Operators val a = 10 //a: Int = 10 -a // res0: Int = -10 //means the same as a.unary_-. a.unary_- //res1: Int = -10 High Order Functions Array(3.14, 1.42, 2.0).map{ (x: Double) => 3 * x } //== Array(3.14, 1.42, 2.0) map { (x: Double) => 3 * x } // diff method and function Collections The key points of this chapter are: • All collections extend the Iterable trait. • The three major categories of collections are sequences, sets, and maps. • Scala has mutable and immutable versions of most collections. • A Scala list is either empty, or it has a head and a tail which is again a list. • Sets are unordered collections. • Use a LinkedHashSet to retain the insertion order or a SortedSet to iterate in sorted order. • + adds an element to an unordered collection; +: and :+ prepend or append to a sequence; ++ concatenates two collections; - and -- remove elements. • The Iterable and Seq traits have dozens of useful methods for common operations. Check them out before writing tedious loops. • Mapping, folding, and zipping are useful techniques for applying a function or operation to the elements of a collection Iterable trait methods: head, last, headOption, lastOption tail, init length, isEmpty map(f), flatMap(f), foreach(f), transform(f), collect(pf) reduceLeft(op), reduceRight(op),foldLeft(init)(op), foldRight(init)(op) reduce(op), fold(init)(op),aggregate(init)(op, combineOp) sum, product, max, min count(pred), forall(pred), exists(pred) filter(pred), filterNot(pred), partition(pred) takeWhile(pred), dropWhile(pred), span(pred) take(n), drop(n), splitAt(n) takeRight(n), dropRight(n) slice(from, to), view(from, to) zip(coll2), zipAll(coll2, fill, fill2), zipWithIndex(cation! the 2nd value in tuple is index) grouped(n), sliding(n) groupBy(k) // mkString(before, between, after), addString(sb, before, between, after) toIterable, toSeq, toIndexedSeq, toArray, toBuffer, toList, toStream, toSet, toVector, toMap, to[C] Important Methods of the Seq Trait: contains(elem), containsSlice(seq), startsWith(seq), endsWith(seq) indexOf(elem), lastIndexOf(elem), indexOfSlice(seq), lastIndexOfSlice(seq), indexWhere(pred) prefixLength(pred), segmentLength(pred, n) padTo(n, fill) intersect(seq), diff(seq) reverse sorted, sortWith(less), sortBy(f) permutations, combinations(n) //The map and flatMap methods are important because they are used //for translating for expressions. For example, the expression: for (i &lt;- 1 to 10) yield i * i //is translated to (1 to 10).map(i => i * i) //and for (i &lt;- 1 to 10; j &lt;- 1 to i) yield i * j //becomes (1 to 10).flatMap(i => (1 to i).map(j => i * j)) val coll = List() coll.par.sum coll.par.count(_ % 2 == 0) for (i &lt;- (0 until 100000).par) print(s" $i") (for (i &lt;- (0 until 100000).par) yield i) == (0 until 100000) Pattern Matching The key points of this chapter are: • The match expression is a better switch, without fall-through. • If no pattern matches, a MatchError is thrown. Use the case _ pattern to avoid that. • A pattern can include an arbitrary condition, called a guard. • You can match on the type of an expression; prefer this over isInstanceOf/asInstanceOf. • You can match patterns of arrays, tuples, and case classes, and bind parts of the pattern to variables. • In a for expression, nonmatches are silently skipped. • A case class is a class for which the compiler automatically produces the methods that are needed for pattern matching. • The common superclass in a case class hierarchy should be sealed. • Use the Option type for values that may or may not be present—it is safer than using null. Annotations The key points of this chapter are: • You can annotate classes, methods, fields, local variables, parameters,expressions, type parameters, and types. • With expressions and types, the annotation follows the annotated item. • Annotations have the form @Annotation, @Annotation(value), or @Annotation(name1 =value1, ...). • @volatile, @transient, @strictfp, and @native generate the equivalent Java modifiers. • Use @throws to generate Java-compatible throws specifications. • The @tailrec annotation lets you verify that a recursive function uses tail call optimization. • The assert function takes advantage of the @elidable annotation. You can optionally remove assertions from your Scala programs. • Use the @deprecated annotation to mark deprecated features. Future The key points of this chapter are: • A block of code wrapped in a Future { ... } executes concurrently. • A future succeeds with a result or fails with an exception. • You can wait for a future to complete, but you don’t usually want to. • You can use callbacks to get notified when a future completes, but that gets tedious when chaining callbacks. • Use methods such as map/flatMap, or the equivalent for expressions, to compose futures. • A promise has a future whose value can be set (once), which gives added flexibility for implementing tasks that produce results. • Pick an execution context that is suitable for the concurrent workload of your computation. Implicits The key points of this chapter are: • Implicit conversions are used to convert between types. • You must import implicit conversions so that they are in scope. • An implicit parameter list requests objects of a given type. They can be obtained from implicit objects that are in scope, or from the companion object of the desired type. • If an implicit parameter is a single-argument function, it is also used as an implicit conversion. • A context bound of a type parameter requires the existence of an implicit object of the given type. • If it is possible to locate an implicit object, this can serve as evidence that a type conversion is valid. Type Class CanBuildFrom</content></entry><entry><title>Rust Packages Crates Mod Notes</title><url>https://zhimoe.github.io/post/rust-packages-crates-mod/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>rust</tag></tags><content type="html"> 初学 rust 对于项目的 package 和 crate 的关系，module 和文件的关系有点理不清。做了一点笔记。
packages and crates A Cargo.toml is a package. and must have a package name, defined in [package] table:
[package] name = "actix-web" A package contains one or more crates.
a package can only have 0 or 1 library crate, no more; the entry file is lib.rs
A package can contain as many binary crates as you’d like. the entry file is main.rs or src/bin/b1.rs etc.
by convention, package-name is use - (dash), but lib_name must use _ (underscores, can not be dash -);
cargo will auto replace the - with _ in package-name to name the default library crate(lib.rs in src root). you can name it in [lib]:
# rename the lib crate [lib] name = "actix_web" path = "src/lib.rs" # also you can rename the binary crate: # it use [[]], array of table in toml, # cuz a package can have many binary crate. [[bin]] name = "my-cool-binary" path = "src/my-cool-binary.rs" one package(project) can only have one library crate, when the lib continues to get bigger, you want to split up the lib into multiple packages.
cargo introduce you with workspace.
A workspace is a set of packages that share the same Cargo.lock and output directory.
here is the actix-web package Cargo.toml file:
[workspace] members = [ ".", "awc", "actix-http", "actix-cors", "actix-files", "actix-framed", "actix-session", "actix-identity", "actix-multipart", "actix-web-actors", "actix-web-codegen", "test-server", ] # awc,actix-http... all are packages that contains their own Cargo.toml and src/lib.rs; crate and mod A crate is a compilation unit in Rust.
Whenever rustc some_file.rs is called, some_file.rs is treated as the crate file.
If some_file.rs has mod declarations in it, then the contents of the module files would be inserted
in places where mod declarations in the crate file are found, before running the compiler it.
In other words, modules do not get compiled individually, only crates get compiled.
mod mod_name {} defines a mod.
mod mod_name; import a mod. cargo will look for mod_name.rs or mod_name/mod.rs and insert the content to current file.
by default the mod is private; but nested mod is allowed to use any code in super mod;
self and super is to ref the current mod and parent mod;
fn main(){ // absolute root path crate::music::popular::play(); // relative path music::popular::play(); } use keyword the use keyword brings path into scope;
注意，rust 中mod才是 import，use只是简化 path 长度。在同一个 package 内部，必须要mod module_name;之后才能使用use module_name::func.
如果是Cargo.toml中的依赖 crate，无需mod也无需use（使用 full path）就可以使用 crate 的 item。
对于 function，一般约定是 use 函数名上一级：use mods::foo::bar;，而不是直接 use 函数use mods::foo::bar::func_name;
//Providing New Names with the as Keyword use std::io::Result as IoResult; //Re-exporting Names with pub use pub use crate::music::popular; //Use nested paths or the glob operator use std::{cmp::Ordering, io}; use std::collections::*; //by default, use is absolute. use crate::music::popular; use std::{self,Write}; // std and Write //bring a module into scope with `use` and a relative path need start `self`: use self::music::popular; in most cases you won&rsquo;t need to use extern crate anymore because Cargo informs the compiler about what crates are present. (There are one or two exceptions):sysroot mod
use foo::bar vs use crate::foo::bar use in mod my_mod { pub mod foo { pub mod bar { pub fn greet() { println!("hello rust"); } } pub fn greet_twice() { // use super::foo::bar::greet; // ok 相对路径 // use self::bar::greet; // ok 相对路径 // use my_mod::foo::bar::greet; // error in 2018+ but ok in 2015 edition. use crate::my_mod::foo::bar::greet; // ok 绝对路径，建议使用 greet(); greet(); } } } fn main() { // use crate::my_mod::foo::bar; // ok 绝对路径 preferred // use self::my_mod::foo::bar; // ok 相对路径 use my_mod::foo::bar; // ok 相对路径，省略了 self, error in 2015 edition: relative paths are not allowed without `self`; bar::greet(); use crate::my_mod::foo; foo::greet_twice(); } split up mod into files the mod can be defined in mod_name.rs or mod_name/mod.rs. and nested mod can be in mod_name/nested_mod.rs. you can ref the nested_mod by use mod nested_mod; in mod_name.rs; pub in struct and enum the Struct members is all private by default even struct name is pub; the Enum members is all public by default if the name is pub;</content></entry><entry><title>git 常用命令备忘录</title><url>https://zhimoe.github.io/post/git-useful-tips/</url><categories><category>编程</category></categories><tags><tag>git</tag><tag>code</tag></tags><content type="html"> 记录日常开发中偶尔会遇到的但是总是记不住的 git 命令。
以下技巧都来自于oh shit git 和 stackoverflow，版权归作者所有。
delete all history commit and commit current content git checkout --orphan tmp_branch &amp;&amp; git add -A &amp;&amp; git commit -am "first commit" &amp;&amp; git branch -D master &amp;&amp; git branch -m master &amp;&amp; git push -f origin master store password in local git config credential.helper store git reflog git reflog # you will see a list of every thing you've # done in git, across all branches! # each one has an index HEAD@{index} # find the one before you broke everything git reset HEAD@{index} # magic time machine git commit &ndash;amend # make your change git add . # or add individual files git commit --amend --no-edit # now your last commit contains that change! # WARNING: never amend public(remote) commits!!! # I need to change the message on my last commit! git commit --amend # follow prompts to change the commit message undo a commit # Oh shit, I need to undo a commit from like 5 commits ago! # find the commit you need to undo git log # use the arrow keys to scroll up and down in history # once you've found your commit, save the hash git revert [saved hash] # git will create a new commit that undoes that commit # follow prompts to edit the commit message # or just save and commit undo a file&rsquo;s changes # find a hash for a commit before the file was changed git log # use the arrow keys to scroll up and down in history # once you've found your commit, save the hash git checkout [saved hash] -- path/to/file # the old version of the file will be in your index git commit -m "Wow, you don't have to copy-paste to undo" git stash # 如果临时想要将代码恢复到最近一次commit 帮助同事复现他的问题 # 使用git stash 暂存当前修改，这个不是stage，也不是commit git stash # 显示当前暂存历史 git stash list # 找回暂存 git stash apply # or spec which stash git stash apply stash@{1} git rebase git pull --rebase git pull request git cherry-pick # switch to main branch git chekcout main # pick on commit from other branch git cherry-pick f commit change in submodule # submodule is a independent repo, # so you need commit/push change in submodule first and then # update(commit) the main project to refer the new commit of submodule # step 1 cd path/to/submodule git add &lt;stuff> git commit -m "comment" git push # step 2 cd /main/project git add path/to/submodule git commit -m "updated my submodule" git push</content></entry><entry><title>DevOps 能力成熟度模型</title><url>https://zhimoe.github.io/post/devops-maturity-model-checklist/</url><categories><category>编程</category></categories><tags><tag>devops</tag></tags><content type="html"> 之前听说过 AWS 的软件工程师是需要自己写需求说明书，前后端代码，测试和上线。还有 instagram 的工程师可以做到 python 的代码提交如果合并到主分支后可以在一个小时内自动部署到生产被用户使用到，感觉这个非常神奇。如果需要做到这个，对组织级与个人都有极高的 devops 能力成熟度要求。
上周代表 CRM 项目通过了信通院的 DevOps 三级认证。感觉提升的空间很大。专门看了一下信通院发布的成熟度模型标准。
核心要点是要有统一的管理系统，系统之间需要联动，
例如记录故事的系统，如何和你提交记录关联？
测试的缺陷问题如何和你的故事关联？
生产正在运行的代码，如何和代码库的某个基线对应上？
测试报告/需求说明书是否统一管理并和你的迭代有关联？
是否可以做到事故之后快速实现回滚部署？
研发运营一体化（DevOps）能力成熟度模型 第 1 部分：总体架构</content></entry><entry><title>Scala Collection Tips</title><url>https://zhimoe.github.io/post/scala-collection-tips/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> scala collection 提供了一整套独立于 Java 的高性能集合，使用上非常灵活，所以需要清楚一些常用的方法：
reduce fold scan 集合的符号方法 数组，tuple 2.13 的集合架构 reduce fold scan //reduce 是一个二元函数，遍历整个集合 List(1, 3, 5).reduceLeft(_ + _) // == ((1+3)+5) //reduceRight start from end of the collection //also you can given initial argument List(1, 3, 5).foldLeft("")(_ + _) // == 135 //foldLeft 等价于 \: 操作符 (0 /: List(1, 3, 5)) (_ - _) //folding 常用于替代 for-loop val wf1 = scala.collection.mutable.Map[Char, Int]() for (c &lt;- "Mississippi") wf1(c) = wf1.getOrElse(c, 0) + 1 // Now freq is Map('i' -> 4, 'M' -> 1, 's' -> 4, 'p' -> 2) //注意使用了不可变 map val wf = (Map[Char, Int]() /: "Mississippi") { (m, c) => m + (c -> (m.getOrElse(c, 0) + 1)) } //scan 方法可以获得每一步中间结果集 (1 to 10).scanLeft(0)(_ + _) //Vector(0, 1, 3, 6, 10, 15, 21, 28, 36, 45, 55) 集合的符号方法 //+ 表示添加一个元素到无序集合 // :+ +:表示添加到有序集合的首/尾 //elem append or prepend to coll (Seq) coll :+ elem elem +: coll //add elem to set/map coll + elem coll + (e1,e2,...) coll ++ coll2 coll2 ++: coll // prepend to lst elem :: lst lst2 ::: lst // 等价 list ++: list2 list ::: list2 // 含有=的表示修改，必须是 mutable 的集合 // TIP: As you can see, Scala provides many operators for adding and removing // elements. Here is a summary: // 1. Append (:+) or prepend (+:) to a sequence. // 2. Add (+) to an unordered collection. // 3. Remove with the - operator. // 4. Use ++ and -- for bulk add and remove. // 5. Mutations are += ++= -= --=. // 6. For lists, many Scala programmers prefer the :: and ::: operators. // 7. Stay away from ++: +=: ++=:. NOTE: For lists, you can use +: instead of :: for consistency, with one
exception: Pattern matching (case h::t) does not work with the +: operator.
其他 //数组的笔记 val ints = new Array[Int](30) // empty array val ints2 = Array[Int](1, 2, 3, 4) // array with init values val matrix4x9 = Array.ofDim[Double](4, 9) //update ints2(3) = 1000 // or ints2.update(3, 1000) //求和 val ints2Sum = ints2.sum val days = Array("Monday", "Tuesday", "Wednesday", "Thrusday", "Friday", "Saturday", "Sunday") //遍历 for (i &lt;- 0 until days.length) println(days(i)) for (day &lt;- days) println(day) days foreach println //遍历中使用 index days.zipWithIndex.map { case (e, i) => (i, e) } //faster for (i &lt;- days.indices) yield (i, days(i)) //Possibly fastest Array.tabulate(days.length) { i => (i, days(i)) } //肯定最快 val b = new Array[(Int, String)](days.length) var i = 0 while (i &lt; days.length) { b(i) = (i, days(i)) i += 1 } //filter days.filter(day => day.length > 4) //map Array(1, 2, 3, 4, 5).map(x => x * x) //sort Array(3, 6, 2, 0, 8, 5).sortWith((e1, e2) => e1 &lt; e2) //小的在前 //reduce，下面的会提示使用 sum, Array(1, 2, 3, 4, 5).reduce((e1, e2) => e1 + e2) //不定长数组 import scala.collection.mutable.ArrayBuffer val arr = ArrayBuffer[Int]() //tuple val oneAndTwo = (1, 2) val oneAndTwo1 = Tuple2(1, 2) //Pair is alias of Tuple2 val oneAndTwo2 = Pair(1, "two") val oneAndTwo3 = 1 -> 2 //访问元素下标是从 1 开始，这是因为 tuple 里面每个元素类型不一样，为了能够和 list 等区分开 //使用了类似 Haskell/ML 的习惯 val two = oneAndTwo._2 //option val emptyOpt: Option[Int] = None val fullOpt: Option[Int] = Some(42) emptyOpt match { case Some(value) => println(value) case None => println("Empty") } fullOpt.get //42 emptyOpt.isEmpty //true //either def divide(a: Double, b: Double): Either[String, Double] = { if (b == 0.0) Left("Division by zero") else Right(a / b) } divide(4, 0) def either(flag: Boolean): Either[String, List[Int]] = { if (flag) Right(List(1, 2, 3)) else Left("Wrong") } val content = either(true).right.map(_.filter(_ > 0)) //cast Seq(1).toArray Seq(1).toBuffer Seq(1).toList Seq((1, 2)).toMap Seq(1).toStream Seq(1).toString Seq(1).toVector Seq(1).toTraversable Seq(1).toIndexedSeq Seq(1).toIterable Set(1).toSeq Seq(1).toSet //zip, zipAll, zipWithIndex, unzip "abcde" zip 1.to(5) //zipAll:第二个参数是调用者元素缺失使用的默认值，第三个参数是第一个实参不够长的默认值 "abcde".zipAll(1.to(2), "caller", "arg") //尝试自己实现一个 zipAll? // "abcde" zipWithIndex Seq((1, 2), (3, 4), (5, 6)) unzip // val s = Seq("a", "b") scala 2.13 collection 基本重写了。参考这两个文档：
collections migration 2.13
the architecture of scala 2.13’s collections</content></entry><entry><title>使用 GTmetrix 对前端静态资源图片优化[翻译]</title><url>https://zhimoe.github.io/post/frontend-assets-optimize-gtmetrix/</url><categories><category>翻译</category></categories><tags><tag>code</tag></tags><content type="html"> GTmetrix 是一个前端页面测试的网站，可以发现你的站点哪些资源加载速度较慢，并针对性的优化。本文包含如何使用 GTmetrix 优化网站图片性能。
source:How to Optimize Images: A Practical Guide</content></entry><entry><title>Spring FactoryBean and ContextAware</title><url>https://zhimoe.github.io/post/spring-factorybean-contextaware/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>spring</tag></tags><content type="html"> 理解 Spring 的 FactoryBean 和 ContextAware 接口。
FactoryBean 一句话就是 FactoryBean 用于返回其他对象实例的，而不是自身类型的实例。
public class Tool { private int id; // standard constructors, getters and setters } public class ToolFactory implements FactoryBean&lt;Tool> { private int factoryId; private int toolId; @Override public Tool getObject() throws Exception { return new Tool(toolId); } @Override public Class&lt;?> getObjectType() { return Tool.class; } @Override public boolean isSingleton() { return false; } // standard setters and getters } 注册 Tool:
&lt;!-- factorybean-spring-ctx.xml --> &lt;beans> &lt;bean id="tool" class="com.baeldung.factorybean.ToolFactory"> &lt;property name="factoryId" value="9090"/> &lt;property name="toolId" value="1"/> &lt;/bean> &lt;/beans> 使用注解注册：
@Bean(name = "tool") ToolFactory toolFactory() { ToolFactory factory = new ToolFactory(); factory.setFactoryId(7070); factory.setToolId(2); return factory; } 使用 Tool:
@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = { "classpath:factorybean-spring-ctx.xml" }) public class FactoryBeanXmlConfigTest { @Autowired private Tool tool; @Test public void testConstructWorkerByXml() { assertThat(tool.getId(), equalTo(1)); } } 访问 ToolFactory，在 bean id 前面添加 &amp;:
@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = { "classpath:factorybean-spring-ctx.xml" }) public class FactoryBeanXmlConfigTest { @Resource(name = "&amp;tool") private ToolFactory toolFactory; @Test public void testConstructWorkerByXml() { assertThat(toolFactory.getFactoryId(), equalTo(9090)); } } 和 BeanFactory 的区别 除了 FactoryBean，还有一个 BeanFactory 的接口及其实现。</content></entry><entry><title>通过例子学习 Clojure</title><url>https://zhimoe.github.io/post/learn-clojure-by-example/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>clojure</tag></tags><content type="html"> 这份笔记试图打造最强的 clojure 小抄，keep refactoring it&hellip;
clojure 入门 (ns clj-notes.core (:gen-class)) ;:gen-class generate java class file ;Parameter is variable in the declaration of function. ;Argument is the actual value of this variable that gets passed to function. ; ;install leiningen: ;put lein.bat in your PATH ;open cmder,run: lein repl ;start repl,use exit,(exit),(quit) or ctrl+d to quit repl (println "hello clojure") ;Symbols are used to bind names to values ;' will prevent a form from being evaluated ;'() same as (quote ()) ;def global variable ;let local variable binding (def object "light") (println object) (let [x 10 y 20 z 30] (+ x y z)) ;=> 60 ;data collection ;seq is abstract for list vector array ;map (def dict {:k1 "v1" :k2 "v2"}) ;keyword as function (:k1 dict) ;return v1 ;map as function (dict :k1) ;return v1 (let [v (dict :k1)] (println v)) ;also you can use get on seq or map (get {:a 1 :b 2} :b) ;=> 2 ;clojure.core/seq is a function that produces a sequence over the given argument. ;Data types that clojure.core/seq can produce a sequence over are called seqable: ; ;Clojure collections ;Java maps ;All iterable types (types that implement java.util.Iterable) ;Java collections (java.util.Set, java.util.List, etc) ;Java arrays ;All types that implement java.lang.CharSequence interface, including Java strings ;All types that implement clojure.lang.Seqable interface ;nil ;function for seq or collection ;= ;count ;conj ;empty ;seq ;first ;rest ;next ;count ;counted? ;conj ;get ;assoc ;defn 定义函数 ;defn- 定义ns内私有函数 (defn f "the second line is doc-string" {:added "1.2" ;this is attr-map :static true} [param] (print "hello " param)) (meta (var f)) ;#' is the reader macro for var and works the exactly same (meta #'f) ;fn create a function (def f (fn [] (println "this is from fn function"))) ;#() is the shortcut for fn (def plus-one #(+ 1 %)) ;% will be replaced with arguments passed to the function ;%1 is for the first argument, %2 is for the second and so on (defn des [{k1 :k1}] ;get :k1 value from argument (map) and binding it to k1(parameter) (println "destructing in map" k1)) (des dict) ;destructing in map v1 ;key don't have to be keyword (defn currency-of [{currency "currency"}] currency) (defn currency-of [{currency 'currency}] currency) ;if want to destructing multi key,use :keys, in this case,parameter name(currency amount) ;must same as arguments's keys(:currency :amount),can not use string as key (defn currency-of [{:keys [currency amount]}] (* currency amount)) (currency-of {:currency "RMB" :amount 100000}) ;ok (currency-of {"currency" "RMB" "amount" 100000}) ;currency will be nil,you will need use :strs or syms (defn currency-strs [{:strs [currency amount]}] currency) (currency-strs {"currency" "RMB" "amount" 100000}) ;ok (defn currency-syms [{:syms [currency amount]}] currency) (currency-syms {'currency "CNY" 'amount 100000}) ;ok ;use :or to give a default value for parameter (defn currency-or [{:keys [currency amount] :or {currency "USD"}}] currency) (currency-or {:amount 100000}) ;=> "USD" ;use &amp; for Variadic Functions parameters (defn log [message &amp; args] (println "args: " args)) ;named params , achieved by Variadic Functions destructing (defn job-info [&amp; {:keys [name job income] :or {job "unemployed" income "$0.00"}}] (if name [name job income] (println "No name specified"))) ;cation! arguments to job-info is not a map (job-info :name "Robert" :job "Engineer") ;["Robert" "Engineer" "$0.00"] ;Without the use of a variadic argument list, ;you would have to call the function with a single map argument such as (job-info {:name "Robert" :job "Engineer"}) ;destructuring example ;https://gist.github.com/john2x/e1dca953548bfdfb9844 (def my-vec [1 2 3]) (let [[a b c d] my-vec] (println a b c d)) ;1 2 3 nil (let [[a b &amp; the-rest] my-vec] (println "a=" a "b=" b "the-rest=" the-rest)) ;a= 1 b= 2 the-rest= (3) (let [[:as all] my-vec] (println all)) ;[1 2 3] (let [[a :as all] my-vec] (println a all)) ;1 [1 2 3] (let [[a b &amp; the-rest :as all] my-vec] (println a b the-rest all)) ;1 2 (3) [1 2 3] ;note: &amp; the-rest convert vector to list, ;but :as preserves them (as a list, or as a vector) (def my-vec ["first" "second"]) (let [{a 0 b 1} my-vec] (println a b)) ;=> "first second" ;optional arguments to functions (defn foo [a b &amp; more-args] (println a b more-args)) (foo :a :b) ;; => :a :b nil (foo :a :b :x) ;; => :a :b (:x) (foo :a :b :x :y :z) ;; => :a :b (:x :y :z) ;map destructuring (def my-hashmap {:a "A" :b "B" :c "C" :d "D"}) (def my-nested-hashmap {:a "A" :b "B" :c "C" :d "D" :q {:x "X" :y "Y" :z "Z"}}) (let [{a :a d :d} my-hashmap] (println a d)) ;; => A D (let [{a :a, b :b, {x :x, y :y} :q} my-nested-hashmap] (println a b x y)) ;; => A B X Y (let [{a :a, b :b, not-found :not-found, :or {not-found ":)"}, :as all} my-hashmap] (println a b not-found all)) ;; => A B :) {:a A :b B :c C :d D} ;!!! There is no &amp; rest for maps. ;everything but false and nil evaluates to true in Clojure. ;:as bind entire map to param ;See https://github.com/ring-clojure/ring/wiki/File-Uploads for explanation (defn file-handler ;表示入参是一个map,里面有:params这个key,将:params ;[{{{tempfile :tempfile filename :filename} "file"} :params :as request}] [{{{tempfile :tempfile filename :filename} "file"} :params :as request}] (println request) (let [n (num-lines tempfile)] (response (str "File " filename " has " n " lines ")))) ;a simple example (defn first-first [[[i _] _]] i) (first-first [[1 2] [3 4]]) ;return 1 ;(defn name doc-string? attr-map? [params*] prepost-map? body) ;(defn name doc-string? attr-map? ([params*] prepost-map? body) + attr-map?) ;function can have params type hint (defn round "^double here is type hint" [^double d ^long precision] (let [factor (Math/pow 10 precision)] (/ (Math/floor (* d factor)) factor))) ;不定长参数 ;重载函数 (defn bar ([a b] (bar a b 100)) ([a b c] (* a b c))) (bar 5 6) (bar 5 6 3) (defn keyworded-map [&amp; {:keys [function sequence]}] (map function sequence)) (keyworded-map :sequence [1 2 3] :function #(+ % 2)) ;trampoline ;trampoline ;namespace ;create-ns create a namespace (create-ns 'zhi.moe.clj) ;in-ns move to a namespace ;require loads a namespace and ;refer refers the namespace. ;To do these at once, you can use use (require 'clojure.by.example) (clojure.by.example/favorite-language) (use 'clojure.by.example) ;you can rename namespace (require '[clojure.by.example :as temp-ns]) ;ns macro creates a new namespace and gives you an opportunity to load other namespaces at the creation time ;import java class (import java.util.Date) (println (str (new Date))) ;Wed Jul 24 22:55:24 CST 2019 ;boolean ;In Clojure, everything except false and nil are true. (if 1 (println "it is true") (println "will never print")) ;if (if true (println "executed when true") (println "executed when false")) ;use do to execute multi expressions (if true (do (println "one") (println "two"))) ;if-let: (defn positive-number [numbers] (if-let [pos-nums (not-empty (filter pos? numbers))] pos-nums "no positive numbers")) ;when when-let case cond condp ; (defn cond-test [n] (cond (= n 1) "n is 1" (and (> n 3) (&lt; n 10)) "n is over 3 and under 10" :else "n is other")) (cond-test 1000) ;string (let [first "Hirokuni" last "Kim"] (str "My name is " first " " last)) ;format (format "My name is %s %s" "Hirokuni" "Kim") ;power function (defn power [x n] (reduce * (repeat n x))) ;bigint,N is a literal for bigint (+ 9223372036854775807 10N) ;list conj nth count '(1 2 3) ;vector conj nth count .indexOf [1 2 3] (.indexOf [1 2 3] 4) (count [1 2]) ;set conj nth count disj sort contains? subset? superset? #{1 2 3} ;map assoc merge keys vals (let [os {:Apple "Mac" :Microsoft "Windows"}] (get os :Apple)) (assoc {:Apple "Mac" :Microsoft "Windows"} :Commodore "Amiga") ;Sequences are data types that abstract all more concrete data types with unified functions. ;These functions are called the Seq library in Clojure. ;seq first rest cons concat map reduce into ;To add an element to the head of sequence, use cons. (cons 4 [1 2 3]) (into [] `(1 2 3)) (reverse [1 2 3]) ;get a sequence of infinite integers with iterate. Be careful, ;though. Running this example will freeze your terminal since the evaluation of this expression never returns. (doc iterate) (doc range) (repeatedly 5 (fn [] (println "hi!"))) ;for each (doseq [animal ["cat" "dog" "horse"]] (println animal)) (take 5 (range 0 100)) (take-while neg? [-3 -2 -1 0 1 2 3]) ;drop will remove the first n elements (drop 5 (range 0 10)) (drop-while neg? [-3 -2 -1 0 1 2 3]) ;(0 1 2 3) (remove pos? [-1 -2 3 4]) ;(-1 -2) (filter pos? [-1 2 3]) (partition-by #(&lt; 3 %) [1 2 3 4 5 6]) (group-by #(&lt; 3 %) [1 2 3 4 5 6 1 2 3]) (println (take 5 (iterate inc 0))) ;for compression (for [x '(1 2 3)] (+ 10 x)) (doc for) ;双重for 循环 (for [x (range 10) y (range 20) :while (&lt; y x)] [x y]) ;&lt;==> {x | x >0} (for [x '(-1 1 2) :when (> x 0)] x) (for [x [0 1 2 3 4 5] :let [y (* x 3)] :when (even? y)] y) ;meta data for function parameters (defn round [^double d ^long precision] (let [factor (Math/pow 10 precision)] (/ (Math/floor (* d factor)) factor))) ;# is Dispatch character that tells the Clojure reader how to interpret the next character using a read table ;set #{1 2 3} ;discard {:a 1, #_#_:b 2, :c 3} ;regular expression (re-matches #"^test$" "test") ;anonymous function #(println %) ;var quote (read-string "#'foo") ;symbolic values (/ 1.0 0.0) ;##Inf ;tagged literals (type #inst "2014-05-19T19:12:37.925-00:00") ;java.util.Date ;meta (meta #'fn-name) ;reader conditionals #?(:clj (Clojure expression) :cljs (ClojureScript expression) :cljr (Clojure CLR expression) :default (fallthrough expression)) ;#?@ splicing reader conditional (defn build-list [] (list #?@(:clj [5 6 7 8] :cljs [1 2 3 4]))) ;return [5 6 7 8] when run on clojure ;#= allows the reader to evaluate an arbitrary form during read time (read-string "#=(+ 3 4)") ;7 ;Recursion ;simple recursion (defn fibo "this is recursion function" [n] (if (or (= n 0) (= n 1)) n (+ (fibo (- n 1)) (fibo (- n 2))))) ;do not do this!!! take a long time to finish (fibo 1000) ;use recur (defn fibo-recur [iteration] (let [fibo (fn [one two n] (if (= iteration n) one (recur two (+ one two) (inc n))))] ;recur re-binds it's arguments to new values and call the function with the new values ;fibo is an inner function (fibo 0N 1N 0))) (fibo-recur 1000) ;it is really fast ;notes ;with simple recursion, each recursive call creates a stack frame which is ;a data to store the information of the called function on memory. ;Doing deep recursion requires large memory for stack frames, but since it cannot, ;we get StackOverflowError ;尾递归 ;A function is tail recursive when the recursion is happening at the end of it's definition ;In other words, a tail recursive function must return itself as it's returned value. ;When you use recur, it makes sure you are doing tail recursion (doc loop) ;loop/recur is merely a friendly way to write recursion code. ;All imperative loops can be converted to recursions and all recursions can be converted to loops, ;so Clojure chose recursions. ;Although you can write code that looks like an imperative loop with loop/recur, ;Clojure is doing recursion under the hood. ; (defmacro unless [test then] "Evaluates then when test evaluates to be falsey" (list 'if (list 'not test) then)) (macroexpand '(unless false (println "hi"))) ;' quoting ;` syntax-quoting returns the fully qualified namespace. ;Using fully qualified namespace is very important in order to avoid name conflicts when defining macro. ;~ unquote `(+ ~(list 1 2 3)) ;(clojure.core/+ (1 2 3)) `(+ ~@(list 1 2 3)) ;(clojure.core/+ 1 2 3) ;The ~@ unquote splice works just like ~ unquote, ;except it expands a sequence and splice the contents of ;the sequence into the enclosing syntax-quoted data structure ;thread first macro (-> [] (conj 1) (conj 2) (conj 3)) ;[1 2 3] (first (.split (.replace (.toUpperCase "a b c d") "A" "X") " ")) ;"X" ;;Perhaps easier to read: ;-> 后面是初始参数,第2行开始每一行是一个函数调用, ;且上一行的返回值会作为这一行第一个参数(这就是thread first)的first含义 ;这里的thread是管道的意思,而不是并发编程的线程 ;如果省略(),那么野生符号(bare symbol)和keyword都会当作一个函数调用, ;例如,这里的.toUpperCase是bare symbol,等效于(.toUpperCase ,,,) ;clojure中 逗号等于空白符,所以上面用,,,表示将会插入的参数(即"a b c d") (-> "a b c d" .toUpperCase (.replace "A" "X") (.split " ") first) ;same as follow, ,,, is equals whitespace (-> "a b c d" (.toUpperCase,,,) (.replace "A" "X") (.split " ") first) ;suppose a function (defn calculate [] (reduce + (map #(* % %) (filter odd? (range 10))))) ;same as ;上一行的结果作为最后一个参数插入,这叫thread last (defn calculate* [] (->> (range 10) (filter odd?,,,) (map #(* % %),,,) (reduce +,,,))) ;如果想要指定每次插入的位置那么需要用 as-> ;v是每一行的返回值的名称,这样你可以在下一行任意参数位置指定 (as-> [:foo :bar] v (map name v) (first v) (.substring v 1)) ; ;destructing ({:keys [firstname lastname] :as person} {:firstname "John" :lastname "Smith"}) ;future and deref (let [future-val (future (inc 1))] (println (deref future-val))) ;deref == @ (let [future-val (future (inc 1))] (println @future-val)) (def my-future (future (Thread/sleep 5000))) (repeatedly 6 (fn [] (println (realized? my-future)) (Thread/sleep 1000))) (doc future) ;promise (def my-promise (promise)) ;you define a promise (def listen-and-callback (fn [] (println "Start listening...") (future (println "Callback fired: " @my-promise)))) (defn do-time-consuming-job [] (Thread/sleep 5000) (deliver my-promise "delivered value")) (listen-and-callback) (do-time-consuming-job) ;atom is like mutable var in other languages but atom is thread safe ;ref dosync ref-set alter (def my-ref (ref 0)) (dosync (alter my-ref (fn [current_ref] (inc current_ref)))) (print @my-ref) (def user (ref {})) (dosync (alter user merge {:name "Kim"}) (throw (Exception. "something wrong happens!")) (alter user merge {:age 32})) (def user-record (atom {})) (do (swap! user-record merge {:name "Kim"}) (throw (Exception. "something wrong happens!")) (swap! user-record merge {:age 32})) ;Java (new java.util.Date "2016/2/19") (java.util.Date.) (java.util.Date. "2016/2/19") (Math/pow 2 3) ;static method (def rnd (new java.util.Random)) (. rnd nextInt 10) (let [date1 (new java.util.Date) date2 (new java.util.Date)] (.equals date1 date2)) ;(.instanceMember instance args*) ;(.instanceMember Classname args*) ;(.-instanceField instance) ;(Classname/staticMethod args*) ;Classname/staticField ;;; (defn geohash [lat lng] (println "geohash:" lat lng) ;;this function take two separate values as params. ;;and it return a geohash for that position ) (let [{:strs [lat lng] :as coord} {"lat" 51.503331, "lng" -0.119500}] (println "calculating geohash for coordinates: " coord) (geohash lat lng)) ;assoc-in associate使加入</content></entry><entry><title>理解 Elasticsearch Query DSL 中的 JSON 结构</title><url>https://zhimoe.github.io/post/elasticsearch-query-dsl/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>elasticsearch</tag></tags><content type="html"> 理解 ES 搜索中 JSON DSL 有助于自己写 JSON 查询，特别是手写复杂嵌套 json。
diffs in es 2.x and es 5.x query dsl aggr query diffs in es 2.x and es 5.x 没有 string 类型，改为 text 和 keyword 2 个类型。text 字段可以指定 fields 来不分词。如下：city 字段被 ingest 为 city 和 city.raw 2 个字段。 { "mappings": { "_doc": { "properties": { "city": { "type": "text", "fields": { "raw": { "type": "keyword", "ignore_above": 256 } } } } } } } default double -> float geo_point //2.x "location": { "type": "geo_point", "lat_lon": true, "geohash": true, "geohash_prefix": true, "geohash_precision": "1m" } //5.x "location": { "type": "geo_point" } query dsl basic query 就像砌房子的砖头，基本查询就是 ES 查询的砖头。基本查询是组合查询 (bool 查询等) 的单元。基本查询有：
//basic query element match, multi_match, common, geoshape, ids, match_all, query_string, simple_query_string, range, prefix, regexp, span_term, term, terms, wildcard 其中common, ids, prefix, span_term, term, terms, wildcard 是不分析搜索 (即不能用于 text 字段) ，match, multi_match, query_string, simple_query_string是全文检索，几乎可以确保可以返回结果。而prefix,regexp,wildcard是模式检索。这里分别给一些例子：
multi_match multi_match 查询为能在多个字段上反复执行相同查询提供了一种便捷方式
既然是多字段查询，则有 3 中场景:best_fields、most_fields 和 cross_fields（最佳字段、多数字段、跨字段）
{ "multi_match": { "query": "Quick brown fox", "type": "best_fields", //默认的，可不填 "fields": [ "title", "body" ], "tie_breaker": 0.3, "minimum_should_match": "30%" } } 等价于下面的形式：
{ "dis_max": { "queries": [ { "match": { "title": { "query": "Quick brown fox", "minimum_should_match": "30%" } } }, { "match": { "body": { "query": "Quick brown fox", "minimum_should_match": "30%" } } }, ], "tie_breaker": 0.3 } } 还可以使用通配符指定字段，以及给某些字段添加权重。
{ "multi_match": { "query": "Quick brown fox", "fields": [ "*_title", "chapter_title^2" ] } } query_string 和 simple_query_string 非常灵活的一个查询方式：
// GET index_name/_search { "query": { "query_string" : { "default_field" : "content", "query" : "(new york city) OR (big apple)" } } } 上面的 query 字段语法可以参考：query_string_syntax
simple_query_string不会抛出异常，而是直接忽略无效语句。
term、terms 完全匹配 // 不要用于 text 字段 // GET /_search { "query": { "term": { "user": { "value": "Kimchy", "boost": 1.0 } } } } //terms 和 term 一样，不过可以指定多个值，"user" : ["kimchy", "elasticsearch"]// 返回 user 为 kimchy 或 elasticsearch 的文档 prefix // user 字段 (不分词字段) 中以"ki"开头的文档 类似 SQL 中的 like 'ki%' { "query": { "prefix" : { "user" : "ki" } } } 组合查询 bool, boosting, constant_score, dis_max, function_score, has_child, has_parent, indices, nested, span_first, span_multi,span_first, span_multi, span_near, span_not, span_or, span_term, top_children, filtered(废弃，使用 bool 包含一个 must 和一个 filter 替代) bool bool 查询的外框架结构为：
{ "query": { "bool": { "must": [ {} ], "should": [ {} ], "must_not": [ {} ], "filter": [ {} ] } } } //some other parameter for bool: //boost,minimum_should_match,disable_coord</content></entry><entry><title>Useful Scala Code Snippets</title><url>https://zhimoe.github.io/post/scala-useful-snippets/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> merge two map and sum its values 多个 map 合并，key 相同时则 value 相加
val map1 = Map(1 -> 1, 2 -> 2) val map2 = Map(1 -> 11, 3 -> 3) val map3 = Map(1 -> 111, 3 -> 3) val mapList = List(map1, map2, map3) val merged = mapList.reduce((m1, m2) => m1 ++ m2.map { case (k, v) => k -> (v + m1.getOrElse(k, 0)) } ) 文件读 // """"""可以避免\\符号 val file = """d:\data\file.txt""" for (line &lt;- Source.fromFile(file, encoding).getLines()) { print(line) } 文件写 //资源管理 def using[A &lt;: {def close() : Unit}, R](resource: A)(fun: A => R): R = { import scala.language.reflectiveCalls try { fun(resource) } finally { resource.close() } } using(new OutputStreamWriter(new FileOutputStream(outputFile), StandardCharsets.UTF_8)) { writer => writer.write(s"""${line}\n""") } 统计词频 val nanoUnit = 1000000 //分词并统计词频 def main(args: Array[String]): Unit = { val path = """D:\code\ideaProjects\scala-notes\data\src\out""" val files: List[File] = new File(path).listFiles.filter(_.isFile).toList val start = System.nanoTime() val wfList = ListBuffer[mutable.Map[String, Long]]() val futures = for (file &lt;- files) yield Future { countWrodsInFile(file, "UTF-8") } for (f &lt;- futures) { val words: mutable.Map[String, Long] = Await.result(f, Duration.Inf) wfList += words } //merge the word frequency map val finalWf = wfList.reduce((m1, m2) => m1 ++ m2.map { case (k, v) => k -> (v + m1.getOrElse(k, 0L)) } ) val end = System.nanoTime() println(s"container size=${finalWf.size}") // sort map val wordsFreq = finalWf.toList.sortWith(_._2 > _._2) write2file(wordsFreq, Paths.get(path, "final.txt").toFile) println(s"total used time = ${(end - start) / nanoUnit} ms") println(s"cups = ${Runtime.getRuntime.availableProcessors()}") } def countWrodsInFile(file: File, encoding: String): mutable.Map[String, Long] = { val wf = mutable.Map[String, Long]().withDefaultValue(0) for (line &lt;- Source.fromFile(file, encoding).getLines()) { val l = line.trim wf.update(l, wf(l) + 1) } println(s"${file.getName} has words:${wf.size}") wf } def write2file(wf: Seq[(String, Long)], out: File): Unit = { using(new OutputStreamWriter(new FileOutputStream(out), StandardCharsets.UTF_8)) { writer => for (it &lt;- wf) { writer.write(s"""${it._1} ${it._2}\n""") } } }</content></entry><entry><title>Scala Future</title><url>https://zhimoe.github.io/post/scala-future/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> some notes on scala future, includes:
future executor context await future result callback recover future import java.time._ import scala.concurrent._ import ExecutionContext.Implicits.global Future { Thread.sleep(10000) println(s"This is the future at ${LocalTime.now}") } println(s"This is the present at ${LocalTime.now}") executor context future need a new thread to execute it task. import ExecutionContext.Implicits.global is a implicit threadpool.
await for future result // for 10.seconds conversion import scala.concurrent.duration._ val f = Future { Thread.sleep(10000); 42 } val result = Await.result(f, Duration.Inf) // if f throw exception, it will rethrow to Await.result // use ready() solve this val f = Future { ... } Await.ready(f, 10.seconds) val Some(t) = f.value // The f.value method returns an Option[Try[T]], // which is None when the future is not completed // and Some(t) when it is is // t is Try type instance // A Try[T] instance is either a Success(v), where v is a value of type T or a Failure(ex) val t = Some(t).get t match { case Success(v) => println(s"The answer is $v") case Failure(ex) => println(ex.getMessage) } // or if (t.isSuccess) println(s"The answer is ${t.get}") callback val f = Future { Thread.sleep(10000) if (random() &lt; 0.5) throw new Exception 42 } f.onComplete { case Success(v) => println(s"The answer is $v") case Failure(ex) => println(ex.getMessage) } callback hell val future1 = Future { getData1() } val future2 = Future { getData2() } future1 onComplete { case Success(n1) => future2 onComplete { case Success(n2) => { val n = n1 + n2 println(s"Result: $n") } case Failure(ex) => ... } case Failure(ex) => ... } // improve val future1 = Future { getData1() } val combined = future1.map(n1 => n1 + getData2()) // val future1 = Future { getData1() } val future2 = Future { getData2() } val combined = future1.map(n1 => future2.map(n2 => n1 + n2)) // use for-yield for ( n1 &lt;- future1 n2 &lt;- future2 ) yield n1+n2</content></entry><entry><title>Spring Cache Notes</title><url>https://zhimoe.github.io/post/draft/spring-cache-notes/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>spring</tag></tags><content type="html"> spring 的缓存一些技巧和陷阱
spring 的缓存
相同方法的缺陷 缓存一个 list 参数方法 sync put evict ehcache 的使用 redis 缓存的使用陷阱</content></entry><entry><title>Spring Boot Notes</title><url>https://zhimoe.github.io/post/spring-boot-notes/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>spring</tag></tags><content type="html"> 一些容易忘记的 spring boot 知识要点。
注意，.yaml 和.yml 文件没任何区别。
配置 SpringBootApplication 注解 @SpringBootApplication // &lt;=等价=> @Configuration @ComponentScan @EnableAutoConfiguration 自动配置 spring 的自动配置依赖以下注解：
配置文件 任何时候硬编码的配置总是不好的，spring 支持从很多环境中读取配置：配置文件，yaml 文件，环境变量，命令参数。
配置可以在@Value注解中使用，也可Environment访问，或者通过@ConfigurationProperties将配置属性绑定到特定的 bean(例子).
spring boot 的配置属性读取顺序为：
Devtools global settings properties on your home directory (~/.spring-boot-devtools.properties when devtools is active). @TestPropertySource annotations on your tests. @SpringBootTest#properties annotation attribute on your tests. Command line arguments. Properties from SPRING_APPLICATION_JSON (inline JSON embedded in an environment variable or system property) ServletConfig init parameters. ServletContext init parameters. JNDI attributes from java:comp/env. Java System properties (System.getProperties()). OS environment variables. A RandomValuePropertySource that only has properties in random.*. Profile-specific application properties outside of your packaged jar (application-{profile}.properties and YAML variants) Profile-specific application properties packaged inside your jar (application-{profile}.properties and YAML variants) Application properties outside of your packaged jar (application.properties and YAML variants). Application properties packaged inside your jar (application.properties and YAML variants). @PropertySource annotations on your @Configuration classes. Default properties (specified using SpringApplication.setDefaultProperties). 因为 spring-boot 主要使用的application.properties/yaml文件，所以后面主要关注这个文件。
此外，spring 代码中使用了大约近千个 (300 多类) 默认值，这些默认值都是可以覆盖的。只需你在你的 propeties/yaml 文件中用相同的 key 即可。
所有的参考值见：example application.properties
application.properties SpringApplication loads properties from application.properties files in the following locations and adds them to the Spring Environment:
A /config subdirectory of the current directory The current directory A classpath /config package The classpath root application.yml yaml 是 json 的超集，相比 properties 文件，有着简洁灵活的优势 例如可以设置数组，设置 group 概念等。
yaml 文件可以配置数组：
# 数组功能，等价 # my.servers[0]=dev.bar.com # my.servers[1]=foo.bar.com my: servers: - dev.bar.com - foo.bar.com #上面的配置可以通过注解绑定到以下 bean 中，非常强大。 @ConfigurationProperties(prefix="my") public class Config { private List&lt;String> servers = new ArrayList&lt;String>(); } # 在一个 yaml 文件设置不同的 profile 配置，properties 文件只能通过拆分文件`application-profiles.properties`实现。 server: address: 192.168.1.100 --- spring: profiles: DEV server: address: 127.0.0.1 --- spring: profiles: PRD server: address: 192.168.1.120 yaml 缺点： YAML files cannot be loaded by using the @PropertySource annotation. So, in the case that you need to load values that way, you need to use a properties file.
当然使用 properties 文件缺点也明显，不能分组 (yaml 的&mdash;功能);同时中文显示容易 unicode 码。
读取配置文件 除了 application.properties 文件，其他的配置属性文件需要我们自己加载读取。注意，下面的PropertySource无法加载 yaml 文件。
使用 PropertySource cron=0/3 * * * * ? @Configuration @PropertySource("classpath:foo.properties") public class PropertiesWithJavaConfig { @Value(${cron}) private String cron; } //or @PropertySource({ "classpath:persistence-${envTarget:mysql}.properties" }) //multi files //java 8+ @PropertySource("classpath:foo.properties") @PropertySource("classpath:bar.properties") public class PropertiesWithJavaConfig { //... } //java 6+ @PropertySources({ @PropertySource("classpath:foo.properties"), @PropertySource("classpath:bar.properties") }) public class PropertiesWithJavaConfig { //... } //通过 xml 加载 //register file in xml &lt;context:property-placeholder location="classpath:foo.properties" /> //foo.properties in src/main/resources &lt;context:property-placeholder location="classpath:foo.properties, classpath:bar.properties"/> 如何加载自定义的 yaml 文件 上面提到 spring 会默认加载application.yml文件的配置。但是其他文件名的 yml 文件无法通过@PropertySource加载。可以有以下方法。
使用 xml，然后在 Java Config 类加载 xml. 个人不推荐使用 xml 文件，脱离 spring boot 的初衷了。 使用 yml 加载器：The YamlPropertiesFactoryBean will load YAML as Properties and the YamlMapFactoryBean will load YAML as a Map. 避免使用，尽量将你的所以配置放在 application.yml 里面，因为 yml 可以有分组功能。 将你文件命名为application-redis.yml,然后在 application.yml 使用spring.profiles.include: 'redis' 加载。 使用 yaml 文件的加载可以通过ConfigurationProperties绑定到配置 bean 中。还要添加 2 个注解注册到 spring:
@Configuration @EnableConfigurationProperties @ConfigurationProperties public class YAMLConfig { private String name; private String environment; private List&lt;String> servers = new ArrayList&lt;>(); // standard getters and setters } spring: profiles: prod name: prod-YAML environment: production servers: - www.abc.com - www.xyz.com profiles 很多配置希望基于环境，spring boot 支持application-profile.properties格式的配置，profile 可以是 DEV,ST,UAT,PRD,TEST 等。
例如某个 class 希望只有在PRD环境才有：
@Profile("PRD") @Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter {} 然后在application.yml/properties设置 profile:
spring: profiles: active: PRD properties 文件设置 profile application.properties文件只能使用application-DEV.properties,application-ST.properties设置 profile.
yml 文件设置 profile application.yml既可以像 properties 文件使用application-DEV.yml来设置 profile，也可以使用---分组。如下示例，logging.level=INFO在所有 profile 中生效，而在生产环境中增加日志文件设置，DEV 环境则使用DEBUG级别日志。
# application.yml logging: level: root: INFO --- spring: profiles: DEV logging: level: root: DEBUG --- spring: profiles: PRD logging: path: /tmp/ file: BookWorm.log level: root: WARN 激活 profiles 在application.yml/properties文件中激活某个 profile:
spring: profiles: active: DEV 如果你设置了SPRING_PROFILES_ACTIVE环境变量，那么会覆盖上面的 profile 设置。当然你也可以使用自定义环境变量和默认值：
spring: profiles: active: ${ENV_TYP:PRD} # 读取 ENV_TYP 环境变量的值作为激活 profile，如果没用这个环境变量，那么设置为 PRD. 测试</content></entry><entry><title>Pattern Matching Anonymous Function</title><url>https://zhimoe.github.io/post/scala-pattern-matching-anonymous-function/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> Scala 中很多使用 if 的地方都可以用 match case 来替换。常见的就是下面的这种写法：
val res = msg match { case it if it.contains("H") => "Hello" case _ => "Other" } //更常见的用法是去匹配参数的模式： case class Player(name: String, score: Int) def message(player: Player) = player match { case Player(_, score) if score > 100000 => "Get a job, dude!" case Player(name, _) => "Hey, $name, nice to see you again!" } def printMessage(player: Player) = println(message(player)) 其实 case 还有一种在匿名函数中的用法，看如下的代码，在词频统计或者过滤中很常见：
val wordFrequencies = ("habitual", 6) :: ("and", 56) :: ("consuetudinary", 2) :: Nil def wordsWithoutOutliers(wordFrequencies: Seq[(String, Int)]): Seq[String] = wordFrequencies.filter(wf => wf._2 > 3 &amp;&amp; wf._2 &lt; 25).map(_._1) 上面的代码有比较大的问题是访问 tuple 元素的方式比较难看，Scala 提供了一种 pattern matching anonymous function 解决这个问题：
def wordsWithoutOutliers(wordFrequencies: Seq[(String, Int)]): Seq[String] = wordFrequencies.filter { case (_, f) => f > 3 &amp;&amp; f &lt; 25 } map { case (w, _) => w } 注意到省略了最早版本的 wf =>,IDEA 其实会提示你省略这个冗余部分。
另一个问题就是上面的操作中我们先过滤想要的序列，然后对序列进行了 map 映射操作.Scala 集合的 API 有一个叫做 collect 的方法，对于 Seq[A] ,它有如下方法签名：
def collect[B](pf: PartialFunction[A, B]): Seq[B] 这个方法将给定的_偏函数 (partial function)_ 应用到序列的每一个元素上，最后返回一个满足条件并处理后新的序列 ,这里偏函数做了 filter 和 map 要做的事情。
现在，我们来重构 wordsWithoutOutliers ,首先定义需要的偏函数：
val pf: PartialFunction[(String, Int), String] = { case (word, freq) if freq > 3 &amp;&amp; freq &lt; 25 => word } wordFrequencies.collect(pf) 我们为这个案例加入了 守卫语句，不在区间里的元素就没有定义。
以上来自Scala 初学者指南
当然有中文版：Scala 初学者指南-gitbook</content></entry><entry><title>Scala Type Class</title><url>https://zhimoe.github.io/post/scala-type-class/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> scala type class notes:
关于 scala type class 非常好的文章
核心知识点 //scala 没有专门的 type class 语法，而是借助 trait + implicit + context bound 来实现的， //所以很多时候识别 type class 比较困难。 //type class 由三部分构成 //1. type class: 即下面的 Show，定义一个行为 toHtml. //2. type class instances：希望实现 toHtml 方法的类型实例 //3. user interface: type class 中伴生对象的同名方法或者隐式转换方法。 // type class trait Show[A] { def toHtml(a: A): String } // 定义在伴生对象的好处就是 implicit 变量自动处于 scope 内 object Show { //利用伴生对象 apply 特点实现下面 Show[A].toHtml 调用方式，即隐藏 implicit sh def apply[A](implicit sh: Show[A]): Show[A] = sh //如果没有 apply，那么下面的 toHtml 需要一个隐式参数： //def toHtml[A](a: A)(implicit sh: Show[A]): String = sh.toHtml(a) //或者： //def toHtml[A: Show](a: A): String = implicitly[Show[A]].toHtml(a) //对外接口，提供 toHtml("type") 的调用形式 def toHtml[A: Show](a: A) = Show[A].toHtml(a) //对外接口，通过隐式转换提供 10 toHtml 的调用形式 implicit class ShowOps[A: Show](a: A) { // 惯例使用 TypeCls+Ops def toHtml = Show[A].toHtml(a) } //为了避免运行开销，可以将 Ops 类定义为 value class： // implicit class ShowOps[A](val a: A) extends AnyVal { // def toHtml(implicit sh: Show[A]) = sh.toHtml(a) // } //上面两个对外接口都利用了伴生对象的 apply 方法和 context bound //type class instance int implicit val intCanShow: Show[Int] = int => s"&lt;int>$int&lt;/int>" //type class instance string implicit val stringCanShow: Show[String] = str => s"&lt;string>$str&lt;/string>" } //use type class import Show._ print(10 toHtml) print(toHtml("type")) 若使用import Show._ 导入全部内容，则用户无法自己实现一些 type class instance 则会覆盖默认实例导致歧义。
可以将对外接口移动到单独的 ops 对象中：
trait Show[A] { def toHtml(a: A): String } object Show { def apply[A](implicit sh: Show[A]): Show[A] = sh object ops { def toHtml[A: Show](a: A) = Show[A].toHtml(a) implicit class ShowOps[A: Show](a: A) { // 惯例使用 TypeCls+Ops def toHtml = Show[A].toHtml(a) } } implicit val intCanShow: Show[Int] = int => s"&lt;int>$int&lt;/int>" implicit val stringCanShow: Show[String] = str => s"&lt;string>$str&lt;/string>" } 使用：
import xxx.Show //如果需要实现自定义的 type class instance 则需要 import xxx.Show.ops._ 自定义 case class Person(name: String, age: Int) implicit val personOps: Show[Person] = p => s"&lt;person>name=${p.name},age=${p.age}&lt;/person>" print(Person("lee", 19) toHtml)//&lt;person>name=lee,age=19&lt;/person> Simulacrum Simulacrum通过宏为 type class 添加便捷语法，是否使用取决于个人判断。
若使用 Simulacrum，则可以一眼找出代码中所有的 type class，并且可省去很多样板代码。
另一方面，使用 @typeclass（Simulacrum 主要注解）则意味着需要依赖 macro paradise 编译器插件。
使用 Simulacrum 重写我们的 Show type class：
import simulacrum._ @typeclass trait Show[A] { def toHtml(a: A): String } 有了 Simulacrum,type class 定义变得非常简洁，我们在其伴生对象中添加 Show[String] 实例：
//Simulacrum 会为 Show 自动生成 ops 对象，与前面自定义的基本一致。 object Show { implicit val stringShow: Show[String] = s ⇒ s"String: $s" }</content></entry><entry><title>Scala 学习笔记</title><url>https://zhimoe.github.io/post/scala2-notes/</url><categories><category>编程</category></categories><tags><tag>code</tag></tags><content type="html"> some notes on scala, includes:
setup with maven import == and eq case class for&hellip;yield companion object and class method and function(def val) _ in scala => in scala () {} in scala implicit string setup with maven 目前用 sbt 的项目比较少，maven 的更多。而且 sbt 烧 cpu. maven 项目使用 scala 参考我的 gist:scala_maven_pom.xml
学习 scala 可以使用 scala 插件的 worksheet，这是一个基于脚本互动的 REPL. 本文后面的代码全部在 worksheet 中测试。
import scala 的 import 语句很灵活，可以在任何地方导入 class 内部外部，方法内部，代码块内部，这样做有一个好处，限制导入方法和对象的 scope，防止污染变量。在后面学了 implicit 隐式转换后，就知道 import scope 有多重要了。
import scala.math._ // import everything in math package import java.util.{ ArrayList => _, _} //第一个下划线表示隐藏 ArrayList，第二个表示通配符，导入所有 //默认，scala 导入： java.lang._ scala._ scala.Predef._ //推荐看一下 Predef 的源代码包括： //Predef 中定义的方法和属性 //常用方法和类 //打印方法 println 等 //一些调试和错误方法 //一个特殊的方法表示方法未实现 def ??? : Nothing = throw new NotImplementedError //Predef 还有大量的隐式转换和隐式参数 == and eq scala 里面==等价于 java 的equals方法即内容比较，并且可以正确处理null(还记得 java 规范里面烦人的 "A".equals(m)规范么？). 而地址 (引用) 比较使用eq 方法，这个方法其实很少用到，应用代码一般无需比较 2 个变量的地址。
case class case class 类似 data class，即 java 的 pojo bean，但是提供了更多的方法。
// 5 个特性 // 1.添加 companion object,apply 方法，unapply 方法 // 2.toString, hashCode and equals and copy methods case class Student(name: String, marks: Int) val s1 = Student("Rams", 550) val s2 = s1.copy() val s3 = s1.copy(marks = 590) s2 == s1 //true s3 == s1 //false // 3. 构造函数参数自动成为成员变量，即自动给构造参数添加 val 前缀 // 4. 可以用于模式匹配 // 5. 默认的，case class 和 case object 是可序列化的 (实现 Serializable),也即是可以网络传输的 for&hellip;yield Scala’s “for comprehensions” are syntactic sugar for composition of multiple operations with foreach, map, flatMap, filter or withFilter
scala 的 for 推导其实就是组合多个foreach, map, flatMap, filter or withFilter的语法糖。
以下代码结果 r1,r2 完全一致：
val c1 = List(1, 2, 3) val c2 = List("a", "b", "c") val c3 = List("!", "@", "#") val r1 = for (x &lt;- c1; y &lt;- c2; z &lt;- c3) yield { x + y + z } //&lt;==> val r2 = c1.flatMap(x => c2.flatMap(y => c3.map(z => { x + y + z }))) assert(r1 == r2)//true companion object Scala 中，除了方法，一切都是对象！函数也是对象，根据参数的个数，函数的类型为 FunctionN.N 为函数参数个数。
伴生对象用于定义一些静态方法 (工厂方法),其中 apply 和 unapply 方法常用。apply 方法用于代替 new 的工厂方法。
同时，companion objects can access private fields and methods of their companion trait/class.
class Person(name: String, age: Int) { private var skill: String = "no skill" def introduce() = println(s"my name is $name, I am $age years old") } // companion object name should be identical to the class name. object Person { def apply(name: String, age: Int): Person = { new Person(name, age) } //apply method override def apply(name: String, age: Int, skill: String): Person = { val p = new Person(name, age) p.skill = skill p } } val dahu = Person("dahu", 30) dahu.introduce 伴生对象在模式匹配和抽取器的应用
//关于抽取器和 unapply 方法的进一步示例： trait User class FreeUser( val name: String, val score: Int, val upgradeProbability: Double) extends User class PremiumUser( val name: String, val score: Int) extends User object FreeUser { def unapply(user: FreeUser): Option[(String, Int, Double)] = Some((user.name, user.score, user.upgradeProbability)) } object PremiumUser { def unapply(user: PremiumUser): Option[(String, Int)] = Some((user.name, user.score)) } val freeUsr = new FreeUser("john", 70, 0.5) freeUsr match { case FreeUser(name, _, p) => if (p > 0.75) println(s"what can I do for you,$name") else println(s"hello,$name") case _ => println("who are you") } //bool 抽取器 object premiumCandidate { def unapply(user: FreeUser): Boolean = user.upgradeProbability > 0.4 } // bool 抽取器的用法 freeUsr match { case freeUser@premiumCandidate() => println(s"恭喜成为黄金会员候选人") case _ => println("欢迎回来") } //来源：[Scala 初学者指南](http://danielwestheide.com/scala/neophytes.html) method and function(def val) 先看函数定义
A function can be invoked with a list of arguments to produce a result.
A function has a parameter list, a body, and a result type. Functions that are
members of a class, trait, or singleton object are called methods.
Functions defined inside other functions are called local functions. Functions
with the result type of Unit are called procedures. Anonymous functions in
source code are called function literals. At run time, function literals are
instantiated into objects called function values.
quote from：
Martin Odersky - Lex Spoon - Bill Venners
函数由一个参数列表，一个函数体，一个结果类型构成。函数如果作为 class,trait 或者 object（注意，这里的 object 是 scala 特有的单例对象，不是 Java 中的 instance）的成员，那么这个函数叫方法。函数和方法的区别就是函数时 FunctionN 的一个实例，编译后是一个单独的 class 文件，而方法是依附对象的，调用方法的格式是 obj.method(param),而调用函数的格式本质是将调用函数对象的 apply 方法。
函数定义在别的函数内部叫局部函数。函数返回值是 Unit 称为过程（procedures）.
匿名函数是通过函数字面量（ ()=>{函数体} ）定义的函数。在运行时，函数字面量被实例化对象，叫函数值。
函数和方法的区别，大部分情况下不用在意区别：
函数是有类型的： (T1, &hellip;, Tn) => U，是 trait FunctionN 的一个实例对象，函数有一个 apply 方法，用来实际执行 function 的函数体。函数还有 toString, andThen ,conpose 等方法。
val fn: Int => String = i => i+"123" //声明一个函数 fn(3) //实际背后是 fn.apply(3); scala 中除了 method，一切都是 instance
method 只能用 def 声明，function 可以是 val 和 def 声明
method 可以有类型参数[] ,function 不能有，函数在声明时就需要知道具体类型。
def fn(p: List[String]): Map[T] = {...} //is function def m[T](t: List[T]): Map[T] = {...} //is method，可以有泛型参数。 将method转换成function有两种方法： val f1 = m1 _ //下划线表示参数列表 eta-expansion val f2: (Int) => Int = m1 //m1 的入参和返回值要和 f2 的一样 //scala 可以自动将 method 转换为 function，如果一个方法需要一个函数作为参数， //那么可以直接将 m1 传递给他，不需要 下划线。 //每一次将方法转换成 function 都是得到一个新的 function object. //function 既然是一个 instance，那么编译成 class 文件会有一个 class 文件。 _ in scala /** * class Reference[T] { * private var contents: T = _ * //使用类型默认值初始化变量，如果 T 是 Int，则 contents 是 0,T 是 boolean，则是 false；Unit 则是 () * } * * * List(1, 2, 3) foreach (print _ ) //output 123，表示实参 * * //在匿名函数中作为参数占位符： * List(1, 2, 3) map ( _ + 2 ) * // _ + 2 是一个匿名函数 * * //模式匹配中的最后一行作为通配符 * case _ => "this is match anything other than before cases " * * expr match { * * case List(1,_,_) => " a list with three element and the first element is 1" * case List(_*) => " a list with zero or more elements " * case Map[_,_] => " matches a map with any key type and any value type " * case _ => * } * * * //import 中作为通配符和隐藏符 * import java.util.{ ArrayList => _, _} * //第一个下划线表示隐藏 ArrayList，第二个表示通配符，导入所有 * * //将方法变为 value * method _ // Eta expansion of method into method value * * //tuple 的访问 * tpl._2 //返回 tpl 第二个元素，注意，tuple 是从 1 开始的 * * * //还有很多高级的概念，目前还不理解，so 上给出的答案 * def f[M[_]] // Higher kinded type parameter * def f(m: M[_]) // Existential type * _ + _ // Anonymous function placeholder parameter * m _ // Eta expansion of method into method value * m(_) // Partial function application * _ => 5 // Discarded parameter * case _ => // Wild card pattern -- matches anything * val (a, _) = (1, 2) // same thing * for (_ &lt;- 1 to 10) // same thing * f(xs: _*) // Sequence xs is passed as multiple parameters to f(ys: T*) * case Seq(xs @ _*) // Identifier xs is bound to the whole matched sequence * var i: Int = _ // Initialization to the default value * def abc_&lt;>! // An underscore must separate alphanumerics from symbols on identifiers * t._2 */ => in scala 函数字面量分隔参数和函数体 在函数字面量中 =>分隔参数和函数体。也可以表示一个函数类型。
(x: Int) => x * 2表示一个匿名函数,接收一个整数,返回参数乘以2的结果. scala> val f: Function1[Int,String] = argInt => "my int: "+argInt.toString f: Int => String = &lt;function1> // Int => String 等价 Function1[Int,String] scala> val f2: Int => String = myInt => "my int v2: "+myInt.toString f2: Int => String = &lt;function1> //注意，匿名函数没有参数也要括号 ()=>{}； //() => Unit 表示没有返回值的函数 call-by-name parameter 在函数的参数声明中使用=>(e.g. def f(arg: => T)) 表示这个参数是"by-name parameter",表示这个参数只有在函数体中包含这个参数的语句被执行才会被 evaluate.
这个特点叫 call-by-name,arg 可以是一个代码块，甚至函数，在传递给 f 时不会 evaluate，只有 f 函数体内部调用 arg 时，arg 才会被执行。
scala> def now()={println("nano time:");System.nanoTime} scala> def callByName(p: => Long):Long = {println("call-by-name:"+p);p;} callByName: (p: => Long)Long scala> def justCall(p : Long) :Long = {println("just-call:"+p);p;} justCall: (p: Long)Long scala> callByName(now()) nano time: call-by-name:5664511571389 nano time: res2: Long = 5664511727048 //now() 在 callByName 的函数体的每个出现的地方都执行了 scala> justCall(now()) nano time: just-call:5667489483159 res3: Long = 5667489483159 //now() 只在传递参数的时候被执行了。 模式匹配中分隔 case 模式和返回值 在 case 语句中，=> 分隔模式和返回表达式。
var a = 1 a match{ case 1 => println("One") case 2 => println("Two") case _ => println("No") } () {} in method call // 规则 1:{}表示 code block，你可以在里面放几乎任何语句，block 的返回值是由最后一句决定 // 规则 2:block 内容如果只有一句可以省略{},但是 case clause 除外:{case ...} // 规则 3: 单参数方法如果实参是 code block，那么可以省略 () { import util.Try println{"hello"} 5 } val tupleList = List[(String, String)]() //规则 2 tupleList takeWhile( { case(t1,t2) => t1==t2 } ) // 规则 2 List(1, 2, 3).reduceLeft(_+_) // 一种特殊情况，提示：隐式转换 val r = List(1, 2, 3).foldLeft(0) {_+_} //val l = r{"hello"} //不要调用这个方法 def loopf(x: Int): Int = loopf {x} //使用{}的特殊情况:for 推导可以和 () 互换，一般建议是除了 yield 的其他情况都用 () for{tpl &lt;-tupleList} yield tpl._2 //不建议 for{tpl &lt;-tupleList} { println(tpl) } //推荐 for(tpl &lt;-tupleList) { println(tpl) } //补充，方法定义时如果没有返回值可以省略=,称为 procedure,scala 2.13 已经废弃，不要这么写 //don't def p(in:String ){ println(s"hello $in") } implicit implicit 分为隐式参数和隐式转换方法。
隐式参数 //1.隐式参数 class Prefixer(val prefix: String) def addPrefix(s: String)(implicit p: Prefixer) = p.prefix + s // addPrefix 需要提供一个隐式实际参数，否则报错。当然可以在调用时显式传递一个参数 implicit val myImplicitPrefixer = new Prefixer("***") addPrefix("abc") // returns "***abc" 隐式转换 //1. 定义一个含有目标方法的 class class BlingString(s:String) { def bling = "*"+s+"*" } //2. 定义隐式转换方法 implicit def str2BlingString(s:String) = new BlingString(s) //3. 使用目标方法 val s = "hello" s.bling // *hello* //在 scala.Predef 中定义了大量的隐式转换，例如 RichInt,StringOps 这些，提供类似 mkString 这些方法 //太阳底下无新事，scala 常用对象的灵活丰富的语法都是通过隐式转换添加的。 implicit class 可以看到上面的第 1,2 步非常的繁琐，于是SIP-13提出一个implicit class,将上面的 2 步合并：
implicit class BlingString(s:String) { def bling = "*"+s+"*" } //implicit def str2BlingString(s:String) = new BlingString(s) val hi = "hello" hi.bling // *hello* 注意，这个只是一个语法糖。去糖后就是上面的那个形式。implicit class 有 3 个约束和一个注解问题：
必须要有主一个构造函数且只能一个构造参数（implicit 参数除外）.构造参数就是源类型。这个构造函数即等价上面第 2 步的隐式转换方法：
implicit class RichDate(date: java.util.Date) // OK! implicit class Indexer[T](collecton: Seq[T], index: Int) // BAD! implicit class Indexer[T](collecton: Seq[T])(implicit index: Index) // OK! 只能定义在其他 trait/class/object 中：
object Helpers { implicit class RichInt(x: Int) // OK! } implicit class RichDouble(x: Double) // BAD! 在当前 scope 内，不允许有和 implicit class 同名的方法，对象，变量。因为 case class 会自动生成同名 object 对象，所以 implicit class 不能是 case class.
object Bar implicit class Bar(x: Int) // BAD! val x = 5 implicit class x(y: Int) // BAD! //cuz case class has companion object by default implicit case class Baz(x: Int) // BAD! conflict with the companion object 还有就是 implicit class 的注解在去语法糖后会自动添加到类和方法，除非在注解中指明范围：
@bar implicit class Foo(n: Int) //desugar @bar implicit def Foo(n: Int): Foo = new Foo(n) @bar class Foo(n:Int) //除非在注解中指明：genClass / method @(bar @genClass) implicit class Foo(n: Int) //desugar 得到 @bar class Foo(n: Int) implicit def Foo(n: Int): Foo = new Foo(n) value class scala 还有一个概念：value class
class Wrapper(val underlying: Int) extends AnyVal //1. 一个 public val 参数表示 runtime 类型，这里是 Int. 编译时是 Wrapper 类型，所以 value class 目的是降低分配开销。 //2. value class 需要 extends AnyVal //3. value class 只能有 defs, 不能有 vals, vars, or nested traits, classes or objects, // 因为 def 是通过静态方法实现的，而 val,var 这些则必须创建相应类型了。 //4. value class 只能扩展通用 trait（universal traits）, // universal traits 是 A universal trait is a trait that extends Any, only has defs as members, and does no initialization. // extension method 当 implicit class 类型参数是 AnyVal 子类时，value class 和上面的 implicit class 形式相近，所以可以通过 value class 降低 implicit class 的分配开销。例如 RichtInt
implicit class RichInt(val self: Int) extends AnyVal { def toHexString: String = java.lang.Integer.toHexString(self) } 因为 RichInt 是 value class，在运行时（runtime）不会有 RichInt 这个类，而是 Int，而3.toHexString实际是通过静态方法实现的： RichInt$.MODULE$.extension$toHexString(3),这么做好处是减少对象分配开销 (avoid the overhead of allocation).如果 implicit class 的类型参数不是 AnyVal 子类，那么在 runtime 时会有相应类型对象被创建，用户察觉不到区别。
value class 还有其他作用和局限性，可以参考上面链接。如果发现错误，请指出，先谢过。
Implicit Design Patterns in Scala​www.lihaoyi.com
The Neophyte&rsquo;s Guide to Scala​
集合类的 implicit 转换 //scala 集合和 java 集合的转换是 scala 编程最常用的，毕竟 java 有大量第三方库。 //scala 提供了两种方法，第一种方法就是隐式转换 collection.JavaConversions(scala 2.8) //很快意识到隐式转换对于使用者的代码阅读比较复杂，在 2.8.1 提供了显示转换 collection.JavaConverters, //先看 JavaConversions 隐式转换： object JavaConversions extends WrapAsScala with WrapAsJava //在 WrapAsJava implicit def mapAsJavaMap[A, B](m: Map[A, B]): ju.Map[A, B] = m match { case null => null case JMapWrapper(wrapped) => wrapped.asInstanceOf[ju.Map[A, B]] case _ => new MapWrapper(m) } //然后看下 collection.JavaConverters._，稍微复杂一些，但是换汤不换药，底层还是隐式转换， object JavaConverters extends DecorateAsJava with DecorateAsScala //在 DecorateAsJava 中有很多隐式转换方法，这些方法将 scala 集合转换为 AsJava 对象 //(注意下面的 ju，是 java.util 缩写，详情见 [征服 scala_1](https://zhuanlan.zhihu.com/p/22670426)) implicit def seqAsJavaListConverter[A](b : Seq[A]): AsJava[ju.List[A]] = new AsJava(seqAsJavaList(b)) // 而 AsJava 中定义了 asJava 方法，这样我们就可以在 scala 集合上面调用 asJava class AsJava[A](op: => A) { /** Converts a Scala collection to the corresponding Java collection */ def asJava: A = op } //并且 asJava 方法的实现是作为构造参数传入 AsJava 的 //上面的 seqAsJavaList 就是将 scala.Seq 转换为 ju.List 的具体实现 def seqAsJavaList[A](s: Seq[A]): ju.List[A] = s match { case null => null case JListWrapper(wrapped) => wrapped.asInstanceOf[ju.List[A]] case _ => new SeqWrapper(s) } //综上，JavaConverters 用的还是隐式转换，只不过增加了一个中间类 AsJava/AsScala. 隐式转换的 scope //无论是隐式参数还是隐式转换，编译器都要知道去哪里查找这些 implicit 参数或者方法， //例如 import collection.JavaConverters._ //由于 scala import 可以出现在任何地方，这为控制 implicit 的 scope 提供了灵活性 //这一块我不是完全清楚，只提供一个自己的理解 // 1.首先是当前 scope 的 Implicits 定义，例如，当前方法内，class 内 // 2.显式导入 import collection.JavaConversions.asScalaIterator // 3.通配符导入 import collection.JavaConverters._ // 4.类型的伴生对象内 (这个常用) // 5.参数类型的隐式 scope (2.9.1 添加):class 构造参数的隐式转换搜索返回会被应用到 class A(val n: Int) { def +(other: A) = new A(n + other.n) } object A { implicit def fromInt(n: Int) = new A(n) } new A(1) + 2 // new A(1) + A.fromInt(2) //6.类型参数的隐式转换，下面的 sorted 方法期望有一个 Ordering[A], //在伴生对象中提供了一个 A -> Ordering[A] , class A(val n: Int) object A { implicit val ord = new Ordering[A] { def compare(x: A, y: A) = implicitly[Ordering[Int]].compare(x.n, y.n) } } List(new A(5), new A(2)).sorted // 注意 implicitly[Ordering[Int]] 表示在当前 scope 内搜索一个隐式参数值 def implicitly[T](implicit e: T): T = e string // The s String Interpolator: val name = "James" println(s"Hello, $name") // Hello, James // The f Interpolator val height = 1.9d val name = "James" println(f"$name%s is $height%2.2f meters tall") // James is 1.90 meters tall // The raw Interpolator // The raw interpolator is similar to the s interpolator except that // it performs no escaping of literals within the string. // Here’s an example processed string // 即不翻译转义字符 scala>raw"a\nb" res1: String = a\nb // """ triple quotes string // triple quotes """ to escape characters val donutJson4: String = """ |{ |"donut_name":"Glazed Donut", |"taste_level":"Very Tasty", |"price":2.50 |} """ .stripMargin // |会被忽略 // """还有个很好的用处，正则表达式： // 在 java 中表示一个或多个空格，"\\s+" // 在 scala 中只要 """\s+""",对于复杂正则表达式非常有用。 links https://www.btbytes.com/scala.html
https://booksites.artima.com/programming_in_scala_2ed/examples/index.html
http://blog.higher-order.com/assets/fpiscompanion.pdf
https://courses.cs.washington.edu/courses/cse341/09au/notes/scala.html
https://github.com/dnvriend/my-scala-notes
https://gist.github.com/jamesyang124/d65b067327452792287a</content></entry><entry><title>使用 redis 的 hash 优化内存使用[翻译]</title><url>https://zhimoe.github.io/post/redis-hash-optimize-memory-usage/</url><categories><category>翻译</category></categories><tags><tag>code</tag><tag>redis</tag></tags><content type="html"> 使用 redis 的 hash 优化内存使用
问题和方案 场景：有 3 亿张图片放在对象存储 (DELL ECS/AMAZON EC2) 上面，现在需要保存图片的 id->用户 id 的映射。最直接的思路是：
set "media:1155220" "user1" set "media:1155221" "user2" 这样设计 key 之后 3 亿张图片需要 21GB 的内存，因为 redis 的 string 是线性增长的。
此时可以使用 hash 优化内存使用.hash 是类似 java hashmap 的数据结构：key field1 value1 field2 value2 &hellip;
hash 的强大在于它可以只获取一个 field 的 value，而无需返回整个 key.
再仔细想想，hash 的 key 可以类比于分库分表的 bucket 概念。
回到上面的问题，Mike Krieger,Instagram 的创始人提出将图片的 id 除以 1000 分片 (sharding) 到 1000 个 hash key 上：
HSET "mda-bkt:1155" "1155220" "user1" "1155221" "user2" # mda-bkt:1155 是1155220/1000之后得到的bucket. HGET "mda-bkt:1155" "1155220" # 这里key的前缀*mda-bkt:)只重复了1000次,而上面的string方式重复了3亿次. 因为 redis 针对hash list zset三种结构使用了ziplist高效存储方案。
新的问题又来了，redis 对于ziplist结构的 key 数量有限制的，即hash-max-ziplist-entries的含义是：可使用内部空间优化存储的最多 hash key
使用ziplist的数据结构有三个list hash zset:
list-max-ziplist-entries 512 list-max-ziplist-value 64 #Limits for ziplist use with LISTs. hash-max-ziplist-entries 512 hash-max-ziplist-value 64 #Limits for ziplist use with HASHes (previous versions of Redis used a different name and encoding for this) #hash-max-zipmap-entries 512 (for Redis &lt; 2.6). zset-max-ziplist-entries 128 zset-max-ziplist-value 64 #Limits for ziplist use with ZSETs. 你可以使用debug_object(key)查看你的 key 是否使用了ziplist结构。
建议hash-max-ziplist-entries最大设置为 1000，过大会影响 redis 性能。
参考资料 redis moemory optimize
9.1.1 The ziplist representation-EBOOK – REDIS IN ACTION
source:Understanding Redis hash-max-ziplist-entries</content></entry><entry><title>Scala 2 Implicit</title><url>https://zhimoe.github.io/post/scala-implicit/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>scala</tag></tags><content type="html"> 隐式参数 //隐式参数是在调用时可以自动填充的参数，需要在调用范围内（scope) 有一个隐式变量可供填充。 def addInt(i:Int)(implicit n: Int) = i + n //需要提供一个隐式变量 n implicit val sn = 1 addInt(2) // 3 //如果有两个满足类型的隐式变量，则在编译 addInt(2) 时报错 //scala 的方法中 ExecutionContext 一般作为 implicit 参数。 隐式转换方法 如果想要给 String 实现一个 mkStr 方法，简单的给 String 添加一个 Ops! 前缀再返回。
//1. 首先实现一个包含目标方法的类型，实现该方法 class StrOps(s:String) { def mkStr(): String = { return "Ops! " + s } } //2. 告诉 scala 编译器 String 可以通过类型转换获得 mkStr 这个方法： implicit final def string2StrOps(s: String) = new StrOps(s) //3. 现在用户可以直接认为 String 有 mkStr 方法 val s = "who changed my string" s.mkStr() //res2: String = Ops! who changed my string //在 scala.Predef 中定义了大量的隐式转换，例如 RichInt,RichDouble,StringOps 这些 implicit class 可以看到第 2 步非常的冗余，于是SIP-13提出一个 implicit class，将上面的 1,2 步合并：
implicit class StrOps(s:String) { def mkStr(): String = { return "Ops! " + s } } 注意，这个只是一个语法糖。去糖后就是上面的那个形式。implicit class 有 3 个约束和一个注解问题：
必须要有主一个构造函数且只能一个构造参数（implicit 参数除外）.构造参数就是源类型。这个构造函数即等价上面第 2 步的隐式转换方法：
implicit class RichDate(date: java.util.Date) // OK! implicit class Indexer[T](collecton: Seq[T], index: Int) // BAD! implicit class Indexer[T](collecton: Seq[T])(implicit index: Index) // OK! 只能定义在其他 trait/class/object 中：
object Helpers { implicit class RichInt(x: Int) // OK! } implicit class RichDouble(x: Double) // BAD! 在当前 scope 内，不允许有和 implicit class 同名的方法，对象，变量。因为 case class 会自动生成同名 object 对象，所以 implicit class 不能是 case class.
object Bar implicit class Bar(x: Int) // BAD! val x = 5 implicit class x(y: Int) // BAD! //cuz case class has companion object by default implicit case class Baz(x: Int) // BAD! conflict with the companion object 还有就是 implicit class 的注解在去语法糖后会自动添加到类和方法，除非在注解中指明范围：
@bar implicit class Foo(n: Int) //desugar @bar implicit def Foo(n: Int): Foo = new Foo(n) @bar class Foo(n:Int) //除非在注解中指明：genClass / method @(bar @genClass) implicit class Foo(n: Int) //desugar 得到 @bar class Foo(n: Int) implicit def Foo(n: Int): Foo = new Foo(n) implicitly 方法 scala 的 PreDef 中有有一个 implicitly 方法，表示在当前 scope 征召一个隐式变量并返回该变量。
//PreDef @inline def implicitly[T](implicit e: T) = e implitly[T] means return implicit value of type T in the context
implicit class Foo(val i: Int) { def addValue(v: Int): Int = i + v } implicit val foo:Foo = Foo(1) val fooImplicitly = implicitly[Foo] // Foo(1) value class scala 还有一个概念：value class
class Wrapper(val underlying: Int) extends AnyVal //1. 一个 public val 参数表示 runtime 类型，这里是 Int. 编译时是 Wrapper 类型，所以 value class 目的是降低分配开销。 //2. value class 需要 extends AnyVal //3. value class 只能有 defs, 不能有 vals, vars, or nested traits, classes or objects, // 因为 def 是通过静态方法实现的，而 val,var 这些则必须创建相应类型了。 //4. value class 只能扩展 通用 trait（universal traits）, // universal traits 是 A universal trait is a trait that extends Any, only has defs as members, and does no initialization. extension method 当 implicit class 类型参数是AnyVal子类时，value class 和上面的 implicit class 形式相近，所以可以通过 value class 降低 implicit class 的分配开销。例如 RichtInt
implicit class RichInt(val self: Int) extends AnyVal { def toHexString: String = java.lang.Integer.toHexString(self) } 因为 RichInt 是 value class，在运行时（runtime）不会有 RichInt 这个类，而是 Int，而 3.toHexString 实际是通过静态方法实现的： RichInt$.MODULE$.extension$toHexString(3),这么做好处是减少对象分配开销（avoid the overhead of allocation）.如果 implicit class 的类型参数不是 AnyVal 子类，那么在 runtime 时会有相应类型对象被创建，用户察觉不到区别。
value class 还有其他作用和局限性，可以参考上面链接。</content></entry><entry><title>使用 travis 自动发布 markdown 到博客</title><url>https://zhimoe.github.io/post/publish-markdown-blog-by-travis/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>github</tag></tags><content type="html"> 如何使用 github pages 和 github actions 构建静态个人博客站点
update at 2021 更新：github 开放 action 功能后，travis-ci 已经没有必要了，目前博客使用 zhimoe 仓库管理源码，使用 action 编译后将 public 目录同步到 zhimoe.github.io 仓库的 gh-pages 分支。
注意，由于使用了 jsdelivr 的 cdn 功能，切换分支后 theme 的相关静态文件的 path 也要修改。
github 给个人和组织免费提供 github pages 功能。就是说如果有个 repo 的名字为 zhimoe.github.io (zhimoe 为你的 github username), 那么这个 repo 里面的 master 或者 gh-pages 分支的内容如果存在 index.html, 那么其他人可以通过 https://zhimoe.github.io 访问这个站点。
借助于一些 static gen 工具，你可以将你的 markdown 转换为一个静态网站 (html,js,css). 然后把静态网站的内容上传到刚说的 repo 中，就有一个自己的博客站点了。static gen 工具非常多，github 推荐的是Jekyll(ruby), 主流的还有 hexo(js) 和 hugo(go)。hexo 因为是基于 js 的，所以高质量的主题多 (因为做主题是需要 js,css 技能), hugo 的编译快些，但是好看的主题不多。高质量的主题除了美观可能还需要考虑移动端 (responsive),评论，访问统计等各种功能。每个 gen 工具都有自己的主题站点。hugo 的主题在这里找：hugo themes.
制作 github pages 站点的一般做法是把代码 (放图片和 markdown) 放在 master 分支，static gen 编译后的 (html,js,css,image) 内容放在 gh-pages 分支。然后在 settings 里面设置。这样就可以得到一个站点了。这么做有个缺点，就是 markdown 文件会被别人整个下载过去，之前就遇到过一次。正好 github 现在有 3 个免费私有仓库。所以我把源码放在私有仓库 zhimoe.github.io.src 里面，而编译后的内容发布的 https://zhimoe.github.io上面去.
自动编译发布这个过程就是持续集成 (continue integration,CI) 了，即我提交一个 markdown 文件，我的主页会自动看到这篇文章，不需要我在本地编译再提交编译结果文件。travis-ci 提供了免费的 github CI 服务。使用 github 账号登录就会有提示操作。这里勾选私有仓库 zhimoe.github.io.src, 然后在项目里面添加.travis.yml 文件告诉 travis 如何编译和发布内容到个人站点。
markdown 渲染设置 hugo 使用 BlackFriday 渲染 markdown 文件，默认的设置有几个过于严格：
没有硬换行，需要使用\来表示换行 标题和#之间必须有空格 代码块前面必须有空行 在 config.toml 可以修改这些配置：
# markdown 解析引擎 blackfriday 配置， # extensions : noEmptyLineBeforeBlock-代码块前面无需空行，hardLineBreak-换行无需使用 backslash # extensionsmask spaceHeaders-标题之间无需空格 [blackfriday] angledQuotes = true extensions = ["hardLineBreak","noEmptyLineBeforeBlock"] extensionsmask = ["spaceHeaders"] fractions = false plainIDAnchors = true travis-ci 配置 就是从一个私有的源码仓库编译，然后将编译后的文件强制覆盖到个人主页 (即 username.github.io 这个仓库) 的仓库中。具体的配置就不说了，注意是需要一个 github 的 personal-access-key. 下面是.travis.yml 内容：
dist: xenial language: python python: 3.7 # Handle git submodules yourself git: submodules: false # Use sed to replace the SSH URL with the public URL, then initialize submodules before_install: - sudo apt update -qq - sudo apt -yq install apt-transport-https - echo -e "Host github.com\n\tStrictHostKeyChecking no\n" >> ~/.ssh/config - git config --global user.email ${GITHUB_EMAIL} - git config --global user.name ${GITHUB_USERNAME} - sed -i 's/git@github.com:/https:\/\/github.com\//' .gitmodules - git submodule update --init --recursive install: # install latest hugo release version # - wget -qO- https://api.github.com/repos/gohugoio/hugo/releases/latest | sed -r -n '/browser_download_url/{/Linux-64bit.deb/{s@[^:]*:[[:space:]]*"([^"]*)".*@\1@g;p;q}}' | xargs wget # use local hugo pkg for speed - sudo dpkg -i hugo*.deb - rm -rf public 2> /dev/null # compile src to dist script: - hugo -d ./dist/ after_success: - git clone https://zhimoe:${GITHUB_TOKEN}@github.com/zhimoe/zhimoe.github.io.git - cd zhimoe.github.io - git rm -rf . &amp;&amp; git clean -fxd - mv -v ../dist/* . - git add . - git commit -m "update site" - git remote set-url origin https://zhimoe:${GITHUB_TOKEN}@github.com/zhimoe/zhimoe.github.io.git - git remote -v - git push -q -f 要点：
在项目的源码中放了 hugo 的 deb 安装包，省去下载的过程 主题以 submodules 放在 themes 目录中，所以编译前一定要git submodule update --init --recursive更新主题到本地。 目标 repo 的远程仓库一定要在 push 前重新设置：git remote set-url origin xxx</content></entry><entry><title>wsl-docker-environment</title><url>https://zhimoe.github.io/post/wsl-docker-environment/</url><categories><category>编程</category></categories><tags><tag>wsl</tag><tag>code</tag></tags><content type="html"> 使用 wsl,MobaXterm,cmder,docker 打造可视化的 linux 开发环境
离不开 Windows 的理由很多，作为后端开发需要使用 linux 的情况也很多，双系统总归是不方便，而且 linux 下的 GUI 体验也没用 Win 10 好。
如果使用虚拟机，那么文件交换和网络等各种问题也需要解决，对系统的内存要求也更高一些。微软为了让更多的开发人员留在 Win10 上面，开发了 WSL，目前的实际体验已经很棒，
今天介绍一下如何打造一个可视化的 linux 开发环境&ndash;即在 Win10 启动 linux 的 GUI 软件，例如 vs code 等。在 wsl 启动 vs code 写代码可以有效避免一些 Windows 和 linux 的编码和换行问题。
本教程分为 2 部分：
配置 wsl 可视化 在 wsl 使用 docker 以下内容中 wsl和ubuntu含义相同，console和命令行含义相同。
配置 wsl 可视化 系统要求是 Win 10 1803+ 版本 (低于 1803 的 wsl 功能有问题),必须是专业版或教育版才有 wsl 功能。以下内容的命令行如果开头有>字符请忽略。
windows 开启 wsl 功能 控制面板\程序\程序和功能\开发或关闭 Windows 功能 > 勾选 &lsquo;适用于 linux 的 Windows 子系统&rsquo; 和 &lsquo;hyper-V&rsquo;(docker for Windows 需要这个功能，也可以使用 virtualbox 代替), 重启电脑。
windows 下载 wsl Windows store 搜索"wsl"或者"ubuntu"下载 ubuntu 版本。ubuntu 和 ubuntu1804 是一个版本，ubuntu1604 是旧的版本。安装完成你的 Windows 应用列表会有一个 ubuntu 应用，点击图标即可打开 ubuntu 命令行。第一次启动需要等待初始化，然后设置用户名和密码。由于字体难看，所以不用这个自带的命令行而使用下面的 cmder.
windws 下载 cmder 软件 cmder 是 Windows 下最强的命令行功能。不要下载 mini 那个，里面没用 vim 和 git.第一次启动 cmder 记得修改 cmder 启动目录 (默认是 c 盘) 和显示中文设置，具体方法请 google.
wsl 修改软件源，使用阿里云的源。 > sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak > sudo sed -i 's/archive.ubuntu.com/mirrors.aliyun.com/g' /etc/apt/sources.list > sudo apt update > sudo apt upgrade -y wsl 安装必要软件 # 安装你需要的软件,git和vim是必须的,后面的编辑命令是使用vim >sudo apt install openjdk-8-jdk-headless openjdk-8-jre-headless maven git unzip vim -y 修改 wsl 下 Windows 磁盘挂载点 默认的 Windows 磁盘在 wsl 的访问方式是/mnt/d/开头，d 表示 d 盘。但是 docker on linux 的访问路径是 /d,所以这里需要修改挂载点路径。
sudo vim /etc/wsl.conf ##添加3行内容 [automount] root = / options = "metadata" 退出 wsl 重启，发现/mnt已经没了，当前目录应该是/c/xxx或者/d/xxx.
wsl 安装 vs code 和中文字体 因为 wsl 没用中文字体将显示豆腐块。
# install chinese fonts for wsl,font name: 'Noto Sans Mono CJK SC' sudo apt install -y fonts-noto-cjk fonts-noto-cjk-extra # Win10下载vs code的deb包,cd到该目录,使用下面命令安装 sudo apt install ./code_1.31.1-1549938243_amd64.deb # 在wsl要启动code必要依赖 sudo apt install libgtk2.0-0 libxss1 libasound2 wsl 设置 SSH 功能 这样可以借助 VcXsrv 的 X11 转发功能打开 GUI 软件
>sudo vim /etc/ssh/sshd_config #取消Port的注释,并将端口改为2222 (端口需要大于1000) #将PasswordAuthentication的值改为yes. #重启 ssh server: sudo service ssh --full-restart #将ssh server设置为服务: sudo service ssh start windows 安装 VcXsrv 用它的 X11 转发功能。安装后默认选项即可，可以设置为开机启动。
启动 wsl 的 vs code 在 wsl 输入code .,等待 2 秒，你会发现 Windows 任务栏启动了一个 vs code，如果没用启动成功，说明你的 VcXsrv 的 X11 转发功能有问题。
配置 vs code. 上面打开的 vs code 有 2 个问题：中文显示豆腐块，和不能全屏。打开 vs code 的设置
#在字体里面先设置你想要英文字体,逗号跟上'Noto Sans Mono CJK SC' #搜索titleBarStyle,将'Window: title Bar Style'设置为 native #上面2个设置也可通过直接编辑文件设置,例如我的vs code文件设置是 > cat ~/.config/Code/User/settings.json { "Window.titleBarStyle": "native", "editor.fontFamily": "monospace,'Noto Sans Mono CJK SC'" } 至此，已经可以在 linux 下面开发了。当然，其他 GUI 软件没用测试不确定是不是会有小问题。但是 vs code 已经可以应付很多开发工作了。
在 wsl 使用 docker 目前的 wsl 是不支持运行 docker 的，但是可以在 wsl 使用 Windows 的 docker，在使用上面是无感的。
安装 docker for Windows. 这个就不细说了，注意 docker 社区版也是需要注册才能下载的。
启动 docker for Windows，右键任务栏的 docker 图标，&ldquo;settings&rdquo;,勾上 &ldquo;expose the daemon on tcp:/localhost:2375 without TLS&rdquo;,这样在 wsl 可以访问这个 docker 服务。
wsl 安装 docker，详细内容可以参考官方文档，下面仅列出必要 bash 命令。
#安装必要组件 sudo apt install -y apt-transport-https ca-certificates curl software-properties-common #gpg 签名 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo apt-key fingerprint 0EBFCD88 #添加 docker 安装源 sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable" sudo apt update sudo apt install -y docker-ce #通过 pip 安装 docker-compose sudo apt install -y python python-pip sudo usermod -aG docker $USER pip install --user docker-compose #验证 docker 安装是否成功 docker info docker-compose --version #修改 docker 服务为 Windows 的 docker echo "export DOCKER_HOST=tcp://localhost:2375" >> ~/.bashrc &amp;&amp; source ~/.bashrc #验证是否可以访问Windows的docker服务,看image list命令输出和Windows的命令行下面的image list输出是不是完全一样. 可以先在Windows下用docker拉几个镜像.然后在wsl验证 docker image list 至此，wsl 的 docker 服务也配置完成。</content></entry><entry><title>Neo4j 入门</title><url>https://zhimoe.github.io/post/neo4j-intro/</url><categories><category>编程</category></categories><tags><tag>neo4j</tag><tag>code</tag><tag>database</tag></tags><content type="html"> neo4j 图数据库介绍 neo4j 是目前排名最高的图数据库，分为商业和社区版本，社区版只支持单机，而且查询的运行时 (runtime) 不同 (cypher runtime:interpreted(社区版),slotted(企业版)). 数据库排名可以在 https://db-engines.com/en/ranking/graph+dbms 查看，下一代最有前景的开源图数据库是 dgraph，目前还积极开发中，生产未就绪，等他的 Java 客户端再成熟一点可以试用。
neo4j 数据库中只有 3 个概念：Node, Relationship, Properties. Node 表示实体类别，使用 Label 区分，例如一个节点可以有 Person/Father 等多个标签，Relationship 即关系，雇佣关系，父子关系，投资关系，交易关系等。Node 和 Relationship 都可以有 Proerties，属性自身不分是属于节点还是属于关系，例如 Person 可以有属性 name，关系也可以用属性 name.你可以在 neo4j browser 左侧看到当前数据库的所有 Node Label,Relationship Type,Properties.
本地安装和在线沙箱 neo4j 背后的公司为了吸引用户，提供了一些好玩的数据库沙箱，这些沙箱数据库已经提前放了一些主题数据，例如购物数据，国会关系数据。你可以通过注册登录 https://neo4j.com/sandbox-v2/, 选择一个数据沙箱实例进行学习试玩。当然你也可以下载社区版，命令行 neo4j.bat console启动，打开 127.0.0.1:7474 开始学习。
一个 neo4j 支持多个数据库但是一次只能激活一个数据库，一个数据库所有文件都在$neo4j_home\data\databases 目录的独立文件夹，在 conf/neo4j.conf 的dbms.active_database=graph.db指定激活那个数据库。
cypher 查询语言 neo4j 使用 cypher 语言作为查询语言。这是一种模式匹配的声明式语言。基本语法和 SQL 相似。
cypher 中常用的子句 (clause) 有：MATCH,RETURN,WITH,WHERE,UNWIND,LIMIT,UNION,SKIP,SET. RETURN,LIMIT WHERE 和 SQL 中是一样的，UNWIND 这些需要用到再查看文档，这里介绍 MATCH 和 WITH.
MTACH用于指定搜索的模式。例如希望找到&rsquo;Tom Hanks&rsquo;在 2018 演过的所有电影：MATCH (p:ACTOR {name:'Tom Hanks' }) -[r: ACT_IN]->(m:MOVIE {time: '2018'}),这是一个模式，可以直接 REUREN 返回 p,r,m 等变量。可以看到模式中的节点 (Node Label) 使用();关系类型 (Relationship Type) 使用[]指定，如果不关心 type，那么[]可以省略。使用&ndash;; 属性 (Properties) 使用{pname: pvalue}指定。
WITH的作用和 python 的 with 非常相似 (实际上 cypher 语言借鉴了 python 的 list 处理语法),用于修改一些变量，变量一般都是上一个子句的查询结果，修改之后传给下一个子句。例如下面的语句找到和 Anders 有关系的人的年龄最大的那个人，返回那个人的所有认识的人的名字。
MATCH (n { name: 'Anders' })--(m) WITH m ORDER BY m.age DESC LIMIT 1 MATCH (m)--(o) RETURN o.name cypher 手册：https://neo4j.com/docs/cypher-manual/3.5/clauses/
cypher 的操作符 如果需要进行 cypher 调优，有必要了解一下 cypher 的操作符。一般编程语言的代码在被执行前都会被编译得到抽象语法树 (AST). 例如 Java 代码，一个 Java 文件会被抽象为一个 package,class, method,variable declare 等不同部分得到一个 Class 对象。cypher 语句一样会被编译得到一棵语法树 (AST),每个树节点是一个操作符。从叶节点的操作符开始执行，得到的结果依次返回给父节点进一步处理。常见的操作符有:AllNodesScan(全局扫描，只能作为叶节点),NodeByLabelScan,Apply 等。例如MATCH (n) return n会得到一个AllNodesScan和ProduceResults操作符构成的 AST, 你可以通过PROFILE查看你语句编译后得到的操作符构成的执行计划。
# 执行语句得到下面的表格 PROFILE MATCH (p:Person { name: 'Tom Hanks' }) RETURN p # 省略了部分列 +-----------------+----------------+------+---------+-----------------+ | Operator | Estimated Rows | Rows | DB Hits | Page Cache Hits | +-----------------+----------------+------+---------+-----------------+ | +ProduceResults | 1 | 1 | 0 | 0 | | | +----------------+------+---------+-----------------+ | +NodeIndexSeek | 1 | 1 | 2 | 0 | +-----------------+----------------+------+---------+-----------------+ cypher runtime pass
neo4j browser 介绍 和大多数数据库一样，neo4j 是 server-client 的数据库，支持 http 和 bolt2 中协议.neo4j 自带一个基于浏览器的客户端，只需在浏览器输入 serverIp:7474 即可使用。
neo4j browser 自带一个教程和电影关系的数据库初始化脚本。方便你可以学习。下面介绍几个常用的命令。
:help help 命令显示各种帮助提示。常见的 topic 有 :help cypher :help commands :help keys :help param :play 交互式学习命令。例如，:play movie graph 进入基于电影数据库的教程。 :param 命令，设置变量。 :param usrname => &ldquo;zhimoe&rdquo;,注意，变量名和=>之间有空格。设置变量之后可以使用变量MATCH (n:Person) WHERE n.name = $usrname :params 显示当前已经设置的所有变量。也可以使用:params {name: &lsquo;Stella&rsquo;, age: 24} 覆盖目前的变量。但是这个命令没用类型安全。 spring-neo4j 配置 pass
cypher 调优 cypher 是一种声明式的，模式匹配的查询语言。模式在 cypher 语言中非常重要。如何合理地设计查询中的模式是 cypher 性能可调优空间最大的地方。下面给出常见的优化建议。
需要说明的是，后面的这些建议其实大都可以在cypher 手册找到，如果感兴趣，建议通读这份长文档&hellip;
避免全局 scan cypher 是一种模式匹配的语言，默认会进行全局扫描，除非你告诉它不要。所以起始节点的 label 非常重要。起始的模式匹配基数大小也非常重要。
缓存和硬盘 IO neo4j 数据库将数据文件和 Page Cache 作了映射，如果在缓存中没有查询到，neo4j 会从硬盘加载数据文件。第二次查询就可以走缓存。所以需要充分利用 Page Cache.记住第一次查询总是会比较慢，因为没用缓存.neo4j 有 2 级缓存:string cache 和 AST cache
string cache
默认 neo4j 在 cache 中保留 1000 个查询计划，可在conf/neo4j.conf中参数 dbms.query_cache_size修改这个设置。 需要注意的是 cache 是根据语句的 string hash 值判断的，所以一样的语句仅仅是大小写不一样或者空白符不一样对缓存来说也是 2 个语句。
PROFILE/EXPLAIN语句只会 cache 其去掉PROFILE/EXPLAIN之后的部分。例如：MATCH (n) return COUNT(n);和PROFILE MATCH (n) return COUNT(n);的 cache 是一致的。
AST cache
编程语言都有语法树。如果在 string cache 中没有找到缓存。那么会将查询正规化，得到语法树并将其缓存。正规化的同时也会做一些优化，例如
match (n:Person {id:101}) return n;在正规化之后得到match (n:Person) where n.id={param1} return n; {param1: 101},AST cache 不区分大小写，空格等，所以以下查询是一致的： match (n:Person) where n.id=101 return n; match (n:Person {id:101}) return n; MATCH ( n:Person { id : 101 } ) RETURN n; execution plan 当 cypher 引擎收到查询语句后如果没用找到对应的缓存，那么 Cypher query planner 会将语句规范化，优化后编译得到一个执行计划 (execution plan).这个执行计划会缓存一切且可以复用。当查询缓存过多，或者数据库的数据变化大时 (设置参数是) 这个执行计划则失效被移除。在查询中使用参数而不是字面量值，可以提高一个执行计划的复用率。
更多信息参考文档:https://neo4j.com/docs/cypher-manual/3.5/execution-plans/#execution-plan-introduction
查看查询计划 如果想要查看查询语句的执行计划，可以在查询语句前加上 EXPLANIN OR PROFILE 关键字，你可以在 neo4j browser 查看 query plan 找到性能瓶颈。结果左侧边里面第 3 个 tab 会给出详细的性能警告 (warn).
EXPLAIN只会给出语句的分析结果;而PROFILE则会执行你的查询语句把给出耗时最多的报告，以及每个操作符返回了多少行记录。注意，profiling 会消耗很多资源，所以不要在生产环境中频繁使用。调优的基础是基于 cypher 的操作符，所以需要你对操作符有基本的了解。
索引 数据库离不开索引。这里有个小陷阱，最早谱系的节点是企业客户 (label: COR_CUSTOMER)+和几十个零售客户节点 (label:RTL_CUSTOMER),我在查询语句起始节点没有指定 label，没用遇到性能问题，后来加入了 3 百万的个人节点数据后，原来 1s 的查询变成了 1 分半钟。所以在干扰的 label 比较少时，你不会察觉到性能问题。务必在起始节点指定 label，即使目前只有一个 label，最好也提前加上。
然而，cypher 语句目前不允许在一个节点指定多个 label，例如你希望起点 label 是COR_CUSTOMER|RTL_CUSTOMER,这个是不允许的。只能在 where 语句指定。
MATCH n WHERE n:COR_CUSTOMER OR n:RTL_CUSTOMER RETURN n 在 3.0 之前的 neo4j 中使用上面的语句，会导致一个 AllNodesScan，在 3.0 之后，该语句则是将 2 个 NodeByLabelScan 匹配结果UNION然后DISTINCT的结果。所以是搜索 2 次再合并结果。你可以在上面的 cypher 语句前面添加EXPLAIN查看执行计划，已确定你的语句是否会导致全局扫描。
SO 上关于多个 label 匹配的讨论
大结果集 如果你的查询返回结果集太大，例如几 M 大小，那么你可能需要考虑你的设计了。过大的结果集会导致查询返回变慢，要注意，这些结果会占用你的缓存空间，而如果在网络情况不好时，情况更加糟糕了。
目前谱系对这一块并没有优化，最大的谱系的返回接口可能达到 1M 多，加上 ES 的数据，前端接收数据会有 4M 多。
锁 当你修改节点的信息时，节点会被锁定;如果修改关系，关系会被锁定;如果增加/删除关系，那么 2 个节点和这个关系都会被锁定。而如果此时有节点/关系的相关查询请求，这些请求会等待。所以，如果你需要将 50 个节点加入一个组 (group)&ndash;即添加 50 个关系，如果你调用 50 次方法，那么这个 group 节点被 lock 的时间较长，此时可以通过UNWIND和列表 (list) 参数处理这个问题。
MATCH (g:Group { uuid: $groupUuid }) UNWIND $personUuidList as personUuid MATCH (p:Person { uuid : personUuid }) MERGE (p)-[:IS_MEMBER]->(g) 常见查询错误 变量名 label 忘记添加冒号，例如 MATCH (Person) 和 MATCH (:Person) 是完全不一样的，前者 Person 是变量，不走索引。 有过大的中间结果集，优化你的语句时思考：尽早 distinct，尽早 limit，使用 collect 减少结果的行数，在正确地方使用 order by; 多个 UNWIND 语句导致笛卡尔积 多个 UNWIND 会导致一个笛卡尔积的结果，这个结果可能会很大。例如下面的结果会得到 3*3=9 行，所以尽量避免笛卡尔积。
with ['a','b','c'] as lts, [1,2,3] as nrs unwind lts as char unwind nrs as nr return char,nr 在 MATCH 中使用多个模式笛卡尔积 在 MATCH 中使用多个模式也会导致笛卡尔积，比较下面的 2 个结果相同的语句，第一个耗时 80s，第二个只需 8ms.
# 1. 笛卡尔积 80000 ms w/ ~900 players, ~40 teams, ~1200 games MATCH (pl:Player),(t:Team),(g:Game) RETURN COUNT(DISTINCT pl), COUNT(DISTINCT t), COUNT(DISTINCT g) # 2. 8ms w/~900 players, ~40 teams, ~1200 games MATCH (pl:Player) WITH COUNT(pl) as players MATCH (t:Team) WITH COUNT(t) as teams, players MATCH (g:Game) RETURN COUNT(g) as games, teams, players 模式中的方向 下面的查询中，如果给关系 ACTED_IN 添加上方向，可以提高查询速度。
MATCH (p:Person)-[:ACTED_IN]-(m) WHERE p.name = "Tom Hanks" RETURN m</content></entry><entry><title>Jupyter Notebook Install New Package[翻译]</title><url>https://zhimoe.github.io/post/python-jupyter-notebook-install-new-package/</url><categories><category>翻译</category></categories><tags><tag>code</tag><tag>python</tag></tags><content type="html"> notes 在 pycharm 写代码中如果使用到新的 package，例如numpy,只需要输入import numpy 然后 ALT+ENTER 在提示中选择 install new package 即可。
在 notebook 中，网上的教程都说是!pip install numpy. 但是这个可能有坑。究其原因是因为：
通过 bash 启动的 notebook 中的python pip conda这几个命令的环境和实际执行 notebook 代码的 python 环境可能不是同一个。
这种情况一般发生在系统有好几个 python 的情况，例如系统自带 python 和用户安装的 anaconda python.
可以通过对比以下两个 notebook 命令的输出判断 pip 执行环境和 notebook 代码执行环境是否一致：
# pip 执行环境 python !type python # notebook 代码执行环境的 python import sys sys.executable 如果不一样，那么需要使用下面命令安装才能在 notebook 中生效：
import sys
!{sys.executable} -m pip install numpy
sys 和 os 区别 os: 操作系统的抽象。 sys: 代码和 python 解释器交互的接口。提供一系列函数来访问修改 python 解释器环境设置。 source:installing new python package from jupyter notebook</content></entry><entry><title>Java 并发 4-线程池与执行器</title><url>https://zhimoe.github.io/post/java-concurrency-4-threadpool-hierachy/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>并发</tag><tag>thread-pool</tag></tags><content type="html"> thread pool classes hierarchy java thread pool class hierarchy Executor (java.util.concurrent) |---ExecutorService (java.util.concurrent) |---AbstractExecutorService (java.util.concurrent) | |---ForkJoinPool (java.util.concurrent) | |---ThreadPoolExecutor (java.util.concurrent) | | |---ScheduledThreadPoolExecutor (java.util.concurrent) |---DelegatedExecutorService in Executors (java.util.concurrent) |---ScheduledExecutorService (java.util.concurrent) three thread pool interfaces Executor, a simple interface that supports launching new tasks.
ExecutorService, a sub-interface of Executor, which adds features that help manage the life cycle, both of the
individual tasks and of the executor itself.
ScheduledExecutorService, a sub-interface of ExecutorService, supports future and/or periodic execution of tasks.
common thread pool implements ThreadPoolExecutor是 thread pool 最常用的实现。一般通过Executors静态工厂方法来创建。
//Executors.newFixedThreadPool //Executors.newCachedThreadPool //Executors.newSingleThreadExecutor //同样的，Executors 还提供了 ScheduledExecutorService 的工具方法 //Executors.newSingleThreadScheduledExecutor /** * corePoolSize - 保留存活的线程个数 * maximumPoolSize - 最大线程个数 * keepAliveTime - 线程数超过 corePoolSize 时，空闲线程存活时间 * unit - keepAliveTime 的单位，毫秒秒分等 * workQueue – 任务队列，只保存通过 execute() 方法提交的 Runnable 任务 * threadFactory – 给自己创建一个线程的工厂方法 * handler – 当线程池达到数量限制或者任务队列满了，对新任务提交的处理策略 */ class ThreadPoolExecutor { public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable> workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) {} } JDK 默认的拒绝策略 RejectedExecutionHandler 有：
/** * ThreadPoolExecutor.AbortPolicy - 默认的 handler，抛出一个 RejectedExecutionException * ThreadPoolExecutor.CallerRunsPolicy - 提交任务的线程自己执行这个任务 * ThreadPoolExecutor.DiscardPolicy - 抛弃这个任务 * ThreadPoolExecutor.DiscardOldestPolicy - 抛弃任务队列中最早提交上来的任务，然后尝试重新提交当前这个任务 */ 任务提交执行流程 fork/join 框架 fork/join和上面ThreadPoolExecutor的区别在于使用了任务窃取算法，工作线程完成自己的任务后可以从其他线程偷取任务，提高整体的任务效率.
核心是一个ForkJoinPool class 和一个扩展的AbstractExecutorService. 执行ForkJoinTask 任务。
在 JDK8 中有个java.util.Arrays.parallelSort()使用的就是 fork/join.
当然，不是所有人都满意 JDK7 引入的 Fork/Join 框架.</content></entry><entry><title>Spark Basic</title><url>https://zhimoe.github.io/post/spark-basic/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>spark</tag></tags><content type="html"> 引言 大数据计算和普通的程序并无本质区别：数据输入=>计算=>输出和结果的持久化。这里的挑战在于计算的效率和容错性。由于数据输入巨大，计算的效率是基本的要求。为了在通用硬件上高效完成大量计算，唯一的途径就是将计算任务拆分分布式计算。这就引出了新的问题：分布式计算资源的管理（Mesos,YARN）,分布式计算失败后的恢复（容错性）（Spark RDD）,以及分布式的数据输入和保存（分布式文件 HDFS）.hadoop 生态圈就是为了解决几个问题设计的 (YARN,MapR,HDFS).只不过在计算这一环节 Spark 做的更加高效取代了 MapR.所以先看下 hadoop 的核心两个组件。
HDFS HDFS 是 hadoop 的虚拟分布式文件系统。满足大数据问题下要求的：可扩展的，容错的，硬件通用的和高并发的特性.HDFS 最重要的特性是不可变性&ndash;数据提交到 HDFS 后即不可更新了，也就是所谓的 WORM(write once read many). 文件在 HDFS 中是以 block 构成，默认一个 block 是 128M.block 是是分布式的，即如果集群中如果有多于 1 个节点，那么有文件可能会被分布在多个节点上.block 是被复制的，这主要是两个目的：1.容错，2.增加数据局部性的概率，有利于访问.block 复制在数据节点接收（ingest：消化）block 时同时发生。如图所示： NameNode：不知道怎么翻译，NameNode 主要负责管理 HDFS 的元数据，包括 directory，文件对象和相关属性（e.g. ACL),元数据是常驻内存中的，硬盘上也有备份以及日志保证持久性和崩溃后的一致性（和数据库相似）.还包括 block 的位置信息&ndash;block 之间的关系。注意，数据（文件）并不经过 NameNode，否则很容易成为性能瓶颈，数据是直接到达 DataNode，并上报给 NameNode 管理。 数据节点（DataNode）负责：block 复制；管理本节点的存储；向 NameNode 上报 block 信息。注意，数据节点不会意识到 HDFS 的目录（directory）和文件（Files）的概念，这些信息是 NameNode 管理保存的，客户端只会和 NameNode 交道。 hdfs 客户端分为：fs shell;hdfs java api;rest proxy 接口（HttpFS 等）. 常见命令： # 上传一个文件 -f表示覆盖 hadoop fs -put -f jour.txt /user/dahu/jour/ # 下载 hadoop fs -get /user/dahu/jour/jour.txt # ls hadoop fs -ls /user/dahu/ # 删除 -r表示递归,删除目录 hadoop fs -rm /user/dahu/jour/jour.txt hadoop fs -rm -r /user/dahu/jour YARN YARN:Yet Another Resource Negotiator 是 hadoop 的资源管理器.YARN 有个守护进程&ndash;ResourceManager，负责全局的资源管理和任务调度，把整个集群当作计算资源池，只关注分配，不管应用，且不负责容错.YARN 将 application（或者叫 job）分发给各个 NodeManager,NodeManager 是实际的 worker 或者 worker 的代理.ResourceManager 主要有两个组件：Scheduler 和 ApplicationsManager. 下图是 YARN 的结构示意图： 上图中 ResourceManager 负责管理和分配全局的计算资源。而 NodeManager 看着更复杂一些：1.用户提交一个 app 给 RM（ResourceManager）；2.RM 在资源充足的 NodeManager 上启动一个 ApplicationMaster（也就是这个 app 对应的第一个 container）.3.ApplicationMaster 负责在所有 NodeManagers 中协调创建几个 task container，也包括 ApplicationMaster 自己所在的 NodeManager（上图中紫色 2 个和红色的 4 个分别表示 2 个 app 的 task container 和 ApplicationMaster）.4. NodeManager 向各个 ApplicationMaster 汇报 task container 的进展和状态.5. ApplicationMaster 向 RM 汇报应用的进展和状态.6.RM 向用户返回 app 的进度，状态，结果。用户一般可通过 Web UI 查看这些。
上面的示意图是 YARN 的核心概念，Spark 程序的运行结构示意图和上面的示意图相同。每个组件都可以近似一样的理解，例如，上面的 Client 在 Spark 中叫 Driver 程序;ResourceManager 在 Spark 中叫 Cluster Manager（为了理解方便，认为一样即可，Spark 的 ClusterManager 目前主要有 YARN,Mesos 和 Spark 自带的三种）；NodeManager 就是 Spark 中的 Worker Node.
Spark 基本概念 上图中的 client 程序在 Spark 中即 Driver 程序.Driver 就是我们编写 Spark 程序 app 的主要部分，包括SparkContext的创建和关闭以及计算任务（Task）的计划（Planning，包括数据数据，转换，输出，持久化等).SparkContext负责和 Cluster Manager 通信，进行资源申请，任务的分配和监控。一般认为SparkContext代表 Driver. ClusterManager：就是上面说的三种-Standalone,YARN,Mesos. WorkerNode: 集群中运行 app 代码的节点，也就是上图中 YARN 的 NodeManager 节点。一个节点运行一个/多个 executor. Executor：app 运行在 worker 节点的一个进程，进程负责执行 task 的 planning.Spark On YARN 中这个进程叫 CoarseGrainedExecutorBackend.每个进程能并行执行的 task 数量取决于分配给它的 CPU 个数了。下图是一个 Spark 程序集群概览图，和上图很相似。 仔细对比上面两个示意图，在 YARN 的结构示意图中，ResourceManager 为程序在某个 NodeManager 上创建的第一个 container 叫 ApplicationMaster,ApplicationMaster 负责只是其他的 task container.在 Spark On YARN 有两种运行模式：client 和 cluster 模式。在 cluster 模式下，用户编写的 driver 程序运行在 YARN 的 ApplicationMaster 的内部。
*RDD:Spark 的核心数据结构。后面详细介绍，可以简单的理解为一个 Spark 程序所有需要处理的数据在 Spark 中被抽象成一个 RDD，数据需要被拆分分发到各个 worker 去计算，所以 RDD 有一个分区（Partation）概念。一般我们的数据是放在分布式文件系统上的 (e.g. HDFS),可以简单理解为一个 RDD 包含一或多个 Partation，每个 Partation 对应的就是 HDFS 的一个 block.当然，Partation 不是和 HDFS 的 block 绑定的，你也可以手动的对数据进行分区，即使他们只是待处理的一个本地文件或者一个小数组。一个 Partation 包含一到多个 Record,Record 可以理解为文本中的一行，excel 的一条记录或者是 kafka 的一条消息。 Task：RDD 的一个 Patation 对应一个 Task,Task 是单个分区上最小的处理单元。 RDD pass
SparkStreaming pass
SparkStreaming+Kafka import org.apache.kafka.clients.consumer.ConsumerRecord import org.apache.kafka.common.serialization.StringDeserializer import org.apache.spark.streaming.kafka010._ import org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent import org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe val kafkaParams = Map[String, Object]( "bootstrap.servers" -> "localhost:9092,anotherhost:9092", "key.deserializer" -> classOf[StringDeserializer], "value.deserializer" -> classOf[StringDeserializer], "group.id" -> "use_a_separate_group_id_for_each_stream", "auto.offset.reset" -> "latest", "enable.auto.commit" -> (false: java.lang.Boolean) ) val topics = Array("topicA", "topicB") val stream = KafkaUtils.createDirectStream[String, String]( streamingContext, PreferConsistent, Subscribe[String, String](topics, kafkaParams) ) stream.map(record => (record.key, record.value)) DStream 的 elements:record is ConsumerRecord&lt;K,V>: A key/value pair to be received from Kafka. This consists of a topic name and a partition number, from which the record is being received and an offset that points to the record in a Kafka partition.包含 key(),offset(),partation() 方法等。
当一个 StreamingContext 中有多个 input stream 时，记得保证给程序分配了足够的资源（特别是 core 的数量，必须大于输入源的数量）. 本地执行程序时，不要使用“local”or“local[1]”as the master URL,streaming 程序至少需要两个 thread，一个接受数据，一个处理数据。直接使用 local[n],n>输入源个数。 DStream 和 RDD 一样支持各种 trans 和 action DStream is batches of RDDs. 常见错误 数据库 (mysql redis) 连接的可序列化问题 dstream.foreachRDD { rdd => val connection = createNewConnection() // executed at the driver rdd.foreach { record => connection.send(record) // executed at the worker } } // 上面的写法会导致 connection 不可序列化的错误：Task not serializable // RDD 的函数 (map,foreach) 会被序列化发送到 worker 节点执行，但是 connection 是和 tcp 连接，和机器绑定的，无法序列化 dstream.foreachRDD { rdd => rdd.foreach { record => // on worker node val connection = createNewConnection() // 给每个 record 处理时新建一个连接，会导致严重的数据库连接性能问题 connection.send(record) connection.close() } } // 更好的方式是给每个 partation 新建一个连接 dstream.foreachRDD { rdd => rdd.foreachPartition { partitionOfRecords => val connection = createNewConnection() partitionOfRecords.foreach(record => connection.send(record)) connection.close() } } // 最好的方法是维护一个静态线程池： [ConnectionPool](https://github.com/RedisLabs/spark-redis/blob/master/src/main/scala/com/redislabs/provider/redis/ConnectionPool.scala) // then use in partition dstream.foreachRDD { rdd => rdd.foreachPartition { partitionOfRecords => // ConnectionPool is a static, lazily initialized pool of connections val connection = ConnectionPool.getConnection() partitionOfRecords.foreach(record => connection.send(record)) ConnectionPool.returnConnection(connection) // return to the pool for future reuse } } // Note that the connections in the pool should be lazily created on demand and timed out if not used for a while. // This achieves the most efficient sending of data to external systems. // 示例 case class RedisCluster(clusterHosts: String, password: String) extends Serializable { def this(conf: SparkConf) { this( conf.get("spark.redis.host", Protocol.DEFAULT_HOST), conf.get("spark.redis.auth", null) ) } /** * * @return use for JedisCluster or JedisPool */ def toSet(): java.util.Set[HostAndPort] = { val nodes: mutable.Set[HostAndPort] = mutable.Set() for (host_port &lt;- clusterHosts.split(",")) { val hp = host_port print(hp) nodes += HostAndPort.from(host_port) } nodes.asJava } } object RedisClusterUtils extends Serializable { @transient private lazy val pools: ConcurrentHashMap[RedisCluster, JedisCluster] = new ConcurrentHashMap[RedisCluster, JedisCluster]() /** * 获取一个 JedisCluster * @param rc * @return */ def connect(rc: RedisCluster): JedisCluster = { pools.getOrElseUpdate(rc, { val poolConfig = new JedisPoolConfig(); poolConfig.setMaxTotal(250) poolConfig.setMaxIdle(32) poolConfig.setTestOnBorrow(false) poolConfig.setTestOnReturn(false) poolConfig.setTestWhileIdle(false) poolConfig.setNumTestsPerEvictionRun(-1) val jedisCluster = new JedisCluster(rc.toSet(), 3000, 3000, 5, rc.password, poolConfig) jedisCluster }) } /** * 查询币种对应汇率 * @param jedisCluster 目标 redis * @param ccyCd 币种代码 * @return 折美元汇率 */ def getCcyRatio(jedisCluster: JedisCluster, ccyCd:String): Double ={ val res = jedisCluster.get("CCY:"+ccyCd) res.split(":")(2).toDouble } } 参考
Design Patterns for using foreachRDD
Redis on Spark:Task not serializable
How to create connection(s) to a Datasource in Spark Streaming for Lookups
DStream 的 RDD 分区数是由 topic 分区数相同的。 最佳实践</content></entry><entry><title>java 单元测试如何 Mock 有参数的 void 方法</title><url>https://zhimoe.github.io/post/java-how-test-void-method-with-parameter/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>java</tag><tag>test</tag></tags><content type="html"> 测试中如果遇到被测试方法调用 void 方法，在 Mockito 中改如何处理？
假设有如下的服务依赖：
@Service class DepositSvc { @Autowired private AccountSvc accSvc; public List&lt;Account> dps(String user) { List&lt;Account> accounts = new ArrayList(); List&lt;Account> banks = getBanks(); accSvc.addLinkedAccounts(user, accounts, banks);//accounts 被改动了如何 mock? return accounts; } } @Service class AccountSvc { @Autowired private RestClient restClient; public void addLinkedAccounts(String user, List&lt;Account> accounts, List&lt;Account> banks) { acc = restClient.getAcc(user); accounts.add(acc); } } 这里的 AccountSvc 只是提供了一个 void 方法处理了入参 accounts，虽然修改入参是被我所不齿的，但是有时改写这类方法挺麻烦的，特别如果方法修改了两个入参的话。
这种情况下如何测试 DepositSvc.dps 方法呢？mockito 的 doAnswer就是用于模拟 void 方法回调的。
class DepositSvcTest { @InjectMocks private DepositSvc depositSvc; @Mock private AccountSvc accountSvc; void test_dps() { // ... arrange // mock void method with arguments doAnswer((invocation) -> { Object[] args = invocation.getArguments(); List&lt;Account> accounts = (List&lt;Account>) args[1]; //这里可以拿到入参 accounts.add(new Account(911); //修改入参 return null; }).when(accountSvc).addLinkedAccounts(any(), anyList(), anyList()); // ...assert } }</content></entry><entry><title>打虎</title><url>https://zhimoe.github.io/about/</url><categories/><tags/><content type="html"> A programmer, use Java/Scala/Rust/Python/Javascript.
Write user stories in daily job.
Customize programming fonts for fun.
email: me#zhi.moe</content></entry><entry><title>java generic</title><url>https://zhimoe.github.io/post/java-generic/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>泛型</tag></tags><content type="html"> 泛型 // 类 class Tuple&lt;T, S> { private T first; private S second; } // 泛型方法也可在非泛型类里面 class ArrayAlg { public static &lt;T> T getMiddle(T... a) { return a[a.length / 2]; } } String middle = ArrayAlg.&lt;String>getMiddle("]ohnM, "Q.n, "Public");// right,&lt;String>可以省略 String middle = GenericCls.getMiddle("hello",0,null);// error // Errr:(7, 45) java: 不兼容的类型：推断类型不符合上限 // 推断：java.lang.Object&amp;java.io.Serializable&amp;java.lang.Comparable&lt;? extends java.lang.Object&amp;java.io.Serializable&amp;java.lang.Comparable&lt;?>> // 上限：java.lang.String,java.lang.Object 类型限定 public static &lt;T extends Comparable> T min(T a) // 如果多个类型，则：T extends Comparable &amp; Serializable // 只能有一个类，且类必须紧跟 extends，但是可以有多个接口 类型擦除 //Tuple&lt;T,S>在虚拟机变为 class Tuple { private Object first;//当调用 getFirst 时，则发生强制转换 private Object second; } //泛型方法同样有擦除 public static &lt;T extends Comparable> T min(T a) // => public static Comparable min(Comparable a) 约束 不能用基本类型实例化泛型，Pair&lt;double>不允许 运行时参数类型检查只能检查原始类型 if (a instanceof Pair&lt;String>) // Error if (a instanceof Pair&lt;T>) // Error Pair&lt;String> p = (Pair&lt;String>) a; //warning 不能创建参数化类型的数组 Pair&lt;String>[] table = new Pair&lt;String>[10]; // Error Pair&lt;String>[] table; //声明是合法的，只是无法实例化 借助@SafeVarargs 参数化类型的数组 @SafeVarargs public static &lt;T> void addAll(Collection&lt;T> coll, T... ts) Class 类本身是泛型。例如，String.daSS 是一个 Class 的实例（事实上，它是唯一的实例.) 因此，makePair 方法能够推断出 pair 的类型 泛型类的静态上下文中类型变量无效 public class Singleton&lt;T> { private static T singlelnstance; // Error public static T getSinglelnstance{// Error if (singleinstance == null) {//construct new instance of T return singlelnstance; } } } 不能抛出或捕获泛型类的实例 public class Problem&lt;T> extends Exception { /* . . . */ } // Error can't extend Throwable 泛型擦除的方法冲突 public class Pair&lt;T> { T first; T second; public boolean equals(T value) { //error 和 Object.equals 冲突 return first.equals(value) &amp;&amp; second, equals(value); } } 泛型继承 class Employee class Manager extends Employee //Pair&lt;Employee> 和 Pair&lt;Manager> 没用任何继承关系 通配符 和 PECS Pair&lt;? extends Employee〉 Pair&lt;? super Manager 反射和泛型</content></entry><entry><title>IO-Java-Stream-Write-Reader</title><url>https://zhimoe.github.io/post/java-io-basic/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 上次总结了 java 中不同读写文件的方法，这次总结一下基本的 IO 流。网上的总结大部分是以 Stream 和 Reader、Writer 来介绍的。这次从封装层次来介绍。
概览 首先理解计算机文件格式都是二进制数据，例如文本，图片，视频，音频等，但是文本非常特殊，所以单独有一类封装设计。
对于非文本类的文件，一般是读取字节 (stream)，而对于文本类文件，则可以读取字符 (reader)
当然，文本文件也可以使用 inputstream 读取后再转换Reader reader = new InputStreamReader(inputStream, StandardCharsets.UTF_8);
stream 首先是 byte 流，每次 read() 读取 8 bits，并用一个 int 的低八位保存：
FileInputStream in = null; FileOutputStream out = null; try { in = new FileInputStream("xanadu.txt"); out = new FileOutputStream("outagain.txt"); int c; while ((c = in.read()) != -1) { out.write(c); } } finally { if (in != null) { in.close(); } if (out != null) { out.close(); } } byte 流是很基础的流，接下来是字符流，使用 int 的低 16 位保存读取内容，一个汉字，使用上面那个字节流，需要读取 2 次，使用下面的字符流，只用一次。其实背后还是一个桥接
具体的对象体现：
FileReader extemds InputStreamReader,
FileWriter extends OutputStreamWriter
InputStreamReader:字节到字符的桥梁
OutputStreamWriter:字符到字节的桥梁：
FileReader inputReader = null; FileWriter outputStream = null; try { inputReader = new FileReader("xanadu.txt"); outputStream = new FileWriter("characteroutput.txt"); int c; while ((c = inputReader.read()) != -1) { outputStream.write(c); } } finally { if (inputReader != null) { inputReader.close(); } if (outputStream != null) { outputStream.close(); } } ByteArrayInputStream、StringBufferInputStream、FileInputStream 是三种基本的介质流，它们分别从 Byte 数组、StringBuffer、和本地文件中读取数据.StringBufferInputStream 已经被 Deprecated，设计错误，只是为了兼容。
File I/O 现在已经不推荐使用了，推荐 nio2 的 Path 及其工具类 Files、Paths;
Path 官方教程
ObjectInputStream 和所有 FilterInputStream 的子类都是装饰流（装饰器模式的主角）
注意：OutputStream 子类中没有 StringBuffer 为目的地的。ObjectOutputStream 和所有 FilterOutputStream 的子类都是装饰流。
几个特殊的类：
PushbackInputStream 的功能是查看最后一个字节，不满意就放入缓冲区。主要用在编译器的语法、词法分析部分。输出部分的 BufferedOutputStream 几乎实现相近的功能。
PrintStream 也可以认为是一个辅助工具。主要可以向其他输出流，或者 FileInputStream 写入数据，本身内部实现还是带缓冲的。本质上是对其它流的综合运用的一个工具而已。一样可以踢出 IO 包！System.out 和 System.err 就是 PrintStream 的实例！System.in 是 InputStream 的实例！
你永远不应该 new PrintStream，请用 PrintWriter
reader writer CharReader、StringReader 是两种基本的介质流，它们分别将 Char 数组、String 中读取数据.PipedReader 是从与其它线程共用的管道中读取数据。
BufferedReader 很明显就是一个装饰器，它和其子类负责装饰其它 Reader 对象。
FilterReader 是所有自定义具体装饰流的父类，其子类 PushbackReader 对 Reader 对象进行装饰，会增加一个行号。
InputStreamReader 是一个连接字节流和字符流的桥梁，它将字节流转变为字符流.FileReader 可以说是一个达到此功能、常用的工具类，在其源代码中明显使用了将 FileInputStream 转变为 Reader 的方法。我们可以从这个类中得到一定的技巧.Reader 中各个类的用途和使用方法基本和 InputStream 中的类使用一致。后面会有 Reader 与 InputStream 的对应关系。
OutputStreamWriter 是 OutputStream 到 Writer 转换的桥梁，它的子类 FileWriter 其实就是一个实现此功能的具体类（具体可以研究一 SourceCode）.功能和使用和 OutputStream 极其类似，后面会有它们的对应图。
PrintWriter 和 PrintStream 极其类似，功能和使用也非常相似。但是还是有不同的，PrintStream prints to an OutputStream, and PrintWriter prints to a Writer.
你永远不应该 new PrintStream，请用 PrintWriter
PrintStream stream = new PrintStream(outputStream); //With the PrintWriter you can however pass an OutputStreamWriter with a specific encoding. PrintWriter writer = new PrintWriter(new OutputStreamWriter(outputStream, "UTF-8")); RandomAccessFile 类 该对象并不是流体系中的一员，其封装了字节流，同时还封装了一个缓冲区（字符数组），通过内部的指针来操作字符数组中的数据。该对象特点：
该对象只能操作文件，所以构造函数接收两种类型的参数：a.字符串文件路径；b.File 对象。
该对象既可以对文件进行读操作，也能进行写操作，在进行对象实例化时可指定操作模式 (r、rw)
注意：该对象在实例化时，如果要操作的文件不存在，会自动创建；如果文件存在，写数据未指定位置，会从头开始写，即覆盖原有的内容。可以用于多线程下载或多个线程同时写数据到文件。
Scanning and formatting The scanner API breaks input into individual tokens associated with bits of data,The formatting API assembles data into nicely formatted, human-readable form.
formatting
int i = 2; double r = Math.sqrt(i); System.out.format("The square root of %d is %f.%n", i, r); Scanner s = new Scanner(new BufferedReader(new FileReader("xanadu.txt"))); By default, a scanner uses white space to separate tokens. also,u can set :
s.useDelimiter(",\\s*");
I/O from commandline You might expect the Standard Streams to be character streams, but, for historical reasons, they are byte streams. System.out and System.err are defined as PrintStream objects. Although it is technically a byte stream, PrintStream utilizes an internal character stream object to emulate many of the features of character streams.(！！！妈的，老子开始就困惑很久了，一直不明白 System.out 怎么可以直接打印出中文.)
By contrast, System.in is a byte stream with no character stream features. To use Standard Input as a character stream, wrap System.in in InputStreamReader.
InputStreamReader cin = new InputStreamReader(System.in);
jdk1.5 开始读写控制台以前常用的是 Scanner：
Scanner scanner = new Scanner(System.in); scanner.nextLine(); 从 JDK1.6 开始，基本类库中增加了 java.io.Console 类，用于获得与当前 Java 虚拟机关联的基于字符的控制台设备。在纯字符的控制台界面下，可以更加方便地读取数据。
Console console = System.console(); if (console == null) { throw new IllegalStateException("不能使用控制台"); } return console.readLine(prompt); Data Streams Data streams support binary I/O of primitive data type values (boolean, char, byte, short, int, long, float, and double) as well as String values. All data streams implement either the DataInput interface or the DataOutput interface. This section focuses on the most widely-used implementations of these interfaces, DataInputStream and DataOutputStream.</content></entry><entry><title>Java 6/7/8 中文件读写</title><url>https://zhimoe.github.io/post/java-file-in-v678/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 如何在 Java 中读写文件，这里保留 Java6/7 版本，但是你永远不应该使用它们，优先使用 Path、Files、Paths 三个类。
资料：Reading and writing text files
Java8 最佳实践 不要用 File 对象，改用 Path 对象，该对象既表示文件路径，也表示文件文本（应该认为文件也是路径的一部分），对于以前的 File，可以 File.toPath() 得到一个 Path 对象。
Files 是一个静态类，操作文件内容.Paths 是静态工具类，操作文件路径，例如拼接文件路径，以前要使用平台无关的分隔符表示：File.pathSeparator、File.separator.
例如，构建一个文件对象：Path path = Paths.get("~/test/", "foo", "bar", "a.txt");
read file to string in java 6/7/8 package angus.java.interview; import java.io.BufferedReader; import java.io.FileInputStream; import java.io.IOException; import java.io.InputStream; import java.io.InputStreamReader; import java.nio.charset.StandardCharsets; import java.nio.file.Files; import java.nio.file.Paths; public class FileToStringJava678 { public static void main(String[] args) throws IOException { // How to read file into String before Java 7 InputStream is = new FileInputStream("filetoStringjava678.txt"); BufferedReader buf = new BufferedReader(new InputStreamReader(is)); String line = buf.readLine(); StringBuilder sb = new StringBuilder(); while (line != null) { sb.append(line).append("\n"); line = buf.readLine(); } String fileAsString = sb.toString(); System.out.println("Contents (before Java 7) : " + fileAsString); // Reading file into Stirng in one line in JDK 7 with using proper character encoding String fileString = new String(Files.readAllBytes(Paths.get("filetoStringjava678.txt")), StandardCharsets.UTF_8); System.out.println("Contents (Java 7 with character encoding ) : " + fileString); //java 7 按行读取 BufferedReader br = new BufferedReader(new FileReader(file)); String line; while((line = br.readLine()) != null) { // do something with line. } //java 8 按行读取 String fileName = "c:/lines.txt"; try (Stream&lt;String> stream = Files.lines(Paths.get(fileName))) { stream.forEach(System.out::println);//or other thing you do with stream } catch (IOException e) { e.printStackTrace(); } // It's even easier in Java 8 Files.lines(Paths.get("filetoStringjava678.txt"), StandardCharsets.UTF_8).forEach(System.out::println); } } java 8 file io demo public class Java8IO { public static void main(String[] args) throws IOException { //读取所有字节： Path path = Paths.get("alice.txt"); String content = new String(Files.readAllBytes(path), StandardCharsets.UTF_8); System.out.println("Characters: " + content.length()); // 读取所有行： List&lt;String> lines = Files.readAllLines(path, StandardCharsets.UTF_8); System.out.println("Lines: " + lines.size()); // JAVA 8 延迟处理： try (Stream&lt;String> lineStream = Files.lines(path, StandardCharsets.UTF_8)) { System.out.println("Average line length: " + lineStream.mapToInt(String::length).average().orElse(0)); } // 按单词读取： try (Scanner in = new Scanner(path, "UTF-8")) { in.useDelimiter("\\PL+");//？ int words = 0; while (in.hasNext()) { in.next(); words++; } System.out.println("Words: " + words); } // 读取一个网页： URL url = new URL("https://horstmann.com/index.html"); try (BufferedReader reader = new BufferedReader(new InputStreamReader(url.openStream()))) { Stream&lt;String> lineStream = reader.lines();////!!!! BufferedReader TO Stream System.out.println("Average line length: " + lineStream.mapToInt(String::length).average().orElse(0)); } // PrintWriter 向文本写文件： path = Paths.get("hello.txt"); try (PrintWriter out = new PrintWriter(Files.newBufferedWriter(path, StandardCharsets.UTF_8))) { out.println("Hello"); } // Files.write 向文本写文件： content = "World\n"; Files.write(path, content.getBytes(StandardCharsets.UTF_8), StandardOpenOption.APPEND); // 多行写入 String fileName = "file.txt"; Path path = Paths.get("file1.txt"); List&lt;String> list = new ArrayList&lt;>(); try (Stream&lt;String> lines = Files.lines(Paths.get(fileName))) { lines.forEach(list::add); Files.write(path, list, StandardCharsets.UTF_8); } catch (IOException e) { e.printStackTrace(); } // 打印错误栈： StringWriter writer = new StringWriter(); Throwable throwable = new IllegalStateException(); throwable.printStackTrace(new PrintWriter(writer)); String stackTrace = writer.toString(); System.out.println("Stack trace: " + stackTrace); // 输入流保存到文件： Files.copy(inputStream,filepath,StandardCopyOption.REPLACE_EXISTING); // 直接将 url 中的 pdf 保存下来： // 适用于任何二进制文件： URL url = new URL("http://www.cninfo.com.cn/1202417936.PDF"); try (InputStream in = new BufferedInputStream(url.openStream())) { Files.copy(in, Paths.get(url.getFile().substring(1)),StandardCopyOption.REPLACE_EXISTING); } // url.getFile().substring(1) 去掉起始地斜杠符 // copy() 有三种形式 // 还有一种方式用于 jdk7 之前： URL website = new URL("XXX.pdf"); ReadableByteChannel rbc = Channels.newChannel(website.openStream()); FileOutputStream fos = new FileOutputStream(url.getFile().substring(1)); fos.getChannel().transferFrom(rbc, 0, Long.MAX_VALUE); // FileChannel 的抽象方法 abstract long transferFrom(ReadableByteChannel src, long position, long count) } }</content></entry><entry><title>Java AOP example</title><url>https://zhimoe.github.io/post/java-aop-example/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>aop</tag></tags><content type="html"> Java AOP: 找到一个最简单的介绍，不怎么想翻译，直接看原文吧：
A Simple Introduction to AOP
注意，使用注解的方式声明切面时，增加了一个空方法去定义 Pointcut，即：
class Test{ @Pointcut("execution(* org.bk.inventory.service.*.*(..))") public void serviceMethods(){ //这是一个空方法用于声明 Pointcut， //后续的 @Before @Around 方法都关联这个方法 } } 在使用 xml 配置的话，就不需要这个方法了，serviceMethods 方法名是后面配置切点的引用。
如果不想引入 spring 的话，可以直接使用 aspectj 或者 jboss aop。</content></entry><entry><title>Java 并发 1-线程与任务</title><url>https://zhimoe.github.io/post/java-concurrency-1-thread/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>并发</tag></tags><content type="html"> 基本概念 线程：任务执行的环境，可以理解为传送带。注意任务必须在线程上面被执行。
任务：Runnable/Callable 的实现，可以理解为传送带上面的工序。
资源：线程在处理任务具体工序时需要使用的对象，例如信号量，锁，并发集合。需要注意，任务本身描述也是一个对象（即 Runnable/Callable 子类实例），所以在 Runnable 代码里面你会看到 synchronized(this) 的用法，就是把任务描述本身当作一个资源，甚至 Thread 内部也可以将当前 thread 对象当做资源。
任务 多线程编程的核心元素就是任务，任务是独立的活动，不依赖其他任务的状态、结果、以及边界效应。定义任务的内容使用 Runnable 和 Callable。
Runnable 接口表示没有返回的一个过程（procedure），没有受检异常；
Callable 接口的 call 方法会返回一个结果，并有可能抛出受检异常。如果要表示没有返回值，可以使用Callable&lt;Void>，但是不鼓励使用这个代替 Runnable，当一个任务内容没有返回值，只是利用副作用时，应该优先使用 Runable，使得含义清晰，并且 JDK 中ScheduledExecutorService也有只能接收 Runable 的方法。
Future 接口描述了任务的生命周期，并提供方法获得任务执行的结果。该接口有一个实现类：FutureTask.该类的实例一定和一个具体任务相关。ExecutorService所有的 submit 方法都会返回一个 Future 实例。你也可以直接通过 FutureTask 构造函数将 Runnable/Callable 对象构建成一个 FutureTask 实例，该实例将管理该任务的生命周期。
注意，FutureTask 实现了 Runnable 和 Future（通过实现 RunnableFuture 接口），所以既可以使用 ExecutorService，也可以使用 Thread 执行 FutureTask 任务内容。
// FutureTask 接口关系 interface RunnableFuture&lt;V> extends Runnable, Future&lt;V> public class FutureTask&lt;V> implements RunnableFuture&lt;V> 线程 Thread 创建一个线程的方法是 new Thread()，但是向线程提交任务的方式有两种：一是直接继承 Thread 将任务编码在自定义 Thread 的 run 方法里面；二是将 Runnable 实例传递给 Thread 构造函数，区别只不过是否将任务绑定在线程实例上而已，第二种方式更灵活实现了线程与任务的解耦，权责分明。
启动线程使用 t.start()，注意，如果是调用 t.run() 是在当前线程中执行任务，不是新线程。
线程的生命周期
详细说明参考Java 并发编程
Thread.join 方法 当调用 t.join 时，调用线程（calling thread）会暂停，一直到线程 t 终止或者抛出一个 InterruptedException。
The join() method may also return if the referenced thread was interrupted. In this case, the join method throws an InterruptedException. ExecutorService 执行器框架，root 接口是 Executor，只有一个 execute 方法执行 runnable 实例。更常用是子接口 ExecutorService，除了可以执行 runnable,callable，还可以 invoke 一个 callable 集合：
&lt;!-- ExecutorService methods --> &lt;T> List&lt;Future&lt;T>> invokeAll(Collection&lt;? extends Callable&lt;T>> tasks) &lt;T> T invokeAny(Collection&lt;? extends Callable&lt;T>> tasks) &lt;T> Future&lt;T> submit(Callable&lt;T> task) Future&lt;?> submit(Runnable task) ScheduledExecutorService The ScheduledExecutorService interface supplements the methods of its parent ExecutorService with schedule, which
executes a Runnable or Callable task after a specified delay. In addition, the interface defines scheduleAtFixedRate and
scheduleWithFixedDelay, which executes specified tasks repeatedly, at defined intervals.
scheduleAtFixedRate: 第一次是 initialDelay 后执行，第二次是 initialDelay + 1 * period 后执行，类推。
scheduleWithFixedDelay: 是前面任务执行结束后开始计算间隔计时。
两个方法都不会并发执行任务，特别是第一个方法，如果任务时间比参数中等待时间 period 长，那么只会延期执行。对于第二个方法，本来就是要等前面结束才执行，所以没有这个问题。两个方法遇到异常，那么后面任务也不会执行，因为任务是重复的，后面也会遇到异常。周期任务可以取消，或者遇到执行器终结才结束。
线程池如何实现复用的 其实非常简单 就是 Thread Worker 的 runWorker() 方法中有一个 while 循环不停获取 task 并调用 task.run 方法。后面单开一篇详细介绍。
CompletionService 如果有多个任务，那么 ExecutorService 只能不停的轮询 Future 看是否有任务结束，并取得结果.CompletionService 则是另外是自动的告诉你那些任务结果已经准备好。注意构造方法需要一个 ExecutorService
# 辅助理解 ExecutorService = incoming queue + worker threads CompletionService = incoming queue + worker threads + output queue CompletionService 参考
ExecutorService executor = Executors.newFixedThreadPool(numberOfThreadsInThePool); CompletionService&lt;String> completionService = new ExecutorCompletionService&lt;String>(executor); for (final String num: nums) { completionService.submit(new Task(num)); //Task is Callable } try { for (int t = 0, n = nums.size(); t &lt; n; t++) { Future&lt;String> f = completionService.take(); System.out.print(f.get()); } } catch (InterruptedException e) { Thread.currentThread().interrupt(); } catch (ExecutionException e) { Thread.currentThread().interrupt(); } finally { if (executor != null) { executor.shutdownNow(); } } 参考书籍： Doug Lea “Concurrent Programming in Java” 2004
Brian Goetz “java concurrency in practice” 2007
Venkat “Programming concurrency on the JVM”</content></entry><entry><title>Java 并发 2-同步与锁</title><url>https://zhimoe.github.io/post/java-concurrency-2-control/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>并发</tag></tags><content type="html"> Object.wait/notify/notifyAll 这三个方法是在 class Object 上面的，也就是所有对象都有这个方法。这里对象就是上一篇中类比的资源，可以当成一个信号量。
Object.wait() to suspend a thread（等价于sem.wait()）。将当前线程暂停并释放当前对象锁，直到其他线程调用了当前对象的 notify/notifyAll 方法。
Object.notify() to wake a thread up（等价sem.signal()）。唤醒一个在等待当前对象锁的线程。
以前用 wait/notify 的地方，现在可以用 CyclicBarrier 和 CountDownLatch 同步工具代替
wait 方法使用模板：
synchronized (obj) { while (condition does not hold){ // 这里即使线程被虚假唤醒，条件还是不满足，则继续 wait obj.wait(); } //... Perform action appropriate to condition } 为什么 wait 方法必须在 synchronized 保护的同步代码中使用？因为需要保证 while 判断和 wait 两个操作是一个原子操作。
两个线程交替打印 A/B
public static void main(String[] args) { PrintTask pt = new PrintTask("A"); new Thread(pt::print).start(); new Thread(pt::print).start(); } static class PrintTask { private String currentChar; PrintTask(String initialChar) { this.currentChar = initialChar; } public void print() { synchronized (this) { while (true) { System.out.println(Thread.currentThread().getId() +" "+currentChar); if ("A".equals(currentChar)) { currentChar = "B"; } else { currentChar = "A"; } try { this.notifyAll(); this.wait(); } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } synchronized 和 volatile volatile 比较简单，可以理解为将一个变量强制同步给所有线程可见，但是不能解决并发写的问题。
java 的每个对象都有内在锁（或者叫监视器锁，intrinsic lock or monitor lock），涉及两个 JVM 指令：monitorenter、monitorexit。
synchronized method 和 synchronized block 的区别：
如果是 synchronized(this),那么和 synchronized 方法没有任何区别，锁定对象都是方法所在的对象。
但是 synchronized block 可以锁定其他对象，而且 synchronized block 的范围是可以控制更灵活，synchronized 方法的边界只能是整个方法
使用 ReentrantLock 场景：
需要以下高级特性时：可定时的，可轮询的，可中断的锁，公平队列，非块结构。
Synchronization vs Lock-stackoverflow
Semaphore 可以理解为资源的许可证数量。
sem.acquire(2): 获取两个许可证。
sem.release() 释放资源的一个许可证。
信号量非常有用，也是基础，基于信号量，可以构建出很多其他的同步工具：turnstile 和 rendezvous，barrier，mutex，Multiplex
CountDownLatch CountDownLatch 是管理一组线程和一个主线程的先后。主线程 wait 后就阻塞，直到所有的 CountDownLatch 调用 countDown 后主线程接着开始。
package zhimoe.intrview.concurrent; import java.util.concurrent.CountDownLatch; import java.util.concurrent.TimeUnit; public class CountDownLatchTest { // 这个方法将启动多个任务，并让它们同时执行，计算完成的时间 public long timer(int taskNums) throws InterruptedException { CountDownLatch startLatch = new CountDownLatch(1); CountDownLatch finishLatch = new CountDownLatch(taskNums); for (int i = 0; i &lt; taskNums; i++) { Task task = new Task(startLatch, finishLatch, i); new Thread(task).start(); } long start = System.nanoTime(); startLatch.countDown();// 准备好线程后开始同时启动所有任务 finishLatch.await();// 等待任务完成 long end = System.nanoTime(); return end - start; } public static void main(String[] args) throws InterruptedException { CountDownLatchTest ct = new CountDownLatchTest(); long time = ct.timer(100); System.out.println( TimeUnit.NANOSECONDS.toSeconds(time) + " SENCODS"); } } class Task implements Runnable { CountDownLatch startLatch; CountDownLatch finishLatch; int time; Task(CountDownLatch startLatch, CountDownLatch finishLatch, int time) { this.startLatch = startLatch; this.finishLatch = finishLatch; this.time = time; } @Override public void run() { try { startLatch.await();// 等待主线程通知任务开始 System.out.println("doing the task!"); Thread.sleep(time * 100); // 模拟任务过程 } catch (InterruptedException e1) { // TODO Auto-generated catch block e1.printStackTrace(); } finally { System.out.println("task done"); finishLatch.countDown();// 告诉主线程任务完成 } } } CyclicBarrier TBD
Exchanger TBD
Lock TBD</content></entry><entry><title>Java 并发 3-ThreadLocal</title><url>https://zhimoe.github.io/post/java-concurrency-3-threadlocal/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>并发</tag></tags><content type="html"> 在通常的业务开发中，ThreadLocal 有两种典型的使用场景。
场景 1，ThreadLocal 用作保存每个线程独享的对象，为每个线程都创建一个副本，这样每个线程都可以修改自己所拥有的副本，而不会影响其他线程的副本，确保了线程安全。
场景 2，ThreadLocal 用作每个线程内需要独立保存信息，以便供其他方法更方便地获取该信息的场景。每个线程获取到的信息可能都是不一样的，前面执行的方法保存了信息后，后续方法可以通过 ThreadLocal 直接获取到，避免了传参，类似于全局变量的概念。
场景 1：保存线程不安全的工具类 注意：实际开发中使用 DateTimeFormatter 代替 SimpleDateFormat.
import java.text.SimpleDateFormat; import java.util.Random; public class ThreadLocalExample implements Runnable{ // SimpleDateFormat is not thread-safe, so give one to each thread private static final ThreadLocal&lt;SimpleDateFormat> formatter = ThreadLocal.withInitial(() -> new SimpleDateFormat("yyyyMMdd HHmm")); public static void main(String[] args) throws InterruptedException { ThreadLocalExample obj = new ThreadLocalExample(); for(int i=0 ; i&lt;10; i++){ Thread t = new Thread(obj, ""+i); Thread.sleep(new Random().nextInt(1000)); t.start(); } } @Override public void run() { System.out.println("Thread Name= "+Thread.currentThread().getName()+" default Formatter = "+formatter.get().toPattern()); try { Thread.sleep(new Random().nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } //formatter pattern is changed here by thread, but it won't reflect to other threads formatter.set(new SimpleDateFormat()); System.out.println("Thread Name= "+Thread.currentThread().getName()+" formatter = "+formatter.get().toPattern()); } } 场景 2：不同线程保存独立信息 例如需要记录 mysql 的 SQL 执行耗时以及其他相关信息
public class MysqlQueryInterceptor implements com.mysql.cj.interceptors.QueryInterceptor { private final ThreadLocal&lt;LocalDateTime> startTimeHolder = new ThreadLocal&lt;>(); @Override public &lt;T extends Resultset> T preProcess(Supplier&lt;String> supplier, Query query) { startTimeHolder.set(LocalDateTime.now()); return null; } } 上面的 ThreadLocal 也可以使用 slf4j 的 MDC(Mapped Diagnostic Context)。</content></entry><entry><title>Java 动态代理</title><url>https://zhimoe.github.io/post/java%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 好文 Java 动态代理机制分析及扩展
更深入的一篇：
java 设计模式 - 动态代理模式
优势 相比 静态代理，动态代理具有更强的 灵活性，因为它不用在我们设计实现的时候就指定 某一个代理类来代理哪一个被代理对象，我们可以把这种指定延迟到程序运行时由 JVM 来实现。
实例 动态代理类接口，接口规范方法。
package angus.interview.proxy; public interface Subject { public void request(); } 需要被代理的真实的类：
package angus.interview.proxy; public class SubjectImpl implements Subject { @Override public void request() { System.out.println(" subject request"); } } 先创建一个代理类。然后利用反射创建一个用真实类加载器创建的一个对象。该对象调用 request 方法实际上调用的是代理类的 invoke 方法。
package angus.interview.proxy; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class DynamicProxy implements InvocationHandler { private Object target; public Object bind(Object target) { this.target = target; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); // 要绑定接口 this(这是一个缺陷，cglib 弥补了这一缺陷) } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println("------------------before------------------"); Object result = method.invoke(target, args); System.out.println("-------------------after------------------"); return result; } } static void main(){ DynamicProxy proxy = new DynamicProxy(); Subject subject= proxy.bind(SubjectImpl); subject.request(); } 和静态代理模式比较的好处
在静态代理模式时，一个真实角色必须对应一个代理角色，如果大量使用会导致类的急剧膨胀;而动态代理则不会有这个问题，我们将接口中的方法委托给 invoke 方法，并在 invoke 中实现拦截。
源码分析 参考:http://rejoy.iteye.com/blog/1627405 主要原来：生成了一个代理类的 class 文件。Proxy.newProInstance() 方法
public static Object newProxyInstance(ClassLoader loader,Class&lt;?>[] interfaces,InvocationHandler h) throws IllegalArgumentException { if (h == null) { throw new NullPointerException(); } final Class&lt;?>[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) { checkProxyAccess(Reflection.getCallerClass(), loader, intfs); } // 这里是生成 class 的地方 Class&lt;?> cl = getProxyClass0(loader, intfs); // 使用我们实现的 InvocationHandler 作为参数调用构造方法来获得代理类的实例 try { final Constructor&lt;?> cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; if (sm != null &amp;&amp; ProxyAccessHelper.needsNewInstanceCheck(cl)) { return AccessController.doPrivileged(new PrivilegedAction&lt;Object>() { public Object run() { return newInstance(cons, ih); } }); } else { return newInstance(cons, ih); } } catch (NoSuchMethodException e) { throw new InternalError(e.toString()); } } 其中 newInstance 只是调用 Constructor.newInstance 来构造相应的代理类实例，这里重点是看 getProxyClass0 这个方法的实现：
private static Class&lt;?> getProxyClass0(ClassLoader loader, Class&lt;?>... interfaces) { // 代理的接口数量不能超过 65535，这是 class 文件格式决定的 if (interfaces.length > 65535) { throw new IllegalArgumentException("interface limit exceeded"); } // JDK 对代理进行了缓存，如果已经存在相应的代理类，则直接返回，否则才会通过 ProxyClassFactory 来创建代理 return proxyClassCache.get(loader, interfaces); } 其中代理缓存是使用 WeakCache 实现的，如下
private static final WeakCache&lt;ClassLoader, Class&lt;?>[], Class&lt;?>> proxyClassCache = new WeakCache&lt;>(new KeyFactory(), new ProxyClassFactory()); 具体的缓存逻辑这里暂不关心，只需要关心 ProxyClassFactory 是如何生成代理类的，ProxyClassFactory 是 Proxy 的一个静态内部类，实现了 WeakCache 的内部接口 BiFunction 的 apply 方法：
private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?>[], Class&lt;?>> { // 所有代理类名字的前缀 private static final String proxyClassNamePrefix = "$Proxy"; // 用于生成代理类名字的计数器 private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?> apply(ClassLoader loader, Class&lt;?>[] interfaces) { // 省略验证代理接口的代码…… String proxyPkg = null; // 生成的代理类的包名 // 对于非公共接口，代理类的包名与接口的相同 for (Class&lt;?> intf : interfaces) { int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) { String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? "" : name.substring(0, n + 1)); if (proxyPkg == null) { proxyPkg = pkg; } else if (!pkg.equals(proxyPkg)) { throw new IllegalArgumentException( "non-public interfaces from different packages"); } } } // 对于公共接口的包名，默认为 com.sun.proxy[源码](http://hg.openjdk.java.net/jdk6/jdk6/jdk/rev/695dd7ceb9e3) if (proxyPkg == null) { proxyPkg = ReflectUtil.PROXY_PACKAGE + "."; } // 获取计数 long num = nextUniqueNumber.getAndIncrement(); // 默认情况下，代理类的完全限定名为:com.sun.proxy.$Proxy0,com.sun.proxy.$Proxy1……依次递增 String proxyName = proxyPkg + proxyClassNamePrefix + num; // 这里才是真正的生成代理类的字节码的地方 byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces); try { // 根据二进制字节码返回相应的 Class 实例 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); } catch (ClassFormatError e) { throw new IllegalArgumentException(e.toString()); } } } ProxyGenerator 是 sun.misc 包中的类，它没有开源，但是可以反编译来一探究竟：
public static byte[] generateProxyClass(final String var0, Class[] var1) { ProxyGenerator var2 = new ProxyGenerator(var0, var1); final byte[] var3 = var2.generateClassFile(); // 这里根据参数配置，决定是否把生成的字节码（.class 文件）保存到本地磁盘， //我们可以通过把相应的 class 文件保存到本地，再反编译来看看具体的实现，这样更直观 if(saveGeneratedFiles) { AccessController.doPrivileged(new PrivilegedAction() { public Void run() { try { FileOutputStream var1 = new FileOutputStream(ProxyGenerator.dotToSlash(var0) + ".class"); var1.write(var3); var1.close(); return null; } catch (IOException var2) { throw new InternalError("I/O exception saving generated file: " + var2); } } }); } return var3; } saveGeneratedFiles 这个属性的值从哪里来呢：
private static final boolean saveGeneratedFiles = ((Boolean)AccessController.doPrivileged( new GetBooleanAction("sun.misc.ProxyGenerator.saveGeneratedFiles"))).booleanValue(); GetBooleanAction 实际上是调用 Boolean.getBoolean(propName) 来获得的，而 Boolean.getBoolean(propName) 调用了 System.getProperty(name),所以我们可以设置 sun.misc.ProxyGenerator.saveGeneratedFiles 这个系统属性为 true 来把生成的 class 保存到本地文件来查看。
反编译 class 文件
自己创建文件写入生成的动态代理类：
package angus.interview.proxy; import java.io.FileOutputStream; import java.io.IOException; import sun.misc.ProxyGenerator; @SuppressWarnings("restriction") public class ProxyGeneratorUtils { public static void writeProxyClassToHardDisk(String path) { // 获取代理类的字节码 byte[] classFile = ProxyGenerator.generateProxyClass("$Proxy11", SubjectImpl.class.getInterfaces()); FileOutputStream out = null; try { out = new FileOutputStream(path); out.write(classFile); out.flush(); } catch (Exception e) { e.printStackTrace(); } finally { try { out.close(); } catch (IOException e) { e.printStackTrace(); } } } } 测试我们的工具类：
package angus.interview.proxy; public class TestProxy { public static void main(String[] args) { System.getProperties().put("sun.misc.ProxyGenerator.saveGeneratedFiles", "true"); DynamicProxy proxy = new DynamicProxy(); Subject sproxy = (Subject) proxy.bind(new SubjectImpl()); sproxy.request(); ProxyGeneratorUtils.writeProxyClassToHardDisk("$Proxy11.class"); } } 刷新目录，得到一个$Proxy11.class，反编译使用 Java Decompiler,GUI 傻瓜式，支持最新语法，编译慢，效果好：
可以看到 $Proxy11 继承 Proxy，并实现了 Subject，同时我们写的那个 InvocationHandler 的子类 DynamicProxy 也被传递进去了。
重点看 request 方法的代码，只有一行 this.h.invoke(this, m3, null);其中 h 的引用就是DynamicProxy.
m3 就是 m3 = Class.forName("angus.interview.proxy.Subject").getMethod("request", new Class[0]);
import angus.interview.proxy.Subject; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; public final class $Proxy11 extends Proxy implements Subject { private static Method m1; private static Method m2; private static Method m3; private static Method m0; public $Proxy11(InvocationHandler paramInvocationHandler) { super(paramInvocationHandler); } public final boolean equals(Object paramObject) { try { return ((Boolean)this.h.invoke(this, m1, new Object[] { paramObject })).booleanValue(); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } public final String toString() { try { return (String)this.h.invoke(this, m2, null); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } public final void request() { try { this.h.invoke(this, m3, null); return; } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } public final int hashCode() { try { return ((Integer)this.h.invoke(this, m0, null)).intValue(); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } static { try { m1 = Class.forName("java.lang.Object").getMethod("equals", new Class[] { Class.forName("java.lang.Object") }); m2 = Class.forName("java.lang.Object").getMethod("toString", new Class[0]); m3 = Class.forName("angus.interview.proxy.Subject").getMethod("request", new Class[0]); m0 = Class.forName("java.lang.Object").getMethod("hashCode", new Class[0]); return; } catch (NoSuchMethodException localNoSuchMethodException) { throw new NoSuchMethodError(localNoSuchMethodException.getMessage()); } catch (ClassNotFoundException localClassNotFoundException) { throw new NoClassDefFoundError(localClassNotFoundException.getMessage()); } } }</content></entry><entry><title>Java 注解和注解处理器</title><url>https://zhimoe.github.io/post/java-annotation-processing/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 注解处理 注解是 jdk1.5 出现的，但是自定义处理注解的功能是 1.6 才有的。Element 等关于注解源码抽象的支持类都是 1.6 出现的。
基本知识 annotation processing integrated into javac compiler since Java 6.0, known as pluggable annotation processing. compiler automatically searches for annotation processors unless disabled with -proc:none option for javac. processors can be specified explicitly with -processor option for javac or -cp processor.jar, processor.jar must include the /META-INF/service/javax.annotation.processing.Processor file and your processor decalared in file;
implement a processor class:
– must implement Processor interface
– typically derived from AbstractProcessor
– new package javax.annotation.processing
同时自定义注解处理器需要指定注解选项：
– by means of annotations: @SupportedAnnotationTypes @SupportedOptions @SupportedSourceVersion 编译器编译源码是会有很多轮 (round)：
第一轮编译器得到所有的注解 - 获取所有的注解处理器 - 进行 match 并 process，如果匹配的处理器中 process 方法的返回值是true，表示该注解被 claim，不再查询其他处理器。如果是false，接着查询匹配处理器处理，所以注解处理器在 META-INF/services/javax.annotation.processing.Processor 声明顺序是有关系的&ndash; 所有的注解都被 claim 后，注解处理完成。
如果注解处理器产生新的 java 文件，那么新的一轮处理开始，前面被调用的那些处理器又被调用，直到没有 java 文件产生。
最后一轮又要调用一遍所有处理器，完成他们的各自工作。
最最后，编译器编译源码和注解处理器生成的源码。
还有一个很重要的类 AbstractProcessor：有一个引用 processingEnv 提供了两个重要工具类：
– Filer for creation of new source, class, or auxiliary files
– Messager to report errors, warnings, and other notices
此外，一个生成 java 文件的重要方法：
FileObject sourceFile = processingEnv.getFiler().createSourceFile(beanClassName); // process() method takes 2 arguments: Set&lt;? extends TypeElement> annotations – the annotation types requested to be processed – subset of the supported annotations RoundEnvironment roundenv – environment for information about the current and prior round – supplies elements annotated with a given annotation or all root elements in the source 一个自定义的注解处理器格式如下：
@SupportedAnnotationTypes({"Property"}) @SupportedSourceVersion(SourceVersion.RELEASE_6) public class PropertyAnnotationProcessor extends AbstractProcessor { public boolean process( Set&lt;? extends TypeElement> annotations, RoundEnvironment env) { // process the source file elements using the mirror API } } jdk1.6 对注解的处理支持建立在对源码的抽象，Element 是javax.lang.model.*中定义的，各种 Element 是对源码抽象数据结构，如：
package com.example; // PackageElement public class Foo { // TypeElement private int a; // VariableElement private Foo other; // VariableElement public Foo () {} // ExecuteableElement } TypeElement 不能提供父类的信息，如果需要这些信息，需要从 Element 中得到 TypeMirror.TypeMirror::element.asType()
实战 动手写注解处理器：定义一个注解@Comparator，使用在方法上。通过一个注解处理器，解析所有被注释的方法，为每一个方法产生一个 Comparator 类。
一共三个类，注解定义，注解使用，注解处理器。
给出注解定义前看看注解怎么使用：
package moe.zhi; public class Name { private final String first; private final String last; public Name(String f, String l) { first = f; last = l; } @Comparator("NameByFirstNameComparator") public int compareToByFirstName(Name other) { if (this == other) return 0; int result; if ((result = this.first.compareTo(other.first)) != 0) return result; return this.last.compareTo(other.last); } } 其中被注解注释的方法将产生一个 NameByFirstNameComparator.java 文件：
package moe.zhi; public class NameByFirstNameComparator implements java.util.Comparator&lt;Name> { public int compare(Name o1, Name o2) { return o1.compareToByFirstName(o2); } public boolean equals(Object other) { return this.getClass() == other.getClass(); } } 定义注解：
package moe.zhi; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Documented @Target(ElementType.METHOD) @Retention(RetentionPolicy.SOURCE) public @interface Comparator { String value(); } 接下来定义注解处理器，有详细注解，特别注意 generate 源码中的空格和分号不要弄丢了：
package moe.zhi; import java.io.IOException; import java.io.PrintWriter; import java.util.Set; import javax.annotation.processing.AbstractProcessor; import javax.annotation.processing.RoundEnvironment; import javax.annotation.processing.SupportedAnnotationTypes; import javax.annotation.processing.SupportedSourceVersion; import javax.lang.model.SourceVersion; import javax.lang.model.element.Element; import javax.lang.model.element.ExecutableElement; import javax.lang.model.element.TypeElement; import javax.lang.model.type.PrimitiveType; import javax.lang.model.type.TypeKind; import javax.lang.model.type.TypeMirror; import javax.tools.Diagnostic; import javax.tools.FileObject; import static java.lang.StringTemplate.STR; @SupportedAnnotationTypes({"moe.zhi.Comparator"}) @SupportedSourceVersion(SourceVersion.RELEASE_8) public class MyProcessor extends AbstractProcessor { @Override public boolean process(Set&lt;? extends TypeElement> annotations, RoundEnvironment roundEnv) { for (final Element element : roundEnv.getElementsAnnotatedWith(Comparator.class)) { if (element instanceof ExecutableElement m) { TypeElement className = (TypeElement) m.getEnclosingElement(); Comparator annotation = m.getAnnotation(Comparator.class); if (annotation == null) { continue; } TypeMirror returnType = m.getReturnType(); if (!(returnType instanceof PrimitiveType) || returnType.getKind() != TypeKind.INT) { processingEnv.getMessager().printMessage(Diagnostic.Kind.ERROR, "@Comparator can only be applied to methods that return int"); continue; } // prepare for java file generation String theProcessedClassesName = className.getQualifiedName().toString(); String comparatorClassName = annotation.value(); String compareToMethodName = m.getSimpleName().toString(); try { writeComparatorFile(theProcessedClassesName, comparatorClassName, compareToMethodName); } catch (IOException e) { e.printStackTrace(); } } } // end for return true; // claimed now,no need next processor } // be careful with spaces and ";" in content private void writeComparatorFile(String fullClassName, String comparatorClassName, String compareToMethodName) throws IOException { int lastIndexOfDot = fullClassName.lastIndexOf("."); String packageName = fullClassName.substring(0, lastIndexOfDot); FileObject sourceFile = processingEnv.getFiler().createSourceFile(packageName + "." + comparatorClassName); if (sourceFile == null) { System.out.println("create source file failed"); throw new IOException("create source file failed:" + packageName + "." + comparatorClassName); } PrintWriter out = new PrintWriter(sourceFile.openWriter()); String parametrizedType = fullClassName.substring(lastIndexOfDot + 1); //!! careful the index var packageLine = ""; if (lastIndexOfDot > 0) { packageLine = STR."package \{ packageName };" ; } // 下面使用了 Java 21 的 STR 模板 var content = STR.""" \{ packageLine } public class \{ comparatorClassName } implements java.util.Comparator&lt;\{ parametrizedType }> { public int compare( \{ parametrizedType } o1, \{ parametrizedType } o2 ){ return o1.\{ compareToMethodName }(o2); } public boolean equals(Object other) { return this.getClass() == other.getClass(); } } """ ; out.println(content); out.close(); } } 测试处理器 代码生成工具 方法 1：使用 javapoet
MethodSpec main = MethodSpec.methodBuilder("main") .addModifiers(Modifier.PUBLIC, Modifier.STATIC) .returns(void.class) .addParameter(String[].class, "args") .addStatement("$T.out.println($S)", System.class, "Hello, JavaPoet!") .build(); TypeSpec helloWorld = TypeSpec.classBuilder("HelloWorld") .addModifiers(Modifier.PUBLIC, Modifier.FINAL) .addMethod(main) .build(); JavaFile javaFile = JavaFile.builder("com.example.helloworld", helloWorld) .build(); javaFile.writeTo(System.out); 方法 2：使用 STR
参考上面的例子
参考 java 注解</content></entry><entry><title>Java-==-and-equals</title><url>https://zhimoe.github.io/post/java--and-equal/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> samples code and notes on java == and equals
/** * samples for == and equal() * @author zhimoe * */ class TestObj { // the class for test == and equal() } public class EqualAndCompare { public static void main(String[] args) { TestObj obj1 = new TestObj(); TestObj obj2 = new TestObj(); TestObj obj3 = obj1; System.out.println(obj1 == obj2);// false , // == Compares references, not values System.out.println(obj1 == obj3);// true System.out.println(obj1.equals(obj2));// false, // equal() method is derived from java.lang.Object, if not override,nor // in superclass,then equal behave as same as == // Always remember to override hashCode if you override equals so as not // to "break the contract". // As per the API, the result returned from the hashCode() method for // two objects must be the same if their equals methods shows that they // are equivalent. The converse is not necessarily true. String s1 = "haha";// constant pool String s2 = new String("haha");// defined in ?heap System.out.println(s1 == s2);// false ,== Compares references, not // values, there is a exception for // static field in class, static String // in class == and equal both always // return *true* // for more infomation,see : // http://stackoverflow.com/questions/7520432/what-is-the-difference-between-vs-equals-in-java System.out.println(s1.equals(s2)); // true compare the // value String s3 = s2.intern();// find the same value String in constant pool System.out.println(s1 == s3);// true int i1 = 2;// primitive type has no equal() method Integer i3 = Integer.valueOf(2); System.out.println(i1 == i3);// true, i3 automatic unboxing into int; System.out.println(i3.equals(i1));// auto boxing into Integer Integer i2 = 2; System.out.println(i3.compareTo(i2)); } /* * Comparable interface, a.compareTo(b) return -1：less,0:equal,1:greater. 0 * should always be returned for objects when the .equals() comparisons * return true. All Java classes that have a natural ordering implement this * (String, Double, BigInteger, ...). * * * Comparator interface: is a util for compare two instance,then you can use * the comparator to sort array and other things * */ }</content></entry><entry><title>单例模式和序列化</title><url>https://zhimoe.github.io/post/java%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%92%8C%E5%BA%8F%E5%88%97%E5%8C%96/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> Java 单例模式的各种写法和序列化
参考资料
饱汉式 public class Singleton { private static Singleton instance = null private Singleton (){} public static Singleton getInstance() { if(instance == null) instance = new Singleton(); return instance; } } //饱汉式，使用时创建 饿汉式 //加载时创建对象 static public class Singleton { private Singleton instance = null; static { instance = new Singleton(); } private Singleton (){} public static Singleton getInstance() { return this.instance; } } 静态内部类 public class Singleton { private Singleton (){} private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } } //这个比较好,线程安全,也达到了延迟加载效果. 枚举类 //这个是最好的 这种方式是Effective Java作者Josh Bloch 提倡的方式,它不仅能避免多线程同步问题,而且还能防止反序列化重新创建新的对象,可谓是很坚强的壁垒啊 public enum Singleton { INSTANCE; public void whateverMethod() { } } 访问这个单例 Singleton.INSTANCE 双重校验锁 其实是不安全的，多线程开销很大，甚至死锁。原因在于指令重排序。
public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 序列化 使用静态内部类举例，只要提供一个 readResolve 方法
public class Singleton { private Singleton (){} private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } private Object readResolve() throws ObjectStreamException{ return SingletonHolder.INSTANCE; } } 无论是实现 Serializable 接口，或是 Externalizable 接口，当从 I/O 流中读取对象时，readResolve() 方法都会被调用到。实际上就是用 readResolve() 中返回的对象直接替换在反序列化过程中创建的对象，而被创建的对象则会被垃圾回收掉。</content></entry><entry><title>理解 Gradle build 脚本结构与语法</title><url>https://zhimoe.github.io/post/gradle-buildscript/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>groovy</tag><tag>gradle</tag></tags><content type="html"> 在看这个之前，希望你有用 ant 或者 maven 的使用经验，还有，对 groovy 的语法有一个简单的了解，不懂也没关系，下面会介绍。
理解 gradle 文件的前提是理解一个重要的 groovy 概念 &ndash; closure
closure 一个 closure 是一个定义在 groovy 文件中的{}代码块，这个代码块类似 js 中的匿名函数，它可以被赋值给变量，可以被调用，可以接收参数，还可以作为参数传递给别的函数。
closure 中最重要的两个概念是委托对象和作为参数传递的语法格式（理解 gradle 文件很重要）。
groovy 方法调用括号的省略 groovy 提供非常优雅的方法调用格式，总结起来是：
//可以省略参数括号,并且链式调用 // equivalent to: turn(left).then(right) turn left then right //groovy数字可以直接转换成字符串 // equivalent to: take(2.pills).of(chloroquinine).after(6.hours) take 2.pills of chloroquinine after 6.hours //两个参数用逗号隔开 // equivalent to: paint(wall).with(red, green).and(yellow) paint wall with red, green and yellow //命名参数用冒号 // with named parameters too // equivalent to: check(that: margarita).tastes(good) check that: margarita tastes good //闭包作为参数也可以省略括号 // with closures as parameters // equivalent to: given({}).when({}).then({}) given { } when { } then { } //没有参数的方法必须有括号 // equivalent to: select(all).unique().from(names) select all unique() from names //如果调用链元素为奇数,那么最后一个元素是前面方法链返回对象的属性 //cookies 是take(3)返回值的一个属性 // equivalent to: take(3).cookies // and also this: take(3).getCookies() take 3 cookies 上面调用的格式是 dsl 的基础。也是看懂 gradle 文件格式的基础。
让我们再深入一点，上面讲的是调用格式，那么怎么创建这种可以链式调用的方法呢？
groovy 和 scala 的方法返回值不需要 return，最后一行就是返回值。 closure 是一个匿名函数，格式{ [closureParameters -> ] statements },默认自带一个名为 it 的参数，所以只接受一个参数时可以省略->. closure 可以访问 scope（作用域）内任何变量。并且这个 scope 是可以通过委托来改变的。 groovy 中 Map 对象的 value 如果是 closure，那么可以接着调用：m .k { arg_expressiong } 有了上面的基础，我们看一个复杂点的例子：
//将closure赋值给一个变量,这个closure接收一个参数,参数名是默认的 it show = { println it } square_root = { Math.sqrt(it) } //为了容易理解,我将参数的type都添加上了, //please方法需要一个closure,接着返回一个map,map的key是the,value是一个closure, //这个closure接收一个closure,并返回一个map, //这个map的keyu是of,value又是一个closure(不要晕了) //最后一个closure接收一个参数n def please(Closure action) { [the: { Closure what -> [of: { n -> action(what(n)) }] }] } //调用: please show the square_root of 100 // 上面等价 please(show).the(square_root).of(100) // 或 please { println it } .the { Math.sqrt(it) } .of 100 总结一下就是，将你需要的操作封装成一个 closure，给一个直观的命名，保证整个 DSL 调用语句有语义，定义返回一个 map 的函数作为入口，map 的 key 是方法名，value 是 closure，这样可以在 key 后面传递一个 closure 接着调用这个 value.
委托对象 gradle 脚本是一个配置脚本，类似 maven 中 pom.xml 文件，不过 gradle 脚本更为强大，因为.gradle 文件就是 groovy 文件，所以还可以在脚本里面直接定义 groovy 对象让脚本使用。
委托对象就是一个 groovy 对象，用来执行 gradle 构建脚本中的 closure.
as a build script executes, it configures an object of type Project. This object is called the delegate object of the script. The following table shows the delegate for each type of Gradle script. 三种不同的gradle脚本对应的委托对象 Build script（build.gradle） ->Project Init script ->Gradle Settings script(setting.gradle) ->Settings 构建中的每一个 project，Gradle 都会创建一个 Project 对象，并将这个对象与构建脚本相关联。
Project 对象与 build.gradle 是一对一的关系。
Gradle 的脚本是配置脚本，当脚本执行时，它是在配置某一个特殊类型的对象。比如一个构建脚本的执行，它就是在配置一个 Project 类型的对象。这个对象叫做脚本的代理对象。
委托有个重要的概念就是 scope，指 closure 的变量引用范围：有时变量不在当前 scope 中，但是可以通过委托，改变 closure 的委托对象，这样就拥有了委托者的 scope，从而可以在 closure 中使用委托者的变量。
关于 groovy closure 的委托有三个重要属性
• this: refers to the instance of the class that the closure was defined in. • owner: is the same as this, unless the closure was defined inside another closure in which case the owner refers to the outer closure. • delegate: is the same as owner. But, it is the only one that can be programmatically changed, and it is the one that makes Groovy closures really powerful. the closure itself will be checked first, followed by the closure's this scope, then the closure's owner, then its delegate. However, Groovy is so flexible this strategy can be changed. Every closure has a property called resolvedStrategy. This can be set to: • Closure.OWNER_FIRST • Closure.DELEGATE_FIRST • Closure.OWNER_ONLY • Closure.DELEGATE_ONLY 来自 &lt;https://dzone.com/articles/groovy-closures-owner-delegate> gradle 是 dsl 解析工具，是对 groovy 语法的扩展，build.gradle 可以理解为就是一个.groovy 文件，gradle 会解析这个文件，发现里面的 closure，并将这些 closure 委托给一个对象去执行。
gradle 将 groovy 的委托机制发挥到极致，要理解 gradle 内部，就要理解 closure 的委托！
closure 作为参数传递 将 closure 作为参数传递的方法有多种：
//method accepts 1 parameter - closure myMethod(myClosure) //if method accepts only 1 parameter - parentheses can be omitted myMethod myClosure //I can create in-line closure myMethod {println 'Hello World'} //method accepts 2 parameters myMethod(arg1, myClosure) //or the same as '4', but closure is in-line myMethod(arg1, { println 'Hello World' }) //if last parameter is closure - it can be moved out of parentheses myMethod(arg1) { println 'Hello World' } 注意第三种和最后一种调用方式，是不是和 gradle 文件中很眼熟？只不过在 gradle 脚本中出现的 closure 更加复杂，因为有 closure 嵌套！！！但是万变不离其宗。下面我们会介绍嵌套不过是委托链的表现。
看一个脚本代码：
buildscript { repositories { jcenter() } dependencies { classpath 'com.android.tools.build:gradle:1.2.3' } } buildscript 是一个方法，接收一个 closure.至于这个方法在哪，可以定义在任何地方，但是可以肯定的是，这个方法一定能够被 Project 对象调用。
因为 build.gradle 脚本就是委托给 Project 对象执行的。事实上，Project 对象也不是亲自执行这个方法，而是委托给 ScriptHandler 执行。
这里，我们 ScriptHandler 对象会搜索到两个配置 closure:repositories 和 dependencies.我们可以在 ScriptHandler api 中搜索到这两个方法。从 api 中我们又发现：
传递给 dependencies 的 closure 又被委托给了DependencyHandler对象&hellip;&hellip;. 这就是委托链。
ScriptHandler api
Project api
注意:这里 buildscript {&hellip;}整体称为一个 script block. 脚本块就是一个接受 closure 参数的方法调用。还有的方法是不接受 closure 的，那些称为 statement（看下面解释）.
A script block is a method call which takes a closure as a parameter
插件 先看看构建脚本的构成：
A build script is made up of zero or more statements and script blocks. Statements can include method calls, property assignments, and local variable definitions. A script block is a method call which takes a closure as a parameter. The closure is treated as a configuration closure which configures some delegate object as it executes.
就是说脚本有两种内容:script block 和 statement.
Project 接口预先定义了几个 block:
allprojects { } Configures this project and each of its sub-projects. artifacts { } Configures the published artifacts for this project. buildscript { } Configures the build script classpath for this project. configurations { } Configures the dependency configurations for this project. dependencies { } Configures the dependencies for this project. repositories { } Configures the repositories for this project. sourceSets { } Configures the source sets of this project. subprojects { } Configures the sub-projects of this project. publishing { } Configures the PublishingExtension added by the publishing plugin. 这些 closure 参数基本都是委托给其他对象执行的。
可以看到，Project 对象的方法是有限而且通用的。真正有用的是插件，gradle 的很多功能也是通过官方写的插件提供的。
如果你看到一个顶级层的something { ... }block，但是在 Project 源码中没有找到 something block 的任何信息。那么这个方法就是通过插件提供的，gradle 自带很多插件，像 java，eclipse，groovy，android 等。
看一个实际的例子：
在 android 开发中的构建脚本：
apply plugin: 'com.android.application' android { compileSdkVersion 22 buildToolsVersion "22.0.1" defaultConfig { applicationId "com.trickyandroid.testapp" minSdkVersion 16 targetSdkVersion 22 versionCode 1 versionName "1.0" } buildTypes { release { minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' } } } 这里，出现了 android{},Project 对象并没有这个 script block.所以，这其实是由插件提供的 block.我们找到 com.android.application入口代码
extension = project.extensions.create('android', AppExtension, this, (ProjectInternal) project, instantiator, buildTypeContainer, productFlavorContainer, signingConfigContainer) setDefaultConfig(extension.defaultConfig, extension.sourceSetsContainer) extensions 是一个 ExtensionContainer 实例，其中 create API:
&lt;T> T create(String name, Class&lt;T> type, Object... constructionArguments)
这里就创建了一个 android 属性，是一个 AppExtension 对象，我们在脚本中提供给 android block 的{}其实是配置了一个 AppExtension 对象。我们可以在 AppExtension 中找到 compileSdkVersion 等属性。
所以，插件扩展的 Project 对象，提供了很多方法，这样，可以在脚本中使用插件定义的方法（script block）了。
一个插件就是实现实现了 org.gradle.api.Plugin 接口的 groovy 类。
我们看怎么写一个插件：
//build.gradle apply plugin: GreetingPlugin //这里提供closure 来配置插件提供的greeting script block greeting { message = 'Hi' greeter = 'Gradle' } class GreetingPlugin implements Plugin&lt;Project> { void apply(Project project) {//注意我们是如果扩展Project对象的,通过extensions对象创建一个script block:greeting,而这个block关联的是一个对象 project.extensions.create("greeting", GreetingPluginExtension) project.task('hello') &lt;&lt; { //注意我们是如何使用greeting的,没有通过extensioins println "${project.greeting.message} from ${project.greeting.greeter}" } } } class GreetingPluginExtension { String message String greeter } /* project.task('hello') &lt;&lt; { println "${project.greeting.message} from ${project.greeting.greeter}" } 使用了重载操作符,等价: project.task('hello').leftShift({ println "${project.greeting.message} from ${project.greeting.greeter}" }) */ 官方文档：如何自己写一个插件
#####参考：
gradle-tip-2
Gradle 深入与实战（六）Gradle 的背后是什么？
DSL 语法 gradle 使用的基于 groovy 中的 DSL 语法，所谓的 dsl，就是基于 groovy 发明的新的“编程语言”,gradle dsl 是 groovy 的超集，就是你可以完全使用 groovy 的语法，但是你还是会看到很多不是 groovy 语法，这时不要困惑，这些语法不过是 gradle 利用 groovy 提供的元编程能力提供的新语法。
以新建 task 的语法为例，在 Project API 中有四个重载形式：
Task task(String name, Closure configureClosure); Task task(Map&lt;String, ?> args, String name, Closure configureClosure); Task task(Map&lt;String, ?> args, String name) throws InvalidUserDataException; Task task(String name) throws InvalidUserDataException; 但是你会看到这样的调用方式：
task intro(dependsOn: hello) { doLast { println "I'm Gradle" } } 这是 dsl，具体的解析方式在TaskDefinitionScriptTransformer
具体见我在 sf 的提问gradle task method syntax in build.gradle
more tips gradle-tips</content></entry><entry><title>面试题 - 类加载过程和子类重写父类方法的调用</title><url>https://zhimoe.github.io/post/java%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%E5%92%8C%E5%AD%90%E7%B1%BB%E9%87%8D%E5%86%99%E7%88%B6%E7%B1%BB%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/</url><categories><category>编程</category></categories><tags><tag>java</tag><tag>code</tag></tags><content type="html"> 最近非常火的一道携程面试题 Java
public class Base { private String baseName = "base"; public Base() { callName(); } public void callName() { System.out.println(baseName); } static class Sub extends Base { private String baseName = "sub"; public void callName() { System.out.println(baseName); } } public static void main(String[] args) { Base b = new Sub(); // 输出？ } } 我的理解：
先理解两个方法：
class 的 (clinit) 方法和 (init) 方法不同：这两个方法一个是虚拟机在装载一个类初始化的时候调用的（&lt;clinit>）.另一个是在类实例化时调用的（&lt;init>）.
在加载类时需要类的初始化，JVM 对应的字节码方法是&lt;clinit>，这个方法会初始化 static 变量和执行 static{}代码块，按源码定义的顺序执行。注意：如果 static{}代码块中引用了 static 变量，那么一定要使用之前定义 static 变量.ide 会提示的。
这时，class 的其他成员变量和方法都没有被执行。变量的内存都已经分配，值为 null 或者 0（基本类型），false(布尔类型).
当创建一个类的实例时，此时会调用&lt;init>方法，这个方法会初始化非 static 变量和执行{}代码块。注意，这两个也是按源码顺序执行的。所以代码块如果要使用非 static 变量，一定要先定义。同样 ide 一般会提示的。但是要明白这个顺序。
以上说的执行顺序通过 eclipse 调试可以确定是正确的。
所以组合起来 创建一个类的实例对象需要下面的顺序：
父类P static代码块和static变量初始化 -> 子类S static代码块和static变量初始化 -> 父类P 非static代码块和非static变量初始化 -> 父类P构造函数 -> 子类S非static代码块和非static变量初始化 -> 子类S构造函数 回到面试题：我们看看创建一个实例对象的调用栈：
可以看到依次进入 16，8，21 行代码：
16 行： static class Sub extends Base
8 行： callName();//Base()构造函数中
21 行： System.out.println (baseName) ;//Sub的callName()
根据前面的分析，这个类没有 static 代码块和 static 变量，也没有代码块。所以第一个执行的是父类非静态成员的 base=&ldquo;base&rdquo;;接着执行构造函数 Base();这里到了魔法的一步，调用的 callName() 是子类（21 行）的方法。这个行为就是动态单分派.详细资料看最后。由于子类的非 static 变量初始化没有完成，所有子类中的 base 变量是 null.输出也是 null.
！！！所以，不要再构造函数中调用可能会被子类覆盖的方法。
有的面试题会出现陷阱：在调用 callName() 方法改为 this.callName(). 其实都是一样的。在调用 Base 构造函数时没有 Base 的实例对象，调用者其实还是 Base$Sub 这个类。
还有一个进阶版：
public class Basic { public void add(int i) { System.out.println("Basic add"); } public Basic() { add('a'); } public static void main(String[] args) { Basic a = new A(); B b = new B(); } } class A extends Basic { public void add(int i) { System.out.println("A add"); } } class B extends Basic { public void add(char i) { System.out.println("B add"); } } 不仅考察单分派，还有重载的静态多分派。进阶版问题的解释需以下知识点-java 的静态分派和动态单分派。
CSDN-类加载机制 - 深入 java 虚拟机 读书笔记
方法分派
重载是静态多分派，编译时期确定。
覆盖是动态单分派，运行时通过实际类型绑定。
静态多分派：所有依赖静态类型来定位方法执行版本的分派过程就叫做静态分派，静态分派最典型的应用就是方法重载。
动态单分派：根据运行期实际类型确定方法执行版本的分派过程叫做动态分派，动态分派最典型的应用就是方法重写。
同时理解：动态单分派就是多态，java 的面向接口编程的根基就是多态。</content></entry><entry><title>Java 新手如何学习 SpringMVC 框架</title><url>https://zhimoe.github.io/post/how-do-newbie-learn-spring/</url><categories><category>编程</category></categories><tags><tag>code</tag><tag>spring</tag><tag>java</tag></tags><content type="html"> 知乎回答备份，原答案写于 15 年
6,404 人赞同了该回答
4 年之后感觉自己当年写的真好。O(∩_∩)O 哈哈~
评论里面有人写到现在都用 spring boot，个人觉得 boot 只要搞清楚一个 autoconfig 就懂了小半了。
学习框架的同时还是需要针对性地深入学习一些 Java 基础，例如反射，CDI，JDBC，Class 类和 MySQL 以及 http（nginx 的使用）。求精不求多，新手也不要搞什么 mongodb，etcd，zk 这些，有了前面的基础，后面上手使用新东西会很快的。举个例子，很多人学习 mybatis 的使用，但是 JDBC 只会一个 Class.forName+Statement，显然也不知道 mybatis 的好处和底层的。
还是要多写，不要复制，单个项目去掉复制代码还有 5000 行的话，其实就能够理解到课本上的“高内聚，低耦合”是什么意思了。
&mdash;&mdash;&mdash;&mdash;&ndash;原回答&mdash;&mdash;&mdash;&mdash;&ndash;
1 想说说自己 Spring 的学习路程。课余自学 Spring 将近一年了，还是不得其道。起初是去年（14 年）暑假学习了一下 JSP，并没有深入理解，所以导致学习 Spring 时对着书本写一些 demo，感觉自己理解了，其实并不知道内部时什么原理，出了问题不停的百度，一个小问题好几天解决不了。
学习一种框架最先需要知道的是为什么需要使用这个框架，任何一个框架的发明都是为了解决编程中的一些痛点，打开任何一本 hibernate 或者其他框架的入门书，第一章都是介绍框架的理念和优势。如果需要理解这些理念和优势，那么你需要知道不使用这个框架之前是怎么处理的，才能知道框架做了一些什么事情。
针对 Spring 的学习，第一步就是了解没有 spring 和 struts 框架之前的 Java web 是如何开发的。你会知道那时候使用 JSP 和 Servlet，然后你就知道，Servlet 是一个规范，那在 Spring 里面，Servlet 去哪了？这时候你知道了 DispatchServlet。然后你会了解到 IoC 和 AOP。
很多新的技术只不过是引入了新的编程元素对原来技术进行了封装。
2 其实 Java Web 开发，spring 不是第一步，首先需要理解的是 HTTP 协议。chrome 的 DevTools 和 curl、postman 要有基本使用。
还要知道服务器发送给浏览器的响应是没有没有 JS、CSS 和图片等外部资源的，浏览器在解析响应时才会再次请求这些资源，这里会出现一些静态资源请求不到的问题，SpringMVC 是怎么配置的？还有 chrome 并发请求数量限制，如何合并雪碧图提高网页加载速度等知识点，属于 http 知识了。
接下来，学习 Servlet 和 JSP。这个步骤不是可以跳过的，现在流行的框架 Spring MVC 和 Struts2 其实都是基于 Servlet 的，只有深入理解了 Servlet 才能理解后面的新技术。
下面几个知识点可以检测你是否理解了 Servlet：
1、什么是 ServletContext，和 tomcat 等 web 容器的关系时什么？Servlet 工作原理解析
简单的说，我们在浏览器点击链接和按钮产生的消息不是发送给 Servlet 的，而是发送给 web 容器的 (在 JSP 出现之前，web 容器也叫 Servlet 容器)。web 容器接收消息后不知道怎么处理，转交给我们编写的 Servlet 处理，那么 web 容器怎么和 Servlet 交流呢？于是就出现了 Servlet 接口，接口是定义一种规范的良好表达形式。只要我们编写的 Java 类符合 Servlet 规范，那么就能被 Web 容器识别并被容器管理。
2、什么是 Session？Session 在实际工程中的应用场景。以及@SessionAttribute 注解的局限性。
3、JSP 是面向服务器的，它并不知道浏览器是什么鬼，是我们在写 JSP 时预设客户端是浏览器，JSP 就是一个 Servlet，JSP 的常用对象和指令。
4、JSP 的中文编码乱码有几种情况？各自的解决方法？提示：JSP 文件的编码，浏览器的解析编码，GET 请求的编码，POST 的编码。
5、Servlet 是一种接口规范，其中请求和响应是 Servlet 容器通过向方法的参数赋值 HttpServletRequest 或者 HttpServletResponse 传递的。在 Struts1 里面，将 doGet() 方法里的响应移到返回值里。在 Struts2 里则：
在 Controller 中彻底杜绝引入 HttpServletRequest 或者 HttpServletResponse 这样的原生 Servlet 对象。
同时将请求参数和响应数据都从响应方法中剥离到了 Controller 中的属性变量。
这是一个很大的技术改造，也造成了 Struts2 的盛行。Spring MVC 走的是中间路线，Spring 的 2.0.8 之前的版本甚至直接使用 Servlet 的 doGet 的。Spring MVC 现在开始流行主要还是因为 Schema xml 的精简和基于注解的配置。所以这里出现了新的知识点：Schema Based XML 的相关知识和 Java5 引入的注解原理。
书籍：推荐许令波的书《深入分析 Java Web 技术内幕 (修订版)》和计文柯的《深入理解 spring 技术内幕》。特别是第二本，对 spring 的分析很是彻底。</content></entry><entry><title>你的半步，我的天涯</title><url>https://zhimoe.github.io/post/hanamitsuki-movie-review/</url><categories><category>随想</category></categories><tags><tag>qq 空间</tag></tags><content type="html"> 好久没看过爱情电影了，当《山楂树》赚尽眼泪时我没有看，当《那些年》红遍两岸时，我没有看。因为没有选择，看了这部电影。
《HANAMITSUKI》是这个名字，中文名是叫《花水木》。
我努力想记起当中那段让我眼眶湿润的片段，却暂时空白。那些记住的片段永远都是女主角那温情的脸庞和男主人公的眉头紧锁，还有那些飘逸的花瓣，孤独守望的灯塔，蔚蓝的天空和海洋，痛苦的泪水和幸福的泪滴。
片中所涉及到的亲情友情爱情，我是想解释都解释不清的，浓浓的化不开，暖暖的让人突然觉得该反省自己去珍惜自己身边的了吗。或者反思我身边有那么类似的感动吗，应该做个让别人也感到温馨的人吧。感动了，就是部好电影，觉得有趣也是部好电影，收获了理解了，她就值得去被人们知道。
现在看到如此的情节，自己的心就会抽痛，以前极少这样的，也许是比以前又驶过了一些年岁，其实心里很不愿意承认的词就是“小资”“多愁善感”，就是或许有的时候就是一种共鸣，然后是所谓的宣泄。心痛，眼眶湿了，这就是方式与途径。
电影，是二十四格的真实。 故事里的情节不停地让人想到自己。爱情，需要面对的太多。悬殊的生活环境，不同的生活话题，长长的距离，渺茫不清的未来，诺言，在这些面前是多么苍白无力！现实如此现实，如果纯一没有牺牲，故事会是怎样的呢？电影里美好的结局被自己心里的一个假设击的粉碎。一段真爱，用尽十年才走在一起，终究给所有人以希望和鼓励。创作者最大的幸福是可以让电影不像现实那样到处遗憾，观赏者最大的快乐就是用眼睛摸一摸自己的理想－－或是有关爱情的，或是有关事业的。
电影，风景，想所想，思绪无边无际。多想也能远离喧嚣凡俗杂事，暂时沉浸在美好当中。
第二遍快进看了一遍，当平泽回到日本，对着放下手中的活来欢迎她的母亲一笑的那个画面我给截了下来。那是怎样的一种繁华落，始得人生之义。最后的最后，一切还是回到了起点，而我们已经不是那个曾经的人了，历经千辛万苦，我们更加珍惜。
新的一年，我想对屏幕前的你说，在寻找幸福的路上，勇敢地去争取渴望的，更要珍惜拥有的，在这个曲折的人生路上，错过，就和相遇一样的偶然。相信爱，因为，美好的，也是易碎的。
很喜欢孙燕资的“遇见”，不仅因为声音，还为歌词。
听见 冬天的离开 我在某年某月 醒过来 我想 我等 我期待 未来却不能理智安排 阴天 傍晚 车窗外 未来有一个人在等待 向左 向右 向前看 爱要拐几个弯才来 我遇见谁 会有怎样的对白 我等的人 他在多远的未来 我听见风来自地铁和人海 我排着队 拿着爱的号码牌 阴天 傍晚 车窗外 未来有一个人在等待 向左 向右 向前看 爱要拐几个弯才来 我遇见谁 会有怎样的对白 我等的人 他在多远的未来 我听见风来自地铁和人海 我排着队 拿着爱的号码牌 我往前飞 飞过一片时间海 我们也常在爱情里受伤害 我看着路 梦的入口有点窄 我遇见你是最美的意外 终有一天 我的谜底会揭开</content></entry><entry><title>写在 2012 岁末</title><url>https://zhimoe.github.io/post/goodbye-2012/</url><categories><category>随想</category></categories><tags><tag>qq 空间</tag></tags><content type="html"> 时光如水，哗啦啦又是一年； 岁月如歌，唏哩哩唱不成调。 去年光棍节写了点感慨，最后是“这仍然还是最好的年代，却也是最坏的年代。2011 年的冬天，虽然阳光很好，但风还是有些冷，愿与君共勉，但冷暖自知。”
事实是 2012，冬天更冷。
这会儿坐着回想今年一年，发现对上半年的记忆是一片空白。所有的记忆是从暑假回家开始的。事先没有说，出车站时发了一条短信，五分钟后朱来接我，每次放假都是如此。第二天还没起床，徐已经冒雨到车站接我，最后冒雨去他家住了一晚。我这个朋友，一个学期里电话都很少打一个，和他们也没有共同的兴趣爱好，却在一起即使不说话也不觉得尴尬。
在家里的二十几天，妈妈变着花样地做饭菜，我没长胖，她自己却长了几斤。
假期只出去玩了一次，和徐去杨家玩了一天，晚上三个人看奥运会，然后三个横着躺在床上听他们说和女友认识的故事，聊大学生活，快两点才睡着。第二天还是下雨，三个人躺在床上看电视，没有多说一句；下午冒雨去水库玩。
然后就是青岛实习。每天都是白天坐车看军舰看潜艇，晚上吃烧烤和扎啤。
还记得穿着裤衩，趿着拖鞋去看海底世界的心情；为阿光饯行那个晚上喝得放纵；印象最深刻的还是黄岛的风光——沿着海岸公路，看到的是风格各异的别墅，数不清的高尔夫球场，漫山遍野的桃树，蓊郁的树林，怪石嶙峋的大珠山，纯朴的小渔村；还有那腥味的海风…一切都是那么新，那么美。
开学后，平静了。视力急剧下降，以致无法正常看书。写周记的习惯也断了，每每想好了，却又觉得没有必要了。或许做的最有意义的一件事就是锻炼吧，身体结实了很多。
2012，末日没有到来，明天还在蔓延，温暖感动很多，不顺的事情更多。2013，但愿运气好一些。
2013，在衰老中成熟，用伪装的坚强去感染生活。
辞旧迎新的时刻，摘抄西班牙诗人加西亚·洛尔卡的诗句，作为我们年复一年的新年许愿的理由：“因为我们想要每天吃的面包，想要桤木的花朵和永久的温存。因为我们要求大地的意志能够实现，将它的果实分给所有人。”</content></entry><entry><title>小城</title><url>https://zhimoe.github.io/post/essay-small-town/</url><categories><category>随想</category></categories><tags><tag>qq 空间</tag></tags><content type="html"> 我不喜欢西安，喜欢一个地方需要时间，而我还找不到理由。我不喜欢因为我仅仅是在这里生活。
我喜欢玉山，因为那里有曾经的我。一个人走在街上，忽然就觉得这一幕好熟悉，分明有一天自己也是这么走着，那天我要去干什么？我已经记不得，甚至有可能是一种幻觉。
一个能让自己产生幻觉的地方，必然是你留下了太多的记忆在那里，留下了太多的不舍和牵挂。
西安没有给我什么，或者说还没有发生什么，她无需给我什么，是我的鲁莽闯入。多情地想起了玉山那个小城。多少年后当我回想起西安会不会也像想起玉山一样&ndash;些许甜蜜些许忧伤些许满足些许遗憾？
玉山最高的地方是塔山，而我竟没有登过顶。如果那天我接过了你递过来剥好的瓜子仁，事情会不会是另一番模样？
“家在故林吴楚间，冰为溪水玉为山”题目问作者是谁。我没有记住老师给的答案。两年后我站在作者的塑像前，一直想起当时没有答上问题时你在朝我偷笑的画面。
“太阳斜了，城里头起了炊烟，水上的烟波也带上了红影。西北的高山一带，有一个尖峰，活像倒插的笔尖，大约是怀玉山了罢？"”这是 1933 年的玉山。当年郁达夫说的“实在是威尼斯里的一条通衢”的沿河，如今被改建的像画一般。
很喜欢沿河路，密密的柳条，撒在斑驳的阳光，走在其间，能触摸到心中的悲悲戚戚。就那么静静地看着那些垂钓者，或者站在石桌旁看那群老者下棋，都是那么让人享受。趴在栏杆上，望着那西流而去的冰溪水，微凉的情绪也会随着河面过来的风摆荡。学校南门外的一段，留住了太多一中学子的记忆。多少年轻的誓言梦呀，都和那里的麻辣烫有关。那些热闹的夜晚，现在还会不会有？
“热闹是他们的、、、”
站在阳台上，看着秦岭，想到那句“西北望长安，可怜无数山”，秦岭由东向西走，无论从西北往长安看，还是从长安往西北看，都没有比秦岭更高的山了。不知道怎么解释，这里太阳自然也下得晚，六点多了还是热情不减，让人觉得秦岭是站错了位置，室友说要是真站在西边，冬天你又该抱怨了。我苦笑，或许是吧！反正我对自己不了解。
望着秦岭，想着玉山的塔山与冰溪河，想到了那句“日暮乡关何处是，烟波江上使人愁”。</content></entry><entry><title>一点回忆</title><url>https://zhimoe.github.io/post/essay-memories-about-mother/</url><categories><category>随想</category></categories><tags><tag>qq 空间</tag></tags><content type="html"> 我想这不是一篇回忆，而是心情。默存说我们年轻时很容易把自己的写作冲动当成一种写作才能。我自知没有如此高雅的才能。但也不想在某一天突然发现自己被时间推着往前走。阿七说长时间的寂寞是所有写作的滥觞。或许我的确是寂寞的吧！一个人走在无人的路上，往事就在街角处看见了……
中考后的第二天，我就说服母亲让我去打工。她在担心之余试图阻止，却用错了方法－－总是挖苦我：一定是没考好吧？想躲出去吧？被激将的我更加坚定要去打工了。说实话考了以后真的没底，感觉很一般，说不出好也说不出坏。而这种情况是最折磨人的，痛苦的像难产。中考后的第三天，我独自一人登上了去丽水的火车。
这是我第一次坐火车。母亲帮我买了车票后就回去了，而我独自等了一个多小时的车。我想母亲的伟大就在于这样放心而又用心地去培养自己的孩子的自立能力吧！虽然有时我也怀疑是否因为哥哥继承了她的所有优秀品质，从小到大让她是如此地放心与骄傲以致于她认为她的孩子都应该是那样的独立自主。
我背着个大书包站在那望着母亲的背影，虽然正午十二点的烈日下那晃动的空气让背影有点模糊，加上在那新建的火车站广场上，看上去背影更加显得小了，但那一刻，望着母亲的背影，我感到很欣慰，是的，是欣慰，或者说是满足。那个曾经病得只剩不到七十斤的人，现在已经能健步如飞了；那个曾经病得没有一根头发的人，现在又有了一头黑发，虽然近看有些许银丝；那张曾经因为进口药和病毒而彻底变形的脸现在又恢复健康了，虽然有一点浮肿…但终究还是健康的。这个伟大的母亲，或许是放不下自己的家人，在被医生宣布无救后又活过来了，那一天，和母亲同病房的有两个手术失败永远地走了…
我永远都忘不了那一天，我在上第三节课时大娘来找我，没有上过一天学的她一直等到放学才敢进班叫我。我跟着她回家，走到小路上，她以那种旁人莫不关心的语气说：“你妈不行了，今天就要回来了。”不知是年少对死亡的无知无惧还是快两年没有见到母亲已经对这个概念没有多少感觉了，听到这句话后我很安静，只是突然觉得天快黑了，应该快点回去。我一路小跑，把大娘甩在后面。该怎样去原谅自己，曾经的无知与幼稚。近两年里我只见过母亲一面，暑假里我理了个光头去外婆家，在那里我看到了母亲，她心疼地问为什么理光头，是不是自己不会洗头？我执拗地没有回答，心里怎么也不愿意承认躺在床上的那个人就是母亲。也是在那一刻，我发现自己以前从没有仔细看过母亲那张漂亮的脸，现在留下的只是模糊的回忆。而当我在写这些字时，我只能回想起一个画面－那时应该还六七岁时，我和母亲去山上打柴，母亲打柴时我就在边上找鹅卵石，有特色的石头。又让她给我做一柄木剑，把所有的树当成敌人去砍。回去时，她挑着一担柴，我跟在她后面，口袋里装满了石头，拿着长木剑，突然脚一滑摔倒了，她马上扔下担跑过来扶我起来，帮我擦汗并蹲下来笑着把我口袋里的石头都装进她的袋子里，也就是在那一刻我看了看母亲的脸，白皙的，铺满了碎碎的汗珠，微笑着责怪我装这么多石头。我把玩了泥巴的手往她脸上一抹撒腿就跑，她也不追，拿下毛巾仔细地把脸擦干净了才起身。最终我还是没记住母亲当年的模样，只是想起那微笑的感觉依旧是那样的温暖。有时访亲时能从亲友们的口中知道母亲年轻时的确是很好看的………
我就就那样站在烈日下望着母亲转过街角，一颗汗珠沿着我的睫毛滑进了眼眶，又立刻溢了出来，顺着脸颊滴在地上，还没来得及溅开就被那厚厚的灰给吸干了，卷成了一个泥珠。
在候车室里我看到许多学生，有些是我的同学，他们也在等车，他们中有的是去家长那里玩，更多的是已经决定了不读书了，出去打工，做生意。看着他们有说有笑，我忽然觉得他们是幸福的，因为他们已经清楚了方向，虽然前途艰辛而漫长，但他们是那样的年轻而乐观，将用自己的双手去开创自己的未来。而我呢，就像一只被捏在空中的鸭子，不知道被扔下去时下面是水还是油。
火车启动的那一刻，我透过玻璃看着陌生的站台，心里第一次有了一点孤独感，那诺大的站台亦是一样吧：目送着一批又一批的人生拓荒者，见证着一场又一场分别时的泪飞，迎来了一群又一群骄傲或落魄的归客…他是知道的那么多，他有那么多的故事可讲，可是没有人肯停下来听一听他的诉说，车站里的人永远是那样的匆忙………
2010 年 7 月</content></entry></search>